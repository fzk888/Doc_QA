《神经网络与深度学习》

> **Neural Networks and Deep Learning**
>
> 邱锡鹏
>
> xpqiu\@fudan.edu.cn
>
> 2019 年 4 月 6 日
>
> 2 2019 年 4 月 6 日

###### 人工智能的流派

> 目前我们对人类智能机理依然知之甚少，还没有一个通用的理论来指导如
> 何构建一个人工智能系统。不同的研究者都有各自的理解，因此在人工智能的
> 研究过程中产生了很多不同的流派。比如一些研究者认为人工智能应该通过研
> 究人类智能的机理来构建一个仿生的模拟系统，而另外一些研究者则认为可以
> 使用其它方法来实现人类的某种智能行为。一个著名的例子是让机器具有飞行
> 能力不需要模拟鸟的飞行方式，而是应该研究空气动力学。
>
> 尽管人工智能的流派非常多，但主流的方法大体上可以归结为以下两种：
>
> 符号主义
> 符号主义（symbolism），又称逻辑主义、心理学派或计算机学派，是通过分析人类智能的功能，然后通过计算机来实现这些功能。符号主义有两个
> 基本假设：（1）信息可以用符号来表示；（2）符号可以通过显式的规则（比如逻辑运算）来操作。人类的认知过程可以看作是符号操作过程。在人工智能的
> 推理期和知识期，符号主义的方法比较盛行，并取得了大量的成果。
>
> 连接主义
> 连接主义（connectionism），又称仿生学派或生理学派，是认知科学领域中的一类信息处理的方法和理论。在认知科学领域，人类的认知过程可以
> 看做是一种信息处理过程。连接主义认为人类的认知过程是由大量简单神经元
> 构成的神经网络中的信息处理过程，而不是符号运算。因此，联结主义模型的
> 主要结构是由大量的简单的信息处理单元组成的互联网络，具有非线性、分布
> 式、并行化、局部性计算以及适应性等特性。
>
> 符号主义方法的一个优点是可解释性，而这也正是连接主义方法的弊端。深
> 度学习的主要模型神经网络就是一种连接主义模型。随着深度学习的发展，越
> 来越多的研究者开始关注如何融合符号主义和连接主义，建立一种高效并且具
> 有可解释性的模型。

#### 神经网络

> 随着神经科学、认知科学的发展，我们逐渐知道人类的智能行为都和大脑活动有关。人类大脑是一个可以产生意识、思想和情感的器官。受到人脑神经系统的启发，早期的神经科学家构造了一种模仿人脑神经系统的数学模型，称为人工神经网络，简称神经网络。在机器学习领域，神经网络是指由很多人工神经元构成的网络结构模型，这些人工神经元之间的连接强度是可学习的参数。

###### 大脑神经网络

> 人类大脑是人体最复杂的器官，由神经元、神经胶质细胞、神经干细胞和
> 血管组成。其中，神经元（Neuron），也叫神经细胞（Nerve Cell），是携带和
>
> 传输信息的细胞，是人脑神经系统中最基本的单元。人脑神经系统是一个非常
> 复杂的组织，包含近860 亿个神经元 \[[Azevedo et al.](\l),
> [2009](\l)\]，每个神经元有上千个突触和其它神经元相连接。这些神经元和它们之间的连接形成巨大的复杂网
> 络，其中神经连接的总长度可达数千公里。我们人造的复杂网络，比如全球的
> 计算机网络，和大脑神经网络相比要"简单"得多。
>
> 早在1904
> 年，生物学家就已经发现了神经元的结构。典型的神经元结构大致可分为细胞体和细胞突起。

-   细胞体（Soma）中的神经细胞膜上有各种受体和离子通道，胞膜的受体
    > 可与相应的化学物质神经递质结合，引起离子通透性及膜内外电位差发生
    > 改变，产生相应的生理活动：兴奋或抑制。

-   细胞突起是由细胞体延伸出来的细长部分，又可分为树突和轴突。

    -   树突（Dendrite）可以接受刺激并将兴奋传入细胞体。每个神经元可以有一或多个树突。

    -   轴突 (Axons) 可以把自身的兴奋状态从胞体传送到另一个神经元或

> 其他组织。每个神经元只有一个轴突。
>
> 神经元可以接受其它神经元的信息，也可以发送信息给其它神经元。神经元之间没有物理连接，中间留有20
> 纳米左右的缝隙。神经元之间靠突触（Synapse）
> 进行互联来传递信息，形成一个神经网络，即神经系统。突触可以理解为神经元之间的链接"接口"，将一个神经元的兴奋状态传到另一个神经元。一个神经元可被视为一种只有两种状态的细胞：兴奋和抑制。神经元的状态取决于从其它的神经细胞收到的输入信号量，及突触的强度（抑制或加强）。当信号量总和超过了某个阈值时，细胞体就会兴奋，产生电脉冲。电脉冲沿着轴突并通过突触传递到其它神经元。图[1.2](\l)给出了一种典型的神经元结构。

![](/root/autodl-tmp/project_knowledge/Doc_QA/Knowledge_based/1828695663060254721/image_output/7.《神经网络与深度学习》/media/image1.png)

> 图 1.2 典型神经元结构^1^
>
> 1
> 图片来源：https://commons.wikimedia.org/wiki/File:Neuron\_Hand-tuned.svg
>
> 我们知道，一个人的智力不完全由遗传决定，大部分来自于生活经验。也就
> 是说人脑神经网络是一个具有学习能力的系统。那么人脑神经网络是如何学习
> 的呢？在人脑神经网络中，每个神经元本身并不重要，重要的是神经元如何组
> 成联接。不同神经元之间的突触有强有弱，其强度是可以通过学习（训练）来不
>
> 断改变的，具有一定的可塑性。不同的连接形成了不同的记忆印痕。1949
> 年，加 Donald Hebb，1904--1985），
>
> 拿大心理学家Donald Hebb 在《行为的组织》（The Organization of
> Behavior） 一书中提出突触可塑性的基本原理，"当神经元 A
> 的一个轴突和神经元B
> 很近，足以对它产生影响，并且持续地、重复地参与了对神经元B
> 的兴奋，那么在这两个神经元或其中之一会发生某种生长过程或新陈代谢变化，以致于神经元A
> 作为能使神经元B
> 兴奋的细胞之一，它的效能加强了。"这个机制称为赫布理论（Hebbian
> Theory）或赫布法则（Hebb's
> Rule）。如果两个神经元总是相关联地受到刺激，它们之间的突触强度增加。这样的学习方法被称为赫布型学习
>
> （Hebbian learning）。Hebb
> 认为人脑有两种记忆：长期记忆和短期记忆。短期记忆持续时间不超过一分钟。如果一个经验重复足够的次数，此经验就可储存
> 在长期记忆中。短期记忆转化为长期记忆的过程就称为凝固作用。人脑中的海
> 马区为大脑结构凝固作用的核心区域。

###### 人工神经网络

> 人工神经网络是一种模拟人脑神经网络而设计的数据模型或计算模型，它
> 从结构、实现机理和功能上模拟人脑神经网络。人工神经网络与生物神经元类
> 似，由多个节点（人工神经元）相互连接而成，可以用来对数据之间的复杂关
> 系进行建模。不同节点之间的连接被赋予了不同的权重，每个权重代表了一个
> 节点对另一个节点的影响大小。每个节点代表一种特定函数，来自其他节点的
> 信息经过其相应的权重综合计算，输入到一个激励函数中并得到一个新的活性
> 值（兴奋或抑制）。从系统观点看，人工神经元网络是由大量神经元通过极其丰
> 富和完善的连接而构成的自适应非线性动态系统。
>
> 虽然我们可以比较容易地构造一个人工神经网络，但是如何让人工神经网
> 络具有学习能力并不是一件容易的事情。早期的神经网络模型并不具备学习能
> 力。首个可学习的人工神经网络是赫布网络，采用一种基于赫布规则的无监督
> 学习方法。感知器是最早的具有机器学习思想的神经网络，但其学习方法无法
> 扩展到多层的神经网络上。直到1980
> 年左右，反向传播算法才有效地解决了多层神经网络的学习问题，并成为最为流行的神经网络学习算法。
>
> 人工神经网络诞生之初并不是用来解决机器学习问题。由于人工神经网络可以看作是一个通用的函数逼近器，一个两层的神经网络可以逼近任意的函数，
> 因此人工神经网络可以看作一个可学习的函数，并应用到机器学习中。理论上，
> 只要有足够的训练数据和神经元数量，人工神经网络就可以学到很多复杂的函
>
> 加拿大神经心理学家，认知心理生理学的开创者。
>
> 感知器参见第[3.4](\l)节。
>
> 本书中描述的人工神经网络主要是一种作为机器学习的
>
> 数。人工神经网络模型的塑造任何函数的能力大小可以称为网络容量（Network
> Capacity），与可以被储存在网络中的信息的复杂度以及数量相关。
>
> 模型。 **1.2.3** 神经网络的发展历史
>
> 神经网络的发展大致经过五个阶段。
>
> Marvin Minsky，1927～ 2016
> 年，人工智能领域最重要的领导者和创新者之一， 麻省理工学院人工智能实验
> 室的创始人之一。因其在人 工智能领域的贡献，1969 年获得图灵奖。
>
> 第一阶段：模型提出 第一个阶段为1943～1969
> 年，是神经网络发展的第一个高潮期。在此期间，科学家们提出了许多神经元模型和学习规则。
>
> 在1943 年，心理学家Warren McCulloch 和数学家Walter Pitts
> 最早描述了一种理想化的人工神经网络，并构建了一种基于简单逻辑运算的计算机制。他
> 们提出的神经网络模型称为*MP* 模型。至此，开启了神经网络研究的序幕。
>
> 阿兰·图灵在1948 年的论文中描述了一种"B
> 型图灵机"。之后，研究人员将基于赫布型学习的思想应用到"B 型图灵机"上。
>
> 1951 年，McCulloch 和Pitts 的学生Marvin Minsky
> 建造了第一台神经网络机SNARC。
>
> [Rosenblatt](\l) \[[1958](\l)\]
> 最早提出可以模拟人类感知能力的神经网络模型，并称之为感知器（Perceptron），并提出了一种接近于人类学习过程（迭代、试错）
> 的学习算法。但感知器因其结构过于简单，不能解决简单的异或（XOR）等线性不可分问题。
>
> 在这一时期，神经网络以其独特的结构和处理信息的方法，在许多实际应
> 用领域（自动控制领域、模式识别等）中取得了显著的成效。
>
> 第二阶段：冰河期 第二阶段为1969 年～1983
> 年，为神经网络发展的第一个低谷期。在此期间，神经网络的研究处于长年停滞及低潮状态。
>
> 1969 年，Marvin Minsky
> 出版《感知机》一书，指出了神经网络的两个关键缺陷：第一个是感知机无法处理异或回路问题；第二个是当时的计算机无法
> 支持处理大型神经网络所需要计算能力。这些论断直接将以感知器为代表的神
> 经网络打入冷宫，导致神经网络的研究进入了十多年的"冰河期"。
>
> 1974 年，哈佛大学的Paul Webos 发明反向传播算法（Backpropagation，
> BP），但当时未受到应有的重视。
>
> 1980 年，[Fukushima](\l)
> \[[1980](\l)\]（福岛邦彦）提出了一种带卷积和子采样操作的多层神经网络：新知机（Neocognitron）。新知机的提出是受到了动物初级视皮层简单细胞和复杂细胞的感受野的启发。但新知机并没有采用反向传播算法，
> 而是采用了无监督学习的方式来训练，因此没有引起足够的重视。
>
> 第三阶段：反向传播算法引起的复兴 第三阶段为1983 年～1995
> 年，为神经网络发展的第二个高潮期。这个时期中，反向传播算法重新激发了人们对神经网
> 络的兴趣。
>
> 1983 年，加州理工学院的物理学家John Hopﬁeld
> 提出了一种用于联想记忆和优化计算的神经网络，称为*Hopﬁeld*
> 网络。Hopﬁeld 网络在旅行商问题上获得当时最好结果，并引起了轰动。
>
> 1984 年，Geoﬀrey Hinton 提出一种随机化版本的Hopﬁeld
> 网络，即玻尔兹曼机。
>
> 真正引起神经网络第二次研究高潮的是反向传播算法。1986 年，David Rumel-
> hart 和James McClelland
> 对于连接主义在计算机模拟神经活动中的应用提供了全面的论述，并重新发明了反向传播算法。Geoﬀrey
> Hinton 等人将引入到多层 感知器\[[Williams and Hinton](\l),
> [1986](\l)\]，人工神经网络才又重新引起人们的注意，
> 并开始成为新的研究热点。随后，[LeCun et al.](\l) \[[1989](\l)\]
> 将反向传播算法引入了卷积神经网络，并在手写体数字识别上取得了很大的成功\[[LeCun
> et al.](\l),
> [1998](\l)\]。反向传播算法是迄今最为成功的神经网络学习算法，不仅用于多层前馈神经网络，
> 还用于其他类型神经网络的训练。
>
> 第四阶段：流行度降低 第四个阶段为1995～2006
> 年，在此期间，支持向量机和其他更简单的方法（例如线性分类器）在机器学习领域的流行度逐渐超过了神
> 经网络。
>
> 虽然神经网络可以很容易地增加层数、神经元数量，而从构建复杂的网络，
> 但其计算复杂性也会指数级增长。当时的计算机性能和数据规模不足以支持训练大规模的神经网络。在20
> 世纪90
> 年代中期，统计学习理论和以支持向量机为代表的机器学习模型开始兴起。相比之下，神经网络的理论基础不清晰、优化困难、可解释性差等缺点更加凸显，神经网络的研究又一次陷入低潮。
>
> 第五阶段：深度学习的崛起 2006 年，[Hinton and Salakhutdinov](\l)
> \[[2006](\l)\]
> 发现多层前馈神经网络可以先通过逐层预训练，再用反向传播算法进行精调的方式进
> 行有效学习。随着深度的人工神经网络在语音识别\[[Hinton et al.](\l),
> [2012](\l)\] 和图像分类\[[Krizhevsky et al.](\l), [2012](\l)\]
> 等任务上的巨大成功，以神经网络为基础的"深度学习"迅速崛起。近年来，随着大规模并行计算以及GPU
> 设备的普及，计算机的计算能力得以大幅提高。此外，可供机器学习的数据规模也越来越大。在计
> 算能力和数据规模的支持下，计算机已经可以训练大规模的人工神经网络。各
> 大科技公司都投入巨资研究深度学习，神经网络迎来第三次高潮。
>
> 参见第[8.3.4.1](\l)节。
>
> 玻尔兹曼机参见第[12.1](\l)节。
>
> 机器学习的详细介绍参见

####  机器学习

> 机器学习（Machine
> Learning，ML）是指从有限的观测数据中学习（或"猜测"）出具有一般性的规律，并将这些规律应用到未观测样本上的方法。
>
> 第[2](\l)章。
> 传统的机器学习主要关注于如何学习一个预测模型。一般需要首先将数据
> 表示为一组特征（Feature），特征的表示形式可以是连续的数值、离散的符号
> 或其它形式。然后将这些特征输入到预测模型，并输出预测结果。这类机器学
> 习可以看作是浅层学习（Shallow
> Learning）。浅层学习的一个重要特点是不涉及特征学习，其特征主要靠人工经验或特征转换方法来抽取。
>
> 当我们用机器学习来解决实际任务时，会面对多种多样的数据形式，比如
> 声音、图像、文本等。像图像这类数据很自然地可以表示为一个连续的向量。而
>
> 比如图像直接将像素的颜色
>
> 值（灰度值或RGB 值）组成一个连续向量。
>
> 文本数据一般由离散符号组成。特别是计算机内部，每个符号都是表示为无意
> 义的编码，很难找到合适的表示方式。因此，在实际任务中使用机器学习模型
> 一般会包含以下几个步骤（如图[1.3](\l)所示）：
>
> 原始数据 结果
>
> 特征处理 浅层学习
>
> 图 1.3 传统机器学习的数据处理流程
>
> 很多特征转换方法也都是机器学习方法。

-   数据预处理：经过数据的预处理，如去除噪声等。比如在文本分类中，去
    > 除停用词等。

-   特征提取：从原始数据中提取一些有效的特征。比如在图像分类中，提取
    > 边缘、尺度不变特征变换（Scale Invariant Feature
    > Transform，SIFT）特征等。

-   特征转换：对特征进行一定的加工，比如降维和升维。降维包括特征抽取

> （Feature Extraction）和特征选择（Feature
> Selection）两种途径。常用的特征转换方法有主成分分析（Principal
> components analysis，PCA）、线性判别分析（Linear Discriminant
> Analysis）等。

-   预测：机器学习的核心部分，学习一个函数进行预测。

> 上述流程中，每步特征处理以及预测一般都是分开进行处理的。传统的机
> 器学习模型主要关注于最后一步，即构建预测函数。但是实际操作过程中，不
> 同预测模型的性能相差不多，而前三步中的特征处理对最终系统的准确性有着
> 十分关键的作用。由于特征处理一般都需要人工干预完成，利用人类的经验来
> 选取好的特征，并最终提高机器学习系统的性能。因此，很多的模式识别问题
> 变成了特征工程（Feature
> Engineering）问题。开发一个机器学习系统的主要工作量都消耗在了预处理、特征提取以及特征转换上。
>
> 1.4 表示学习 2019 年 4 月 6 日 15

#### 表示学习

> 为了提高机器学习系统的准确率，我们就需要将输入信息转换为有效的特
> 征，或者更一般性称为表示（representation）。如果有一种算法可以自动地学
> 习出有效的特征，并提高最终机器学习模型的性能，那么这种学习就是可以叫
> 做表示学习（Representation Learning）。
>
> 语义鸿沟 表示学习的关键是解决语义鸿沟（Semantic
> Gap）问题。语义鸿沟问题是指输入数据的底层特征和高层语义信息之间的不一致性和差异性。比如给定一些关于"车"的图片，由于图片中每辆车的颜色和形状等属性都不尽相同，
> 不同图片在像素级别上的表示（即底层特征）差异性也会非常大。但是我们人理解这些图片是建立在比较抽象的高层语义概念上的。如果一个预测模型直接建立在底层特征之上，会导致对预测模型的能力要求过高。如果可以有一个好的表示在某种程度上可以反映出数据的高层语义特征，那么我们就可以相对容易地构建后续的机器学习模型。
>
> 在表示学习中，有两个核心问题：一是"什么是一个好的表示？"；二是"如何学习到好的表示？"

###### 局部表示和分布式表示

> "好的表示"是一个非常主观的概念，没有一个明确的标准。但一般而言，
> 一个好的表示具有以下几个优点：

-   一个好的表示应该具有很强的表示能力，即同样大小的向量可以表示更多
    > 信息。

-   一个好的表示应该使后续的学习任务变得简单，即需要包含更高层的语义
    > 信息。

-   一个好的表示应该具有一般性，是任务或领域独立的。虽然目前的大部分
    > 表示学习方法还是基于某个任务来学习，但我们期望其学到的表示可以比
    > 较容易的迁移到其它任务上。

> 在传统机器学习中，我们经常使用两种方式来表示特征：局部表示（Local
> Representation）和分布式表示（Distributed Representation）。
>
> 以颜色表示为例，我们一般有两种表示方法。
>
> 以颜色表示为例，我们有很多词来形容颜色的词[^1^](\l)，除了基本的"红"、"蓝"、"绿"、"白"、"黑"等之外，有很多以地区或物品命名的，比如"中国红"、"天蓝色"、"咖啡色"、"琥
>
> 珀色"等等。
>
> 1 据不完全统计，现有的颜色命名已经有 1300
> 多种。https://en.wikipedia.org/wiki/Lists\_of\_ colors
>
> one-hot 向量参见第[A.1.4](\l)节。
>
> 分布式表示叫做分散式表示可能更容易理解。即一种颜色的语义分散到语义空间中的不同基向量上。
>
> 一种表示颜色的方式是以不同名字来命名不同的颜色，这种表示方式叫做
> 局部表示，也称为离散表示或符号表示。局部表示通常可以表示为one-hot
> 向量的形式。假设所有颜色的名字构成一个词表V，词表大小为\|V\|。我们可以用一
> 个\|V\| 维的one-hot 向量来表示每一种颜色。第*i* 种颜色的one-hot
> 向量中，第*i* 维的值为1，其它都为0。
>
> 局部表示有两个不足之处：（1）one-hot
> 向量的维数很高，且不能扩展。如果有一种新的颜色，我们就需要增加一维来表示；（2）不同颜色之间的相似度都为0，即我们无法知道"红色"和"中国红"的相似度要比"红色"和"黑色"
> 的相似度要高。
>
> 另一种表示颜色的方式是用RGB 值来表示颜色，不同颜色对应到R、G、B
> 三维空间中一个点，这种表示方式叫做分布式表示。分布式表示通常可以表示
> 为低维的稠密向量。
>
> 相比与局部表示，分布式表示的表示能力要比局部表示强很多，分布式表
> 示的向量维度一般都比较低。我们只需要用一个三维的稠密向量就可以表示所
> 有颜色。并且分布式表示也很容易表示新的颜色名。此外，不同颜色之间的相
> 似度也很容易计算。
>
> 表[1.1](\l)列出了4 种颜色的局部表示和分布式表示。

+----------+---------------------------+-------------------------------------+
| > 颜色   | > 局部表示                | > 分布式表示                        |
+----------+---------------------------+-------------------------------------+
| > 琥珀色 | > \[1*,* 0*,* 0*,* 0\]^T^ | > \[1*.*00*,* 0*.*75*,* 0*.*00\]^T^ |
+----------+---------------------------+-------------------------------------+
| > 天蓝色 | > \[0*,* 1*,* 0*,* 0\]^T^ | > \[0*.*00*,* 0*.*5*,* 1*.*00\]^T^  |
+----------+---------------------------+-------------------------------------+
| > 中国红 | > \[0*,* 0*,* 1*,* 0\]^T^ | > \[0*.*67*,* 0*.*22*,* 0*.*12\]^T^ |
+----------+---------------------------+-------------------------------------+
| > 咖啡色 | > \[0*,* 0*,* 0*,* 1\]^T^ | > \[0*.*44*,* 0*.*31 0*.*22\]^T^    |
+----------+---------------------------+-------------------------------------+

> 表 1.1 局部表示和分布式表示示例
>
> 我们可以使用神经网络来将高维的局部表示空间R\|V\|
> 映射到一个非常低维的分布式表示空间R*d, d* ≪
> \|V\|。在这个低维空间中，每个特征不在是坐标轴上的点，而是分散在整个低维空间中。在机器学习中，这个过程也称为嵌入
>
> （embedding）。嵌入通常指将一个度量空间中的一些对象映射到另一个低维的
> 度量空间中，并尽可能保持不同对象之间的拓扑关系。比如自然语言中词的分
> 布式表示，也经常叫做词嵌入。
>
> 图[1.4](\l)展示了一个3 维one-hot 向量空间和一个2
> 维嵌入空间的对比。在one- hot
> 向量空间中，每个特征都位于坐标轴上，每个坐标轴上一个特征。而在低维的嵌入空间中，每个特征都不在坐标轴上，特征之间可以计算相似度。
>
> 图 1.4 One-hot 向量空间与嵌入空间

###### 表示学习

> 要学习到一种好的高层语义表示（一般为分布式表示），通常需要从底层特
> 征开始，经过多步非线性转换才能得到。一个深层结构的优点是可以增加特征
> 的重用性，从而指数级地增加表示能力。因此，表示学习的关键是构建具有一
> 定深度的多层次特征表示\[[Bengio et al.](\l), [2013](\l)\]。
>
> 在传统的机器学习中，也有很多有关特征学习的方法，比如主成分分析、线
> 性判别分析、独立成分分析等。但是传统的特征学习一般是通过人为地设计一
> 些准则，然后根据这些准则来选取有效的特征。特征的学习是和最终预测模型
> 的学习分开进行的，因此学习到的特征不一定可以提升最终模型的性能。

#### 深度学习

> 为了学习一种好的表示，需要构建具有一定"深度"的模型，并通过学习
> 算法来让模型来自动学习出好的特征表示（从底层特征，到中层特征，再到高
> 层特征），从而最终提升预测模型的准确率。所谓"深度"是指原始数据进行非
> 线性特征转换的次数。如果把一个表示学习系统看作是一个有向图结构，深度
> 也可以看作是从输入节点到输出节点所经过的最长路径的长度。
>
> 这样我们就需要一种学习方法可以从数据中学习一个"深度模型"，这就是
> 深度学习（Deep
> Learning，DL）。深度学习是机器学习的一个子问题，其主要目的是从数据中自动学习到有效的特征表示。
>
> 连续多次的线性转换等价于一次线性转换。
>
> 参见第[2.6.1](\l)节。
>
> 深度学习虽然早期主要用来进行表示学习，但越来越多地用来进行处理更加复杂的推理、决策等问题。
>
> 图[1.5](\l)给出了深度学习的数据处理流程。通过多层的特征转换，把原始数据变成为更高层次、更抽象的表示。这些学习到的表示可以替代人工设计的特征，
> 从而避免"特征工程"。
>
> 原始数据 结果
>
> 表示学习
>
> 深度学习
>
> 图 1.5 深度学习的数据处理流程
>
> 强化学习参见第[14](\l)章。
>
> 深度学习是将原始的数据特征通过多步的特征转换得到一种特征表示，并进一步输入到预测函数得到最终结果。和"浅层学习"不同，深度学习需要解决的关键问题是贡献度分配问题（Credit
> Assignment Problem，CAP）\[[Minsky](\l),
> [1963](\l)\]，即一个系统中不同的组件（Components）或其参数对最终系统输出结果的贡献或影响。以下围棋为例，每当下完一盘棋，最后的结果要么赢要么输。我们会思考哪几步棋导致了最后的胜利，而又是哪几步棋导致了最后的败局。如何判断每一步棋的贡献就是贡献度分配问题，这也是一个非常困难的问题。从某种意义上讲，深度学习也可以看作是一种强化学习（Reinforcement
> Learning，
> RL），每个内部组件并不能直接得到监督信息，需要通过整个模型的最终监督信息（奖励）得到，并且有一定的延时性。
>
> 目前，深度学习采用的模型主要是神经网络模型，其主要原因是神经网络模型可以使用误差反向传播算法，从而可以比较好地解决贡献度分配问题。只要是超过一层神经网络都会存在贡献度分配问题，因此超过一层的神经网络都可以看作是深度学习模型。随着深度学习的快速发展，模型深度也从早期的5
> ∼ 10
> 层到目前的数百层。随着模型深度的不断增加，其特征表示的能力也越来越强，
> 从而使后续的预测更加容易。

###### 端到端学习

> 在一些复杂任务中，传统机器学习方法需要将一个任务的输入和输出之间
> 人为地切割成很多子模块（或多个阶段），每个子模块分开学习。比如一个自然
> 语言理解任务，一般需要分词、词性标注、句法分析、语义分析、语义推理等
> 步骤。这种学习方式有两个问题：一是每一个模块都需要单独优化，并且其优
> 化目标和任务总体目标并不能保证一致。二是错误传播，即前一步的错误会对
> 后续的模型造成很大的影响。这样就增加了机器学习方法在实际应用的难度。
>
> 端到端学习（End-to-End
> Learning），也称端到端训练，是指在学习过程中不进行分模块或分阶段进行训练，直接优化任务的总体目标。在端到端学习中，一般不需要明确地给出不同模块或阶段的功能，中间过程不需要人为干预。
>
> 端到端学习的训练数据为"输入-输出"对的形式，无需提供其它额外信息。因
> 此，端到端学习和深度学习一样，都是要解决"贡献度分配"问题。目前，大
> 部分采用神经网络模型的深度学习也可以看作是一种端到端的学习。

###### 常用的深度学习框架

> 在深度学习中，一般通过误差反向传播算法来进行参数学习。采用手工方式来计算梯度再写代码实现的方式会非常低效，并且容易出错。此外，深度学习模型需要的计算机资源比较多，一般需要在CPU
> 和GPU 之间不断进行切换，
> 开发难度也比较大。因此，一些支持自动梯度计算、无缝CPU 和GPU
> 切换等功能的深度学习框架就应运而生。比较有代表性的框架包括：Theano、Caﬀe、TensorFlow、Pytorch、Keras
> 等。
>
> Theano[1](\l)：蒙特利尔大学的Python 工具包，用来高效地定义、优化和执行
> Theano

项目目前已停止维

> 多维数组数据对应数学表达式。Theano 可以透明的使用 GPUs 和高效的符号
> 护。
>
> 微分。
>
> Caﬀe[2](\l)：全称为Convolutional Architecture for Fast Feature
> Embedding，
> 是一个卷积网络模型的计算框架，所要实现的网络结构可以在配置文件中指定，
> 不需要编码。Caﬀe 是用C++ 和Python 实现，主要用于计算机视觉。
>
> TensorFlow[3](\l)：Google 公司开发的Python 工具包，可以在任意具备CPU
> 或者GPU 的设备上运行。TensorFlow 的计算过程使用数据流图来表示。Tensor-
> Flow 的名字来源于其计算过程中的操作对象为多维数组，即张量（tensor）。
>
> Chainer[4](\l)：一个最早采用动态计算图的神经网络框架，其核心开发团队为来自日本的一家机器学习创业公司Preferred
> Networks。和 Tensorﬂow、Theano、Caﬀe
> 等框架使用的静态计算图相比，动态计算图可以在运行时动态地构建计算图，因此非常很适合进行一些复杂的决策或推理任务。
>
> PyTorch[5](\l)：由Facebook、NVIDIA、Twitter
> 等公司开发维护的深度学习框架，其前身为Lua 语言的Torch[6](\l)。PyTorch
> 也是基于动态计算图的框架，在需要动态改变神经网络结构的任务中有着明显的优势。
>
> 此外，还有一些深度学习框架，包括微软的CNTK[7](\l)，由亚马逊、华盛顿大
>
> 1 http://www.deeplearning.net/software/theano
>
> 2 http://caﬀe.berkeleyvision.org
>
> 3 https://www.tensorﬂow.org
>
> 4 https://chainer.org
>
> 5 http://pytorch.org
>
> 6 http://torch.ch
>
> 7 全称为Microsoft Cognitive Toolkit。https://github.com/Microsoft/CNTK
>
> 学和卡内基梅隆大学等开发维护的MXNet[1](\l)和百度开发的PaddlePaddle[2](\l)等。在这些基础框架之上，还有一些建立在这些框架之上的高度模块化的神经
>
> 网络库，使得构建一个神经网络模型就像搭积木一样容易。其中比较有名的模
> 块化神经网络框架有：（1）基于TensorFlow 和Theano
> 的Keras[3](\l)和（2）基于Theano 的Lasagne[4](\l)。
>
> 更多的深度学习框架可以参考https://en.wikipedia.org/wiki/Comparison\_
> of\_deep\_learning\_software。

#### 本书的组织结构

> 本书主要对神经网络和深度学习所涉及的知识提出一个较全面的基础性介
> 绍。本书的组织结构如图[1.6](\l)所示，可以分为三大块：机器学习、神经网络和概
> 率图模型。

![](/root/autodl-tmp/project_knowledge/Doc_QA/Knowledge_based/1828695663060254721/image_output/7.《神经网络与深度学习》/media/image2.png)

> 图 1.6 本书的组织结构
>
> 机器学习
> 机器学习可以分为监督学习、无监督学习和强化学习。第[2](\l)章对机器学习进行概述，使读者能够了解机器学习的基本概念，并以线性回归为例来讲
> 述不同学习算法之间的关联。第[3](\l)章主要介绍一些基本的线性模型。这两章都以
> 监督学习为主进行介绍。第[9](\l)章介绍了一些无监督学习方法。第[10](\l)章中介绍一些
>
> 1 https://mxnet.apache.org
>
> 2 全称为Parallel Distributed Deep Learning。http://paddlepaddle.org/
>
> 3 http://keras.io/
>
> 4 https://github.com/Lasagne/Lasagne

6.  总结和深入阅读 2019 年 4 月 6 日 21

> 和模型无关的机器学习方法。第[14](\l)章介绍了深度强化学习的知识。
>
> 神经网络
> 第[4](\l)章到第[6](\l)章分别讲述三种主要的神经网络模型：前馈神经网络、卷积神经网络和循环神经网络。并在第[6](\l)章中介绍一种更一般性的网络：图网络。
> 第[7](\l)章介绍神经网络的优化与正则化方法。第[8](\l)章介绍神经网络中的注意力机制和外部记忆。
>
> 概率图模型
> 概率图模型为机器学习提供了一个更加便捷的描述框架。目前深度学习和概率图模型的融合已经十分流行。第[11](\l)章介绍了概率图模型的基本概念，并在第[12](\l)章介绍两种概率图模型：玻尔兹曼机和深度信念网络。第[13](\l)章和
> 第[15](\l)章分布介绍两种概率生成模型：深度生成模型和序列生成模型。
>
> 由于深度学习涉及到非常多的研究领域，因此很多知识无法进行追根溯源并深入介绍。每章最后一节都提供了一些参考文献，读者度需要通过深入阅读来了解这些知识。此外，本书的附录中介绍了一些深度学习涉及到的数学知识，
> 包括线性代数、微积分、概率论、信息论和优化等。
>
> **1.7** 总结和深入阅读
>
> 要理解深度学习的意义或重要性，就得从机器学习或者是人工智能的更广
> 的视角来分析。在传统机器学习中，除了模型和学习算法外，特征或表示也是
> 影响最终学习效果的重要因素，甚至在很多的任务上比算法更重要。因此，要
> 开发一个实际的机器学习系统，人们往往需要花费大量的精力去尝试设计不同
> 的特征以及特征组合，来提高最终的系统能力，这就是所谓的特征工程问题。
>
> 如何自动学习有效的数据表示是成为机器学习中的关键问题。早期的表示学习方法，比如特征抽取和特征选择，都是人工引入一些主观假设来进行学习的。这种表示学习不是端到端的学习方式，得到的表示不一定对后续的机器学习任务有效。而深度学习是将表示学习和预测模型的学习进行端到端的学习，中间不需要人工干预。深度学习所要解决的问题是贡献度分配问题，而神经网络恰好是解决这个问题的有效模型。套用马克思的一句名言"金银天然不是货币，
> 但货币天然是金银"，我们可以说，深度学习天然不是神经网络，但神经网络天然是深度学习。
>
> 目前，深度学习主要以神经网络模型为基础，研究如何设计模型结构，如
> 何有效地学习模型的参数，如何优化模型性能以及在不同任务上的应用等。
>
> [Bengio et al.](\l) \[[2013](\l)\]
> 给出了一个很好的表示学习综述。若希望全面了解人工神经网络和深度学习的知识，可以参考《Deep
> Learning》\[[Goodfellow et al.](\l), [2015](\l)\] 以及文献
> \[[Bengio](\l),
> [2009](\l)\]。关于神经网络的历史可以参考文献\[[Anderson](\l)
>
> 22 2019 年 4 月 6 日 参考文献
>
> and Rosenfeld, [2000](\l)\]。斯坦福大学的CS231n[1](\l)
> 和CS224n[2](\l)是两门非常好的深度学习入门课程，分别从计算机视觉和自然语言处理两个角度来讲授了深度学习
> 的基础知识和最新进展。
>
> 深度学习的研究进展非常迅速。因此，最新的文献一般会发表在学术会议
> 上。和深度学习相关的学术会议主要有：

-   国际表示学习会议[^3^](\l)（International Conference on Learning
    > Representa- tions，ICLR）：主要聚焦于深度学习。

-   神经信息处理系统年会[^4^](\l)（Annual Conference on Neural
    > Information Pro- cessing
    > Systems，NeurIPS）：交叉学科会议，但偏重于机器学习。主要包括神经信息处理，统计方法，学习理论以及应用等。

-   国际机器学习会议[^5^（](\l)International Conference on Machine
    > Learning，ICML）：机器学习顶级会议，深度学习作为近年来的热点，也占据了ICML
    > 的很大

> 比例。

-   国际人工智能联合会议[^6^](\l)（International Joint Conference on
    > Artiﬁcial In-
    > telligence，IJCAI）：人工智能领域最顶尖的综合性会议。历史悠久，从1969
    > 年开始举办。

-   美国人工智能协会年会[^7^（](\l)AAAI Conference on Artiﬁcial
    > Intelligence，AAAI）：人工智能领域的顶级会议，每年二月份左右召开,
    > 地点一般在北美。

> 另外，人工智能的很多子领域也都有非常好的专业学术会议。在计算机视觉领域，有计算机视觉与模式识别大会（IEEE
> Conference on Computer Vision and Pattern
> Recognition，CVPR）和国际计算机视觉会议（International Com- ference on
> Computer Vision，ICCV）。在自然语言处理领域，有计算语言学年会（Annual
> Meeting of the Association for Computational Linguistics，ACL）
> 和自然语言处理实证方法大会（Conference on Empirical Methods in Natural
> Language Processing，EMNLP）等。

#### 参考文献

> 1 http://cs231n.stanford.edu
>
> 2 http://web.stanford.edu/class/cs224n/
>
> 3 http://www.iclr.cc
>
> 4 https://nips.cc
>
> 5 https://icml.cc
>
> 6 https://www.ijcai.org
>
> 7 http://www.aaai.org
>
> 周志华. 机器学习. 清华大学出版社, 北京, 2016. ISBN 978-7-302-206853-6.
>
> 参考文献 2019 年 4 月 6 日 23
>
> James A Anderson and Edward Rosenfeld. *Talking nets: An oral history
> of neural net-* *works*. MiT Press, 2000.
>
> Frederico AC Azevedo, Ludmila RB Car- valho, Lea T Grinberg, José
> Marcelo Far- fel, Renata EL Ferretti, Renata EP Leite, Roberto Lent,
> Suzana Herculano-Houzel, et al. Equal numbers of neuronal and non-
> neuronal cells make the human brain an iso- metrically scaled-up
> primate brain. *Journal of Comparative Neurology*, 513(5):532--541,
> 2009.
>
> Yoshua Bengio. Learning deep architectures
>
> The shared views of four research groups. *IEEE Signal Processing
> Magazine*, 29(6): 82--97, 2012.
>
> Geoﬀrey E Hinton and Ruslan R Salakhut- dinov. Reducing the
> dimensionality of data with neural networks. *Science*, 313(5786):
> 504--507, 2006.
>
> Alex Krizhevsky, Ilya Sutskever, and Ge- oﬀrey E Hinton. Imagenet
> classiﬁcation with deep convolutional neural networks. In *Advances in
> neural information processing* *systems*, pages 1097--1105, 2012.
>
> Yann LeCun, Bernhard Boser, John S
>
> for AI. *Foundations and trends*⃝R *chine Learning*, 2(1):1--127,
> 2009.
>
> *in Ma-*
>
> Denker, Donnie Henderson, Richard E Howard, Wayne Hubbard, and
> Lawrence D
>
> Yoshua Bengio, Aaron Courville, and Pas-
>
> cal Vincent. Representation learning: A re- view and new perspectives.
> *IEEE transac- tions on pattern analysis and machine in-*
> *telligence*, 35(8):1798--1828, 2013.
>
> Kunihiko Fukushima. Neocognitron: A
>
> self-organizing neural network model for a mechanism of pattern
> recognition unaf- fected by shift in position. *Biological cyber-*
> *netics*, 36(4):193--202, 1980.
>
> Ian Goodfellow, Aaron Courville, and
>
> Yoshua Bengio. Deep learning. Book in preparation for MIT Press, 2015.
> URL http://goodfeli.github.io/dlbook/.
>
> Geoﬀrey Hinton, Li Deng, Dong Yu, George E Dahl, Abdel-rahman Mohamed,
> Navdeep Jaitly, Andrew Senior, Vin- cent Vanhoucke, Patrick Nguyen,
> Tara N Sainath, et al. Deep neural networks for acoustic modeling in
> speech recognition:
>
> Jackel. Backpropagation applied to hand- written zip code recognition.
> *Neural com-* *putation*, 1(4):541--551, 1989.
>
> Yann LeCun, Léon Bottou, Yoshua Ben- gio, and Patrick Haﬀner.
> Gradient-based learning applied to document recognition. *Proceedings
> of the IEEE*, 86(11):2278--2324, 1998.
>
> Marvin Minsky. Steps toward artiﬁcial in- telligence. *Computers and
> thought*, 406:450, 1963.
>
> Frank Rosenblatt. The perceptron: a prob- abilistic model for
> information storage and organization in the brain. *Psychological re-*
> *view*, 65(6):386, 1958.
>
> DE Rumelhart GE Hinton RJ Williams and GE Hinton. Learning
> representations by back-propagating errors. *Nature*, pages 323--533,
> 1986.

第**2** 章 机器学习概述
=======================

> 机器学习是对能通过经验自动改进的计算机算法的研究。
>
> --- [Mitchell](\l) \[[1997](\l)\]
>
> 通俗地讲，机器学习（Machine
> Learning，ML）就是让计算机从数据中进行自动学习，得到某种知识（或规律）。作为一门学科，机器学习通常指一类问
> 题以及解决这类问题的方法，即如何从观测数据（样本）中寻找规律，并利用
> 学习到的规律（模型）对未知或无法观测的数据进行预测。
>
> 机器学习问题在早期的工程领域也经常称为模式识别（Pattern Recogni-
> tion，PR），但模式识别更偏向于具体的应用任务，比如光学字符识别、语音识别，人脸识别等。这些任务的特点是对于我们人类而言，这些任务很容易完
> 成，但我们不知道自己是如何做到的，因此也很难人工设计一个计算机程序来
> 解决这些任务。一个可行的方法是设计一个算法可以让计算机自己从有标注的
> 样本上学习其中的规律，并用来完成各种识别任务。随着机器学习技术的应用
> 越来越广，现在机器学习的概念逐渐替代模式识别，成为这一类问题及其解决
> 方法的统称。
>
图片识别内容

> 图[2.1](\l)中的例子，将 识别为数字5，将
图片识别内容

> 总结每个数字的手写体特征，或者区分不同数字的规则，因此设计一套识别算
> 法几乎是一项几乎不可能的任务。在现实生活中，很多问题都类似于手写体数
> 字识别这类问题，比如物体识别、语音识别等。对于这类问题，我们不知道如
> 何设计一个计算机程序来解决，即使可以通过一些启发式规则来实现，其过程
> 也是极其复杂的。因此，人们开始尝试采用另一种思路，即让计算机"看"大量的样本，并从中学习到一些经验，然后用这些经验来识别新的样本。要识别手
> 写体数字，首先通过人工标注大量的手写体数字图像（即每张图像都通过人工
> 标记了它是什么数字），这些图像作为训练数据，然后通过学习算法自动生成一
>
> 套模型，并依靠它来识别新的手写体数字。这和人类学习过程也比较类似，我
> 们教小孩子识别数字也是这样的过程。这种通过数据来学习的方法就称为机器
> 学习的方法。

图片识别内容


> 图 2.1 手写体数字识别示例（图片来源\[[LeCun et al.](\l),
> [1998](\l)\]）
>
> 本章先介绍机器学习的基本概念和要素，并较详细地描述一个简单的机器
> 学习例子，线性回归。

#### 基本概念

> 特 征 也 可 以 称 为 属 性
>
> 首先介绍下机器学习中的一些基本概念：包括样本、特征、标签、模型、学习算法等。以一个生活中的经验学习为例，假设我们要到市场上购买芒果，但
> 是之前毫无挑选芒果的经验，那么我们如何通过学习来获取这些知识？
>
> 首先，我们从市场上随机选取一些芒果，列出每个芒果的特征（feature） ，
>
> （attribute）。
> 包括颜色，大小，形状，产地，品牌，以及我们需要预测的标签（label）。标
> 签可以连续值（比如关于芒果的甜度、水分以及成熟度的综合打分），也可以是
> 离散值（比如"好""坏"两类标签）。
>
> 一个标记好特征以及标签的芒果可以看作是一个样本（sample）。一组样本
>
> 样本（sample），也叫示例
>
> （instance）。 构成的集合称为数据集（data
> set）。一般将数据集分为两部分：训练集和测试
>
> 集。训练集（training
> set）中的样本是用来训练模型的，也叫训练样本（training
> sample），而测试集（test set）中的样本是用来检验模型好坏的，也叫测试样
>
> 在很多领域，数据集也经常
>
> 本（test sample）。
>
> 称为语料库（corpus）。 我们用一个*d* 维向量**x** = \[*x*~1~*, x*~2~*,*
> · · · *, x~d~*\]T 表示一个芒果的所有特征构成的
>
> 向量，称为特征向量（feature vector），其中每一维表示一个特征。
>
> 并不是所有的样本特征都是
>
> 数值型，需要通过转换表示为特征向量，参见第[2.6](\l)节。
>
> 假设训练集由*N* 个样本组成，其中每个样本都是独立同分布（Identically
> and Independently Distributed，IID）的，即独立地从相同的数据分布中抽取
>
> 2.1 基本概念 2019 年 4 月 6 日 27

的，记为

> D = {(**x** *, y* )*,* (**x** *, y* )*,* · · · *,* (**x** *, y* )}*.*
> (2.1)
>
> 给定训练集D，我们希望让计算机自动寻找一个函数*f* (**x***, θ*)
> 来建立每个样本特性向量**x** 和标签*y*
> 之间的映射。对于一个样本**x**，我们可以通过决策函数来预测其标签的值
>
> *y*ˆ = *f* (**x***, θ*)*,* (2.2)
>
> 或标签的条件概率
>
> 其中*θ* 为可学习的参数。
>
> *p*(*y*\|**x**) = *f~y~*(**x***, θ*)*,* (2.3)
>
> 通过一个学习算法（learning
> algorithm）A，在训练集上找到一组参数*θ*^∗^， 使得函数*f* (**x***,
> θ*^∗^)
> 可以近似真实的映射关系。这个过程称为学习（learning）或训练（training）过程，函数*f*
> (**x***, θ*) 称为模型（model）。
>
> 下次从市场上买芒果（测试样本）时，可以根据芒果的特征，使用学习到
> 的模型*f* (**x***, θ*^∗^)
> 来预测芒果的好坏。为了评价的公正性，我们还是独立同分布地抽取一组样本作为测试集D′，并在测试集中所有样本上进行测试，计算预测结果的准确率。
>
> 在有些文献中，学习算法也叫做学习器（learner）。
>
> *Acc*(*f* (**x***, θ*^∗^)) = [ 1]{.underline} Σ *I f* (**x***, θ*^∗^)
> = *y ,* (2.4)
>
> \|D′\| (**x***,y*)∈D′
>
> 其中*I*(·) 为指示函数，\|D′\| 为测试集大小。
> 第[2.7](\l)节中会介绍更多的评价
>
> 图[2.2](\l)给出了机器学习的基本概念。对一个预测任务，输入特征向量为**x**，输
> 出标签为*y*，我们选择一个函数*f* (**x***, θ*)，通过学习算法A
> 和一组训练样本D，找到一组最优的参数*θ*^∗^，得到最终的模型*f* (**x***,
> θ*^∗^)。这样就可以对新的输入**x** 进行预测。
>
> 方法。
>
> **x** *f* (**x***, θ*^∗^)
>
> 输入 模型
>
> *y* 或 *p*(*y* **x**)
>
> 输出
>
> (*i*) (*i*) *N i*=1

训练样本集合

> A
>
> 学习算法
>
> 图 2.2 机器学习系统示例

#### 机器学习的三个基本要素

> 这里，[输入空间]{.underline}默认为样本
>
> 机器学习是从有限的观测数据中学习（或"猜测"）出具有一般性的规律，
> 并可以将总结出来的规律推广应用到未观测样本上。机器学习方法可以粗略地分为三个基本要素：模型、学习准则、优化算法。

###### 模型

> 一个机器学习任务要先需要确定其输入空间X
> 和输出空间Y。不同机器学习任务的主要区别在于输出空间不同。在两类分类问题中Y
> = {+1*,* −1}，在*C* 类分类问题中Y = {1*,* 2*,* · · · *,
> C*}，而在回归问题中Y = R。
>
> 的特征空间。 输入空间X 和输出空间Y
> 构成了一个样本空间。对于样本空间中的样本
>
> (**x***, y*) ∈ X × Y，假定存在一个未知的真实映射函数*g* : X → Y 使得
>
> *y* = *g*(**x**)*,* (2.5)
>
> 或者真实条件概率分布
>
> *p~r~*(*y*\|**x**)*,* (2.6)
>
> 机器学习的目标是找到一个模型来近似真实映射函数*g*(**x**)
> 或真实条件概率分布*p~r~*(*y*\|**x**)。
>
> 由于我们不知道真实的映射函数*g*(**x**)
> 或条件概率分布*p~r~*(*y*\|**x**) 的具体形式，
> 只能根据经验来确定一个假设函数集合F，称为假设空间（hypothesis
> space）， 然后通过观测其在训练集D
> 上的特性，从中选择一个理想的假设（hypothesis） *f* ^∗\ ∈\ F。^
>
> 假设空间F 通常为一个参数化的函数族
>
> F = {*f* (**x***, θ*)\|*θ* ∈ R*^m^*}*,* (2.7)
>
> 其中*f* (**x***, θ*) 为假设空间中的模型，*θ* 为一组可学习参数，*m*
> 为参数的数量。 常见的假设空间可以分为线性和非线性两种，对应的模型*f*
> 也分别称为线
>
> 性模型和非线性模型。

1.  线性模型

> 对于分类问题，一般为广义
>
> 线性模型的假设空间为一个参数化的线性函数族，
>
> 线性函数，参见公式([3.3](\l))。 *f* (**x***, θ*) = **w**T**x** + *b,*
> (2.8)
>
> 其中参数*θ* 包含了权重向量**w** 和偏置*b*。

2.  非线性模型

> 广义的非线性模型可以写为多个非线性基函数*ϕ*(**x**) 的线性组合
>
> *f* (**x***, θ*) = **w**T***ϕ***(**x**) + *b,* (2.9)
>
> 其中***ϕ***(**x**) = \[*ϕ*~1~(**x**)*, ϕ*~2~(**x**)*,* · · · *,
> ϕ~K~*(**x**)\]T 为*K* 个非线性基函数组成的向量，参数 *θ*
> 包含了权重向量**w** 和偏置*b*。
>
> 如果***ϕ***(**x**) 本身为可学习的基函数，比如
>
> *ϕ~k~*(**x**) = *h*(**w**T***ϕ***^′^(**x**) + *b~k~*)*,* ∀1 ≤ *k* ≤
> *K,* (2.10)
>
> 其中*h*(·) 为非线性函数，***ϕ***^′^(**x**) 为另一组基函数，**w***~k~*
> 和*b~k~* 为可学习的参数，则 *f* (**x***, θ*) 就等价于神经网络模型。

###### 学习准则

> 令训练集D = {(**x**(*n*)*, y*^(*n*)^)}*N* 是由 *N*
> 个独立同分布（Identically and In-
>
> dependently Distributed，IID）的样本组成，即每个样本(**x***, y*) ∈ X ×
> Y 是从X 和Y 的联合空间中按照某个未知分布 *p~r~*(**x***, y*)
> 独立地随机产生的。这里要求样本分布*p~r~*(**x***, y*)
> 必须是固定的（虽然可以是未知的），不会随时间而变化。如果*p~r~*(**x***,
> y*) 本身可变的话，我们就无法通过这些数据进行学习。
>
> 一个好的模型 *f* (**x***, θ*^∗^) 应该在所有(**x***, y*)
> 的可能取值上都与真实映射函数*y* = *g*(**x**) 一致，即
>
> \|*f* (**x***, θ*^∗^) − *y*\| *\< ϵ,* ∀(**x***, y*) ∈ X × Y*,* (2.11)
>
> 或与真实条件概率分布*p~r~*(*y*\|**x**) 一致，即
> 这里两个分布相似性的定义
>
> \|*f* (**x***, θ*^∗^) − *p* (*y*\|**x**)\| *\< ϵ,* ∀(**x***, y*) ∈ X ×
> Y*,* (2.12)
>
> 不太严谨，更好的方式为[KL]{.underline}
>
> 其中*ϵ* 是一个很小的正数，*f~y~*(**x***, θ*^∗^)
> 为模型预测的条件概率分布中*y* 对应的概率。
>
> 模型*f* (**x***, θ*) 的好坏可以通过期望风险（Expected Risk）𝑌(*θ*)
> 来衡量。 期望风险也称为期望错误
>
> 𝑌(*θ*) = E~(**x***,y*)∼*p*~*r* (**x***,y*)\[L(*y, f* (**x***,
> θ*))\]*,* (2.13)
>
> 其中*p~r~*(**x***, y*) 为真实的数据分布，L(*y, f* (**x***, θ*))
> 为损失函数，用来量化两个变量之间的差异。

3.  损失函数

> 损失函数是一个非负实数函数，用来量化模型预测和真实标签之间的差异。
> 下面介绍几种常用的损失函数。
>
> （Expected Error）。
>
> **0-1** 损失函数 最直观的损失函数是模型预测的错误率，即 *0-1*
> 损失函数（0-1 Loss Function）。

L(*y, f* (**x***, θ*)) =

> 0 **if** *y* = *f* (**x***, θ*)
>
> (2.14)
>
> 其中*I*(·) 是指示函数。
>
> 1 **if** *y* ̸= *f* (**x***, θ*)
>
> = *I*(*y* ̸= *f* (**x***, θ*))*,* (2.15)
>
> 虽然0-1
> 损失能够客观的评价模型的好坏，但缺点是数学性质不是很好：不连续且导数为0，难以优化。因此经常用连续可微的损失函数替代。
>
> 平方损失函数 平方损失函数（Quadratic Loss
> Function）经常用在预测标签*y*
>
> 为实数值的任务中。
>
> 参见习题[2-1](\l)。
>
> L(*y, f* (**x***, θ*)) = [1]{.underline} *y* − *f* (**x***, θ*) 2*.*
> (2.16)
>
> 平方损失函数一般不适用于分类问题。
>
> 交叉熵损失函数 交叉熵损失函数（Cross-Entropy Loss
> Function）一般用于分类问题。假设样本的标签*y* ∈ {1*,* · · · *C*}
> 为离散的类别，模型*f* (**x***, θ*) ∈ \[0*,* 1\]*C*
> 的输出为类别标签的条件概率分布，即
>
> *p*(*y* = *c*\|**x***, θ*) = *f~c~*(**x***, θ*)*,* (2.17)
>
> 并满足

*f~c~*(**x***, θ*) ∈ \[0*,* 1\]*,*

> *C*
>
> *f~c~*(**x***, θ*) = 1*.* (2.18)
>
> *c*=1
>
> 交叉熵参见第[E.3.1](\l)节。
>
> 我们可以用一个*C* 维的one-hot向量**y**
> 来表示样本标签。假设样本的标签为*k*，那么标签向量**y** 只有第*k*
> 维的值为1，其余元素的值都为0。标签向量**y**
> 可以看作是样本标签的真实概率分布，即第*c* 维（记为*y~c~*，1 ≤ *c* ≤
> *C*）是类别为*c* 的真实概率。假设样本的类别为*k*，那么它属于第*k*
> 类的概率为1，其它类的概率为0。
>
> 对于两个概率分布，一般可以用交叉熵来衡量它们的差异。标签的真实分
> 布**y** 和模型预测分布*f* (**x***, θ*) 之间的交叉熵为
>
> *C*
>
> (**y***, f* (**x***, θ*)) = *y~c~* log *f~c~*(**x***, θ*)*.* (2.19)
>
> *c*=1
>
> 比如对于三类分类问题，一个样本的标签向量为**y** = \[0*,* 0*,*
> 1\]T，模型预测的标签分布为*f* (**x***, θ*) = \[0*.*3*,* 0*.*3*,*
> 0*.*4\]T，则它们的交叉熵为
>
> L(*θ*) = − 0 × log(0*.*3) + 0 × log(0*.*3) + 1 × log(0*.*4)
>
> = − log(0*.*4)*.*
>
> 因为**y** 为one-hot 向量，公式([2.19](\l)) 也可以写为

L(*y, f* (**x***, θ*)) = − log *f~y~*(*x, θ*)*,* (2.20)

> 其中*f~y~*(**x***, θ*) 可以看作真实类别*y*
> 的似然函数。因此，交叉熵损失函数也就是负对数似然损失函数（Negative
> Log-Likelihood Function）。
>
> **Hinge** 损失函数 对于两类分类问题，假设*y* 和*f* (*x, θ*)
> 的取值为{−1*,* +1}。*Hinge*
>
> 损失函数（Hinge Loss Function）为

L(*y, f* (*x, θ*)) = max (0*,* 1 − *yf* (*x, θ*)) (2.21)

, \[1 − *yf* (*x, θ*)\]~+~*.* (2.22)

4.  风险最小化准则

> 一个好的模型*f* (**x***, θ*)
> 应当有一个比较小的期望错误，但由于不知道真实的数据分布和映射函数，实际上无法计算期望风险𝑌(*θ*;
> **x***, y*)。给定一个训练集
>
> D = {(**x**(*n*)*,
> y*^(*n*))}*N*\ ，我们可以计算的是经验风险（Empirical\ Risk），即在^
>
> 训练集上的平均损失。

*emp* [1]{.underline}

𝑌 *θ*

> Σ L(*y*^(*n*)^*, f* (*x*^(*n*)^*, θ*))*.* (2.23)
>
> 经验风险也称为经验错误
>
> （Empirical Error）。
>
> 因此，一个切实可行的学习准则是找到一组参数*θ*^∗\ 使得经验风险最小，^
>
> *θ*^∗^ = arg min 𝑌*emp*(*θ*)*,* (2.24)

*θ* D

> 这就是经验风险最小化（Empirical Risk Minimization，ERM）准则。
>
> 过拟合 根据大数定理可知，当训练集大小\|D\|
> 趋向于无穷大时，经验风险就趋向于期望风险。然而通常情况下，我们无法获取无限的训练样本，并且训练样
> 本往往是真实数据的一个很小的子集或者包含一定的噪声数据，不能很好地反
> 映全部数据的真实分布。经验风险最小化原则很容易导致模型在训练集上错误
>
> 率很低，但是在未知数据上错误率很高。这就是所谓的过拟合（Overﬁtting）。
> 如 何 选 择 训 练 样 本 个 数
>
> 可以参考[PAC 理论]{.underline}， 参见第[2.8.1](\l)节。
>
> 过拟合问题往往是由于训练数据少和噪声以及模型能力强等原因造成的。
> 为了解决过拟合问题，一般在经验风险最小化的基础上再引入参数的正则化
>
> （regularization），来限制模型能力，使其不要过度地最小化经验风险。这种
> 准则就是结构风险最小化（Structure Risk Minimization，SRM）准则。
>
> *θ*^∗^ = arg min 𝑌*struct*(*θ*) (2.25)

*θ* D

> = arg min 𝑌*emp*(*θ*) + [1]{.underline} *λ*∥*θ*∥2 (2.26)
>
> *θ* D 2
>
> = arg min [ 1]{.underline} *N* ( ( )) + (2.27)
>
> L *y , f x , θ λ*∥*θ*∥ *,*
>
> *θ n*=1 2
>
> 更 多 的 正 则 化 方 法 参 见第[7.7](\l)节。
>
> *ℓ*~1~ 范 数 的 稀 疏 性 参 见
>
> 其中∥*θ*∥ 是*ℓ*~2~ 范数的正则化项，用来减少参数空间，避免过拟合；*λ*
> 用来控制正则化的强度。
>
> 正则化项也可以使用其它函数，比如*ℓ*~1~ 范数。*ℓ*~1~
> 范数的引入通常会使得参数有一定稀疏性，因此在很多算法中也经常使用。在贝叶斯学习的角度来讲，正
>
> 第[7.7.1](\l)节。 则化是假设了参数的先验分布，不完全依赖训练数据。
>
> 正则化的贝叶斯解释参见第[2.3.1.4](\l)节。
>
> 总之，机器学习中的学习准则并不仅仅是拟合训练集上的数据，同时也要
> 使得泛化错误最低。给定一个训练集，机器学习的目标是从假设空间中找到一
> 个泛化错误较低的"理想"模型，以便更好地对未知的样本进行预测，特别是
> 不在训练集中出现的样本。因此，机器学习可以看作是一个从有限、高维、有
> 噪声的数据上得到更一般性规律的泛化问题。
>
> 和过拟合相反的一个概念是欠拟合（underﬁtting），即模型不能很好地拟
> 合训练数据，在训练集的错误率比较高。欠拟合一般是由于模型能力不足造成
> 的。图[2.3](\l)给出了欠拟合和过拟合的示例。

图片识别内容

图片识别内容

图片识别内容


> 图 2.3 欠拟合和过拟合示例

###### 优化算法

> 在确定了训练集D、假设空间F 以及学习准则后，如何找到最优的模型 *f*
> (**x***, θ*^∗^)
> 就成了一个最优化（optimization）问题。机器学习的训练过程其实就是最优化问题的求解过程。
>
> 参数与超参数 在机器学习中，优化又可以分为参数优化和超参数优化。模型
> *f* (**x***, θ*) 中的*θ*
> 称为模型的参数，可以通过优化算法进行学习。除了可学习的参数*θ*
> 之外，还有一类参数是用来定义模型结构或优化策略的，这类参数叫做超参数（hyper-parameter）。
>
> 常见的超参数包括：聚类算法中的类别个数、梯度下降法的步长、正则项
> 的系数、神经网络的层数、支持向量机中的核函数等。超参数的选取一般都是
> 组合优化问题，很难通过优化算法来自动学习。因此，超参数优化是机器学习
> 的一个经验性很强的技术，通常是按照人的经验设定，或者通过搜索的方法对
> 一组超参数组合进行不断试错调整。

5.  梯度下降法

> 为了充分利用凸优化中一些高效、成熟的优化方法，比如共轭梯度、拟牛
> 顿法等，很多机器学习方法都倾向于选择合适的模型和损失函数以构造一个凸
> 函数作为优化目标。但也有很多模型（比如神经网络）的优化目标是非凸的，只
> 能退而求其次找到局部最优解。
>
> 不同机器学习算法的区别在于模型、学习准则（损失函数）和优化算法的差
> 异。相同的模型也可以有不同的学习算法。比如线性分类模型有感知器、logistic
> 回归和支持向量机，它们之间的差异在于使用了不同的学习准则和优化算法。
>
> 在机器学习中，最简单、常用的优化算法就是梯度下降法，即通过迭代的
> 方法来计算训练集D 上风险函数的最小值。
>
> 在贝叶斯方法中，超参数可以理解为参数的参数，即控制模型参数分布的参数。
>
> 超参数的优化参见第[7.6](\l)节。
>
> 梯 度 下 降 法 参 见第[C.2.0.2](\l)节。

*θt*+1

> = *θ~t~*
>
> *α[∂]{.underline}*[𝑌~D~(*θ*)]{.underline}
>
> *∂θ*
>
> (2.28)

= *θ* − *α* · [ 1]{.underline}

> *n*Σ=1
>
> *∂ y*^(*n*)^*, f* (**x**(*n*)*, θ*)
>
> *,* (2.29)
>
> *∂θ*
>
> 其中*θ~t~* 为第*t* 次迭代时的参数值，*α* 为搜索步长。在机器学习中，*α*
> 一般称为学习率（learning rate）。

6.  提前停止

> 针对梯度下降的优化算法，除了加正则化项之外，还可以通过提前停止来
> 防止过拟合。
>
> 验 证 集 也 叫 开 发 集
>
> 在梯度下降训练的过程中，由于过拟合的原因，在训练样本上收敛的参数，
> 并不一定在测试集上最优。因此，除了训练集和测试集之外，有时也会使用一个验证集（validation
> set）来进行模型选择，测试模型在验证集上是否最优。在每次
>
> （development set）。 迭代时，把新得到的模型*f* (**x***, θ*)
> 在验证集上进行测试，并计算错误率。如果在验证集上的错误率不再下降，就停止迭代。这种策略叫提前停止（early
> stop）。如
>
> 果没有验证集，可以在训练集上划分出一个小比例的子集作为验证集。图[2.4](\l)给
> 出了提前停止的示例。
>
> 图 2.4 前提停止

7.  随机梯度下降法

> 在公式([2.28](\l))
> 的梯度下降法中，目标函数是整个训练集上风险函数，这种方式称为批量梯度下降法（Batch
> Gradient
> Descent，BGD）。批量梯度下降法在每次迭代时需要计算每个样本上损失函数的梯度并求和。当训练集中的样本
> 数量*N* 很大时，空间复杂度比较高，每次迭代的计算开销也很大。
>
> 在机器学习中，我们假设每个样本都是独立同分布的从真实数据分布中随
>
> 机抽取出来的，真正的优化目标是期望风险最小。批量梯度下降相当于是从真
> 实数据分布中采集 *N*
> 个样本，并由它们计算出来的经验风险的梯度来近似期望风险的梯度。为了减少每次迭代的计算复杂度，我们也可以在每次迭代时只
> 采集一个样本，计算这个样本损失函数的梯度并更新参数，即随机梯度下降法
>
> （Stochastic Gradient
> Descent，SGD）。当经过足够次数的迭代时，随机梯度下降也可以收敛到局部最优解\[[Nemirovski
> et al.](\l), [2009](\l)\]。
>
> 随机梯度下降法的训练过程如算法[2.1](\l)所示。
>
> 随机梯度下降法也叫增量梯度下降。
>
> 算法 **2.1:** 随机梯度下降法
>
> 输入**:** 训练集D = {(**x**(*n*)*, y*^(*n*))}^*N*
>
> ，验证集V，学习率*α*
>
> **1** 随机初始化*θ*;
>
> **2 repeat**
>
> **3** 对训练集D 中的样本随机重排序;
>
> **4 for** *n* = 1 · · · *N* **do**
>
> **5** 从训练集D 中选取样本(**x**(*n*)*, y*^(*n*));^
>
> // 更新参数
>
> **6** *θ* ← *θ* − *α ∂θ* ;
>
> **7 end**
>
> **8 until** 模型*f* (**x***, θ*) 在验证集V 上的错误率不再下降;
>
> [ ]{.underline} [输出**:** *θ *]{.underline}
>
> 批量梯度下降和随机梯度下降之间的区别在于每次迭代的优化目标是对所有样本的平均损失函数还是单个样本的损失函数。随机梯度下降因为实现简单，
> 收敛速度也非常快，因此使用非常广泛。随机梯度下降相当于在批量梯度下降的梯度上引入了随机噪声。当目标函数非凸时，反而可以使其逃离局部最优点。
>
> 小批量梯度下降法
> 随机梯度下降法的一个缺点是无法充分利用计算机的并行计算能力。小批量梯度下降法（Mini-Batch
> Gradient
> Descent）是批量梯度下降和随机梯度下降的折中。每次迭代时，我们随机选取一小部分训练样本来计
> 算梯度并更新参数，这样既可以兼顾随机梯度下降法的优点，也可以提高训练
> 效率。
>
> 第*t* 次迭代时，随机选取一个包含*K*
> 个样本的子集I*~t~*，计算这个子集上每个样本损失函数的梯度并进行平均，然后再进行参数更新。
>
> *K* 通常不会设置很大，一般

[ 1]{.underline}

*θ~t~*~+1~ ← *θ~t~* − *α* ·

> Σ *∂*L *y, f* (**x***, θ*)

*.* (2.30)

> 在 1 ∼ 100 之间。在实际应用中为了提高计算效率，通

*K* (**x***,y*)∈I *∂θ*

> 常设置为2 的*n* 次方。
>
> 在实际应用中，小批量随机梯度下降方法有收敛快，计算开销小的优点，因
> 此逐渐成为大规模的机器学习中的主要优化算法\[[Bottou](\l),
> [2010](\l)\]。

#### 机器学习的简单示例：线性回归

> 在本节中，我们通过一个简单的模型（线性回归）来具体了解机器学习的
> 一般过程，以及不同学习准则（经验风险最小化、结构风险最小化、最大似然
> 估计、最大后验估计）之间的关系。
>
> 线性回归（Linear
> Regression）是机器学习和统计学中最基础和广泛应用的模型，是一种对自变量和因变量之间关系进行建模的回归分析。自变量数量
> 为1 时称为简单回归，自变量数量大于1 时称为多元回归。
>
> 从机器学习的角度来看，自变量就是样本的特性向量**x** ∈
> R*d*（每一维对应一个自变量），因变量是标签*y*，这里*y* ∈
> R是连续值（实数或连续整数）。假设空间是一组参数化的线性函数
>
> *f* (**x**; **w***, b*) = **w**T**x** + *b,* (2.31)
>
> 其中权重向量**w** 和偏置*b* 都是可学习的参数，函数*f* (**x**; **w***,
> b*) ∈ R也称为线性模型。
>
> 为了简单起见，我们将公式([2.31](\l)) 写为
>
> *f* (**x**; **w**ˆ ) = **w**ˆ T**x**ˆ*,* (2.32)
>
> 其中**w**ˆ 和**x**ˆ 分别称为增广权重向量和增广特征向量。
>
>  
>
>  **x** 
>
> *x*1 
>
>  . 
>
> **x**ˆ = **x** ⊕ 1 ,   =   *,* (2.33)
>
>   
>
>  1 
>
>  
>
>  1 
>
>  *w*1 
>
>  **w**   . 
>
> **w**ˆ = **w** ⊕ *b* ,   =   *,* (2.34)
>
>   
>
>  *b*   *b* 
>
> 其中⊕ 定义为两个向量的拼接操作。
>
> 不失一般性，在本章后面的描述中我们采用简化的表示方法，直接用**w**
> 和**x** 来表示增广权重向量和增广特征向量。即线性回归的模型简写为 *f*
> (**x**; **w**) = **w**T**x**。

###### 参数学习

> 给定一组包含*N* 个训练样本的训练集D = {(**x**(*n*)*,
> y*^(*n*))}*,*\ 1\ ≤\ *n*\ ≤\ *N*\ ，我们希望能够学习一个最优的线性回归的模型参数**w**。^
>
> 我们介绍四种不同的参数估计方法：经验风险最小化、结构风险最小化、最
> 大似然估计、最大后验估计。

1.  经验风险最小化

> 由于线性回归的标签*y*
> 和模型输出都为连续的实数值，因此平方损失函数非常合适来衡量真实标签和预测标签之间的差异。
>
> 根据经验风险最小化准则，训练集D 上的的经验风险定义为
>
> *N*
>
> 平 方 损 失 函 数 参 见第[2.2.2.1](\l)节。
>
> 𝑌(**w**) = Σ L(*y*^(*n*)^*, f* (**x**(*n*)*,* **w**))

(2.35)

> 为了简化起见，这里的风险函数省略了 [^\ 1^]{.underline} 。

N

= [1]{.underline} *N*

*n*=1

> *y*(*n*)
>
> − **w x**(*n*) 2
>
> (2.36)

= [1]{.underline} ∥**y** − *X*T**w**∥2*,*

> (2.37)
>
> 其中**y** ∈ R*N* 是由每个样本的真实标签*y*^(1)^*,* · · · *, y*^(*N*)^
> 组成的列向量，*X* ∈ R(*d*+1)×*N*
>
> 是所有输入 **x**(1)*,* · · · *,* **x**(*N* ) 组成的矩阵

 (1) (2) (*N* )

 . .

> . . . . 

*X* = (1) (2)

> *.* (2.38)
>
> (*N* )

*xd xd* · · · *xd* 

 1 1 · · · 1 

> 风险函数𝑌(**w**) 是关于**w** 的凸函数，其对**w** 的偏导数为
>
> [*∂*𝑌(**w**)]{.underline} = 1 *∂* ∥**y** − *X*T**w**∥2

(2.39)

> 参见习题[2-2](\l)。

*∂***w** 2 *∂***w**

> = −*X*(**y** − *X*T**w**)*,* (2.40)
>
> 令 [*^\ ∂^*]{.underline} ^𝑌(**w**)\ =\ 0，得到最优的参数**w**∗\ 为^
>
> *XX*^T^)−1*X* 也称为 *X* 的伪
>
> **w**∗ = (*XX*T)−1*X***y** (2.41)
>
> 逆矩阵。

= Σ*N*

> **x**( ) **x**( ) T −1 Σ*N*
>
> **x**( )
>
> ( )
>
> (2.42)
>
> 这种求解线性回归参数的方法也叫最小二乘法估计（Least Square
> Estimation，
> LSE）。图[2.5](\l)给出了用最小二乘法估计方法来进行参数学习的示例。

2

*y* = 0*.*60·x+0*.*52

1

0

> −1
>
> −1*.*5 −1 −0*.*5 0 0*.*5 1 1*.*5
>
> 图 2.5 线性回归示例
>
> 参见习题[2-3](\l)。
>
> 共线性是指一个特征可以通过其他特征的线性组合来被较准确地预测。
>
> 在最小二乘法估计方法中，*XX*T ∈ R(*d*+1)×(*d*+1)
> 必须存在逆矩阵，即*XX*T是满秩的（rank(*XX*T) = *d* +1）。也就是说，*X*
> 中的每一行特征之间是线性不相关的。一种常见的*XX*T
> 不可逆情况是样本数量*N* 小于特征数量(*d* + 1)，*XX*T 的秩为*N*
> 。这时会存在很多解**w**∗，可以使得𝑌(**w**∗) = 0。
>
> 当*XX*T
> 不可逆时，可以使用主成分分析等方法来预处理数据，消除不同特征之间的相关性，然后再使用最小二乘估计方法来求解。或者是通过用梯度下
> 降法来求解。初始化**w**~0~ = 0，通过下面公式进行迭代，
>
> **w** ← **w** + *αX*(**y** − *X*T**w**)*,* (2.43)
>
> 其中*α* 是学习率。这种方法也称为最小均方误差（Least Mean
> Squares，LMS） 算法。

2.  结构风险最小化

> 最小二乘法估计的基本要求是各个特征之间要相互独立，保证*XX*T
> 可逆。但即使*XX*T
> 可逆，如果特征之间可能会有较大的共线性（multicollinearity），
> 也会使得*XX*T 的逆在数值上无法准确计算。数据集*X*
> 上一些小的扰动就会导致(*XX*T)−1
> 发生大的改变，进而使得最小二乘法估计的计算变得很不稳定。为
>
> 了解决这个问题，[Hoerl and Kennard](\l) \[[1970](\l)\]
> 提出了岭回归（Ridge Regression）
>
> ，给*XX*T 的对角线元素都加上一个常数*λI* 使得(*XX*T + *λI*)
> 的秩不为0。最优的参数**w**∗ 为
>
> **w**∗ = (*XX*T + *λI*)−1*X***y***,* (2.44)
>
> 其中*λ \>* 0 为预先设置的超参数，*I* 为单位矩阵。
>
> 岭回归的解**w**∗ 可以看做是结构风险最小化准则下的最小二乘法估计。
>
> 参见习题[2-4](\l)。
>
> 1 T 2 1 2
>
> 𝑌(**w**) = 2 ∥**y** − *X* **w**∥
>
> 其中*λ \>* 0 为正则化系数。

3.  最大似然估计

> \+ 2 *λ*∥**w**∥ *,* (2.45)
>
> 机器学习任务可以分为两类，一类是样本的特征向量**x** 和标签*y*
> 之间如果存在未知的函数关系 *y* = *h*(**x**)，另一类是条件概率
> *p*(*y*\|**x**)
> 服从某个未知分布。第[2.3.1.1](\l)中介绍的最小二乘估计是属于第一类，直接建模**x**
> 和标签*y*
> 之间的函数关系。此外，线性回归还可以通过建模条件概率*p*(*y*\|**x**)
> 的角度来进行参数估计。
>
> 假设标签*y* 为一个随机变量，其服从以均值为*f* (**x***,* **w**) =
> **w**T**x** 为中心，方差为*σ*^2^ 的高斯分布。
>
> *p*(*y*\|**x***,* **w***, σ*) = N(*y*\|**w**T**x***, σ*^2^) (2.46)
>
> 这里**x** 看作是确定值的参数。

= √2*πσ* exp

> (*y* **w**T**x**)2
>
> − 2*σ*2
>
> *.* (2.47)
>
> 参数**w** 在训练集D 上的似然函数（likelihood）为
> 似然函数是关于统计模型的
>
> *N*
>
> *p*(**y** *X,* **w***, σ*) = *p*(*y*^(*n*)^ **x**(*n*)*,* **w***, σ*)
> (2.48)
>
> *n*=1
>
> 参数的函数。
>
> 似然 *p*(*x*\|*w*) 和概率 *p*(*x*\|*w*)
>
> 之 间 的 区 别 在 于： 概 率

*N*

( ) ( ) 2

> (*x*\|*w*) 是描述固定参数*w* 时，
>
> = (*y ^n^* **w**T**x** *n , σ* )*,* (2.49)
>
> *n*=1
>
> 其中**y** = \[*y*^(1)^*,* · · · *, y*^(*N*)^\]T
> 为所有样本标签组成的向量，*X* = \[**x**(1)*,* · · · *,* **x**(*N* )\]
> 为所有样本特征向量组成的矩阵。
>
> 为了方便计算，对似然函数取对数得到对数似然函数（log likelihood），
>
> *p*
>
> 随机变量 *x* 的分布情况，而似然*p*(*x*\|*w*) 则是描述已知随机变量 *x*
> 时，不同的参数 *w* 对其分布的影响。

*N*

log *p*(**y** *X,* **w***, σ*) = log (*y*^(*n*)^ **w**T**x**(*n*)*,
σ*^2^)*.* (2.50)

> *n*=1
>
> 最大似然估计（Maximum Likelihood Estimate，MLE）是指找到一组参数
>
> **w** 使得似然函数*p*(**y**\|*X,* **w***, σ*)
> 最大，等价于对数似然函数log *p*(**y**\|*X,* **w***, σ*) 最大。
>
> 最小二乘估计解参见公式
>
> 令 [*∂* log *p*(**y**\|*X,* **w***, σ*)]{.underline} = 0，得到
>
> *∂*
>
> **w***ML* = (*XX*T)−1*X***y***.* (2.51)
>
> 可以看出，最大似然估计的解和最小二乘估计的解相同。
>
> 参见习题[2-5](\l)。
>
> ([2.41](\l))。 **2.3.1.4** 最大后验估计
>
> 假设参数**w**
> 为一个随机向量，并服从一个先验分布*p*(**w**\|*ν*)。简单起见，一般令*p*(**w**\|*ν*)
> 为各向同性的高斯分布
>
> *p*(**w**\|*ν*) = N(**w**\|**0***, ν*^2^*I*)*,* (2.52)
>
> 其中*ν*^2^ 为每一维上的方差。
>
> 贝 叶 斯 公 式 参 见 公 式
>
> ([D.32](\l))。 根据贝叶斯公式，那么参数**w** 的后验概率分布（posterior
> distribution）为
>
> 分母为和**w** 无关的常量。

*p*(**w**

\|*X,*

**y** ) = [ *p*(**w***,* **y**\|*X, ν, σ*) ]{.underline}

> **~w~** *p ,* \|*X, ν, σ*
>
> 𝖺 *p*(**y**\|*X,* **w***, σ*)*p*(**w**\|*ν*)*,*
>
> (2.53)
>
> (2.54)
>
> 统计推断参见第[11.2](\l)节。
>
> 其中*p*(**y**\|*X,* **w***, σ*) 为**w**
> 的似然函数，定义见公式([2.48](\l))，*p*(**w**\|*ν*) 为**w**
> 的先验。这种估计参数 **w**
> 的后验概率分布的方法称为贝叶斯估计（Bayesian Esti-
>
> mation），是一种统计推断问题。采用贝叶斯估计的线性回归也称为贝叶斯线
> 性回归（Bayesian Linear Regression）。
>
> 贝叶斯估计是一种参数的区间估计，即参数在一个区间上的分布。如果我
> 们希望得到一个最优的参数值（即点估计），可以使用最大后验估计。最大后
> 验估计（Maximum A Posteriori
> Estimation，MAP）是指最优参数为后验分布*p*(**w**\|*X,* **y***, ν, σ*)
> 中概率密度最高的参数**w**。

**w***MAP* = arg max *p*(**y**\|*X,* **w***, σ*)*p*(**w**\|*ν*)*,*
(2.55)

> 令似然函数*p*(**y**\|*X,* **w***, σ*) 为公式([2.49](\l))
> 中定义的高斯密度函数，则后验分布
>
> *p*(**w**\|*X,* **y***, ν, σ*) 的对数为

log *p*(**w**\|*X,* **y***, ν, σ*) 𝖺 log *p*(**y**\|*X,* **w***, σ*) +
log *p*(**w**\|*ν*) (2.56)

[ 1]{.underline} *^N^*

𝖺 − 2*σ*2

*n*

> *y*(*n*)
>
> − **w x**

(n) 2

> [ 1 ]{.underline}
>
> − 2*ν*2
>
> T**w***,* (2.57)
>
> *N*
>
> − 2 2 ∥ − *X*∥ − 2 *.*
>
> *σ n*=1 2*ν*
>
> 可以看出，最大后验概率等价于平方损失的结构方法最小化，其中正则化系数
>
> *λ* = *σ*^2^*/*2*ν*^2^。
>
> 最大似然估计和贝叶斯估计可以看作是频率学派和贝叶斯学派对需要估计
> 的参数**w** 的不同解释。当*ν* → ∞ 时，先验分布*p*(**w**\|*ν*)
> 退化为均匀分布，称为无信息先验（non-informative
> prior），最大后验估计退化为最大似然估计。

#### 偏差**-**方差分解

> 为了避免过拟合，我们经常会在模型的拟合能力和复杂度之间进行权衡。拟合能力强的模型一般复杂度会比较高，容易导致过拟合。相反，如果限制模型的复杂度，降低其拟合能力，又可能会导致欠拟合。因此，如何在模型能力和复杂度之间取得一个较好的平衡对一个机器学习算法来讲十分重要。偏差*-*方差分解（Bias-Variance
> Decomposition）为我们提供一个很好的分析和指导工具。
>
> 以回归问题为例，假设样本的真实分布为 *p~r~*(**x***,
> y*)，并采用平方损失函数， 模型*f* (**x**) 的期望错误为
>
> 本节介绍的偏差-方差分解以回归问题为例，但其结论同样适用于分类问题。
>
> 这里省略了模型参数*θ*。
>
> 𝑌(*f* ) = E~(**x**~ ~)~ ~(**x**~ ~)~h *y* − *f* (**x**) 2i*.* (2.59)
>
> 那么最优的模型为
>
> *f* ^∗^(**x**) = E~*y*∼*p*~*r* (*y*\|**x**) *y .* (2.60)
>
> 参见习题[2-8](\l)。
>
> 其中*p~r~*(*y*\|**x**) 为样本的真实条件分布，*f* ^∗^(**x**)
> 为使用平方损失作为优化目标的最优模型，其损失为
>
> *ε* = E~(**x**~ ~)~ ~(**x**~ ~)~h *y* − *f* ^∗^(**x**) 2i*.* (2.61)
>
> 损失*ε* 通常是由于样本分布以及噪声引起的，无法通过优化模型来减少。
>
> 期望错误可以分解为
>
> 𝑌(*f* ) = E(**x***,y*)∼*pr* (**x***,y*)

*y* − *f* ^∗^(**x**) + *f* ^∗^(**x**) − *f* (**x**) 2

> (2.62)

= E**x**∼*pr* (**x**)

*f* (**x**) − *f* ^∗^(**x**) 2 + *ε,*

(2.63)

> 根 据 公 式[2.60](\l)，E**x**Ey\[*y* −
>
> *f* ^∗^(**x**)\] = 0*.*
>
> 其中第一项是机器学习算法可以优化的真实目标，是当前模型和最优模型之间
> 的差距。
>
> 在实际训练一个模型*f* (**x**) 时，训练集D 是从真实分布*p~r~*(**x***,
> y*)
> 上独立同分布地采样出来的有限样本集合。不同的训练集会得到不同的模型。令*f*~D~(**x**)
> 表示在训练集D
> 学习到的模型，一个机器学习算法（包括模型以及优化算法）的能力可以用不同训练集上的模型的平均性能来评价。
>
> 对于单个样本**x**，不同训练集D 得到模型*f*~D~(**x**) 和最优模型*f*
> ^∗^(**x**) 的上的期望差距为
>
> ~2~
>
> E~D~ *f*~D~(**x**) − *f* ^∗^(**x**)

= E~D~

*f*D

(**x**) − E~D~

*f*D

(**x**) + E~D~

*f*D

(**x**) − *f* ^∗^(**x**) 2

> (2.64)
>
> = E~D~ *f*~D~(**x**) − *f* ^∗^(**x**) +

2

E~D~

~2~

*f*~D~(**x**) − E~D~ *f*~D~(**x**) *.*

> (2.65)
>
> \` (b˛ia¸s)2 x \`
>
> var˛ia¸nce x
>
> 参见习题[2.65](\l)。
>
> 其中第一项为偏差（bias），是指一个模型的在不同训练集上的平均性能和最优模型的差异。偏差可以用来衡量一个模型的拟合能力；第二项是方差（variance），
> 是指一个模型在不同训练集上的差异，可以用来衡量一个模型是否容易过拟合。
>
> 结合公式([2.63](\l)) 和([2.65](\l))，期望错误可以分解为
>
> 𝑌(*f* ) = (bias) + variance + *ε.* (2.66)
>
> 其中

(bias)^2^ = E**~x~**

ED

*f*D

(**x**) − *f* ^∗^(**x**) 2 *,* (2.67)

variance = E**~x~** E~D~

*f*D

(x) − E~D~

*f*D

(**x**) 2i *.* (2.68)

> 参见习题[2-9](\l)。
>
> 结构错误最小化参见公式
>
> 最小化期望错误等价于最小化偏差和方差之和。
>
> 图[2.6](\l)给出了机器学习算法的偏差和方差的四种不同组合情况。每个图的中心点为最优模型*f*
> ^∗^(**x**)，蓝点为不同训练集*D*
> 上得到的模型*f*~D~(**x**)。图[2.6](\l)a
> 给出了一种理想情况，方差和偏差都比较小。图[2.6](\l)b
> 为高偏差低方差的情况，表示模型的泛化能力很好，但拟合能力不足。图[2.6](\l)c
> 为低偏差高方差的情况，表示模型的拟合能力很好，但泛化能力比较差。当训练数据比较少时会导致过拟合。
> 图[2.6](\l)d 为高偏差高方差的情况，是一种最差的情况。
>
> 方差一般会随着训练样本的增加而减少。当样本比较多时，方差比较少，我
> 们可以选择能力强的模型来减少偏差。然而在很多机器学习任务上，训练集上
> 往往都比较有限，最优的偏差和最优的方差就无法兼顾。
>
> 随着模型复杂度的增加，模型的拟合能力变强，偏差减少而方差增大，从
> 而导致过拟合。以结构错误最小化为例，我们可以调整正则化系数*λ*
> 来控制模型的复杂度。当*λ*
> 变大时，模型复杂度会降低，可以有效地减少方差，避免过

([2.27](\l))。 拟合，但偏差会上升。当*λ*
过大时，总的期望错误反而会上升。因此，一个好的

正则化系数*λ*
需要在偏差和方差之间取得比较好的平衡。图[2.7](\l)给出了机器学习

低方差

高方差

> 低偏差
>
图片识别内容
8

>
> (a)

图片识别内容
.


> (c)
>
> 高偏差
>
图片识别内容

>
> (b)

图片识别内容


> (d)
>
> 图 2.6 偏差和方差的四种组合
>
> 模型的期望错误、偏差和方差随复杂度的变化情况。最优的模型并不一定是偏
> 差曲线和方差曲线的交点。
>
> 模型复杂度
>
> 图 2.7 模型的期望错误、偏差和方差随复杂度的变化情况
>
> 集成模型参见第[10.1](\l)节。
>
> 偏差和方差分解给机器学习模型提供了一种分析途径，但在实际操作中难以直接衡量。一般来说，当一个模型在训练集上的错误率比较高时，说明模型的拟合能力不够，偏差比较高。这种情况可以增加数据特征、提高模型复杂度，
> 减少正则化系数等操作来改进模型。当模型在训练集上的错误率比较低，但验证集上的错误率比较高时，说明模型过拟合，方差比较高。这种情况可以通过降低模型复杂度，加大正则化系数，引入先验等方法来缓解。此外，还有一种有效的降低方差的方法为集成模型，即通过多个高方差模型的平均来降低方差。
>
> **2.5** 机器学习算法的类型
>
> 机器学习算法可以按照不同的标准来进行分类。比如按函数*f* (**x***, θ*)
> 的不同，
> 机器学习算法可以分为线性模型和非线性模型；按照学习准则的不同，机器学习算法也可以分为统计方法和非统计方法。
>
> 但一般来说，我们会按照训练样本提供的信息以及反馈方式的不同，将机
> 器学习算法分为以下几类：
>
> 监督学习 如果机器学习的目标是通过建模样本的特征 **x** 和标签 *y*
> 之间的关系： *y* = *f* (**x***, θ*) 或*p*(*y*\|**x***,
> θ*)，并且训练集中每个样本都有标签，那么这类机器学习称为监督学习（Supervised
> Learning）。根据标签类型的不同，监督学习又可以分为回归和分类两类。

1.  回归（Regression）问题中的标签*y* 是连续值（实数或连续整数），*f*
    > (**x***, θ*)

> 的输出也是连续值。

2.  分类（Classiﬁcation）问题中的标签*y*
    > 是离散的类别（符号）。在分类问题中，
    > 学习到模型也称为分类器（Classiﬁer）。分类问题根据其类别数量又可分为两类分类（Binary
    > Classiﬁcation）和多类分类（Multi-class Classiﬁcation） 问题。

3.  结构化学习（Structured
    > Learning）的输出是结构化的对象，比如序列、树或图等。由于结构化学习的输出空间比较大，因此我们一般定义一个联合特征空间，将**x***,*
    > **y** 映射为该空间中的联合特征向量***ϕ***(**x***,*
    > **y**)，预测模型可以写为

> 一种基于感知器的结构化学
>
> **y**ˆ = arg max *f **ϕ***(**x***,* **y**)*, θ ,* (2.69)
>
> **y**∈Gen(**x**)
>
> 其中Gen(**x**) 表示输入**x** 所有可能的输出目标集合。计算arg max
> 的过程也
>
> 习参见第[3.4.4](\l)节。
> 称为解码（decoding）过程，一般通过动态规划的方法来计算。
>
> 无监督学习 无监督学习（Unsupervised
> Learning，UL）是指从不包含目标标签的训练样本中自动学习到一些有价值的信息。典型的无监督学习问题有聚类、
> 密度估计、特征学习、降维等。
>
> 无监督学习参见第[9](\l)章。
>
> 强化学习 强化学习（Reinforcement
> Learning，RL）是一类通过交互来学习的机器学习算法。在强化学习中，智能体根据环境的状态做出一个动作，并得到
> 即时或延时的奖励。智能体在和环境的交互中不断学习并调整策略，以取得最
> 大化的期望总回报。
>
> 表[2.1](\l)给出了三种机器学习类型的比较。
>
> 强化学习参见第[14](\l)章。
>
> 监督学习 无监督学习 强化学习
>
> 训练集 训练集

训练样本

> {(**x**

(n)

*, y*(n)

> N
>
> n=1
>
> {**x** }~n=1~
>
> 智能体和环境交互的
>
> 轨迹*τ* 和累积奖励*G*τ
>
> 优化目标 *y* = *f* (**x**) 或*p*(*y*\|**x**) *p*(**x**) 或带隐变量
>
> **z** 的 *p*(**x**\|**z**)
>
> 期望总回报Eτ \[*G*τ \]

学习准则

> 期望风险最小化最大似然估计
>
> 最大似然估计最小重构错误
>
> 策略评估策略改进
>
> 表 2.1 三种机器学习类型的比较
>
> 监督学习需要每个样本都有标签，而无监督学习则不需要标签。一般而言，
> 监督学习通常大量的有标签数据集，这些数据集是一般都需要由人工进行标注，
> 成本很高。因此，也出现了很多弱监督学习（Weak Supervised
> Learning）和半监督学习（Semi-Supervised
> Learning）的方法，希望从大规模的无标注数据中充分挖掘有用的信息，降低对标注样本数量的要求。强化学习和监督学习的不同在于强化学习不需要显式地以"输入/输出对"的方式给出训练样本，是一种在线的学习机制。

#### 数据的特征表示

> 在实际应用中，数据的类型多种多样，比如文本、音频、图像、视频等。不同类型的数据，其原始特征（raw
> features）的空间也不相同。比如一张灰度图像（像素数量为*n*）的特征空间为\[0*,*
> 255\]*n*，一个自然语言句子（长度为*L*）的特征空间为\|V\|*L*，其中V
> 为词表集合。而很多机器学习算法要求是输入的样本特征是数学上可计算的，因此，在机器学习之前我们需要将这些不同类型的数
> 据转换为向量表示。
>
> 图像特征 在手写体数字识别任务中，样本*x* 为待识别的图像。为了识别*x*
> 是什么数字，我们可以从图像中抽取一些特征。如果图像是一张大小为*m* ×
> *n* 的图像，其特征向量可以简单地表示为*m* × *n*
> 维的向量，每一维的值为图像中对应像素的灰度值。为了提高模型准确率，也会经常加入一个额外的特征，比如直
>
> 也有一些机器学习算法（比如决策树）不需要向量形式的特征。
>
> 词袋模型在信息检索中也叫做向量空间模型（Vector Space Model，VSM）
>
> 单独一个单词的BoW 表示
>
> 方图、宽高比、笔画数，纹理特征、边缘特征等。假设我们总共抽取了*d*
> 个特征，这些特征可以表示为一个向量**x** ∈ R*d*。
>
> 文本特征 在文本情感分类任务中，样本*x* 为自然语言文本，类别*y* ∈
> {+1*,* −1} 分别表示正面或负面的评价。为了将样本*x*
> 从文本形式转为为向量形式，一种简单的方式是使用词袋模型（Bag-of-Words，BoW）模型。假设训练集合中的词都来自一个词表V，大小为\|V\|，则每个样本可以表示为一个\|V\|
> 维的向量**x** ∈ R\|V\|， 向量中每一维*x~i~* 的值为词表中的第*i*
> 个词是否在*x* 中出现。如果出现值为1，否则为0。
>
> 比如两个文本"我 喜欢 读书"和"我 讨厌
> 读书"中共有"我"、"喜欢"、"讨厌"、"读书"四个词，它们的BoW 表示分别为
>
> **v**~1~ = \[1 1 0 1 \]T*,*
>
> **v**~2~ = \[1 0 1 1 \]T*.*
>
> 为one-hot 向量。
> 词袋模型将文本看做是词的集合，不考虑词序信息，不能精确地表示文本
>
> 信息。一种改进方式是使用n 元组合特征，即每n 个连续词构成一个基本单元，
>
> \$ 和\# 分别表示文本的开始
>
> 然后再用词袋模型进行表示。以最简单的二元特征（即两个词的组合特征）为
>
> 和结束。 例，上面的两个文本中共有"\$
> 我"、"我喜欢"、"我讨厌"、"喜欢读书"、"讨厌读书"、"读书\#"六个特征单元，它们的二元特征BoW
> 表示分别为
>
> **v**~1~ = \[1 1 0 1 0 1\]T*,*
>
> **v**~2~ = \[1 0 1 0 1 1\]T*.*
>
> 随着n 数量的增长，n
> 元特征的数量会指数上升，上限为\|V\|*n*。因此，在实际应用中，文本特征维数通常在十万或百万级别以上的。
>
> 参见习题[2-11](\l)。
>
> 表示学习可以看作是一个特殊的机器学习任务，即有自己的模型、学习准则和优化方法。
>
> 表示学习
> 如果直接用数据的原始特征来进行预测，对机器学习模型的能力要求比较高。这些原始特征可能存在以下几种不足：（1）特征比较单一，需要进行
>
> （非线性的）组合才能发挥其作用；（2）特征之间冗余度比较高；（3）并不是所有的特征都对预测有用；（4）很多特征通常是易变的；（5）特征中往往存在一些噪声。
>
> 为了提高机器学习算法的能力，我们需要抽取有效、稳定的特征。传统的特征提取是通过人工方式进行的，需要大量的人工和专家知识。一个成功的机器学习系统通常需要尝试大量的特征，称为特征工程（Feature
> Engineering）。但即使这样，人工设计的特征在很多任务上也不能满足需要。因此，如何让机器自动地学习出有效的特征也成为机器学习中的一项重要研究内容，称为特征学习（Feature
> Learning），也叫表示学习（Representation Learning）。特征
>
> 学习在一定程度上也可以减少预测模型复杂性、缩短训练时间、提高模型泛化
> 能力、避免过拟合等。

###### 传统的特征学习

> 传统的特征学习一般是通过人为地设计一些准则，然后根据这些准则来选
> 取有效的特征，具体又可以分为两种：特征选择和特征抽取。

1.  特征选择

> 特征选择（Feature
> Selection）是选取原始特征集合的一个有效子集，使得基于这个特征子集训练出来的模型准确率最高。简单地说，特征选择就是保留
> 有用特征，移除冗余或无关的特征。
>
> 子集搜索 一种直接的特征选择方法为子集搜索（subset
> search）。假设原始特征数为*d*，则共有2*d*
> 个候选子集。特征选择的目标是选择一个最优的候选子集。最暴力的做法是测试每个特征子集，看机器学习模型哪个子集上的准确率最高。
> 但是这种方式效率太低。常用的方法是采用贪心的策略：由空集合开始，每一轮添加该轮最优的特征，称为前向搜索（forward
> search）；或者从原始特征集合开始，每次删除最无用的特征，称为反向搜索（backward
> search）。
>
> 子集搜索方法又可以分为过滤式和包裹式的方法。
>
> 过滤式（ﬁlter）方法不依赖具体的机器学习模型。每次增加最有信息量
> 的特征，或删除最没有信息量的特征\[[Hall](\l),
> [1999](\l)\]。信息量可以通过信息增益
>
> （information gain）来衡量。
>
> 包裹式（wrapper）方法是用后续机器学习模型的准确率来评价一个特征子
> 集。每次增加对后续机器学习模型最有用的特征，或删除对后续机器学习任务
> 最无用的特征。这种方法是将机器学习模型包裹到特征选择过程的内部。
>
> *ℓ*~1~ 正则化 此外，我们还可以通过*ℓ*~1~
> 正则化来实现特征选择。由于*ℓ*~1~
> 正则化会导致稀疏特征，间接实现了特征选择。

2.  特征抽取

> 特征抽取（Feature
> Extraction）是构造一个新的特征空间，并将原始特征投影在新的空间中。以线性投影为例，原始特征向量**x**
> ∈ R*d*，经过线性投影后得到在新空间中的特征向量**x**′。
>
> 其中*P* ∈ R*k*×*d* 为映射矩阵。
>
> **x**′ = *P* **x***,* (2.70)
>
> 特征抽取又可以分为监督和无监督的方法。监督的特征学习的目标是抽取
> 对一个特定的预测任务最有用的特征，比如线性判别分析（Linear
> Discriminant
> Analysis，LDA）。而无监督的特征学习和具体任务无关，其目标通常是减少冗余信息和噪声，比如主成分分析（Principle
> Components Analysis，PCA）。
>
> 表[2.2](\l)列出了一些传统的特征选择和特征抽取方法。
>
> 监督学习 无监督学习
>
> 特征选择 标签相关的子集搜索、*ℓ*1 正则化、决策树
>
> 标签无关的子集搜索
>
> 特征抽取 线性判别分析 主成分分析、独立成分分析、流形学习、自编码器
>
> 表 2.2 传统的特征选择和特征抽取方法
>
> 正则化参见第[7.7](\l)节。
>
> 参见第[1.4](\l)节。
>
> 特征选择和特征抽取的优点是可以用较少的特征来表示原始特征中的大部分相关信息，去掉噪声信息，并进而提高计算效率和减小维度灾难（Curse
> Of
> Dimensionality）。对于很多没有正则化的模型，特征选择和特征抽取非常必要。
> 经过特征选择或特征抽取后，特征的数量一般会减少，因此特征选择和特征抽取也经常称为维数约减或降维（Dimension
> Reduction）。

###### 深度学习方法

> 传统的特征抽取一般是和预测模型的学习分离的。我们会先通过主成分分
> 析或线性判别分析等方法抽取出有效的特征，然后再基于这些特征来训练一个
> 具体的机器学习模型。
>
> 如果我们将特征的表示学习和机器学习的预测学习有机地统一到一个模型中，建立一个端到端的学习算法，可以有效地避免它们之间准则的不一致性。这种表示学习方法就称为深度学习（Deep
> Learning，DL）。深度学习方法的难点是如何评价表示学习对最终系统输出结果的贡献或影响，即贡献度分配问题。
> 目前比较有效的模型是神经网络，即将最后的输出层作为预测学习，其它层作为表示学习。

#### 评价指标

> 为了衡量一个机器学习模型的好坏，需要给定一个测试集，用模型对测试
> 集中的每一个样本进行预测，并根据预测结果计算评价分数。
>
> 对于分类问题，常见的评价标准有正确率、准确率、召回率和F 值等。
>
> 2.7 评价指标 2019 年 4 月 6 日 49
>
> 给定测试集𝘧 = (**x**(1)*, y*^(1)^)*,* · · · *,* (**x**(*N* )*,
> y*^(*N*)^)，假设标签*y*^(*n*)^ ∈ {1*, , C*}，
>
> 用学习好得模型*f* (**x***, θ*)
> 对测试集中的每一个样本进行预测，结果为*Y* = *y*ˆ(1)*,* *, y*ˆ(*N* )。
>
> 准确率 最常用的的评价指标为准确率（Accuracy）
>
> 其中*I*(·) 为指示函数。

[ 1]{.underline}

> ACC *N*
>
> *n*Σ=1

*I*(*y*

(*n*)

> = *y*ˆ(*n*)

)*,* (2.71)

> 错误率 和准确率相对应的就是错误率（Error Rate）。
>
> 𝗌 = 1 − ACC (2.72)

= [ 1]{.underline} Σ

> ( ( ) = ˆ( ))
>
> (2.73)

*N n*=1

*I y ^n^ y ^n^ .*

> 查准率和查全率
> 准确率是所有类别整体性能的平均，如果希望对每个类都进行性能估计，就需要计算查准率和查全率。查准率和查全率是广泛用于信息检索
> 和统计学分类领域的两个度量值，在机器学习的评价中也被大量使用。
>
> 对于类别*c* 来说，模型在测试集上的结果可以分为以下四种情况：

1.  真正例（True Positive，TP）：一个样本的真实类别为*c* 并且模型正确地

> 预测为类别*c*。这类样本数量记为 TP 表示。

*N*

> *TP~c~* = *I*(*y*^(*n*)^ = *y*ˆ(*n*) = *c*)*.* (2.74)
>
> *n*=1

2.  假负例（False
    > Negative，FN）：一个样本的真实类别为*c*，模型错误地预测为其它类。这类样本数量记为

> *N*
>
> *FN~c~* = *I*(*y*^(*n*)^ = *c y*ˆ(*n*)
>
> *n*=1
>
> *c*)*.* (2.75)

3.  假正例（False
    > Positive，FP）一个样本的真实类别为其它类，模型错误地预测为类*c*。这类样本数量记为

> *N*
>
> *FP~c~* = *I*(*y*^(*n*)^
>
> *n*=1
>
> *c* ∧ *y*ˆ(*n*) = *c*)*.* (2.76)

4.  真负例（True
    > Negative，TN）：一个样本的真实类别为其它类，模型也预测为其它类。这类样本数量记为*TN~c~*。对于类别*c*
    > 来说，这种情况一般不需要关注。

> 预测类别
>
> [ *y*ˆ = *c y*ˆ ̸= *c *]{.underline}
>
> *y* = *c TP~c~ FN~c~*
>
> 真实类别
>
> [ *y* ̸= *c FP~c~ TN~c~ *]{.underline}
>
> 表 2.3 类别*c* 的预测结果的混淆矩阵
>
> 这四种情况的关系如表[2.3](\l)所示的混淆矩阵来表示。
>
> 查准率（Precision），也叫精确率或精度，类别*c*
> 的查准率为是所有预测为类别*c* 的样本中，预测正确的比例。

P*~c~* = *TP*

*TP~c~*

*~c~* + *FP~c~*

*,* (2.77)

> 查全率（Recall），也叫召回率，类别*c*
> 的查全率为是所有真实标签为类别*c* 的样本中，预测正确的比例。

𝑌*~c~* = *TP*

> *TP~c~*

*~c~* + *FN~c~*

*,* (2.78)

> *F* 值（F Measure）是一个综合指标，为查准率和查全率的调和平均。
>
> (1 + *β*^2^) × P*~c~* × 𝑌*~c~*

F*~c~* =

> *β*2 × P*~c~*
>
> \+ 𝑌*~c~*
>
> *,* (2.79)
>
> 其中*β* 用于平衡查全率和查准率的重要性，一般取值为1。*β* = 1 时的F
> 值称为F1 值，是查准率和查全率的调和平均。
>
> 宏平均和微平均 为了计算分类算法在所有类别上的总体准确率、召回率和F1
> 值，经常使用两种平均方法，分别称为宏平均（macro
> average）和微平均（micro average）\[[Yang](\l), [1999](\l)\]。
>
> 宏平均是每一类的性能指标的算术平均值，
>
> [1]{.underline} Σ

P*macro* = *C*

> *c*=1

P*~c~,* (2.80)

> *C*
>
> 𝑌 𝑌 *,*

*macro*

> *C c*=1

F1*macro*

> = [2 × P*macro* × *Rmacro*]{.underline} *.* (2.82)
>
> *Pmacro Rmacro*

文 献 上，F1 值 的

均 为 F1macro =

而微平均是每一个样本的性能指标的算术平均。对于单个样本而言，它的

> ~1~ F1c。
>
> 准确率和召回率是相同的（要么都是1，要么都是0）。因此准确率的微平均和
> 召回率的微平均是相同的。同理，F1
> 值的微平均指标是相同的。当不同类别的样本数量不均衡时，使用宏平均会比微平均更合理些。宏平均会更关注于小类
> 别上的评价指标。
>
> 在实际应用中，我们通过调整分类模型的阈值来进行更全面的评价，比如AUC（Area
> Under Curve）、ROC（Receiver Operating Characteristic）曲线、
> PR（Precision-Recall）曲线等。此外，很多任务还有自己专门的评价方式，比如TopN
> 准确率。
>
> 交叉验证 交叉验证（Cross
> Validation）是一种比较好的可能衡量机器学习模型的统计分析方法，可以有效避免划分训练集和测试集时的随机性对评价结果造
> 成的影响。我们可以把原始数据集平均分为*K* 组不重复的子集，每次选*K* −
> 1 组子集作为训练集，剩下的一组子集作为验证集。这样可以进行*K*
> 次试验并得
>
> 关于更详细的模型评价指标， 可以参考《机器学习》\[[周志华](\l),
> [2016](\l)\] 的第二章。
>
> 到*K* 个模型。这*K*
> 个模型在各自验证集上的错误率的平均作为分类器的评价。
>
> *K* 一般大于3。

#### 理论和定理

> 在机器学习中，有一些非常有名的理论或定理，对理解机器学习的内在特
> 性非常有帮助。

1.  **PAC** 学习理论

> 当使用机器学习方法来解决某个特定问题时，通常靠经验或者多次试验来选择合适的模型、训练样本数量以及学习算法收敛的速度等。但是经验判断或多次试验往往成本比较高，也不太可靠，因此希望有一套理论能够分析问题难度、
> 计算模型能力，为学习算法提供理论保证，并指导机器学习模型和学习算法的设计。这就是计算学习理论。计算学习理论（Computational
> Learning Theory）
> 是关于机器学习的理论基础，其中最基础的理论就是可能近似正确（Probably
> Approximately Correct，PAC）学习理论。
>
> 机器学习中一个很关键的问题是期望错误和经验错误之间的差异，称为泛
> 化错误（Generalization Error）。泛化错误可以衡量一个机器学习模型*f*
> 是否可以很好地泛化到未知数据。
>
> G~D~(*f* ) = 𝑌(*f* ) − 𝑌*emp*(*f* )*.* (2.83)
>
> 根据大数定律，当训练集大小\|D\| 趋向于无穷大时，泛化错误趋向于0，即
>
> "泛化错误"在有些文献中也指"期望错误"，指在未知样本上的错误。
>
> 经验风险趋近于期望风险。
>
> lim
>
> \|D\|→∞

𝑌(*f* ) − 𝑌*emp*(*f* ) = 0*.* (2.84)

> 由于我们不知道真实的数据分布 *p*(**x***, y*)，也不知道真实的目标函数
> *g*(**x**)， 因此期望从有限的训练样本上学习到一个期望错误为0 的函数*f*
> (**x**) 是不切实际
> 的。因此，需要降低对学习算法能力的期望，只要求学习算法可以以一定的概率学习到一个近似正确的假设，即PAC
> 学习。
>
> PAC 学习可以分为两部分：
>
> 一是"近似正确"（Approximately Correct）。一个假设 *f* ∈ F
> 是"近似正确"的，是指其在泛化错误G~D~(*f* ) 小于一个界限*ϵ*。*ϵ*
> 一般为0 到 ^1^ 之间的数， 0 *\< ϵ \<* ^1^ 。如果G~D~(*f* )
> 比较大，说明模型不能用来做正确的"预测"。
>
> 二是"可能"。一个学习算法A 有"可能"以1 − *δ*
> 的概率学习到这样一个"近似正确"的假设。*δ* 一般为0 到 ^1^ 之间的数，0
> *\< δ \<* ^1^ 。
>
> 2 2
>
> 一个PAC
> 可学习的算法是指该学习算法能够在多项式时间内从合理数量的训练数据中学习到一个近似正确的*f*
> (**x**)。
>
> *P* (𝑌(*f* ) − 𝑌*emp*(*f* )) ≤ *ϵ* ≥ 1 − *δ,* (2.85)
>
> 其中*ϵ*,*δ* 是和样本数量*n*、假设空间F
> 相关的变量。如果固定*ϵ*,*δ*，可以反过来计算出样本复杂度为
>
> 1 2
>
> \[[Blum et al.](\l), [2016](\l)\] 定理5.3。
>
> *n*(*ϵ, δ*) ≥ 2*ϵ*2 (ln \|F\| + ln *δ* )*,* (2.86)
>
> 其中\|F\| 为假设空间的大小。
>
> PAC
> 学习理论也可以帮助分析一个机器学习方法在什么条件下可以学习到一个近似正确的分类器。从公式([2.86](\l))
> 可以看出，如果希望模型的假设空间越大，泛化错误越小，其需要的样本数量越多。

###### 没有免费午餐定理

> 没有免费午餐定理（No Free Lunch Theorem，NFL）是由Wolpert 和Mac-
> erday在最优化理论中提出的。没有免费午餐定理证明：对于基于迭代的最优化算法，不存在某种算法对所有问题（有限的搜索空间内）都有效。如果一个算法对某些问题有效，那么它一定在另外一些问题上比纯随机搜索算法更差。也就是说，不能脱离具体问题来谈论算法的优劣，任何算法都有局限性。必须要"具体问题具体分析"。
>
> 没有免费午餐定理对于机器学习算法也同样适用。不存在一种机器学习算
> 法适合于任何领域或任务。如果有人宣称自己的模型在所有问题上都好于其他
> 模型，那么他肯定是在吹牛。

###### 丑小鸭定理

> 丑小鸭定理（Ugly Duckling Theorem）是1969
> 年由渡边慧提出的\[[Watan-](\l) [able](\l),
> [1969](\l)\]。"丑小鸭与白天鹅之间的区别和两只白天鹅之间的区别一样大"。这个定理初看好像不符合常识，但是仔细思考后是非常有道理的。因为世界上不
> 存在相似性的客观标准，一切相似性的标准都是主观的。如果以体型大小的角
> 度来看，丑小鸭和白天鹅的区别大于两只白天鹅的区别；但是如果以基因的角
> 度来看，丑小鸭与它父母的差别要小于他父母和其他白天鹅之间的差别。

###### 奥卡姆剃刀

> 奥卡姆剃刀（Occam's Razor）是由14 世纪逻辑学家William of Occam
> 提出的一个解决问题的法则："如无必要，勿增实体"。奥卡姆剃刀的思想和机器学习上正则化思想十分类似：简单的模型泛化能力更好。如果有两个性能相近
> 的模型，我们应该选择更简单的模型。因此，在机器学习的学习准则上，我们
> 经常会引入参数正则化来限制模型能力，避免过拟合。
>
> 奥卡姆剃刀的一种形式化是最小描述长度（Minimum Description Length，
> MDL）原则，即对一个数据集D，最好的模型*f* ∈ F
> 是会使得数据集的压缩效果最好，即编码长度最小。
>
> 最小描述长度也可以通过贝叶斯学习的观点来解释\[[MacKay and Mac
> Kay](\l), [2003](\l)\]。模型*f* 在数据集D 上的对数后验概率为
>
> max log *p*(*f* \|D) = max log *p*(D\|*f* ) + log *p*(*f* ) (2.87)
>
> [渡边慧（Satosi Watanabe）， 1910-1993，美籍日本学者，
> 理论物理学家，也是模式识 别的最早研究者之一。](\l)
>
> 这里的"丑小鸭"是指白天鹅的幼雏，而不是"丑陋的小鸭子"。
>
> *f f*
>
> = min − log *p*(D\|*f* ) − log *p*(*f* )*,* (2.88)
>
> 其中− log *p*(*f* ) 和− log *p*(D\|*f* ) 可以分别看作是模型*f*
> 的编码长度和在该模型下数据集D
> 的编码长度。也就是说，我们不但要使得模型*f*
> 可以编码数据集D，也要使得模型*f* 尽可能简单。

###### 归纳偏置

> 在机器学习中，很多学习算法经常会对学习的问题做一些假设，这些假设
> 就称为归纳偏置（Inductive Bias）[Mitchell](\l)
> \[[1997](\l)\]。比如在最近邻分类器中，我们会假设在特征空间中，一个小的局部区域中的大部分样本都同属一类。在朴
> 素贝叶斯分类器中，我们会假设每个特征的条件概率是相互独立的。
>
> 归纳偏置在贝叶斯学习中也经常称为先验（priors）。

#### 总结和深入阅读

> 本章简单地介绍了机器学习的基础知识，并为后面介绍的神经网络进行一
> 些简单的铺垫。机器学习算法虽然种类繁多，但其中三个基本的要素为：模型、学
> 习准则、优化算法。大部分的机器学习算法都可以看作是这三个基本要素的不同
> 组合。如果需要快速全面地了解机器学习的基本概念和体系可以阅读《Pattern
> Classiﬁcation》\[[Duda et al.](\l), [2001](\l)\]、《Machine Learning:
> a Probabilistic Per- spective》\[[Murphy](\l), [2012](\l)\]
> 和《机器学习》\[[周志华](\l), [2016](\l)\]。
>
> 目前机器学习中最主流的一类方法是统计学习方法，将机器学习问题看作
> 是统计推断问题，并且又可以进一步分为频率学派和贝叶斯学派。频率学派将
> 模型参数*θ* 看作是固定常数；而贝叶斯学派将参数*θ*
> 看作是随机变量，并且存在某种先验分布。想进一步深入了解统计学习的知识，可以阅读《Pattern
> Recog- nition and Machine Learning》\[[Bishop](\l), [2007](\l)\]
> 和《The Elements of Statistical Learning》\[[Hastie et al.](\l),
> [2009](\l)\]。关于统计学习理论的知识可以参考\[[Vapnik](\l),
> [1998](\l)\]。
>
> 此外，机器学习中一个重要内容是表示学习。[Bengio et al.](\l)
> \[[2013](\l)\] 系统地给
> 出了关于表示学习的全面综述。传统的表示学习方法，即特征选择和特征抽取，
> 可以参考《机器学习》\[[周志华](\l), [2016](\l)\] 中的第10 章和第11
> 章。

#### 习题

> 习题 **2-1** 分析为什么平方损失函数不适用于分类问题。
>
> 习题 **2-2** 在线性回归中，如果我们给每个样本(**x**(*n*)*,
> y*^(*n*))\ 赋予一个权重^
>
> *r*^(*n*)^，经验风险函数为
>
> *N*

𝑌(**w**) = 2

> *n*
>
> *r*(*n*) *y*

(*n*)

> − **w x**

(*n*) 2

*,* (2.89)

> 计算其最优参数**w**∗，并分析权重*r*^(*n*)\ 的作用。^
>
> 习题**2-3** 在线性回归中，如果样本数量*N* 小于特征数量*d* + 1，则*XX*T
> 的秩最大为*N* 。
>
> 习题**2-4**
> 在线性回归中，验证岭回归的解为结构风险最小化准则下的最小二乘法估计，见公式([2.45](\l))。
>
> 参考文献 2019 年 4 月 6 日 55
>
> 习题 **2-5** 在线性回归中，若假设标签*y* ∼ N(**w**T**x***,
> β*)，并用最大似然估计来优化参数时，验证最优参数为公式([2.51](\l))
> 的解。
>
> 习题 **2-6** 假设有*N* 个样本*x*^(1)^*, x*^(2)^*, , x*^(*N*)^
> 服从正态分布N(*µ, σ*^2^)，其
>
> 中*µ* 未知。（1）使用最大似然估计来求解最优参数*µ^ML^*。（2）若参数*µ*
> 为随机变量，并服从正态分布N(*µ*~0~*,
> σ*^2^)，使用最大后验估计来求解最优参数*µ^MAP^* 。
>
> 习题**2-7** 在习题[2-6](\l)中，证明当*N* →
> ∞时，最大后验估计趋向于最大似然估计。
>
> 习题 **2-8** 验证公式([2.60](\l))。
>
> 习题 **2-9**
> 试分析在什么因素会导致模型出现图[2.6](\l)所示的高偏差和高方差情况。
>
> 习题 **2-10** 验证公式([2.65](\l))。
>
> 习题 **2-11**
> 分别用一元、二元和三元特征的词袋模型表示文本"我打了张三"和"张三打了我"，并分析不同模型的优缺点。
>
> 习题 **2-12**
> 对于一个三类分类问题，数据集的真实标签和模型的预测标签如下：
>
> 真实标签 1 1 2 2 2 3 3 3 3
>
> 预测标签 1 2 2 2 3 3 3 1 2
>
> 分别计算模型的查准率、查全率、F1 值以及它们的宏平均和微平均。

#### 参考文献

> 周志华. 机器学习. 清华大学出版社, 北京, 2016. ISBN 978-7-302-206853-6.
>
> Yoshua Bengio, Aaron Courville, and Pas- cal Vincent. Representation
> learning: A re- view and new perspectives. *IEEE transac- tions on
> pattern analysis and machine in-*
>
> *telligence*, 35(8):1798--1828, 2013.
>
> Christopher M. Bishop. *Pattern recogni- tion and machine learning,
> 5th Edition*. In- formation science and statistics. Springer, 2007.
> ISBN 9780387310732.
>
> Avrim Blum, John Hopcroft, and Ravin-
>
> 56 2019 年 4 月 6 日 参考文献
>
> dran Kannan. Foundations of data science.
>
> *Vorabversion eines Lehrbuchs*, 2016.
>
> Léon Bottou. Large-scale machine learning with stochastic gradient
> descent. In *Pro- ceedings of COMPSTAT*, pages 177--186.
>
> Springer, 2010.
>
> Richard O. Duda, Peter E. Hart, and David G. Stork. *Pattern
> classiﬁcation, 2nd*
>
> *Edition*. Wiley, 2001. ISBN 9780471056690.
>
> Mark Andrew Hall. *Correlation-based fea- ture selection for machine
> learning*. PhD thesis, University of Waikato Hamilton,
>
> 1999.
>
> Trevor Hastie, Robert Tibshirani, and Jerome H. Friedman. *The
> elements of sta- tistical learning: data mining, inference, and
> prediction, 2nd Edition*. Springer se- ries in statistics. Springer,
> 2009. ISBN
>
> 9780387848570.
>
> Arthur E Hoerl and Robert W Kennard. Ridge regression: Biased
> estimation for nonorthogonal problems. *Technometrics*, 12
>
> (1):55--67, 1970.
>
> Yann LeCun, Corinna Cortes, and Christo- pher JC Burges. MNIST
> handwritten digit database. Online, 1998. URL http://yann.
> lecun.com/exdb/mnist.
>
> David JC MacKay and David JC Mac Kay. *Information theory, inference
> and learn- ing algorithms*. Cambridge university press, 2003.
>
> Tom M. Mitchell. *Machine learning*. McGraw Hill series in computer
> science. McGraw-Hill, 1997. ISBN 978-0-07-042807-
>
> 2.
>
> Kevin P. Murphy. *Machine learning - a probabilistic perspective*.
> Adaptive compu- tation and machine learning series. MIT Press, 2012.
> ISBN 0262018020.
>
> Arkadi Nemirovski, Anatoli Juditsky, Guanghui Lan, and Alexander
> Shapiro. Robust stochastic approximation approach to stochastic
> programming. *SIAM Journal* *on optimization*, 19(4):1574--1609, 2009.
>
> Vladimir Vapnik. *Statistical learning the-* *ory*. Wiley, New York,
> 1998.
>
> S Watanable. Knowing and guessing: A quantitative study of inference
> and informa- tion, 1969.
>
> Yiming Yang. An evaluation of statistical approaches to text
> categorization. *Informa- tion retrieval*, 1(1-2):69--90, 1999.
>
> 第**3** 章 线性模型
>
> 正确的判断来自于经验，而经验来自于错误的判断。
>
> --- Frederick P. Brooks
>
> 线性模型（Linear
> Model）是机器学习中应用最广泛的模型，指通过样本特征的线性组合来进行预测的模型。给定一个*d*
> 维样本\[*x*~1~*,* · · · *, x~d~*\]T，其线性组合函数为
>
> *f* (**x***,* **w**) = *w*~1~*x*~1~ + *w*~2~*x*~2~ + · · · +
> *w~d~x~d~* + *b* (3.1)

= **w**T**x** + *b,* (3.2)

> 其中**w** = \[*w*~1~*,* · · · *, w~d~*\]T 为*d* 维的权重向量，*b*
> 为偏置。上一章中介绍的线性回归就是典型的线性模型，直接用*f* (**x***,*
> **w**) 来预测输出目标*y* = *f* (**x***,* **w**)。
>
> 在分类问题中，由于输出目标 *y* 是一些离散的标签，而 *f* (**x***,*
> **w**) 的值域为实数，因此无法直接用 *f* (**x***,* **w**)
> 来进行预测，需要引入一个非线性的决策函数
>
> （decision function）*g*(·) 来预测输出目标

*y* = *g f* (**x***,* **w**) *,* (3.3)

> 其中*f* (**x***,* **w**) 也称为判别函数（discriminant function）。
>
> 对于两类分类问题，*g*(·) 可以是符号函数（sign function）
>
> *g f* (**x***,* **w**) = sgn *f* (**x***,* **w**) (3.4)
>
> 简单起见，这里用*f* (**x***,* **w**) 来表示*f* (**x***,* **w***, b*)。
>
> ,  +1 if *f* (**x***,* **w**) *\>* 0*,*
>
>  −1 if *f* (**x***,* **w**) *\<* 0*.*
>
> (3.5)
>
> 当*f* (**x***,* **w**) = 0 时不进行预测。公式([3.5](\l))
> 定义了一个典型的两类分类问题的决策函数，其结构如图[3.1](\l)所示。

######## ![](/root/autodl-tmp/project_knowledge/Doc_QA/Knowledge_based/1828695663060254721/image_output/7.《神经网络与深度学习》/media/image14.png) [ ]{.underline} [ ]{.underline}

图片识别内容


> 图 3.1 两类分类的线性模型
>
> *y* 有时也会表示为{0*,* 1}。
>
> 超平面就是三维空间中的平 面在更高维空间的推广。*d* 维空间中的超平面是
> *d* − 1 维的。在二维空间中，决策边界为一个直线；在三维空间中，
> 决策边界为一个平面；在高 维空间中，决策边界为一个 超平面。
>
> 参见习题[3-2](\l)。
>
> 在本章，我们主要介绍四种不同线性分类模型：logistic 回归、softmax
> 回归、感知器和支持向量机，这些模型区别主要在于使用了不同的损失函数。

#### 线性判别函数和决策边界

> 从公式([3.3](\l))可知，一个线性分类模型（Linear Classiﬁcation
> Model）或线性分类器（Linear
> Classiﬁer），是由一个（或多个）线性的判别函数*f* (**x***,* **w**) =
> **w**T**x** + *b* 和非线性的决策函数*g*(·)
> 组成。我们首先考虑两类分类的情况，然后在扩展到多类分类的情况。

###### 两类分类

> 两类分类（Binary Classiﬁcation）的类别标签*y*
> 只有两种取值，通常可以设为{+1*,* −1}。
>
> 在两个分类中，我们只需要一个线性判别函数*f* (**x***,* **w**) =
> **w**T**x** + *b*。特征空间R*d* 中所有满足*f* (**x***,* **w**) = 0
> 的点组成用一个分割超平面（hyperplane），称为决策边界（decision
> boundary）或决策平面（decision
> surface）。决策边界将特征空间一分为二，划分成两个区域，每个区域对应一个类别。
>
> 所谓"线性分类模型"就是指其决策边界是线性超平面。在特征空间中，
> 决策平面与权重向量 **w**
> 正交。特征空间中每个样本点到决策平面的有向距离
>
> （signed distance）为
>
> *γ* = *.* (3.6)
>
> ∥ ∥
>
> *γ* 也可以看作是点**x** 在**w** 方向上的投影。
>
> 图[3.2](\l)给出了一个两维数据的线性决策边界示例，其中样本特征向量
> **x** = \[*x*~1~*, x*~2~\]，权重向量**w** = \[*w*~1~*, w*~2~\]。

1.  线性判别函数和决策边界 2019 年 4 月 6 日 59

> *x*~1~
>
> *x*~2~
>
> 图 3.2 两类分类的决策边界示例
>
> 给定*N* 个样本的训练集D = {(**x**(*n*)*,
> y*^(*n*))}*N*\ ，其中*y*(*n*)\ ∈\ {+1*,*\ −1}，线^
>
> 性模型试图学习到参数**w**∗，使得对于每个样本(**x**(*n*)*,
> y*^(*n*))\ 尽量满足^
>
> *f* (**x**(*n*)*,* **w**∗) *\>* 0 if *y*^(*n*)^ = 1*,*
>
> *f* (**x**(*n*)*,* **w**∗) *\<* 0 if *y*^(*n*)^ = −1*.*
>
> 上面两个公式也可以合并，即参数**w**∗ 尽量满足
>
> (3.7)
>
> *y*^(*n*)^*f* (**x**(*n*)*,* **w**∗) *\>* 0*,* ∀*n* ∈ \[1*, N* \]*.*
> (3.8)
>
> 为了学习参数**w**，我们需要定义合适的损失函数以及优化方法。对于两类
> 分类问题，最直接的损失函数为0-1 损失函数，即
>
> L~01~ *y, f* (**x***,* **w**) = *I yf* (**x***,* **w**) *\>* 0 *,*
> (3.9)
>
> 其中 *I*(·) 为指示函数。但0-1 损失函数的数学性质不好，其关于 **w**
> 的导数为0， 从而导致无法优化**w**。
>
> 1 ≤ *i \< j* ≤ *C*

######  多类分类

> 多类分类（Multi-class Classiﬁcation）问题是指分类的类别数*C*
> 大于2。多类分类一般需要多个线性判别函数，但设计这些判别函数有很多种方式。
>
> 假设一个多类分类问题的类别为{1*,* 2*,* · · · *,
> C*}，常用的方式有以下三种：

1.  "一对其余"方式：把多类分类问题转换为*C*
    > 个"一对其余"的两类分类问题。这种方式共需要*C*
    > 个判别函数，其中第*c* 个判别函数*f~c~* 是将类*c*
    > 的样本和不属于类*c* 的样本分开。

2.  "一对一"方式：把多类分类问题转换为*C*(*C* − 1)*/*2
    > 个"一对一"的两类分类问题。这种方式共需要*C*(*C* − 1)*/*2
    > 个判别函数，其中第(*i, j*) 个判别函数是把类*i* 和类*j*
    > 的样本分开。

3.  "*argmax*"方式：这是一种改进的"一对其余"方式，共需要*C*
    > 个判别函数*f~c~*(**x***,* **w***~c~*) = **w**T**x** + *b~c~, c* =
    > \[1*,* · · · *, C*\] (3.10)

> 如果存在类别*c*，对于所有的其他类别*c*˜(*c*˜ ≠ *c*)
> 都满足*f~c~*(**x***,* **w***~c~*) *\> f~c~*~˜~(**x***,*
> **w**~*c*˜~)，那么**x** 属于类别*c*。即
>
> *y* = arg max *f~c~*(**x***,* **w***~c~*)*.* (3.11)
>
> *c*=1
>
> 参见习题[3-3](\l)。
> "一对其余"方式和"一对一"方式都存在一个缺陷：特征空间中会存在
> 一些难以确定类别的区域，而"argmax"方式很好地解决了这个问题。图[3.3](\l)给出了用这三种方式进行三类分类的示例，其中不用颜色的区域表示预测的类别，
> 红色直线表示判别函数*f* (·) = 0 的直线。在"argmax"方式中，相邻两类*i*
> 和*j* 的决策边界实际上是由*f~i~*(**x***,* **w***~i~*) −
> *f~j~*(**x***,* **w***~j~*) = 0 决定，其法向量为**w***~i~* −
> **w***~j~*。

𝑓1

𝑓1

> 𝑓12

a.  "一对其余"方式

b.  "一对一"方式

> 图 3.3 三个多类分类方式

c.  "argmax"方式

<!-- -->

2.  Logistic 回归 2019 年 4 月 6 日 61

> 从上面定义可以，如果数据集可以多类线性可分的，那么一定存在一个"argmax"
> 方式的线性分类器可以将它们正确分开。

2.  **Logistic** 回归

> *Logistic* 回归（Logistic
> Regression，LR）是一种常用的处理两类分类问题的线性模型。在本节中我们采用*y*
> ∈ {0*,* 1} 以符合logistic 回归的描述习惯。
>
> 为了解决连续的线性函数不适合进行分类的问题，我们引入非线性函数*g* :
>
> R*d* → (0*,* 1) 来预测类别标签的后验概率*p*(*y* = 1\|**x**)。
>
> *p*(*y* = 1\|**x**) = *g*(*f* (**x***,* **w**))*,* (3.12)
>
> 其中*g*(·) 通常称为激活函数（activation
> function），其作用是把线性函数的值域从实数区间"挤压"到了(0*,* 1)
> 之间，可以用来表示概率。在统计文献中，*g*(·) 的逆函数*g*^−1^(·)
> 也称为联系函数（link function）。
>
> 参见习题[3-4](\l)。
>
> 在logistic 回归中，我们使用logistic 函数来作为激活函数。标签*y* = 1
> 的后 logistic 函数参见第[B.2.3](\l)节。
>
> 验概率为

*p*(*y* = 1\|**x**) = *σ*(**w**T**x**) (3.13)

, [ 1]{.underline} *,* (3.14)

> 1 + exp(−**w**T**x**)
>
> 标签*y* = 0 的后验概率为

*p*(*y* = 0\|**x**) = 1 − *p*(*y* = 1\|**x**) (3.15)

T

> 1 + exp(−**w**T**x**) *.* (3.16)
>
> 图[3.4](\l)给出了使用线性回归和logistic
> 回归来解决一维的两类分类问题示例。
>
> 简 单 起 见， 这 里**x** = \[*x*~1~*,* · · · *, x*~d~*,* 1\]T和 **w**
> = \[*w*~1~*,* · · · *, w*~d~*, b*\]T 分别为 *d* + 1
> 维的增广特征向量和增广权重向量。
>
> 将公式([3.14](\l)) 进行变换后得到
>
> T *p*(*y* = 1\|**x**)
>
> − *p*(*y* = 1\|**x**)
>
> (3.17)
>
> = log [*p*(*y* = 1\|**x**)]{.underline} *,* (3.18)
>
> *p*(*y* = 0\|**x**)
>
> ![](/root/autodl-tmp/project_knowledge/Doc_QA/Knowledge_based/1828695663060254721/image_output/7.《神经网络与深度学习》/media/image27.png)1*.*5
>
图片识别内容

>
> *y* = 0*.*50 x+0*.*53
>
> 1
>
> 0
>
> 1
>
> 0*.*5
>
> 0
>
> −1
>
> −1*.*5 −1 −0*.*5 0 0*.*5 1 1*.*5

a.  线性回归

> −0*.*5
>
> −3 −2 −1 0 1

b.  Logistic 回归

> 图 3.4 一维数据的两类问题示例
>
> 其中 ^[*p*(*y*=1\|**x**)]{.underline}^ 为样本**x**
> 为正反例后验概率的比值，称为几率（odds），几率的对

\|

> 数称为对数几率（log odds，或logit）。公式([3.17](\l))
> 的左边是线性函数，logistic
> 回归可以看作是预测值为"标签的对数几率"的线性回归模型。因此，logistic
> 回归也称为对数几率回归（Logit Regression）。

###### 参数学习

> Logistic
> 回归采用交叉熵作为损失函数，并使用梯度下降法来对参数进行优化。
>
> 给定*N* 个训练样本{(**x**(*n*)*,
> y*^(*n*))}*N*\ ，用logistic\ 回归模型对每个样本**x**(*n*)^
>
> 进行预测，并用输出**x**(*n*) 的标签为1 的后验概率，记为*y*ˆ(*n*)，
>
> *y*ˆ(*n*) = *σ*(**w**T**x**(*n*))*,* 1 ≤ *n* ≤ *N.* (3.19)
>
> 由于*y*^(*n*)\ ∈\ {0*,*\ 1}，样本(**x**(*n*)*,\ y*(*n*))\ 的真实条件概率可以表示为^
>
> *p~r~*(*y*^(*n*)^ = 1\|**x**(*n*)) = *y*^(*n*)^*,* (3.20)
>
> *p~r~*(*y*^(*n*)^ = 0\|**x**(*n*)) = 1 − *y*^(*n*)^*.* (3.21)
>
> 简单起见，这里忽略了正则
>
> 使用交叉熵损失函数，其风险函数为：

化项。

[1]{.underline} ΣN

> ( ) ( ) ( )
>
> ( ) ( )
>
> ( )

𝑌(**w**) = − *N*

> n=1
>
> *p*r(*y* n
>
> = 1\|**x** ^n^ ) log *y*ˆ ^n^
>
> \+ *p*r(*y* n
>
> = 0\|**x** ^n^ ) log(1 − *y*ˆ ^n^ )
>
> (3.22)

[1]{.underline} ΣN

> ( ) ( ) ( )
>
> ( )
>
> 风险函数𝑌(**w**) 关于参数**w** 的偏导数为：
>
> [*∂*𝑌(**w**)]{.underline} [ 1]{.underline} ΣN ( ) *y*ˆ^(n)^(1 −
> *y*ˆ^(n)^) ~(~ ~)~
>
> ( ) *y*ˆ(n)(1 − *y*ˆ(n))
>
> ( )

[1]{.underline} ΣN

> ( )
>
> ( ) ( )
>
> ( ) ( )
>
> ( )
>
> 见第[B.2.3](\l)节。

[1]{.underline} ΣN

> ( ) ( )
>
> ( )
>
> 采用梯度下降法，logistic 回归的训练过程为：初始化**w**~0~ ←
> 0，然后通过下式来迭代更新参数。

**w***t*+1 ←

> **w***~t~* + *α*

*N*

> *n*Σ=1

**x**(*n*) *y*

(*n*)

> − *y*ˆ(*n*) *,*
>
> (3.27)
>
> 其中*α* 是学习率，*y*ˆ^(*n*)^ 是当参数为**w** 时，logistic
> 回归模型的输出。
>
> **w***t t*
>
> 从公式([3.23](\l)) 可知，风险函数𝑌(**w**) 是关于参数**w**
> 的连续可导的凸函数。因此除了梯度下降法之外，logistic
> 回归还可以用高阶的优化方法，比如牛顿法，来进行优化。

### Softmax 回归

> *Softmax* 回归（Softmax Regression），也称为多项（multinomial）或多类
>
> （multi-class）的logistic 回归，是logistic
> 回归在多类分类问题上的推广。 Softmax 回归也可以看作是
>
> 对于多类问题，类别标签*y* ∈ {1*,* 2*,* · · · *, C*} 可以有*C*
> 个取值。给定一个样本**x**，softmax 回归预测的属于类别*c*
> 的条件概率为：
>
> *p*(*y* = *c*\|**x**) = softmax(**w**T**x**) (3.28)
>
> 一种条件最大熵模型，参见第[11.1.5.1](\l)节。

= exp(**w***~c~*𝖳**x**)

> *,* (3.29)
>
> *C*
>
> *c*=1
>
> exp(**w***~c~*𝖳**x**)
>
> 其中**w***~c~* 是第*c* 类的权重向量。 softmax 函 数 参 见
>
> Softmax 回归的决策函数可以表示为：
>
> 第[B.2.4](\l)节。

*C*

*y p y c*

> *c*=1
>
> = arg*^C^*max **w**T**x***.* (3.31)
>
> *c*=1
>
> 与 **logistic** 回归的关系 当类别数*C* = 2 时，softmax
> 回归的决策函数为
>
> *y*ˆ = arg max **w**T**x** (3.32)
>
> *y*∈{0*,*1}
>
> = *I* **w**T**x** − **w**T**x** *\>* 0 (3.33)
>
> = *I* (**w**~1~ − **w**~0~)T**x** *\>* 0 *,* (3.34)
>
> 其中*I*(·) 是指示函数。对比公式([3.5](\l))
> 中的两类分类决策函数，可以发现两类分类中的权重向量**w** = **w**~1~ −
> **w**~0~。
>
> 向量表示 公式([3.29](\l)) 用向量形式可以写为：
>
> **y**ˆ = softmax(*W* T**x**) (3.35)
>
> T
>
> **1**T exp (*W* T**x**) *,* (3.36)
>
> 其中*W* = \[**w**~1~*,* · · · *,* **w***~C~*\] 是由*C*
> 个类的权重向量组成的矩阵，**1** 为全1 向量，**y**ˆ ∈ R*C*
> 为所有类别的预测条件概率组成的向量，第 *c* 维的值是第 *c*
> 类的预测条件概率。
>
> **3.3.1** 参数学习
>
> 给定*N* 个训练样本{(**x**(*n*)*,
> y*^(*n*))}*N*\ ，softmax\ 回归使用交叉熵损失函数来^
>
> 简单起见，这里忽略了正则
>
> 学习最优的参数矩阵*W* 。
>
> 为了方便起见，我们用*C* 维的one-hot向量**y** ∈ {0*,* 1}*C*
> 来表示类别标签。对于类别*c*，其向量表示为
>
> **y** = \[*I*(1 = *c*)*, I*(2 = *c*)*,* · · · *, I*(*C* = *c*)\]T*,*
> (3.37)
>
> 其中*I*(·) 是指示函数。
>
> 采用交叉熵损失函数，softmax 回归模型的风险函数为：
>
> 化项。 *N C*

𝑌(*W* ) = −

> Σ Σ **y**(*n*) log **y**ˆ(*n*)
>
> (3.38)

= − [ 1]{.underline}

> Σ(**y**( ))T log **y**ˆ(*n*)*,* (3.39)
>
> *n*
>
> *n*=1
>
> 其中**y**ˆ(*n*) = softmax(*W* T**x**(*n*)) 为样本**x**(*n*)
> 在每个类别的后验概率。
>
> 风险函数𝑌(*W* ) 关于*W* 的梯度为

[*∂*𝑌(*W* )]{.underline} =

> [1]{.underline} Σ
>
> **x**( ) **y**( )
>
> **y**ˆ( ) T
>
> (3.40)
>
> 证明*.* 计算公式([3.40](\l))
> 中的梯度，关键在于计算每个样本的损失函数L(*n*)(*W* ) =
>
> −(**y**(*n*))T log **y**ˆ(*n*) 关于参数*W*
> 的梯度，其中需要用到的两个导数公式为：

1.  若**y** = softmax(**z**)，则 ^[*∂***y**]{.underline}^ = diag (**y**)
    > − **yy**𝖳。 softmax 函数的导数

2.  若**z** = *W* T**x** = \[**w**T**x***,* **w**T**x***,* · · · *,*
    > **w**T **x**\]T，则 [^\ *∂***z**^]{.underline} 为第*c*
    > 列为**x**，其余为0 的

> 参见第[B.2.4](\l)节。

矩阵。

> 1 2 *C ∂***w***~c~*
>
> *∂***z** *∂***w**T**x** *∂***w**T**x** *∂***w**T **x**
>
> = \[ [^\ 1^]{.underline} *, [ ]{.underline}*[^2^]{.underline} *,* · ·
> · *, [^\ C^]{.underline}* \] (3.41)

*∂***w***~c~*

> *∂***w***~c~*
>
> *∂***w***~c~*
>
> *∂***w***~c~*
>
> = \[**0***,* **0***,* · · · *,* **x***,* · · · *,* **0**\] (3.42)
>
> , M*~c~*(**x**)*.* (3.43)
>
> 根据链式法则，L(*n*)(*W* ) = −(**y**(*n*))T log **y**ˆ(*n*)
> 关于**w***~c~* 的偏导数为
>
> *∂*L(n)(*W* ) =

*∂* c

=

> *∂* (**y**(n))^T^ log **y**ˆ^(n)^
>
> − *∂***w**c
>
> *∂***z**(n) *∂***y**ˆ^(n)^ *∂* log **y**ˆ^(n)^
>
> (n)
>
> (3.44)

− *∂***w**c

> *∂***z**(n)
>
> *∂***y**ˆ(n) **y**
>
> (3.45)
>
> = −M (**x**^(n)^) diag **y**ˆ^(n)^ − **y**ˆ^(n)^(**y**ˆ^(n)^)^T^
> diag(**y**ˆ^(n)^) −1 **y**^(n)^
>
> (3.46)
>
> **y**T diag(**y**)^−1^ = **1**T 为全 **1** 的
>
> = −Mc(**x**^(n)^) **I** −
>
> **y**ˆ(n)**1**T **y**(n)

(3.47)

> 行向量。
>
> = −Mc(**x**(n)) **y**(n) − **y**ˆ(n)**1**T**y**(n)

(3.48)

> 因为**y** 为onehot 向量，所以
>
> = −Mc(**x**(n)) **y**(n)
>
> − **y**ˆ(n)

(3.49)

> **1**T**y** = 1。
>
> = −**x**(n) **y**(n) − **y**ˆ(n) *.*
>
> (3.50)
>
> 公式([3.50](\l)) 也可以表示为非向量形式，

*∂*L(*n*)(*W* ) =

*∂ ~c~*

> −**x**(*n*)

*I*(*y*

(*n*) =

> *c*) −
>
> **y**ˆ(*n*) *,*
>
> (3.51)
>
> 其中*I*(·) 是指示函数。
>
> 根据公式([3.50](\l)) 可以得到

*∂*L(*n*)(*W* ) =

*∂W*

> −**x**(*n*) **y**(*n*)
>
> − **y**ˆ(*n*) T
>
> (3.52)
>
> 采用梯度下降法，softmax 回归的训练过程为：初始化*W*~0~ ←
> 0，然后通过下式进行迭代更新。

\+ [1]{.underline} Σ

> **x**( ) **y**( )
>
> **y**ˆ( ) T!
>
> (3.53)
>
图片识别内容

> 是当参数为*W~t~* 时，softmax 回归模型的输出。
>
> 要注意的是，softmax 回归中使用的*C*
> 个权重向量是冗余的，即对所有的权重向量都减去一个同样的向量
> **v**，不改变其输出结果。因此， softmax
> 往往需要使用正则化来约束其参数。此外，我们可以利用这个特性来避免计算softmax
> 函数时在数值计算上溢出问题。
>
> Frank Rosenblatt，1928 年- 1971 年，美国心理学家，人工智能领域开拓者。
>
> 最早发明的感知器是一台机器而不是一种算法，后来才被实现为IBM 704
> 机器上可运行的程序。

####  感知器

> 感知器（Perceptron）由Frank Roseblatt 于1957
> 年提出，是一种广泛使用的线性分类器。感知器可谓是最简单的人工神经网络，只有一个神经元。
>
> 感知器是对生物神经元的简单数学模拟，有与生物神经元相对应的部件，如
> 权重（突触）、偏置（阈值）及激活函数（细胞体），输出为+1 或-1。
>
> 感知器是一种简单的两类线性分类模型，其分类准则与公式([3.5](\l)) 相同。
>
> *y*ˆ = sgn(**w**T**x**)*.* (3.54)

###### 参数学习

> 感知器学习算法也是一个经典的线性分类器的参数学习算法。
>
> 给定*N* 个样本的训练集: {(**x**(*n*)*,
> y*^(*n*))}*N*\ ，其中*y*(*n*)\ ∈\ {+1*,*\ −1}，感知器^
>
> 试图学习感知器试图学习到参数**w**∗，使得对于每个样本(**x**(*n*)*,
> y*^(*n*))\ 有^

*y*^(*n*)^**w**∗T**x**(*n*) *\>* 0*,* ∀*n* ∈ \[1*, N* \]*.* (3.55)

> 感知器的学习算法是一种错误驱动的在线学习算法\[[Rosenblatt](\l),
> [1958](\l)\]。先初始化一个权重向量**w** ←
> 0（通常是全零向量），然后每次分错一个样本(**x***,
> y*)时，即*y***w**T**x** *\<* 0，就用这个样本来更新权重。

**w** ← **w** + *y***x***.* (3.56)

> 具体的感知器参数学习策略如算法[3.1](\l)所示。
>
> 算法 **3.1:** 两类感知器算法
>
> 输入**:** 训练集{(**x**(*n*)*, y*^(*n*))}*N*\ ，迭代次数*T*^
>
> **1** 初始化：**w**~0~ ← 0, *k* ← 0 ;
>
> **2 for** *t* = 1 · · · *T* **do**
>
> **3** 随机对训练样本进行随机排序;
>
> **4 for** *n* = 1 · · · *N* **do**
>
> **5** 选取一个样本(**x**(*n*)*, y*^(*n*));^
>
> **6 if w**T(*y*^(*n*)^**x**(*n*)) ≤ 0 **then**
>
> **7 w***k*+1 ← **w***k* + *y*(*n*)**x**(*n*);
>
> **8** *k* ← *k* + 1;
>
> **9 end**
>
> **10 end**
>
> **11 end**
>
> [ 输出]{.underline}[**: w***~k~ *]{.underline}
>
> 根据感知器的学习策略，可以反推出感知器的损失函数为：
>
> L(**w**; **x***, y*) = max(0*,* −*y***w**T**x**)*.* (3.57)
>
> 采用随机梯度下降，其每次更新的梯度为

[*∂*L(**w**; **x***, y*)]{.underline} =

> 0 if *y***w**T**x** *\>* 0*,*

T

> (3.58)

*∂*  −*y***x** if *y***w x** *\<* 0*.*

> 图[3.5](\l)给出了感知器参数学习的更新过程，其中红色实心点为正例，蓝色空
> 心点为负例。黑色箭头表示权重向量，红色虚线箭头表示权重的更新方向。
>
> ![](/root/autodl-tmp/project_knowledge/Doc_QA/Knowledge_based/1828695663060254721/image_output/7.《神经网络与深度学习》/media/image30.png)1
> 1

0.5

0

-0.5

> 0.5
>
> ![](/root/autodl-tmp/project_knowledge/Doc_QA/Knowledge_based/1828695663060254721/image_output/7.《神经网络与深度学习》/media/image34.png)0
>
> -0.5

-1 [ ]{.underline}

-1 -0.5 0 0.5 1

> -1
>
> -1 -0.5 0 0.5 1
>
> ![](/root/autodl-tmp/project_knowledge/Doc_QA/Knowledge_based/1828695663060254721/image_output/7.《神经网络与深度学习》/media/image30.png)1
> 1
>
> 0.5 0.5

0

-0.5

-1

> \- w3
>
> \+
>
> [ ]{.underline}
>
> -1 -0.5 0 0.5 1

0

-0.5

-1

> 图 3.5 感知器参数学习的更新过程

###### 感知器的收敛性

> [Novikoﬀ](\l) \[[1963](\l)\]
> 证明对于两类问题，如果训练集是线性可分的，那么感知器算法可以在有限次迭代后收敛。然而，如果训练集不是线性分隔的，那么这个
> 算法则不能确保会收敛。
>
> 当数据集是两类线性可分时，对于训练集D = (**x**(*n*)*,
> y*^(*n*))}*N*\ ，其中**x**(*n*)^
>
> 为样本的增广特征向量，*y
> ^n^*^)\ ∈\ {−1*,*\ 1}，那么存在一个正的常数*γ*(*γ\ \>*\ 0)\ 和权^
>
> 重向量**w**∗，并且∥**w**∗∥ = 1，对所有*n*
> 都满足(**w**∗)T(*y*^(*n*)^**x**(*n*)) ≥ *γ*。我们可以证明如下定理。
>
> 证明*.* 感知器的权重向量的更新方式为
>
> **w***~k~* = **w**~*k*−1~ + *y*^(*k*)^**x**(*k*)*,* (3.59)
>
> 其中**x**(*k*)*, y*^(*k*)\ 表示第*k*\ 个错误分类的样本。^
>
> 因为初始权重向量为0，在第*K* 次更新时感知器的权重向量为
>
> *K*
>
> **w***~K~* = *y*^(*k*)^**x**(*k*)*.* (3.60)
>
> *k*=1
>
> 分别计算∥**w***~K~*∥2 的上下界：
>
> （1）∥**w***~K~*∥2 的上界为：

∥**w***~K~*∥

> = ∥**w**~*K*−1~ + *y*

(*K*)

**x**(*K*)∥

> (3.61)
>
> *y*~k~**w**T **x**(K) ≤ 0*.*
>
> = ∥**w***K*−1∥2 + ∥*y*(*K*)**x**(*K*)∥2 + 2*y*(*K*)**w**T
>
> **x**(*K*)
>
> (3.62)
>
> ≤ ∥**w**~*K*−1~∥
>
> ≤ ∥**w**~*K*−2~∥
>
> ≤ *KR*
>
> \+ *R*^2^
>
> \+ 2*R*^2^
>
> (3.63)
>
> (3.64)
>
> (3.65)
>
> （2）∥**w***~K~*∥2 的下界为：
>
> ∥**w***~K~*∥2 = ∥**w**∗∥2 · ∥**w***~K~*∥2
>
> ≥ ∥**w**∗T**w***~K~*∥2
>
> *K*
>
> = **w**∗T (*y*(*k*)**x**(*k*)) 2
>
> *k*=1

(3.66)

(3.67)

(3.68)

> ∥**w**∗∥ = 1*.*
>
> 两个向量内积的平方一定小于等于这两个向量的模的乘积
>
> *K*

= **w**∗T(*y*(*k*)**x**(*k*)) 2

> *k*=1

(3.69)

> **w**∗T(*y*^(n)^**x**(n)) ≥ *γ,* ∀*n.*

≥ *K*

> 由公式([3.65](\l)) 和([3.70](\l))，得到

2*γ*2*.*

> (3.70)
>
> *K*^2^*γ*^2^ ≤ \|\|**w***~K~*\|\|2 ≤ *KR*^2^*.* (3.71)
>
> 取最左和最右的两项，进一步得到，*K*^2^*γ*^2^ ≤
> *KR*^2^。然后两边都除*K*，最终得到

2

> *K* ≤ *γ*2 *.* (3.72)
>
> 因此，在线性可分的条件下，算法[3.1](\l)会在 *^R^*2 步内收敛。
>
> 虽然感知器在线性可分的数据上可以保证收敛，但其存在以下不足之处：

1.  在数据集线性可分时，感知器虽然可以找到一个超平面把两类数据分开，
    > 但并不能保证能其泛化能力。

2.  感知器对样本顺序比较敏感。每次迭代的顺序不一致时，找到的分割超平
    > 面也往往不一致。

3.  如果训练集不是线性可分的，就永远不会收敛\[[Freund and Schapire](\l),
    > [1999](\l)\]。

    3.  ###### 参数平均感知器

> 根据定理[3.1](\l)，如果训练数据是线性可分的，那么感知器可以找到一个判别
> 函数来分割不同类的数据。如果间隔*γ*
> 越大，收敛越快。但是感知器并不能保证找到的判别函数是最优的（比如泛化能力高），这样可能导致过拟合。
>
> 感知器的学习到的权重向量和训练样本的顺序相关。在迭代次序上排在后
> 面的错误样本，比前面的错误样本对最终的权重向量影响更大。比如有1*,* 000
> 个训练样本，在迭代100
> 个样本后，感知器已经学习到一个很好的权重向量。在接下来的899
> 个样本上都预测正确，也没有更新权重向量。但是在最后第1*,* 000
> 个样本时预测错误，并更新了权重。这次更新可能反而使得权重向量变差。
>
> 投票感知器是一种集成模型， 参见第[10.1](\l)节。
>
> 为了改善这种情况，可以使用"参数平均"的策略来提高感知器的鲁棒性，
> 也叫投票感知器（Voted Perceptron）\[[Freund and Schapire](\l),
> [1999](\l)\]。
>
> 投票感知器记录第 *k* 次更新后得到的权重 **w***~k~*
> 在之后的训练过程中正确分类样本的次数*c~k~*。这样最后的分类器形式为：
>
> *K*
>
> *y*ˆ = sgn *c~k~* sgn(**w**T

**x**) (3.73)

> 其中sgn(·) 为符号函数。
>
> *k*
>
> *k*=1
>
> 投票感知器虽然提高了感知器的泛化能力，但是需要保存 *K*
> 个权重向量。在实际操作中会带来额外的开销。因此，人们经常会使用一个简化的版本，也叫做平均感知器（Averaged
> Perceptron）\[[Collins](\l), [2002](\l)\]。

*K*

*y*ˆ = sgn *c~k~*(**w**T

**x**) (3.74)

> *k*=1

= sgn ( *K*

> *k*=1
>
> *k*

*c~k~***w***~k~*)T**x** (3.75)

> = sgn(**w**¯ T**x**)*,* (3.76)
>
> 其中**w**¯ 为平均的权重向量。
>
> 假设**w***~t,n~* 是在第*t* 轮更新到第*n*
> 个样本时权重向量的值，平均的权重向量
>
> **w**¯ 也可以写为

**w**¯ = ΣT Σ*n*

> **w***t,n*
>
> (3.77)
>
> [ *t*=1 *n*=1 ]{.underline}
>
> *nT*
>
> 这个方法非常简单，只需要在算法[3.1](\l)中增加一个**w**¯
> ，并且在处理每一个样本后，更新
>
> 参见习题[3-7](\l)。
>
> **w**¯ ← **w**¯ + **w***~t,n~.* (3.78)
>
> 但这个方法需要在处理每一个样本时都要更新**w**¯ 。因为**w**¯
> 和**w***~t,n~*
> 都是稠密向量，因此更新操作比较费时。为了提高迭代速度，有很多改进的方法，让这
> 个更新只需要在错误预测发生时才进行更新。
>
> 算法[3.2](\l)给出了一个改进的平均感知器算法的训练过程\[[Daumé
> III](\l)\]。

###### 扩展到多类分类

> 原始的感知器是一种两类分类模型，但也可以很容易地扩展到多类分类问
> 题，甚至是更一般的结构化学习问题\[[Collins](\l), [2002](\l)\]。
>
> 算法 **3.2:** 平均感知器算法
>
> 输入**:** 训练集{(**x**(*n*)*, y*^(*n*))}*N*\ ，最大迭代次数*T*^
>
> **1** 初始化：**w** ← 0, **u** ← 0, *c* ← 0 ;
>
> **2 for** *t* = 1 · · · *T* **do**
>
> **3** 随机对训练样本进行随机排序;
>
> **4 for** *n* = 1 · · · *N* **do**
>
> **5** 选取一个样本(**x**(*n*)*, y*^(*n*));^
>
> **6** 计算预测类别*y*ˆ*~t~*;

**7 if**

> **8**
>
> **9**
>
> *y*ˆ*~t~* ̸= *y~t~* **then**
>
> **w** ← **w** + *y*^(*n*)^**x**(*n*);
>
> **u** ← **u** + *cy*^(*n*)^**x**(*n*);
>
> **10 end**
>
> **11** *c* ← *c* + 1 ;
>
> **12 end**
>
> **13 end**
>
> **14 w**¯ = **w***~T~* − 1 **u** ;
>
> [ ]{.underline} [输出**: w**¯ ]{.underline}
>
> 之前介绍的分类模型中，分类函数都是在输入**x**
> 的特征空间上。为了使得感知器可以处理更复杂的输出，我们引入一个构建输入输出联合空间上的特征
> 函数***ϕ***(**x***,* **y**)，将样本(**x***,* **y**)
> 对映射到一个特征向量空间。
>
> 在联合特征空间中，我们可以建立一个广义的感知器模型，
>
> **y**ˆ = arg max **w**T***ϕ***(**x***,* **y**)*,* (3.79)
>
> **y**∈Gen(**x**)
>
> 其中**w** 为权重向量，Gen(**x**) 表示输入**x**
> 所有的输出目标集合。当处理*C* 类分类问题时，Gen(**x**) = {1*,* · · ·
> *, C*}。
>
> 在*C* 类分类中，一种常用的特征函数***ϕ***(**x***,* **y**) 是**y**
> 和**x** 的外积，其中**y** 为类别的one-hot 向量表示。
>
> ***ϕ***(**x***,* **y**) = **vec**(**yx**T) ∈ R^(*d*×*C*)^*,* (3.80)
>
> 其中**vec** 是向量化算子。
>
> 通过引入特征函数 ***ϕ***(**x***,* **y**)， 感知器不但可以用于多类分
> 类问题，也可以用于结构化 学习问题，比如输出是序列 形式。
>
> 给定样本(**x***,* **y**)，若**x** ∈ R*d*，**y** 为第*c* 维为1
> 的one-hot 向量，则





***ϕ***(**x***,* **y**) = 





> . 
>
> ←第(*c* − 1) × *d* + 1 行



> ←第(*c* − 1) × *d* + *d* 行

. 

> (3.81)
>
> 广义感知器算法的训练过程如算法[3.3](\l)所示。
>
> 算法 **3.3:** 广义感知器参数学习算法
>
> 输入**:** 训练集:{(**x**(*n*)*,* **y**(*n*))}*N* ，最大迭代次数*T*
>
> **1** 初始化：**w**~0~ ← 0, *k* ← 0 ;
>
> **2 for** *t* = 1 · · · *T* **do**
>
> **3** 随机对训练样本进行随机排序;
>
> **4 for** *n* = 1 · · · *N* **do**
>
> **5** 选取一个样本(**x**(*n*)*,* **y**(*n*));
>
> **6** 用公式([3.79](\l)) 计算预测类别**y**ˆ(*n*);

**7 if**

> **y**ˆ(*n*)
>
> **y**(*n*) **then**
>
> **8 w**~*k*+1~ ← **w***~k~* + ***ϕ***(**x**(*n*)*,* **y**(*n*)) −
> ***ϕ***(**x**(*n*)*,* **y**ˆ(*n*)) ;
>
> **9** *k* = *k* + 1 ;
>
> **10 end**
>
> **11 end**
>
> **12 end**
>
> [ 输出]{.underline}[**: w***~k~ *]{.underline}

1.  广义感知器的收敛性

> 广义线性可分是多类线性可分的扩展，参见定义[3.2](\l)。
>
> 广义感知器在满足广义线性可分条件时，也能够保证在有限步骤内收敛。
> 广义线性可分条件的定义如下：
>
> 广义感知器的收敛性定义如下：
>
> [Collins](\l) \[[2002](\l)\]
> 给出了广义感知器在广义线性可分的收敛性证明，具体推导过程和两类感知器比较类似。

#### 支持向量机

> 支持向量机（Support Vector Machine，SVM）是一个经典两类分类算法，
> 其找到的分割超平面具有更好的鲁棒性，因此广泛使用在很多任务上，并表现出了很强优势。
>
> 参见习题[3-8](\l)。
>
> 给定一个两类分类器数据集D = {(**x**(*n*)*,
> y*^(*n*))}*N*\ ，其中\ *y*^*~n~* ∈ {+1*,* −1}，
>
> 如果两类样本是线性可分的，即存在一个超平面
>
> **w**T**x** + *b* = 0 (3.82)
>
> 将两类样本分开，那么对于每个样本都有*y*^(*n*)(**w**T**x**(*n*)\ +\ *b*)\ *\>*\ 0^。数据集D
> 中每个样本**x**(*n*) 到分割超平面的距离为：
>
> 本节中不使用增广的特征向量和特征权重。

*γ*(*n*) =

> ∥**w**T**x**(*n*) + *b*∥
>
> ∥**w**∥
>
> = *y*(*n*)(**w**T**x**(*n*) + *b*)
>
> ∥**w**∥

*.* (3.83)

> 我们定义整个数据集*D* 中所有样本到分割超平面的最短距离为间隔（Margin）
>
> *γ*
>
> *γ* = min *γ*^(*n*)^*.* (3.84)

*n*

> 如果间隔*γ*
> 越大，其分割超平面对两个数据集的划分越稳定，不容易受噪声等因素影响。支持向量机的目标是寻找一个超平面(**w**∗*,
> b*^∗^) 使得*γ* 最大，即
>
> max
>
> **w***,b*
>
> *γ* (3.85)

s*.*t*.*

> *y*(*n*)(**w**T**x**(*n*) + *b*)
>
> ∥**w**∥ ≥ *γ,* ∀*n*
>
> 令∥**w**∥ · *γ* = 1，则公式([3.85](\l)) 等价于
>
> max
>
> **w***,b*
>
> [ 1 ]{.underline}
>
> ∥**w**∥2
>
> (3.86)
>
> s*.*t*. y*^(*n*)^(**w**T**x**(*n*) + *b*) ≥ 1*,* ∀*n*
>
> 数据集中所有满足*y*^(*n*)(**w**T**x**(*n*)+*b*)\ =\ 1的样本点，都称为支持向量（Support\ Vector）。^
>
> 对于一个线性可分的数据集，其分割超平面有很多个，但是间隔最大的超
> 平面是唯一的。图[3.6](\l)给定了支持向量机的最大间隔分割超平面的示例，其红色
> 样本点为支持向量。
>
> *x*~2~
>
> 图 3.6 支持向量机示例

###### 参数学习

> 为了找到最大间隔分割超平面，将公式([3.86](\l))
> 的目标函数写为凸优化问题
>
> min
>
> **w***,b*
>
> 2 ∥**w**∥ (3.87)
>
> 参见第**??**节。
>
> s*.*t*.* 1 − *y*^(*n*)^(**w**T**x**(*n*) + *b*) ≤ 0*,* ∀*n*
>
> 使用拉格朗日乘数法，公式([3.87](\l)) 的拉格朗日函数为

Λ(**w**

*, b, λ*

) = [1]{.underline} ∥

> *N*

**w** 2 +

> *n*=1

*λ~n~* 1

> − *y* (**w**T

**x**(*n*) +

b)  *\
    > ,*

> (3.88)
>
> 其中*λ*~1~ ≥ 0*,* · · · *, λ~N~* ≥ 0 为拉格朗日乘数。计算Λ(**w***, b,
> λ*) 关于**w** 和*b* 的导数， 并令其等于0 得到

*N*

> **w** = *λ~n~y*^(*n*)^**x**(*n*)*,* (3.89)
>
> *n*=1 *N*
>
> 0 = *λ~n~y*^(*n*)^*.* (3.90)
>
> *n*=1
>
> 将公式([3.89](\l))
> 代入公式([3.88](\l))，并利用公式([3.90](\l))，得到拉格朗日对偶函数
>
> Γ(*λ*) = − [1]{.underline} Σ Σ *λ*
>
> *λ y*^(^
>
> )*y*(*n*)(**x**(*m*))T**x**(*n*) + Σ *λ*
>
> *.* (3.91)
>
> 支持向量机的主优化问题为凸优化问题，满足强对偶性，即主优化问题可以通过最大化对偶函数max~*λ*≥0~
> Γ(*λ*) 来求解。对偶函数Γ(*λ*) 是一个凹函数，因
> 此最大化对偶函数是一个凸优化问题，可以通过多种凸优化方法来进行求解，
> 得到拉格朗日乘数的最优值*λ*^∗^。但由于其约束条件的数量为训练样本数量，一般的优化方法代价比较高，因此在实践中通常采用比较高效的优化方法，比如SMO（Sequential
> Minimal Optimization）算法\[[Platt](\l), [1998](\l)\] 等。
>
> 根据KKT
> 条件中的互补松弛条件，最优解满足*λ*^∗\ 1−*y*(*n*)(**w**∗T**x**(*n*)+*b*∗^)
> = 0。如果样本**x**(*n*) 不在约束边界上，*λ*^∗^*n* =
> 0，其约束失效；如果样本**x**(*n*) 在约束边界上，*λn*∗ ≥
> 0。这些在约束边界上样本点称为支持向量（support
> vector），即离决策平面距离最近的点。
>
> 再计算出*λ*^∗\ 后，根据公式([3.89](\l))\ 计算出最优权重**w**∗，最优偏置*b*∗\ 可以通过任选一个支持向量(**x**˜*,\ y*˜)\ 计算得到。^
>
> *b*^∗^ = *y*˜ − **w**∗T**x**˜*.* (3.92)
>
> 最优参数的支持向量机的决策函数为
>
> *f* (**x**) = sgn(**w**∗T**x** + *b*^∗^) (3.93)
>
> 参见公式([C.26](\l))。
>
> = sgn *N n*=1

*λ*∗*ny*(*n*)

(**x**(*n*))T**x** +

> *b*^∗^! *.*
>
> (3.94)
>
> 支持向量机的决策函数只依赖*λ*^∗^*n \>* 0 的样本点，即支持向量。
>
> 支持向量机的目标函数可以通过SMO
> 等优化方法得到全局最优解，因此比其它分类器的学习效率更高。此外，支持向量机的决策函数只依赖与支持向量，
> 与训练样本总数无关，分类速度比较快。

###### 核函数

> 支持向量机还有一个重要的优点是可以使用核函数（kernel
> function）隐式地将样本从原始特征空间映射到更高维的空间，并解决原始特征空间中的线性
> 不可分问题。比如在一个变换后的特征空间*ϕ* 中，支持向量机的决策函数为
>
> *f* (**x**) = sgn(**w**∗T*ϕ*(**x**) + *b*^∗^) (3.95)
>
> = sgn *N n*=1

*λ*∗*ny*(*n*)*K*

(**x**(*n*)*,*

**x**) +

> *b*^∗^! *,*
>
> (3.96)
>
> 参见习题[3-10](\l)。
>
> 其中*K*(**x***,* **z**) = *ϕ*(**x**)T*ϕ*(**z**)
> 为核函数。通常我们不需要显式地给出*ϕ*(**x**)
> 的具体形式，可以通过核技巧（kernel trick）来构造。比如以**x***,* **z**
> ∈ R2 为例，我们可以构造一个核函数
>
> *K*(**x***,* **z**) = (1 + **x**T**z**)2 = *ϕ*(**x**)T*ϕ*(**z**)*,*
> (3.97)
>
> 来隐式地计算**x***,* **z** 在特征空间*ϕ* 中的内积，其中*ϕ*(**x**) =
> \[1*,* √2*x*~1~*,* √2*x*~2~*,*
>
> √2*x*~1~*x*~2~*, x*^2^*, x*^2^\]T。

1 2

###### 软间隔

> 在支持向量机的优化问题中，约束条件比较严格。如果训练集中的样本在
> 特征空间中不是线性可分的，就无法找到最优解。为了能够容忍部分不满足约
> 束的样本，我们可以引入松弛变量*ξ*，将优化问题变为

min [1]{.underline} **w**∥2 + *C* Σ *ξ*

> (3.98)

**w***,b* 2 ∥

> *n*
>
> *n*=1
>
> s*.*t*.* 1 − *y*^(*n*)^(**w**T**x**(*n*) + *b*) − *ξ~n~* ≤ 0*,* ∀*n
> ξ~n~* ≥ 0*,* ∀*n*
>
> 其中参数*C \>* 0
> 用来控制间隔和松弛变量惩罚的平衡。引入松弛变量的间隔称为软间隔（soft
> margin）。公式([3.98](\l)) 也可以表示为经验风险+正则化项的形式。

min

> Σ max 0 1
>
> ( )(**w**
>
> **x**( ) +
>
> ) + [ 1]{.underline}
>
> [1]{.underline} **w** 2
>
> (3.99)
>
> 其中max 0*,* 1 −
> *y*^(*n*)(**w**T**x**(*n*)\ +\ *b*)\ 称为*hinge*\ 损失函数，\ [\ 1]{.underline}^
> 可以看作是正则化
>
> 系数。
>
> 参见公式([2.21](\l))。
>
> 参见习题[3-11](\l)。
>
> 软间隔支持向量机的参数学习和原始支持向量机类似，其最终决策函数也
> 只和支持向量有关，即满足1 −
> *y*^(*n*)(**w**T**x**(*n*)\ +\ *b*)\ −\ *ξ*^*~n~* = 0 的样本。

6.  损失函数对比 2019 年 4 月 6 日 77

#### 损失函数对比

> 本章介绍的三种两类分类模型：logistic
> 回归、感知器和支持向量机。虽然它们的决策函数相同，但由于使用了不同的损失函数以及相应的优化方法，导
> 致它们之间在实际任务上的表现存在一定的差异。
>
> 为了比较这些损失函数，我们统一定义类别标签 *y* ∈ {+1*,* −1}，并定义
> *f* (**x***,* **w**) = **w**T**x** + *b*。这样对于样本(**x***,
> y*)，若*yf* (**x***,* **w**) *\>*
> 0，则分类正确，相反则分类错误。这样为了方便比较这些模型，我们可以将它们的损失函数都表述
> 为定义在*yf* (**x***,* **w**) 上的函数。
>
> logistic 回归的损失函数可以改写为
>
> L*~LR~* = − log *p*(*y*\|**x**)
>
> = −*I*(*y* = 1) log *σ f* (**x***,* **w**) − *I*(*y* = −1) log *σ* −
> *f* (**x***,* **w**)
>
> = log 1 + exp − *yf* (**x***,* **w**) *.*
>
> 感知器的损失函数为
>
> (3.100)
>
> (3.101)
>
> (3.102)
>
> 1 − *σ*(*x*) = *σ*(−*x*)*.*
>
> L*~p~* = max 0*,* −*yf* (**x***,* **w**) *.* (3.103)
>
> 软间隔支持向量机的损失函数为
>
> L*~hinge~* = max 0*,* 1 − *yf* (**x***,* **w**) *.* (3.104)
>
> 平方损失可以重写为

L*squared*

> = *y* − *f* (**x***,* **w**) ^2^
>
> = 1 − 2*yf* (**x***,* **w**) + (*yf* (**x***,* **w**))2
>
> = 1 − *yf* (**x***,* **w**) 2*.*
>
> (3.105)
>
> (3.106)
>
> (3.107)
>
> *y*^2^ = 1*.*
>
> 图[3.7](\l)给出了不同损失函数的对比。对于两类分类来说，当*yf*
> (**x***,* **w**) *\>* 0 时， 分类器预测正确，并且*yf* (**x***,* **w**)
> 越大，模型的预测越正确；当*yf* (**x***,* **w**) *\<* 0 时，
> 分类器预测错误，并且*yf* (**x***,* **w**)
> 越小，模型的预测越错误。因此，一个好的损失函数应该随着*yf* (**x***,*
> **w**)
> 的增大而减少。从图[3.7](\l)中看出，除了平方损失，其它损失函数都比较适合于两类分类问题。
>
> −3 −2 −1 0 1 2 3
>
> *yf* ( *,* )
>
> 图 3.7 不同损失函数的对比

#### 总结和深入阅读

> 和回归问题不同，分类问题中的目标标签*y*
> 是离散的类别标签，因此分类问题中的决策函数需要输出离散值或是标签的后验概率。线性分类模型一般是
> 一个广义线性函数，即一个线性判别函数*f* (**x***,* **w**) = **w**T**x**
> 加上一个非线性激活函数*g*(·)。
>
> 表[3.1](\l)给出了几种常见的线性模型的比较。在logistic
> 回归和softmax回归中，
>
> **y** 为类别的one-hot 向量表示；在感知器和支持向量机中，*y* 为{+1*,*
> −1}。
>
> Logistic 回归是一种概率模型，其通过使用logistic
> 函数来将一个实数值映射到\[0*,* 1\]
> 之间。事实上，还有很多函数也可以达到此目的，比如正态分布的累积概率密度函数，即probit
> 函数。这些知识可以参考《Pattern Recognition and Machine
> Learning》\[[Bishop](\l), [2007](\l)\] 的第四章。
>
> [Rosenblatt](\l) \[[1958](\l)\]
> 最早提出了两类感知器算法，并随后给出了感知机收敛定理。但是感知器的输出是离散的以及学习算法比较简单，不能解决线性不可分问题，限制了其应用范围。[Minsky
> and Seymour](\l) \[[1969](\l)\]
> 在《感知器》一书中分析了感知器的局限性，证明感知器不能解决非常简单的异或（XOR）问题。从现在的视角看，[Minsky
> and Seymour](\l) \[[1969](\l)\] 仅仅给出了一个显而易见的证明：
>
> 3.7 总结和深入阅读 2019 年 4 月 6 日 79

+-----------------+-----------------+-----------------+-----------------+
|                 | > 激活函数      | > 损失函数      | > 优化方法      |
+-----------------+-----------------+-----------------+-----------------+
| 线性回归        | > \-            | > (*y* −        | > 最小二乘、梯度下降 |
|                 |                 | > **w**T**x**)2 |                 |
+-----------------+-----------------+-----------------+-----------------+
| Logistic 回归   | > *σ*(**w**T**x | > **y** log     | > 梯度下降      |
|                 | **)             | > *σ*(**w**T**x |                 |
|                 |                 | **)             |                 |
+-----------------+-----------------+-----------------+-----------------+
| Softmax 回归    | > softmax(*W*   | > **y** log     | > 梯度下降      |
|                 | > T**x**)       | > softmax(*W*   |                 |
|                 |                 | > T**x**)       |                 |
+-----------------+-----------------+-----------------+-----------------+
| 感知器          | > sgn(**w**T**x | > max(0*,*      | > 随机梯度下降  |
|                 | **)             | > −*y***w**T**x |                 |
|                 |                 | **)             |                 |
+-----------------+-----------------+-----------------+-----------------+
| 支持向量机      | > sgn(**w**T**x | > max(0*,* 1 −  | > 二次规划、SMO |
|                 | **)             | > *y***w**T**x* | > 等            |
|                 |                 | *)              |                 |
+-----------------+-----------------+-----------------+-----------------+

> 表 3.1 几种不同的线性模型对比
>
> 线性模型不能解决非线性问题，但依然给感知器以及人工智能领域的研究造成了很大的负面影响。虽然书中也认为多层的网络可以解决非线性问题，但遗憾的是，在当时这个问题还不可解。直到
> 1980 年以后，Geoﬀrey Hinton、Yann LeCun
> 等人用连续输出代替离散的输出，并将反向传播算法\[[Werbos](\l),
> [1974](\l)\] 引 入到多层感知器\[[Williams and Hinton](\l),
> [1986](\l)\]，人工神经网络才又重新引起人们 的注意。[Minsky and
> Papert](\l) \[[1987](\l)\]
> 也修正之前的看法。另外一方面，人们对感知器本身的认识也在不断发展。[Freund
> and Schapire](\l) \[[1999](\l)\]
> 提出了使用核技巧改进感知器学习算法，并用投票感知器来提高泛化能力。[Collins](\l)
> \[[2002](\l)\]
> 将感知器算法扩展到结构化学习，给出了相应的收敛性证明，并且提出一种更加有效并且实用的参数平均化策略。[McDonald
> et al.](\l) \[[2010](\l)\] 又扩展了平均感知器算法，
> 使得感知器可以在分布式计算环境中并行计算，这样感知器可以用在大规模机器学习问题上。
>
> 要深入了解支持向量机以及核方法，可以参考《Learning with Kernels:
> Support Vector Machines, Regularization, Optimization, and
> Beyond》\[[Scholkopf](\l) [and Smola](\l), [2001](\l)\]。

#### 习题

> 习题 **3-1** 证明在两类线性分类中，权重向量**w** 与决策平面正交。
>
> 习题 **3-2** 在线性空间中，证明一个点**x** 到平面*f* (**x***,* **w**)
> = **w**T**x** + *b* = 0 的距离为\|*f* (**x***,* **w**)\|*/*∥**w**∥。
>
> 习题**3-3** 在线性分类中，决策区域是凸的。即若点**x**~1~ 和**x**~2~
> 被分为类*c*，则
>
> 80 2019 年 4 月 6 日 参考文献
>
> 点*ρ***x**~1~ + (1 − *ρ*)**x**~2~ 也会被分为类*c*，其中*ρ* ∈ (0*,*
> 1)。
>
> 习题 **3-4** 在多类分类中，1）如果一个数据集中每个类的样本都可以其它
>
> 类是线性可分的，则该数据集一定是线性可分的；2）如果一个数据集中每两个
> 类的样本是线性可分的，则该数据集不一定是线性可分的。
>
> 习题**3-5** 在logistic 回归中，是否可以用*y*ˆ = *σ*(**w**T**x**)
> 去逼近正确的标签*y*，并用平方损失(*y* − *y*ˆ)2 最小化来优化参数**w**？
>
> 习题 **3-6** 在softmax
> 回归的风险函数（公式([3.39](\l))）中，如果去掉正则化项会有什么影响？
>
> 习题 **3-7**
> 验证平均感知器训练算法[3.2](\l)中给出的平均权重向量的计算方式和公式([3.78](\l))
> 等价。
>
> 习题 **3-8** 证明定理[3.2](\l)。
>
> 习题**3-9**
> 若数据集线性可分，证明支持向量机中将两类样本正确分开的最大间隔分割超平面存在且唯一。
>
> 习题 **3-10** 验证公式([3.97](\l))。
>
> 习题 **3-11**
> 在软间隔支持向量机中，试给出原始优化问题的对偶问题，并列出其KKT 条件。

#### 参考文献

> Christopher M. Bishop. *Pattern recogni- tion and machine learning,
> 5th Edition*. In- formation science and statistics. Springer, 2007.
> ISBN 9780387310732.
>
> Michael Collins. Discriminative training methods for hidden markov
> models: The- ory and experiments with perceptron algo- rithms. In
> *Proceedings of the conference on Empirical methods in natural
> language pro- cessing*, pages 1--8. Association for Compu-
>
> tational Linguistics, 2002.
>
> Hal Daumé III. A course in machine learn-
>
> ing. http://ciml.info/. \[Online\].
>
> Yoav Freund and Robert E Schapire. Large margin classiﬁcation using
> the perceptron algorithm. *Machine learning*, 37(3):277--
>
> 296, 1999.
>
> Ryan McDonald, Keith Hall, and Gideon Mann. Distributed training
> strategies for the structured perceptron. In *Human Lan- guage
> Technologies: The 2010 Annual Con-*
>
> 参考文献 2019 年 4 月 6 日 81
>
> *ference of the North American Chapter of the Association for
> Computational Linguis- tics*, pages 456--464. Association for Com-
> putational Linguistics, 2010.
>
> Marvin Minsky and Papert Seymour. Per-
>
> ceptrons. 1969.
>
> Marvin L Minsky and Seymour A Papert. *Perceptrons - Expanded Edition:
> An Intro- duction to Computational Geometry*. MIT
>
> press Boston, MA:, 1987.
>
> Albert BJ Novikoﬀ. On convergence proofs
>
> for perceptrons. Technical report, DTIC Document, 1963.
>
> John Platt. Sequential minimal optimiza- tion: A fast algorithm for
> training support vector machines. Technical report, April 1998.
>
> Frank Rosenblatt. The perceptron: a prob- abilistic model for
> information storage and organization in the brain. *Psychological re-
> view*, 65(6):386, 1958.
>
> Bernhard Scholkopf and Alexander J Smola. *Learning with kernels:
> support vector ma- chines, regularization, optimization, and beyond*.
> MIT press, 2001.
>
> Paul Werbos. Beyond regression: New tools for prediction and analysis
> in the behavioral sciences. 1974.
>
> DE Rumelhart GE Hinton RJ Williams and GE Hinton. Learning
> representations by back-propagating errors. *Nature*, pages 323--533,
> 1986.

第二部分基础模型
================

> 第**4** 章 前馈神经网络
>
> 神经网络是一种大规模的并行分布式处理器，天然具有存
> 储并使用经验知识的能力。它从两个方面上模拟大脑：（1）网络获取的知识是通过学习来获取的；（2）内部神经元的连接强
> 度，即突触权重，用于储存获取的知识。
>
> --- [Haykin](\l) \[[1994](\l)\]
>
> 人工神经网络（Artiﬁcial Neural
> Network，ANN）是指一系列受生物学和神经学启发的数学模型。这些模型主要是通过对人脑的神经元网络进行抽象，构
> 建人工神经元，并按照一定拓扑结构来建立人工神经元之间的连接，来模拟生
> 物神经网络。在人工智能领域，人工神经网络也常常简称为神经网络（Neural
> Network，NN）或神经模型（Neural Model）。
>
> 神经网络最早是作为一种主要的连接主义模型。20 世纪 80
> 年代后期，最流行的一种连接主义模型是分布式并行处理（Parallel
> Distributed Processing， PDP）网络\[[Rumelhart et al.](\l),
> [1986](\l)\]，其有3
> 个主要特性：1）信息表示是分布式的（非局部的）；2）记忆和知识是存储在单元之间的连接上；3）通过逐渐改变单元之间的连接强度来学习新的知识。
>
> 连接主义的神经网络有着多种多样的网络结构以及学习方法，虽然早期模
> 型强调模型的生物可解释性（biological
> plausibility），但后期更关注于对某种特定认知能力的模拟，比如物体识别、语言理解等。尤其在引入误差反向传播来
> 改进其学习能力之后，神经网络也越来越多地应用在各种模式识别任务上。随
> 着训练数据的增多以及（并行）计算能力的增强，神经网络在很多模式识别任
> 务上已经取得了很大的突破，特别是语音、图像等感知信号的处理上，表现出
> 了卓越的学习能力。
>
> 在本章中，我们主要关注于采用误差反向传播来进行学习的神经网络，即
> 作为一种机器学习模型的神经网络。从机器学习的角度来看，神经网络一般可
> 以看作是一个非线性模型，其基本组成单位为具有非线性激活函数的神经元，通
>
> 后面我们会介绍一种用来进行记忆存储和检索的神经网络，参见第[8.3.4](\l)节。
>
> 过大量神经元之间的连接，使得神经网络成为一种高度非线性的模型。神经元
> 之间的连接权重就是需要学习的参数，可以通过梯度下降方法来进行学习。
>
> **4.1** 神经元
>
> 净输入也叫净活性值（net
>
> 人工神经元（Artiﬁcial
> Neuron），简称神经元（Neuron），是构成神经网络的基本单元，其主要是模拟生物神经元的结构和特性，接受一组输入信号并
> 产出输出。
>
> 生物学家在20
> 世纪初就发现了生物神经元的结构。一个生物神经元通常具有多个树突和一条轴突。树突用来接受信息，轴突用来发送信息。当神经元所
> 获得的输入信号的积累超过某个阈值时，它就处于兴奋状态，产生电脉冲。轴
> 突尾端有许多末梢可以给其他个神经元的树突产生连接（突触），并将电脉冲信
> 号传递给其它神经元。
>
> 1943 年，心理学家McCulloch 和数学家Pitts
> 根据生物神经元的结构，提出了一种非常简单的神经元模型，MP
> 神经元\[[McCulloch and Pitts](\l),
> [1943](\l)\]。现代神经网络中的神经元和M-P
> 神经元的结构并无太多变化。不同的是，MP 神经元中的激活函数*f* 为0 或1
> 的阶跃函数，而现代神经元中的激活函数通常要求是连续可导的函数。
>
> 假设一个神经元接受*d* 个输入*x*~1~*, x*~2~*,* · · · *,
> x~d~*，令向量**x** = \[*x*~1~; *x*~2~; · · · ; *x~d~*\]
> 来表示这组输入，并用净输入（Net Input）*𝑥* ∈ R
> 表示一个神经元所获得的输入
>
> activation）。 信号**x** 的加权和，
>
> *d*
>
> *𝑥* = *w~i~x~i~* + *b* (4.1)
>
> *i*=1

= **w**T**x** + *b,* (4.2)

> 其中**w** = \[*w*~1~; *w*~2~; · · · ; *w~d~*\] ∈ R*d* 是*d*
> 维的权重向量，*b* ∈ R 是偏置。
>
> 净输入*𝑥* 在经过一个非线性函数*f* (·)
> 后，得到神经元的活性值（Activation）
>
> *a*，

*a* = *f* (*𝑥*)*,* (4.3)

> 其中非线性函数*f* (·) 称为激活函数（Activation
> Function）。图[4.1](\l)给出了一个典型的神经元结构示例。

![](/root/autodl-tmp/project_knowledge/Doc_QA/Knowledge_based/1828695663060254721/image_output/7.《神经网络与深度学习》/media/image52.png)
[ ]{.underline}

> *f a*
>
> 激活函数
>
> 输入
>
> 图 4.1 典型的神经元结构
>
> 激活函数
> 激活函数在神经元中非常重要的。为了增强网络的表示能力和学习能力，激活函数需要具备以下几点性质：

1.  连续并可导（允许少数点上不可导）的非线性函数。可导的激活函数可以
    > 直接利用数值优化的方法来学习网络参数。

2.  激活函数及其导函数要尽可能的简单，有利于提高网络计算效率。

3.  激活函数的导函数的值域要在一个合适的区间内，不能太大也不能太小，
    > 否则会影响训练的效率和稳定性。

> 下面介绍几种在神经网络中常用的激活函数。

1.  **Sigmoid** 型激活函数

> Sigmoid 型函数是指一类S 型曲线函数，为两端饱和函数。常用的Sigmoid
>
> 型函数有Logistic 函数和Tanh 函数。
>
> **Logistic** 函数 Logistic 函数定义为
>
> *σ*(*x*) = 1 + exp(−*x*) *.* (4.4)
>
> Logistic 函数可以看成是一个"挤压"函数，把一个实数域的输入"挤压"
> 到(0*,* 1)。当输入值在0 附近时，Sigmoid
> 型函数近似为线性函数；当输入值靠近两端时，对输入进行抑制。输入越小，越接近于0；输入越大，越接近于1。这样的特点也和生物神经元类似，对一些输入会产生兴奋（输出为1），对另一些输入产生抑制（输出为0）。和感知器使用的阶跃激活函数相比，Logistic
> 函数是连续可导的，其数学性质更好。
>
> 参见第[6.6](\l)节。
>
> 因为Logistic 函数的性质，使得装备了Logistic
> 激活函数的神经元具有以下两点性质：1）其输出直接可以看作是概率分布，使得神经网络可以更好地和统计学习模型进行结合。2）其可以看作是一个软性门（Soft
> Gate），用来控制其它神经元输出信息的数量。
>
> **Tanh** 函数 Tanh 函数是也一种Sigmoid 型函数。其定义为
>
> tanh(*x*) = [exp(*x*) − exp(−*x*)]{.underline} *.* (4.5)
>
> exp(*x*) + exp(−*x*)
>
> Tanh 函数可以看作是放大并平移的Logistic 函数，其值域是(−1*,* 1)。
>
> tanh(*x*) = 2*σ*(2*x*) − 1*.* (4.6)
>
> 参见第[7.4](\l)节。
>
> 参见习题[4-1](\l)。
>
> 图[4.2](\l)给出了Logistic 函数和Tanh 函数的形状。Tanh
> 函数的输出是零中心化的（Zero-Centered），而Logistic
> 函数的输出恒大于0。非零中心化的输出会使得其后一层的神经元的输入发生偏置偏移（Bias
> Shift），并进一步使得梯度下降的收敛速度变慢。

1

> 0.5
>
> −6 −4 −2
>
> 2 4 6
>
> −0.5
>
> −1
>
> 图 4.2 Logistic 函数和Tanh 函数
>
> **4.1.1.1 Hard-Logistic** 和 **Hard-Tanh** 函数
>
> Logistic 函数和Tanh 函数都是Sigmoid
> 型函数，具有饱和性，但是计算开销较大。因为这两个函数都是在中间（0
> 附近）近似线性，两端饱和。因此，这两个函数可以通过分段函数来近似。
>
> 以Logistic 函数*σ*(*x*) 为例，其导数为*σ*^′^(*x*) = *σ*(*x*)(1 −
> *σ*(*x*))。Logistic 函数在0 附近的一阶泰勒展开（Taylor expansion）为
>
> *g~l~*(*x*) ≈ *σ*(0) + *x* × *σ*^′^(0) (4.7)
>
> = 0*.*25*x* + 0*.*5*.* (4.8)
>
> 用分段来近似Logistic 函数，得到
>
> 1 *g* (*x*) 1 hard-logistic(*x*) = *gl* 0 *\< gl*(*x*) *\<* 1

0 *g~l~*(*x*) ≤ 0

> (4.9)

= max(min(*g~l~*(*x*)*,* 1)*,* 0) (4.10)

= max(min(0*.*25*x* + 0*.*5*,* 1)*,* 0)*.* (4.11)

> 同样，Tanh 函数在0 附近的一阶泰勒展开为
>
> *g~t~*(*x*) ≈ tanh(0) + *x* × tanh^′^(0) (4.12)

= *x,* (4.13)

> 这样Tanh 函数也可以用分段函数hard-tanh(*x*) 来近似。

hard-tanh(*x*) = max(min(*g~t~*(*x*)*,* 1)*,* −1) (4.14)

= max(min(*x,* 1)*,* −1)*.* (4.15)

> 图[4.3](\l)给出了hard-Logistic 和hard-Tanh 函数两种函数的形状。

1 1

0*.*8

0*.*6

0*.*4

0*.*2

0

> −4 −2 0 2 4 6

a.  Hard Logistic 函数

> 0*.*5
>
> 0
>
> −0*.*5
>
> −1
>
> −4 −2 0 2 4 6
>
> \(b) Hard Tanh 函数
>
> 图 4.3 Hard Sigmoid 型激活函数

2.  修正线性单元

> 修正线性单元（Rectiﬁed Linear Unit，ReLU）\[[Nair and Hinton](\l),
> [2010](\l)\]，也叫rectiﬁer 函数\[[Glorot et al.](\l),
> [2011](\l)\]，是目前深层神经网络中经常使用的激活函数。ReLU
> 实际上是一个斜坡（ramp）函数，定义为

ReLU(*x*) = *x x* ≥ 0

0 *x \<* 0

> (4.16)
>
> 参见第[4.6.2](\l)节。
>
> 优点 采用ReLU
> 的神经元只需要进行加、乘和比较的操作，计算上更加高效。ReLU
> 函数被认为有生物上的解释性，比如单侧抑制、宽兴奋边界（即兴奋程度也可以非常高）。在生物神经网络中，同时处于兴奋状态的神经元非常稀疏。人脑中在同一时刻大概只有1
> ∼ 4% 的神经元处于活跃状态。Sigmoid 型激活函数
> 会导致一个非稀疏的神经网络，而ReLU 却具有很好的稀疏性，大约50%
> 的神经元会处于激活状态。
>
> 在优化方面，相比于Sigmoid 型函数的两端饱和，ReLU 函数为左饱和函数，
> 且在*x \>* 0
> 时导数为1，在一定程度上缓解了神经网络的梯度消失问题，加速梯度下降的收敛速度。
>
> 缺点 ReLU 函数的输出是非零中心化的，给后一层的神经网络引入偏置偏移，
>
> 会影响梯度下降的效率。此外，ReLU 神经元在训练时比较容易"死亡"。在训
> ReLU 神经元指采用 ReLU
>
> 练时，如果参数在一次不恰当的更新后，第一个隐藏层中的某个ReLU
> 神经元在所有的训练数据上都不能被激活，那么这个神经元自身参数的梯度永远都会是
> 0，在以后的训练过程中永远不能被激活。这种现象称为死亡*ReLU*
> 问题（Dying ReLU Problem），并且也有可能会发生在其它隐藏层。
>
> 在实际使用中，为了避免上述情况，有几种ReLU 的变种也会被广泛使用。

1.  带泄露的 **ReLU**

> 带泄露的ReLU（Leaky ReLU）在输入 *x \<* 0
> 时，保持一个很小的梯度*λ*。这样当神经元非激活时也能有一个非零的梯度可以更新参数，避免永远不能被激活\[[Maas
> et al.](\l), [2013](\l)\]。带泄露的ReLU 的定义如下：
>
> 作为激活函数的神经元。
>
> 参见公式([4.61](\l))。参见习题[4-3](\l)。
>
> LeakyReLU(*x*) = *x* if *x \>* 0

*γx* if *x* ≤ 0

> (4.18)
>
> 其中 *γ* 是一个很小的常数，比如0*.*01。当*γ \<* 1 时，带泄露的ReLU
> 也可以写为
>
> LeakyReLU(*x*) = max(*x, γx*)*,* (4.20)
>
> 相当于是一个比较简单的maxout 单元。

2.  带参数的 **ReLU**

> 带参数的ReLU（Parametric
> ReLU，PReLU）引入一个可学习的参数，不同神经元可以有不同的参数\[[He et
> al.](\l), [2015](\l)\]。对于第*i* 个神经元，其PReLU 的定义为
>
> 参见第[4.1.4](\l)节。
>
> PReLU (*x*) = *x* if *x \>* 0
>
> (4.21)
>
> *γ~i~x* if *x* ≤ 0
>
> = max(0*, x*) + *γ~i~* min(0*, x*)*,* (4.22)
>
> 其中*γ~i~* 为*x* ≤ 0 时函数的斜率。因此，PReLU
> 是非饱和函数。如果*γ~i~* = 0，那么PReLU 就退化为ReLU。如果*γ~i~*
> 为一个很小的常数，则PReLU 可以看作带泄露的ReLU。PReLU
> 可以允许不同神经元具有不同的参数，也可以一组神经元共享一个参数。

3.  **ELU**

> 指数线性单元（Exponential Linear Unit，ELU）\[[Clevert et al.](\l),
> [2015](\l)\] 是一个近似的零中心化的非线性函数，其定义为
>
> ELU(*x*) = *x* if *x \>* 0

*γ*(exp(*x*) − 1) if *x* ≤ 0

> (4.23)
>
> 参见第[7.5.1](\l)节。
>
> = max(0*, x*) + min(0*, γ*(exp(*x*) − 1))*,* (4.24)
>
> 其中 *γ* ≥ 0 是一个超参数，决定*x* ≤ 0 时的饱和曲线，并调整输出均值在0
> 附近。

4.  **Softplus** 函数

> Softplus 函数\[[Dugas et al.](\l), [2001](\l)\] 可以看作是rectiﬁer
> 函数的平滑版本，其定义为
>
> Softplus(*x*) = log(1 + exp(*x*))*.* (4.25)
>
> Softplus 函数其导数刚好是Logistic 函数。Softplus
> 函数虽然也有具有单侧抑制、宽兴奋边界的特性，却没有稀疏激活性。
>
> 图[4.4](\l)给出了ReLU、Leaky ReLU、ELU 以及Softplus 函数的示例。
>
> 图 4.4 ReLU、Leaky ReLU、ELU 以及Softplus 函数

3.  **Swish** 函数

> Swish 函数是一种自门控（Self-Gated）激活函数 \[[Ramachandran et
> al.](\l), [2017](\l)\]，定义为
>
> swish(*x*) = *xσ*(*βx*)*,* (4.26)
>
> 其中*σ*(·) 为Logistic 函数，*β* 为可学习的参数或一个固定超参数。*σ*(·)
> ∈ (0*,* 1) 可以看做是一种软性的门控机制。当*σ*(*βx*) 接近于1
> 时，门处于"开"状态，激活函数的输出近似于*x* 本身；当*σ*(*βx*) 接近于0
> 时，门的状态为"关"，激活函数的输出近似于0。
>
> 图[4.5](\l)给出了Swish 函数的示例。
>
> 图 4.5 Swish 函数
>
> 当*β* = 0 时，Swish 函数变成线性函数*x/*2。当*β* = 1 时，Swish
> 函数在*x \>* 0 时近似线性，在*x \<* 0
> 时近似饱和，同时具有一定的非单调性。当*β* → +∞ 时， *σ*(*βx*)
> 趋向于离散的0-1 函数，Swish 函数近似为ReLU函数。因此，Swish
> 函数可以看作是线性函数和ReLU 函数之间的非线性插值函数，其程度由参数*β*
> 控制。

4.  **Maxout** 单元

> Maxout 单元\[[Goodfellow et al.](\l), [2013](\l)\]
> 也是一种分段线性函数。Sigmoid 型函数、ReLU
> 等激活函数的输入是神经元的净输入*𝑥*，是一个标量。而maxout
> 单元的输入是上一层神经元的全部原始输入，是一个向量**x** = \[*x*~1~;
> *x*~2~; · · · *, x~d~*\]。
>
> 每个maxout 单元有*K* 个权重向量**w***~k~* ∈ R*d* 和偏置*b~k~* (1 ≤ *k*
> ≤ *K*)。对于
>
> 采用maxout 单元的神经网络也就做*maxout* 网络。
>
> 输入**x**，可以得到*K* 个净输入*𝑥~k~,* 1 ≤ *k* ≤ *K*。
>
> *𝑥~k~* = **w**T**x** + *b~k~,* (4.27)
>
> 其中**w***~k~* = \[*w~k,~*~1~*,* · · · *, w~k,d~*\]T 为第*k*
> 个权重向量。
>
> Maxout 单元的非线性函数定义为
>
> maxout(**x**) = max (*𝑥~k~*)*.* (4.28)
>
> *k*∈\[1*,K*\]
>
> Maxout
> 单元不单是净输入到输出之间的非线性映射，而是整体学习输入到输出之间的非线性映射关系。Maxout
> 激活函数可以看作任意凸函数的分段线性近似，并且在有限的点上是不可微的。

2.  网络结构

> 一个生物神经细胞的功能比较简单，而人工神经元只是生物神经细胞的理想化和简单实现，功能更加简单。要想模拟人脑的能力，单一的神经元是远远不够的，需要通过很多神经元一起协作来完成复杂的功能。这样通过一定的连接方式或信息传递方式进行协作的神经元可以看作是一个网络，就是神经网络。
>
> 到目前为止，研究者已经发明了各种各样的神经网络结构。目前常用的神
> 经网络结构有以下三种：

###### 前馈网络

> 前馈网络中各个神经元按接受信息的先后分为不同的组。每一组可以看作
> 一个神经层。每一层中的神经元接受前一层神经元的输出，并输出到下一层神
> 经元。整个网络中的信息是朝一个方向传播，没有反向的信息传播，可以用一
> 个有向无环路图表示。前馈网络包括全连接前馈网络\[本章中的第[4.3](\l)节\]
> 和卷积神经网络\[第[5](\l)章\] 等。
>
> 前馈网络可以看作一个函数，通过简单非线性函数的多次复合，实现输入
> 空间到输出空间的复杂映射。这种网络结构简单，易于实现。

###### 反馈网络

> 反馈网络中神经元不但可以接收其它神经元的信号，也可以接收自己的反
> 馈信号。和前馈网络相比，反馈网络中的神经元具有记忆功能，在不同的时刻具
> 有不同的状态。反馈神经网络中的信息传播可以是单向或双向传递，因此可用
> 一个有向循环图或无向图来表示。反馈网络包括循环神经网络\[第[6](\l)章\]，Hopﬁeld
> 网络\[第[6](\l)章\]、玻尔兹曼机\[第[12](\l)章\] 等。
>
> 反馈网络可以看作一个程序，具有更强的计算和记忆能力。
>
> 为了增强记忆网络的记忆容量，可以引入外部记忆单元和读写机制，用来保
> 存一些网络的中间状态，称为记忆增强网络（Memory-Augmented Neural Net-
> work）\[第[8](\l)章\]，比如神经图灵机\[[Graves et al.](\l),
> [2014](\l)\] 和记忆网络\[[Sukhbaatar](\l) [et al.](\l), [2015](\l)\]
> 等。

###### 图网络

> 前馈网络和反馈网络的输入都可以表示为向量或向量序列。但实际应用中
> 很多数据是图结构的数据，比如知识图谱、社交网络、分子（molecular
> ）网络等。前馈网络和反馈网络很难处理图结构的数据。
>
> 图网络是定义在图结构数据上的神经网络\[第[6.8.2](\l)节\]。图中每个节点都一
> 个或一组神经元构成。节点之间的连接可以是有向的，也可以是无向的。每个
> 节点可以收到来自相邻节点或自身的信息。
>
> 图网络是前馈网络和记忆网络的泛化，包含很多不同的实现方式，比如图
> 卷积网络（Graph Convolutional Network，GCN）\[[Kipf and Welling](\l),
> [2016](\l)\]、消息传递网络（Message Passing Neural
> Network，MPNN）\[[Gilmer et al.](\l), [2017](\l)\] 等。
>
> 图[4.6](\l)给出了前馈网络、反馈网络和图网络的网络结构示例。

![](/root/autodl-tmp/project_knowledge/Doc_QA/Knowledge_based/1828695663060254721/image_output/7.《神经网络与深度学习》/media/image70.png)

a.  前馈网络 (b) 反馈网络 (c) 图网络

> 图 4.6 三种不同的网络模型

#### 前馈神经网络

> 给定一组神经元，我们可以以神经元为节点来构建一个网络。不同的神经网络模型有着不同网络连接的拓扑结构。一种比较直接的拓扑结构是前馈网络。
> 前馈神经网络（Feedforward Neural Network，FNN）是最早发明的简单人工神
> 经网络。
>
> 在前馈神经网络中，各神经元分别属于不同的层。每一层的神经元可以接
> 收前一层神经元的信号，并产生信号输出到下一层。第0
> 层叫输入层，最后一层叫输出层，其它中间层叫做隐藏层。整个网络中无反馈，信号从输入层向输
> 出层单向传播，可用一个有向无环图表示。
>
> 前馈神经网络也经常称为多层感知器（Multi-Layer
> Perceptron，MLP）。但多层感知器的叫法并不是十分合理，因为前馈神经网络其实是由多层的Logistic
> 回归模型（连续的非线性函数）组成，而不是由多层的感知器（不连续的非线
> 性函数）组成 \[[Bishop](\l), [2007](\l)\]。
>
> 图[4.7](\l)给出了前馈神经网络的示例。

输入层

> 隐藏层 隐藏层
>
> 输出层
>
> *x*~1~
>
> *x*~2~
>
> *y*
>
> *x*~3~
>
> *x*~4~
>
> 图 4.7 多层前馈神经网络
>
> 层数一般只考虑隐藏层和输出层。
>
> 我们用下面的记号来描述一个前馈神经网络：

-   *L*：表示神经网络的层数；

-   *m*^(*l*)：表示第*l*\ 层神经元的个数；^

-   *f~l~*(·)：表示*l* 层神经元的激活函数；

-   *W*
    > ^(*l*)\ ∈\ R*m*(*l*)×*ml*−1\ ：表示*l*\ −\ 1\ 层到第*l*\ 层的权重矩阵；^

-   **b**(*l*) ∈ R*ml* ：表示*l* − 1 层到第*l* 层的偏置；

-   **z**(*l*) ∈ R*ml* ：表示*l* 层神经元的净输入（净活性值）；

-   **a**(*l*) ∈ R*ml* ：表示*l*
    > 层神经元的输出（活性值）。前馈神经网络通过下面公式进行信息传播，

> **z**(*l*) = *W* (*l*) · **a**(*l*−1) + **b**(*l*)*,* (4.29)
>
> **a**(*l*) = *f~l~*(**z**(*l*))*.* (4.30)
>
> 公式([4.29](\l)) 和([4.30](\l)) 也可以合并写为：
>
> **z**(*l*) = *W* (*l*) · *fl*−1(**z**(*l*−1)) + **b**(*l*)*,* (4.31)
>
> 或者
>
> **a**(*l*) = *f~l~*(*W* ^(*l*)^ · **a**(*l*−1) + **b**(*l*))*.* (4.32)
>
> 这样，前馈神经网络可以通过逐层的信息传递，得到网络最后的输出**a**(*L*)。
>
> 整个网络可以看作一个复合函数*ϕ*(**x**; *W,* **b**)，将向量**x**
> 作为第1 层的输入**a**(0)，将第*L* 层的输出**a**(*L*)
> 作为整个函数的输出。
>
> **x** = **a**(0) → **z**(1) → **a**(1) → **z**(2) → · · · →
> **a**(*L*−1) → **z**(*L*) → **a**(*L*) = *φ*(**x**; *W,* **b**))*,*

(4.33)

> 其中*W,* **b** 表示网络中所有层的连接权重和偏置。

###### 通用近似定理

> 前馈神经网络具有很强的拟合能力，常见的连续非线性函数都可以用前馈
> 神经网络来近似。
>
> 通用近似定理在实数空间R*d* 中的有界闭集上依然成立。
>
> 根据通用近似定理，对于具有线性输出层和至少一个使用"挤压"性质的激
> 活函数的隐藏层组成的前馈神经网络，只要其隐藏层神经元的数量足够，它可
> 以以任意的精度来近似任何从一个定义在实数空间R*d*
> 中的有界闭集函数\[[Fu-](\l) [nahashi and Nakamura](\l), [1993](\l),
> [Hornik et al.](\l), [1989](\l)\]。所谓"挤压"性质的函数
>
> 定义在实数空间Rd 中的有界闭集上的任意连续函数， 也称为Borel 可测函数。
>
> 参见第[2.6.1.2](\l)节。
>
> 反之，Logistic 回归或soft- max 回归也可以看作是只有
>
> 是指像Sigmoid
> 函数的有界函数，但神经网络的通用近似性质也被证明对于其它类型的激活函数，比如ReLU，也都是适用的。
>
> 通用近似定理只是说明了神经网络的计算能力可以去近似一个给定的连续函数，但并没有给出如何找到这样一个网络，以及是否是最优的。此外，当应用到机器学习时，真实的映射函数并不知道，一般是通过经验风险最小化和正则化来进行参数学习。因为神经网络的强大能力，反而容易在训练集上过拟合。

###### 应用到机器学习

> 根据通用近似定理，神经网络在某种程度上可以作为一个"万能"函数来
> 使用，可以用来进行复杂的特征转换，或逼近一个复杂的条件分布。
>
> 在机器学习中，输入样本的特征对分类器的影响很大。以监督学习为例，好
> 的特征可以极大提高分类器的性能。因此，要取得好的分类效果，需要样本的
> 原始特征向量**x**
> 转换到更有效的特征向量*φ*(**x**)，这个过程叫做特征抽取。
>
> 多层前馈神经网络可以看作是一个非线性复合函数*φ* : R*d* → R*d*′
> ，将输入**x** ∈ R*d* 映射到输出*φ*(**x**) ∈ R*d*′
> 。因此，多层前馈神经网络也可以看成是一种特征转换方法，其输出*φ*(**x**)
> 作为分类器的输入进行分类。
>
> 给定一个训练样本 (**x***, y*)，先利用多层前馈神经网络将**x**
> 映射到*φ*(**x**)，然后再将*φ*(**x**) 输入到分类器*g*(·)。
>
> *y*ˆ = *g*(*φ*(**x**)*, θ*)*,* (4.36)
>
> 其中*g*(·) 为线性或非线性的分类器，*θ* 为分类器*g*(·)
> 的参数，*y*ˆ为分类器的输出。特别地，如果分类器*g*(·) 为Logistic
> 回归分类器或softmax 回归分类器，那
>
> 么*g*(·)
> 也可以看成是网络的最后一层，即神经网络直接输出不同类别的后验概率。
>
> 参见习题[4-6](\l)。
>
> 一层的神经网络。 对于两类分类问题*y* ∈ {0*,* 1}，并采用Logistic
> 回归，那么Logistic 回归分
>
> 类器可以看成神经网络的最后一层。也就是说，网络的最后一层只用一个神经
> 元，并且其激活函数为Logistic 函数。网络的输出可以直接可以作为类别*y* =
> 1
>
> Logistic 回归参见第[3.3](\l)节。
>
> 的后验概率。

*p*(*y* = 1\|**x**) = *a*^(*L*)^*,* (4.37)

> Softmax 回归参见第[3.3](\l)节。
>
> 其中*a*^(*L*)\ ∈\ R\ 为第*L*\ 层神经元的活性值。^
>
> 对于多类分类问题*y* ∈ {1*,* · · · *, C*}，如果使用softmax
> 回归分类器，相当于网络最后一层设置*C* 个神经元，其激活函数为softmax
> 函数。网络的输出可以作为每个类的后验概率。
>
> **y**ˆ = softmax(**z**(*L*))*,* (4.38)
>
> 其中**z**(*L*) ∈ R 为第*L* 层神经元的净输入；**y**ˆ ∈ R*C* 为第*L*
> 层神经元的活性值，分别是不同类别标签的预测后验概率。

###### 参数学习

> 如果采用交叉熵损失函数，对于样本(**x***, y*)，其损失函数为
>
> L(**y***,* **y**ˆ) = −**y**T log **y**ˆ*,* (4.39)
>
> 其中**y** ∈ {0*,* 1}*C* 为标签*y* 对应的one-hot 向量表示。
>
> 给定训练集为D = {(**x**(*n*)*,
> y*^(*n*))}*N*\ ，将每个样本**x**(*n*)\ 输入给前馈神经网^
>
> 络，得到网络输出为**y**ˆ(*n*)，其在数据集D 上的结构化风险函数为：

𝑌(*W,* **b**) =

> *N*
>
> L *, λ*∥*W* ∥ *,*

*n*

*N n*=1 2

= [ 1]{.underline}

> *N*
>
> L *, λ*∥*W* ∥ *,*
>
> *F*
>
> *n*=1
>
> 其中 *W* 和 **b** 分别表示网络中所有的权重矩阵和偏置向量；∥*W* ∥2
> 是正则化项， 用来防止过拟合；*λ* 是为正数的超参数。*λ* 越大，*W*
> 越接近于 。这里的 *W* ^2^

*F* 注意这里的正则化项只包含

> 一般使用Frobenius 范数：
>
> *L m*(*l*) *m*(*l*−1)
>
> 权重参数*W* ，而不包含偏置
>
> **b**。

∥*W* ∥*~F~*

> =
>
> *l*=1 *i*=1
>
> (*l*) 2
>
> *ij*
>
> *j*=1
>
> 有了学习准则和训练样本，网络参数可以通过梯度下降法来进行学习。在
> 梯度下降方法的每次迭代中，第*l* 层的参数*W*
> ^(*l*)\ 和**b**(*l*)\ 参数更新方式为^

*W* ^(*l*)^ ← *W* ^(*l*)^ − *α[∂]{.underline}*[𝑌(*W,*
**b**)]{.underline} *,* (4.43)

= *W* ^(*l*)^ − *α*

> [1]{.underline} *N* (*n*) (*n*) (*l*)
>
> *n*=1
>
> *λW* ^(*l*)^! *,*
>
> (4.44)

**b**(*l*) ← **b**(*l*) − *α[∂]{.underline}*[𝑌(*W,* **b**)]{.underline}
*,* (4.45)

= **b**(*l*) − *α*

> 其中*α* 为学习率。
>
> [ 1]{.underline}
>
> *N n*=1
>
> *∂* (**y**(*n*)*,* **y**ˆ(*n*))
>
> *∂***b**(*l*) *,*
>
> (4.46)
>
> 梯度下降法需要计算损失函数对参数的偏导数，如果通过链式法则逐一对
> 每个参数进行求偏导效率比较低。在神经网络的训练中经常使用反向传播算法
> 来计算高效地梯度。
>
> 链式法则参见第[B.11](\l)节。

####  反向传播算法

> 假设采用随机梯度下降进行神经网络参数学习，给定一个样本(**x***,*
> **y**)，将其输入到神经网络模型中，得到网络输出为**y**ˆ。假设损失函数为L(**y***,*
> **y**ˆ)，要进行参数学习就需要计算损失函数关于每个参数的导数。
>
> 不失一般性，对第*l* 层中的参数*W* ^(*l*)^ 和**b**(*l*)
> 计算偏导数。因为 ^[*∂*L(**y***,***y**ˆ)]{.underline}^
> 的计算涉及矩阵微分，十分繁琐，因此我们先计算偏导数
> ^[*∂*L(**y***,***y**ˆ)]{.underline}^ 。根据链式法则，
>
> *ij*

[*∂*L(**y***,* **y**ˆ)]{.underline}

> *∂***z**(*l*) !T [*∂*L(**y***,* **y**ˆ)]{.underline}

(*l*) =

*ij*

> (*l*)
>
> *ij*
>
> *∂***z**(*l*) *,* (4.47)

[*∂*L(**y***,* **y**ˆ)]{.underline}

> *∂***z**(*l*) T [*∂*L(**y***,* **y**ˆ)]{.underline}
>
> 公式([4.47](\l)) 和([4.48](\l)) 中的第二项是都为目标函数关于第*l*
> 层的神经元**z**(*l*) 的

*∂***z**(*l*)

> 偏导数，称为误差项，因此可以共用。我们只需要计算三个偏导数，分别为

(l) ，

> *∂Wij*
>
> *∂***z**(*l*)
>
> *∂***b**(*l*) 和
>
> *∂*L(**y***,* **y**ˆ) 。
>
> *∂***z**(*l*)
>
> 下面分别来计算这三个偏导数。

1.  计算偏导数

> 因此偏导数
>
> *∂***z**(*l*)
>
> (*l*)
>
> *ij*
>
> 因为**z**

(*l*)

和*W* ^(*l*)\ 的函数关系为^ **z**

(*l*)

> = *W* (*l*)

**a**(*l*−1)

\+ **b**(*l*)，

*∂***z**(*l*)

> (*l*)
>
> *ij*
>
> *∂*(*W* (*l*)**a**(*l*−1) + **b**(*l*))
>
> (*l*)
>
> *ij*
>
> (4.49)
>
>  *∂*(*W* (*l*)**a**(*l*−1)+**b**(*l*))   
>
> (*l*)
>
> *ij*
>
>  

=  *∂*(*W* (*l*)**a**(*l*−1)+**b**(*l*))

>  = 
>
> (*l*−1) 
>
> (4.50)

*i*:

> 
>
>  ~*∂*(*W*~ (*l*)
>
> (*l*)
>
> *ij*
>
> .
>
> **a**(*l*−1)+**b**(*l*)) 
>
> *aj*

.

>  0
>
> ← 第*i* 行
>
> 

, I*~i~*(

> *m*(*l*):
>
> (*l*)
>
> *ij*
>
> ^(*l*−1)^)*,* (4.51)
>
> *aj*
>
> 其中*W* ^(*l*)\ 为权重矩阵*W*\ (*l*)\ 的第*i*\ 行。^

(*l*)

2.  计算偏导数 *∂***b**(*l*) 因为**z**

> 因此偏导数

(*l*)

> 和**b**(*l*)
>
> 的函数关系为 **z**

(*l*)

> = *W* (*l*)

**a**(*l*−1)

> \+ **b**(*l*)，

*∂***z**(*l*)

*∂***b**(*l*)

> = **I***~m~*(*l*) *,*
>
> (4.52)
>
> 4.4 反向传播算法 2019 年 4 月 6 日 101
>
> 为*m*^(*l*)\ ×\ *m*(*l*)\ 的单位矩阵。^

3.  计算误差项 [*∂*L(**y***,* **y**ˆ)]{.underline}

*∂*

> 我们用*δ*^(*l*)\ 来定义第*l*\ 层神经元的误差项，^
>
> *δ*^(*l*)^ = [*∂*L(**y***,* **y**ˆ)]{.underline} ∈ R*^m^*(*l*) *.*
> (4.53)
>
> 误差项*δ*^(*l*)\ 来表示第*l*\ 层神经元对最终损失的影响，也反映了最终损失对第*l*\ 层神经元的敏感程度。误差项也间接反映了不同神经元对网络能力的贡献程度，从^
> 而比较好地解决了"贡献度分配问题"。
>
> 根据**z**(*l*+1) = *W* (*l*+1)**a**(*l*) + **b**(*l*+1)，有

*∂***z**(*l*+1)

*∂***a**(*l*)

> *W* (*l*+1))T

*.* (4.54)

> 根据**a**(*l*) = *f~l~*(**z**(*l*))，其中*f~l~*(·)
> 为按位计算的函数，因此有
>
> *∂***a**(*l*) = *∂f~l~*(**z**(*l*))
>
> (4.55)

*∂***z**(*l*)

> *∂***z**(*l*)
>
> = diag(*fl*′(**z**(*l*)))*.* (4.56)
>
> 因此，根据链式法则，第*l* 层的误差项为
>
> *δ*(*l*) , [*∂*L(**y***,* **y**ˆ)]{.underline}
>
> =
>
> =
>
> (4.57)
>
> (4.58)
>
> (4.59)
>
> = *fl*′(**z**(*l*)) ⊙ (*W* ^(*l*+1)^)T*δ*^(*l*+1)^ *,* (4.60)
>
> 其中⊙ 是向量的点积运算符，表示每个元素相乘。
>
> 从公式([4.60](\l)) 可以看出，第*l* 层的误差项可以通过第*l* + 1
> 层的误差项计算得到，这就是误差的反向传播。反向传播算法的含义是：第*l*
> 层的一个神经元的误差项（或敏感性）是所有与该神经元相连的第*l* + 1
> 层的神经元的误差项的权重和。然后，再乘上该神经元激活函数的梯度。
>
> 在计算出上面三个偏导数之后，公式([4.47](\l)) 可以写为

[*∂*L(**y***,* **y**ˆ)]{.underline} = I (

> (*l*−1))T*δ*(*l*) =
>
> (*l*)
>
> ^(*l*−1)^*.* (4.61)
>
> (*l*)
>
> *ij*
>
> *~i~ aj*
>
> *δi aj*
>
> 进一步，L(**y***,* **y**ˆ) 关于第*l* 层权重*W* ^(*l*)^ 的梯度为
>
> [*∂*L(**y***,* **y**ˆ)]{.underline} = *δ*^(*l*)^(**a**(*l*−1))T*.*
> (4.62)
>
> *∂W*
>
> 同理可得，L(**y***,* **y**ˆ) 关于第*l* 层偏置**b**(*l*) 的梯度为
>
> [*∂*L(**y***,* **y**ˆ)]{.underline} = *δ*^(*l*)^*.* (4.63)
>
> *∂*
>
> 在计算出每一层的误差项之后，我们就可以得到每一层参数的梯度。因此，
> 基于误差反向传播算法（backpropagation，BP）的前馈神经网络训练过程可以分为以下三步：

1.  前馈计算每一层的净输入**z**(*l*) 和激活值**a**(*l*)，直到最后一层；

2.  反向传播计算每一层的误差项*δ*^(*l*)；^

3.  计算每一层参数的偏导数，并更新参数。

> 算法[4.1](\l)给出使用随机梯度下降的误差反向传播算法的具体训练过程。
>
> 算法 **4.1:** 基于随机梯度下降的反向传播算法
>
> 输入**:** 训练集D = {(**x**(*n*)*,
> y*^(*n*))}*N*\ ,\ 验证集V,\ 学习率*α*,\ 正则化系数^
>
> *λ*, 网络层数*L*, 神经元数量*m*^(*l*),\ 1\ ≤\ *l*\ ≤\ *L*.^
>
> **1** 随机初始化 *W,* **b** ;
>
> **2 repeat**
>
> **3** 对训练集D 中的样本随机重排序;
>
> **4 for** *n* = 1 · · · *N* **do**
>
> **5** 从训练集D 中选取样本(**x**(*n*)*, y*^(*n*));^
>
> **6** 前馈计算每一层的净输入**z**(*l*)
> 和激活值**a**(*l*)，直到最后一层;
>
> **7** 反向传播计算每一层的误差*δ*^(*l*)^; // 公式([4.60](\l))
>
> // 计算每一层参数的导数
>
> **8** ∀*l, ^∂^*^L(**y**^(*n*)*,***y**ˆ(*n*)) =
> *δ*^(*l*)^(**a**(*l*−1))T; // 公式([4.62](\l))
>
> **9** ∀*l, ^∂^*^L(**y**^(*n*)*,***y**ˆ(*n*)) = *δ*^(*l*)^; //
> 公式([4.63](\l))
>
> // 更新参数
>
> **10** *W* (*l*) ← *W* (*l*) − *α*(*δ*(*l*)(**a**(*l*−1))T + *λW*
> (*l*));
>
> **11 b**(*l*) ← **b**(*l*) − *αδ*(*l*);
>
> **12 end**
>
> **13 until** 神经网络模型在验证集V 上的错误率不再下降;
>
> 输出**:** *W,* **b**

#### 自动梯度计算

> 神经网络的参数主要通过梯度下降来进行优化的。当确定了风险函数以及
> 网络结构后，我们就可以手动用链式法则来计算风险函数对每个参数的梯度，并
> 用代码进行实现。但是手动求导并转换为计算机程序的过程非常琐碎并容易出
>
> 错，导致实现神经网络变得十分低效。目前，几乎所有的主流深度学习框架都
> 包含了自动梯度计算的功能，即我们可以只考虑网络结构并用代码实现，其梯
> 度可以自动进行计算，无需人工干预。这样开发的效率就大大提高了。
>
> 自动计算梯度的方法可以分为以下三类：

###### 数值微分

> 数值微分（Numerical Diﬀerentiation）是用数值方法来计算函数*f* (*x*)
> 的导数。函数*f* (*x*) 的点*x* 的导数定义为

*f* ^′^(*x*) = lim

∆*x*→0

> [*f*(*x* + ∆*x*) − *f*(*x*)]{.underline} *.* (4.64)
>
> *x*
>
> 要计算函数*f* (*x*) 在点*x* 的导数，可以对*x*
> 加上一个很少的非零的扰动∆*x*， 通过上述定义来直接计算函数*f* (*x*)
> 的梯度。数值微分方法非常容易实现，但找到一个合适的扰动∆*x*
> 却十分困难。如果∆*x* 过小，会引起数值计算问题，比如舍入误差；如果∆*x*
> 过大，会增加截断误差，使得导数计算不准确。因此，数值微分的实用性比较差。在实际应用，经常使用下面公式来计算梯度，可以减少截断误差。
>
> 舍入误差（Round-oﬀ Error)
> 是指数值计算中由于数字舍入造成的近似值和精确值之间的差异，比如用浮点数来表示实数。
>
> 截断误差（Truncation Er-

*f* ^′^(*x*) = lim

∆*x*→0

> [*f*(*x* + ∆*x*) − *f*(*x* − ∆*x*)]{.underline} *.* (4.65)
>
> *x*
>
> ror）是数学模型的理论解与数值计算问题的精确解之间的误差。
>
> 数值微分的另外一个问题是计算复杂度。假设参数数量为*n*，则每个参数都
>
> 需要单独施加扰动，并计算梯度。假设每次正向传播的计算复杂度为*O*(*n*)，则计算数值微分的总体时间复杂度为*O*(*n*^2^)。

###### 符号微分

> 符号微分（Symbolic
> Diﬀerentiation）是一种基于符号计算的自动求导方法。符号计算，也叫代数计算，是指用计算机来处理带有变量的数学表达式。这里的变量看作是符号（Symbols），一般不需要代入具体的值。符号计算的输入和输出都是数学表达式，一般包括对数学表达式的化简、因式分解、微分、积
> 分、解代数方程、求解常微分方程等运算。
>
> 比如数学表达式的化简：
>
> 输入：3*x* − *x* + 2*x* + 1 (4.66)
>
> 输出：4*x* + 1*.* (4.67)
>
> 符号计算一般来讲是对输入的表达式，通过迭代或递归使用一些事先定义
> 的规则进行转换。当转换结果不能再继续使用变换规则时，便停止计算。
>
> 和符号计算相对应的概念是数值计算，即将数值代入数学表示中进行计算。
>
> 符号微分可以在编译时就计算梯度的数学表示，并进一步利用符号计算方
> 法进行优化。此外，符号计算的一个优点是符号计算和平台无关，可以在CPU
> 或GPU
> 上运行。符号微分也有一些不足之处。一是编译时间较长，特别是对于循环，需要很长时间进行编译；二是为了进行符号微分，一般需要设计一种专
> 门的语言来表示数学表达式，并且要对变量（符号）进行预先声明；三是很难
> 对程序进行调试。

###### 自动微分

> 自动微分（Automatic
> Diﬀerentiation，AD）是一种可以对一个（程序）函数进行计算导数的方法。符号微分的处理对象是数学表达式，而自动微分的处理对
> 象是一个函数或一段程序。而自动微分可以直接在原始程序代码进行微分。自
> 动微分的基本原理是所有的数值计算可以分解为一些基本操作，包含+*,* −*,*
> ×*, /* 和一些初等函数exp*,* log*,* sin*,* cos 等。
>
> 自动微分也是利用链式法则来自动计算一个复合函数的梯度。我们以一个
> 神经网络中常见的复合函数的例子来说明自动微分的过程。为了简单起见，令
> 复合函数*f* (*x*; *w, b*) 为
>
> ( ; *w, b*) = [ 1]{.underline} *,* (4.68)
>
> *f x* exp − (*wx* + *b*) + 1
>
> 其中*x* 为输入标量，*w* 和*b* 分别为权重和偏置参数。
>
> 首先，我们将复合函数*f* (*x*; *w, b*)
> 分解为一系列的基本操作，并构成一个计算图（Computational
> Graph）。计算图是数学运算的图形化表示。计算图中的每个非叶子节点表示一个基本操作，每个叶子节点为一个输入变量或常量。
> 图[4.8](\l)给出了当*x* = 1*, w* = 0*, b* = 0 时复合函数*f* (*x*; *w,
> b*)
> 的计算图，其中连边上的红色数字表示前向计算时复合函数中每个变量的实际取值。
>
> 1

*x*

> *[∂h]{.underline}*1 = *w*
>
> *h*1

0

> × *[∂h]{.underline}*2 = 1
>
> *h*2
>
> 0
>
> \+
>
> *[∂h]{.underline}*3 = −1
>
> *h*3
>
> 0
>
> × *[∂h]{.underline}*4 = exp(*h* )
>
> *h*4

exp

> 1
>
> *[∂h]{.underline}*5 = 1

1

> ![](/root/autodl-tmp/project_knowledge/Doc_QA/Knowledge_based/1828695663060254721/image_output/7.《神经网络与深度学习》/media/image76.png)*h*5
> *h*6
>
> 2
>
> \+ /
>
> *[∂h]{.underline}*6 [1 ]{.underline}
>
> = −
>
> *f* (*x*; *w, b*)

*∂x ∂h*1

*∂h*2

*∂h*3

> ^3^ *∂h*
>
> *∂h*5 2

= 0 0 *[∂h]{.underline}*1 = *x*

*∂w*

> 0 *∂h*

= 1

^2^ = 1

> = −0*.*25
>
> *∂b*
>
> *w* = 1 *b* −1 1
>
> 图 4.8 复合函数*f* (*x*; *w, b*) 的计算图
>
> 从计算图上可以看出，复合函数*f* (*x*; *w, b*) 由6 个基本函数*h~i~,* 1
> ≤ *i* ≤ 6
> 组成。如表[4.1](\l)所示，每个基本函数的导数都十分简单，可以通过规则来实现。
>
> 函数 导数
>
> *h*~1~ = *x* × *w [∂h]{.underline}*[1]{.underline} = *x
> [∂h]{.underline}*[1]{.underline} = *w*
>
> *h*~2~ = *h*~1~ + *b [∂h]{.underline}*[2]{.underline} = 1
> [*∂h*2]{.underline} = 1
>
> *∂h*~1~ *∂b*
>
> *h*~3~ = *h*~2~ 1 [*∂h*3]{.underline} = 1
>
> *∂h*~2~
>
> *h*~4~ = exp(*h*~3~) [*∂h*4]{.underline} = exp(*h*~3~)
>
> *∂h*~3~
>
> *h*~5~ = *h*~4~ + 1 [*∂h*5]{.underline} = 1
>
> *∂h*~4~
>
> [*∂h*~6~]{.underline} 1

*h*~6~ = 1*/h*~5~

> *∂h*~5~ = − *h*^2^
>
> 表 4.1 复合函数*f* (*x*; *w, b*) 的6 个基本函数及其导数
>
> 整个复合函数 *f* (*x*; *w, b*) 关于参数 *w* 和 *b*
> 的导数可以通过计算图上的节点 *f* (*x*; *w, b*) 与参数*w* 和*b*
> 之间路径上所有的导数连乘来得到，即
>
> [*∂f*(*x*; *w, b*)]{.underline} = [*∂f*(*x*; *w, b*) *∂h*~6~ *∂h*~5~
> *∂h*~4~ *∂h*~3~ *∂h*~2~ *∂h*~1~]{.underline} *,* (4.69)
>
> *∂w ∂h*~6~ *∂h*~5~ *∂h*~4~ *∂h*~3~ *∂h*~2~ *∂h*~1~ *∂w*

[*∂f*(*x*; *w, b*)]{.underline} = [*∂f*(*x*; *w, b*) *∂h*~6~ *∂h*~5~
*∂h*~4~ *∂h*~3~ *∂h*~2~]{.underline} *.* (4.70)

> *∂b ∂h*~6~ *∂h*~5~ *∂h*~4~ *∂h*~3~ *∂h*~2~ *∂b*
>
> 以 ^[*∂f*(*x*;*w,b*)]{.underline}^ 为例，当*x* = 1*, w* = 0*, b* = 0
> 时，可以得到
>
> *∂f* (*x*; *w, b*) *∂f* (*x*; *w, b*) *∂h*~6~ *∂h*~5~ *∂h*~4~ *∂h*~3~
> *∂h*~2~ *∂h*~1~
>
> *∂w* \|*x*=1*,w*=0*,b*=0 =
>
> *∂h*~6~
>
> (4.71)
>
> *∂h*~5~ *∂h*~4~ *∂h*~3~ *∂h*~2~ *∂h*~1~ *∂w*
>
> = 1 × −0*.*25 × 1 × 1 × −1 × 1 × 1 (4.72)
>
> = 0*.*25*.* (4.73)
>
> 如果函数和参数之间有多条路径，可以将这多条路径上的导数再进行相加，
> 得到最终的梯度。
>
> 按照计算导数的顺序，自动微分可以分为两种模式：前向模式和反向模式。
>
> 前向模式 前向模式是按计算图中计算方向的相同方向来递归地计算梯度。以
>
> ^[*∂f*(*x*;*w,b*)]{.underline}^ 为例，当*x* = 1*, w* = 0*, b* = 0
> 时，前向模式的累积计算顺序如下：
>
> [*∂h*1]{.underline} = *x* = 1 (4.74)
>
> *∂w*
>
> [*∂h*2]{.underline} = [*∂h*2 *∂h*1]{.underline} = 1 × 1 = 1 (4.75)

*∂w ∂h*~1~ *∂w*

> [*∂h*3]{.underline} = [*∂h*3 *∂h*2]{.underline} = −1 × 1 (4.76)

*∂w ∂h*~2~ *∂w*

.

> . (4.77)
>
> [*∂h*6]{.underline} = [*∂h*6 *∂h*5]{.underline} = −0*.*25 × −1 =
> 0*.*25 (4.78)
>
> *∂w ∂h*~5~ *∂w*
>
> [*∂f*(*x*; *w, b*)]{.underline} = [*∂f*(*x*; *w, b*)
> *∂h*~6~]{.underline} = 1 × 0*.*25 = 0*.*25 (4.79)
>
> *∂w ∂h*~6~ *∂w*
>
> 反向模式 反向模式是按计算图中计算方向的相反方向来递归地计算梯度。以
>
> ^[*∂f*(*x*;*w,b*)]{.underline}^ 为例，当*x* = 1*, w* = 0*, b* = 0
> 时，反向模式的累积计算顺序如下：
>
> [*∂f*(*x*; *w, b*)]{.underline} = 1
>
> *∂h*~6~
>
> [*∂f*(*x*; *w, b*)]{.underline} = [*∂f*(*x*; *w, b*)
> *∂h*~6~]{.underline}

*∂h*~5~

*∂h*~6~

> *∂h*~5~
>
> [*∂f*(*x*; *w, b*)]{.underline} = [*∂f*(*x*; *w, b*)
> *∂h*~5~]{.underline}

*∂h*~4~

.

*∂h*~5~

.

> *∂h*~4~
>
> [*∂f*(*x*; *w, b*)]{.underline} = [*∂f*(*x*; *w, b*)
> *∂h*~1~]{.underline}
>
> *∂w ∂h*~1~ *∂w*
>
> 前向模式和反向模式可以看作是应用链式法则的两种梯度累积方式。从反
> 向模式的计算顺序可以看出，反向模式和反向传播的计算梯度的方式相同。
>
> 对于一般的函数形式*f* : R*n* →
> R*m*，前向模式需要对每一个输入变量都进行一遍遍历，共需要*n*
> 遍。而反向模式需要对每一个输出都进行一个遍历，共需要*m* 遍。当*n \> m*
> 时，反向模式更高效。在前馈神经网络的参数学习中，风险函数为*f* : R*n* →
> R，输出为标量，因此采用反向模式为最有效的计算方式， 只需要一遍计算。
>
> 符号微分和自动微分
> 符号微分和自动微分都利用计算图和链式法则来自动求解导数。符号微分在编译阶段先构造一个复合函数的计算图，通过符号计算得
> 到导数的表达式，还可以对导数表达式进行优化，在程序运行阶段才代入变量
> 的具体数值进行计算导数。而自动微分则无需事先编译，在程序运行阶段边计
> 算边记录计算图，计算图上的局部梯度都直接代入数值进行计算，然后用前向
> 或反向模式来计算最终的梯度。
>
> 图[4.9](\l)给出了符号微分与自动微分的对比。
>
> 4.6 优化问题 2019 年 4 月 6 日 107
>
> 符号微分
>
> 程序实现 程序实现

+-----------------------+-----------------------+-----------------------+
| > 程序函数 function   | > 自动微分            | > 程序函数 function   |
| > f(x){· · · }        |                       | > df(x){· · · }       |
+-----------------------+-----------------------+-----------------------+
|                       |                       |                       |
+-----------------------+-----------------------+-----------------------+

> 图 4.9 符号微分与自动微分对比
>
> 静态计算图和动态计算图
> 计算图的构建可以分为静态计算图和动态计算图。静态计算图是在编译时构建计算图，计算图构建好之后在程序运行时不能改变，而
> 动态计算图是在程序运行时动态构建。两种构建方式各有优缺点。静态计算图
> 在构建时可以进行优化，并行能力强，但灵活性比较差。动态计算图则不容易
> 优化，当不同输入的网络结构不一致时，难以并行计算，但是灵活性比较高。
>
> 在目前深度学习框架里，Theano 和Tensorﬂow
> 采用的是静态计算图，而DyNet，Chainer 和PyTorch 采用的是动态计算图。

#### 优化问题

> 神经网络的参数学习比线性模型要更加困难，主要原因有两点：（1）非凸优化问题和（2）梯度消失问题。

###### 非凸优化问题

> 神经网络的优化问题是一个非凸优化问题。以一个最简单的1-1-1 结构的2
>
> 层神经网络为例来其损失函数与参数的可视化例子。
>
> *y* = *σ*(*w*~2~*σ*(*w*~1~*x*))*,* (4.85)
>
> 其中*w*~1~ 和*w*~2~ 为网络参数，激活函数为Logistic 函数*σ*(·)。
>
> 给定一个输入样本(1*,*
> 1)，分别使用两种损失函数，第一种损失函数为平方误差损失：L(*w*~1~*,
> w*~2~) = (1−*y*)2，第二种损失函数为交叉熵损失L(*w*~1~*, w*~2~) = ln
> *y*。当*x* = 1*, y* = 1
> 时，其平方误差和交叉熵损失函数分别为：L(*w*~1~*, w*~2~) = (1 − *y*)2
> 和L(*w*~1~*, w*~2~) = ln *y*。损失函数与参数*w*~1~ 和*w*~2~
> 的关系如图[4.10](\l)所示，可以看出损失函数关于两个参数是一种非凸的函数关系。

###### 梯度消失问题

> 在神经网络中误差反向传播的迭代公式为
>
> *δ*(*l*) = *f* ′(**z**(*l*)) ⊙ *W* (*l*+1) T*δ*(*l*+1)*,* (4.86)
>
图片识别内容

>
> 6
>
> 0.75
>
> 0.50 5
>
> 0.25 4
>
> L
>
> 0.00 3
>
> L
>
> 0.25
>
> 2
>
> 0.50
>
> 1
>
> 0.75
>
> 1.00 0
>
> 4
>
> 2
>
> 0 4
>
> w2 2
>
> 2 0
>
> 4 2 w1

4

1

> 4
>
> 2
>
> 0
>
> w2 2

4

4

2

0

2 w1

4

(a) 平方误差损失 (b) 交叉熵损失

> 图 4.10 神经网络*y* = *σ*(*w*~2~*σ*(*w*~1~*x*)) 的损失函数
>
> 误差从输出层反向传播时，在每一层都要乘以该层的激活函数的导数。当我们
> 使用Sigmoid 型函数：Logistic 函数*σ*(*x*) 或Tanh 函数时，其导数为
>
> *σ*^′^(*x*) = *σ*(*x*) 1 − *σ*(*x*) ∈ \[0*,* 0*.*25\] (4.87)
>
> tanh^′^(*x*) = 1 − tanh(*x*) 2 ∈ \[0*,* 1\]*.* (4.88) Sigmoid
> 型函数导数的值域都小于1，如图[4.11](\l)所示。

0*.*25

0*.*2

0*.*15

0*.*1

5 · 10−2

> −4 −2 0 2 4 6

(a) Logistic 函数的导数

1

0*.*8

0*.*6

0*.*4

0*.*2

0

> −4 −2 0 2 4 6

(b) Tanh 函数的导数

> 图 4.11 激活函数的导数
>
> 梯度消失问题在过去的二三 十年里一直没有有效地解决，
> 是阻碍神经网络发展的重要 原因之一。
>
> 由于Sigmoid
> 型函数的饱和性，饱和区的导数更是接近于0。这样，误差经过每一层传递都会不断衰减。当网络层数很深时，梯度就会不停的衰减，甚至消
> 失，使得整个网络很难训练。这就是所谓的梯度消失问题（Vanishing Gradient
> Problem），也叫梯度弥散问题。
>
> 在深层神经网络中，减轻梯度消失问题的方法有很多种。一种简单有效的
> 方式是使用导数比较大的激活函数，比如ReLU 等。

7.  总结和深入阅读 2019 年 4 月 6 日 109

> **4.7** 总结和深入阅读
>
> 神经网络是一种典型的分布式并行处理模型，通过大量神经元之间的交
> 互来处理信息，每一个神经元都发送兴奋和抑制的信息到其它神经元\[[Rumel-](\l)
> [hart et al.](\l),
> [1986](\l)\]。和感知器不同，神经网络中的激活函数一般为连续可导函数。表[4.2](\l)给出了常见激活函数及其导数。在一个神经网络中选择合适的激活函
> 数十分重要。[Ramachandran et al.](\l) \[[2017](\l)\]
> 设计了不同形式的函数组合方式，并通过强化学习来搜索合适的激活函数，在多个任务上发现Swish
> 函数具有更好的性能。
>
> 激活函数 函数 导数
>
> Logistic 函数 *f* (*x*) = [ 1 ]{.underline}
>
> −
>
> [exp(*x*)]{.underline} [exp(]{.underline} [*x*)]{.underline}
> exp(*x*)+exp(−*x*)
>
> *f* ^′^(*x*) = *f* (*x*) 1 − *f* (*x*)
>
> *f* ^′^(*x*) = 1 − *f* (*x*)2
>
> ReLU *f* (*x*) = max(0*, x*) *f* ^′^(*x*) = *I*(*x \>* 0)
>
> ELU *f* (*x*) = max(0*, x*) + min 0*, γ*(exp(*x*) − 1)
>
> *f* ^′^(*x*) = *I*(*x \>* 0) + *I*(*x* ≤
>
> 0\) · *γ* exp(*x*)
>
> [ ]{.underline} SoftPlus 函数 *f* (*x*) = log 1 + exp(*x*) *f*
> ^′^(*x*) = [ 1 ]{.underline}
>
> 表 4.2 常见激活函数及其导数
>
> 本章介绍的前馈神经网络是一种类型最简单的网络，相邻两层的神经元之间为全连接关系，也称为全连接神经网络（Fully
> Connected Neural Network，
> FCNN）或多层感知器。前馈神经网络作为一种机器学习方法在很多模式识别和机器学习的教材中都有介绍，比如《Pattern
> Recognition and Machine Learning》\[[Bishop](\l),
> [2007](\l)\]，《Pattern Classiﬁcation》\[[Duda et al.](\l),
> [2001](\l)\] 等。
>
> 前馈神经网络作为一种能力很强的非线性模型，其能力可以由通用近似定
> 理来保证。关于通用近似定理的详细介绍可以参考\[[Haykin](\l),
> [2009](\l)\]。
>
> 前馈神经网络在20 世纪80
> 年代后期就已被广泛使用，但是基本上都是两层网络（即一个隐藏层和一个输出层），神经元的激活函数基本上都是Sigmoid型函数，并且使用的损失函数大多数是平方损失。虽然当时前馈神经网络的参
> 数学习依然有很多难点，但其作为一种连接主义的典型模型，标志人工智能从
> 高度符号化的知识期向低符号化的学习期开始转变。
>
> TensorFlow 游乐场[^1^](\l)
> 提供了一个非常好的神经网络训练过程可视化系统。
>
> 1 http://playground.tensorﬂow.org
>
> 110 2019 年 4 月 6 日 参考文献

#### 习题

> 习题**4-1** 对于一个神经元*σ*(**w**T**x** +
> *b*)，并使用梯度下降优化参数**w** 时，如果输入**x**
> 恒大于0，其收敛速度会比零均值化的输入更慢。
>
> 习题 **4-2** 试设计一个前馈神经网络来解决XOR
> 问题，要求该前馈神经网络具有两个隐藏神经元和一个输出神经元，并使用ReLU
> 作为激活函数。
>
> 习题 **4-3** 试举例说明"死亡ReLU 问题"，并提出解决方法。
>
> 参见第[4.1.3](\l)节。
>
> 参见定理[4.1](\l)。
>
> 习题 **4-4** 计算Swish 函数的导数。
>
> 习题**4-5** 如果限制一个神经网络的总神经数量为*N*
> ，层数为*L*，每个隐藏层的神经元数量为 ^[*N*−1]{.underline}^
> ，试分析参数数量和层数*L* 的关系。
>
> *L*−1
>
> 习题**4-6** 证明通用近似性质对于具有线性输出层和至少一个使用ReLU
> 激活函数的隐藏层组成的前馈神经网络，也都是适用的。
>
> 习题 **4-7** 为什么在神经网络模型的结构化风险函数中不对偏置 **b**
> 进行正则化？
>
> 习题 **4-8**
> 为什么在用反向传播算法进行参数学习时要采用随机参数初始化的方式而不是直接令*W*
> = 0*,* **b** = 0？
>
> 习题 **4-9** 梯度消失问题是否可以通过增加学习率来缓解？

#### 参考文献

> Christopher M. Bishop. *Pattern recogni- tion and machine learning,
> 5th Edition*. In- formation science and statistics. Springer, 2007.
> ISBN 9780387310732.
>
> Djork-Arné Clevert, Thomas Unterthiner, and Sepp Hochreiter. Fast and
> accu- rate deep network learning by exponen- tial linear units (elus).
> *arXiv preprint*
>
> *arXiv:1511.07289*, 2015.
>
> George Cybenko. Approximations by su- perpositions of a sigmoidal
> function. *Math- ematics of Control, Signals and Systems*, 2:
>
> 183--192, 1989.
>
> Richard O. Duda, Peter E. Hart, and David G. Stork. *Pattern
> classiﬁcation, 2nd Edition*. Wiley, 2001. ISBN 9780471056690.
>
> 参考文献 2019 年 4 月 6 日 111
>
> Charles Dugas, Yoshua Bengio, François Bélisle, Claude Nadeau, and
> René Gar- cia. Incorporating second-order functional knowledge for
> better option pricing. *Ad- vances in Neural Information Processing*
> *Systems*, pages 472--478, 2001.
>
> Ken-ichi Funahashi and Yuichi Nakamura. Approximation of dynamical
> systems by continuous time recurrent neural networks. *Neural
> networks*, 6(6):801--806, 1993.
>
> Justin Gilmer, Samuel S Schoenholz, Patrick F Riley, Oriol Vinyals,
> and George E Dahl. Neural message passing for quantum chemistry.
> *arXiv preprint* *arXiv:1704.01212*, 2017.
>
> Xavier Glorot, Antoine Bordes, and Yoshua Bengio. Deep sparse rectiﬁer
> neural net- works. In *International Conference on Arti- ﬁcial
> Intelligence and Statistics*, pages 315-- 323, 2011.
>
> Ian J Goodfellow, David Warde-Farley, Mehdi Mirza, Aaron C Courville,
> and Yoshua Bengio. Maxout networks. In *Pro- ceedings of the
> International Conference on* *Machine Learning*, pages 1319--1327,
> 2013. Alex Graves, Greg Wayne, and Ivo Dani- helka. Neural turing
> machines. *arXiv* *preprint arXiv:1410.5401*, 2014.
>
> Simon Haykin. Neural networks: A compre- hensive foundation: Macmillan
> college pub- lishing company. *New York*, 1994.
>
> Simon Haykin. *Neural networks and learn- ing machines*, volume 3.
> Pearson Upper Saddle River, NJ, USA:, 2009.
>
> Kaiming He, Xiangyu Zhang, Shaoqing Ren, and Jian Sun. Delving deep
> into recti- ﬁers: Surpassing human-level performance on imagenet
> classiﬁcation. In *Proceedings*
>
> *of the IEEE International Conference on* *Computer Vision*, pages
> 1026--1034, 2015. Kurt Hornik, Maxwell Stinchcombe, and Halbert White.
> Multilayer feedforward net- works are universal approximators.
> *Neural* *networks*, 2(5):359--366, 1989.
>
> Thomas N Kipf and Max Welling. Semi- supervised classiﬁcation with
> graph con- volutional networks. *arXiv preprint* *arXiv:1609.02907*,
> 2016.
>
> Andrew L Maas, Awni Y Hannun, and An- drew Y Ng. Rectiﬁer
> nonlinearities improve neural network acoustic models. In *Pro-
> ceedings of the International Conference on* *Machine Learning*, 2013.
>
> Warren S McCulloch and Walter Pitts. A logical calculus of the ideas
> immanent in nervous activity. *The bulletin of mathemat-* *ical
> biophysics*, 5(4):115--133, 1943.
>
> Vinod Nair and Geoﬀrey E Hinton. Rec- tiﬁed linear units improve
> restricted boltz- mann machines. In *Proceedings of the Inter-
> national Conference on Machine Learning*, pages 807--814, 2010.
>
> Prajit Ramachandran, Barret Zoph, and Quoc V Le. Searching for
> activation func- tions. *arXiv preprint arXiv:1710.05941*, 2017.
>
> David E Rumelhart, Geoﬀrey E Hinton, James L McClelland, et al. A
> general framework for parallel distributed process- ing. *Parallel
> distributed processing: Explo- rations in the microstructure of
> cognition*, 1:45--76, 1986.
>
> Sainbayar Sukhbaatar, Jason Weston, Rob Fergus, et al. End-to-end
> memory networks. In *Advances in Neural Information Process- ing
> Systems*, pages 2431--2439, 2015.

第**5** 章 卷积神经网络
=======================

> 一切都应该尽可能地简单，但不能过于简单。
>
> --- 艾伯特· 爱因斯坦
>
> 卷积神经网络（Convolutional Neural Network，CNN
> 或ConvNet）是一种具有局部连接、权重共享等特性的深层前馈神经网络。
>
> 卷积神经网络最早是主要用来处理图像信息。如果用全连接前馈网络来处
> 理图像时，会存在以下两个问题：

1.  参数太多：如果输入图像大小为100 × 100 × 3（即图像高度为100，
    > 宽度为100，3
    > 个颜色通道：RGB）。在全连接前馈网络中，第一个隐藏层的每个神经元到输入层都有100
    > × 100 × 3 = 30*,* 000
    > 个相互独立的连接，每个连接都对应一个权重参数。随着隐藏层神经元数量的增多，参数的规模也会急剧增加。
    > 这会导致整个神经网络的训练效率会非常低，也很容易出现过拟合。

2.  局部不变性特征：自然图像中的物体都具有局部不变性特征，比如在
    > 尺度缩放、平移、旋转等操作不影响其语义信息。而全连接前馈网络很难提取
    > 这些局部不变特征，一般需要进行数据增强来提高性能。

> 卷积神经网络是受生物学上感受野的机制而提出。感受野（Receptive Field）
> 主要是指听觉、视觉等神经系统中一些神经元的特性，即神经元只接受其所支配的刺激区域内的信号。在视觉神经系统中，视觉皮层中的神经细胞的输出依赖于视网膜上的光感受器。视网膜上的光感受器受刺激兴奋时，将神经冲动信号传到视觉皮层，但不是所有视觉皮层中的神经元都会接受这些信号。一个神经元的感受野是指视网膜上的特定区域，只有这个区域内的刺激才能够激活该神经元。
>
> 目前的卷积神经网络一般是由卷积层、汇聚层和全连接层交叉堆叠而成的
> 前馈神经网络，使用反向传播算法进行训练。卷积神经网络有三个结构上的特
>
> 全连接层一般在卷积网络的最顶层。
>
> 性：局部连接，权重共享以及汇聚。这些特性使得卷积神经网络具有一定程度上的平移、缩放和旋转不变性。和前馈神经网络相比，卷积神经网络的参数更少。
>
> 卷积神经网络主要使用在图像和视频分析的各种任务上，比如图像分类、人
> 脸识别、物体识别、图像分割等，其准确率一般也远远超出了其它的神经网络
> 模型。近年来卷积神经网络也广泛地应用到自然语言处理、推荐系统等领域。

#### 卷积

> 这里我们只考虑离散序列的情况。
>
> 卷积（Convolution），也叫摺积，是分析数学中一种重要的运算。在信号
> 处理或图像处理中，经常使用一维或二维卷积。
>
> 一维卷积
> 一维卷积经常用在信号处理中，用于计算信号的延迟累积。假设一个信号发生器每个时刻*t*
> 产生一个信号*x~t~*，其信息的衰减率为*w~k~*，即在*k* − 1
> 个时间步长后，信息为原来的*w~k~* 倍。假设*w*~1~ = 1*, w*~2~ = 1*/*2*,
> w*~3~ = 1*/*4，那么在时刻 *t* 收到的信号*y~t~*
> 为当前时刻产生的信息和以前时刻延迟信息的叠加，

*y~t~* = 1 × *x~t~* + 1*/*2 × *x~t~*~−1~ + 1*/*4 × *x~t~*~−2~ (5.1)

= *w*~1~ × *x~t~* + *w*~2~ × *x~t~*~−1~ + *w*~3~ × *x~t~*~−2~ (5.2)

3

= *w~k~ x~t~*~−*k*+1~*.* (5.3)

> *k*=1
>
> 我们把*w*~1~*, w*~2~*,* · · ·
> 称为滤波器（Filter）或卷积核（Convolution
> Kernel）。假设滤波器长度为*m*，它和一个信号序列*x*~1~*, x*~2~*,* · · ·
> 的卷积为
>
> *m*
>
> *y~t~* = *w~k~ x~t~*~−*k*+1~*,* (5.4)
>
> *k*=1
>
> 信号序列**x** 和滤波器**w** 的卷积定义为
>
> **y** = **w** ⊗ **x***,* (5.5)
>
> 其中⊗ 表示卷积运算。
>
> 一般情况下滤波器的长度*m* 远小于信号序列长度*n*。当滤波器*f~k~* =
> 1*/m,* 1 ≤ *k* ≤ *m*
> 时，卷积相当于信号序列的移动平均。图[5.1](\l)给出了一维卷积示例。滤波器为\[−1*,*
> 0*,* 1\]，连接边上的数字为滤波器中的权重。

+-----+------+------+------+------+------+-----+
|     | > -1 | > 2  | > 1  | > 1  | > 0  |     |
+-----+------+------+------+------+------+-----+
|     | > -1 | > -1 | > -1 | > -1 | > -1 |     |
+-----+------+------+------+------+------+-----+
| 0   |      | 0    | 0 0  | 0    |      |     |
+-----+------+------+------+------+------+-----+
| > 1 | > 1  | > 1  | > 1  | > 1  |      |     |
+-----+------+------+------+------+------+-----+
| > 1 | > 1  | > 2  | > -1 | > 1  | > -2 | > 1 |
+-----+------+------+------+------+------+-----+

> 图 5.1 一维卷积示例
>
> 二维卷积
> 卷积也经常用在图像处理中。因为图像为一个两维结构，所以需要将一维卷积进行扩展。给定一个图像*X*
> ∈ R*M* ×*N* ，和滤波器 *W* ∈ R*m*×*n*，一般*m \<\< M, n \<\< N*
> ，其卷积为

*m n*

> *yij* = *wuv xi*−*u*+1*,j*−*v*+1*.* (5.6)
>
> *u*=1 *v*=1
>
> 图[5.2](\l)给出了二维卷积示例。

⊗ =

> 图 5.2 二维卷积示例
>
> 常用的均值滤波（mean
> ﬁlter）就是当前位置的像素值设为滤波器窗口中所有像素的平均值，也就是*f~uv~*
> = [ 1]{.underline} 。
>
> 在图像处理中，卷积经常作为特征提取的有效方法。一幅图像在经过卷积
> 操作后得到结果称为特征映射（Feature
> Map）。图[5.3](\l)给出在图像处理中几种常用的滤波器，以及其对应的特征映射。图中最上面的滤波器是常用的高斯滤
> 波器，可以用来对图像进行平滑去噪；中间和最下面的过滤器可以用来提取边
> 缘特征。

图片识别内容


原始图像

> 滤波器
>
> =
>
图片识别内容

图片识别内容

>
图片识别内容

>
> 输出特征映射
>
> 图 5.3 图像处理中几种常用的滤波器示例

###### 互相关

> 翻转就是从两个维度（从上 到下、从左到右）颠倒次序， 即旋转180 度。
>
> 在机器学习和图像处理领域，卷积的主要功能是在一个图像（或某种特征）
> 上滑动一个卷积核（即滤波器），通过卷积操作得到一组新的特征。在计算卷积的过程中，需要进行卷积核翻转。在具体实现上，一般会以互相关操作来代替卷积，从而会减少一些不必要的操作或开销。互相关（Cross-Correlation）是一个衡量两个序列相关性的函数，通常是用滑动窗口的点积计算来实现。给定一个图像*X*
> ∈ R*M* ×*N* 和卷积核*W* ∈ R*m*×*n*，它们的互相关为
>
> *m n*
>
> 互相关和卷积的区别也可以
>
> *yij* = *wuv xi*+*u*−1*,j*+*v*−1*.* (5.7)
>
> *u*=1 *v*=1
>
> 和公式([5.6](\l))
> 对比可知，互相关和卷积的区别在于卷积核仅仅是否进行翻转。因此互相关也可以称为不翻转卷积。
>
> 理解为图像是否进行翻转。
> 在神经网络中使用卷积是为了进行特征抽取，卷积核是否进行翻转和其特
> 征抽取的能力无关。特别是当卷积核是可学习的参数时，卷积和互相关是等价
>
> 的。因此，为了实现上（或描述上）的方便起见，我们用互相关来代替卷积。事实上，很多深度学习工具中卷积操作其实都是互相关操作。
>
> 公式([5.7](\l)) 可以表述为
>
> *Y* = *W* ⊗ *X,* (5.8)
>
> 其中*Y* ∈ R*M* −*m*+1*,N* −*n*+1 为输出矩阵。

###### 卷积的变种

> 在卷积的标准定义基础上，还可以引入滤波器的滑动步长和零填充来增加
> 卷积的多样性，可以更灵活地进行特征抽取。
>
> 滤波器的步长（Stride）是指滤波器在滑动时的时间间隔。图[5.4a](\l)给出了步
> 长为2 的卷积示例。
>
> 零填充（Zero
> Padding）是在输入向量两端进行补零。图[5.4b](\l)给出了输入的两端各补一个零后的卷积示例。
>
> 在本书之后描述中，除非特别声明，卷积一般指"互相关"。
>
> 步长也可以小于1，即微步卷积参见第[5.5.1](\l)节。

+-----+-----+-----+------+-----+------+-----+
|     |     |     |      |     |      |     |
+-----+-----+-----+------+-----+------+-----+
| > 1 | > 1 | > 2 | > -1 | > 1 | > -3 | > 1 |
+-----+-----+-----+------+-----+------+-----+

a.  步长*s* = 2

+------+------+-----+------+-----+------+------+--+
| > -1 | > -1 | > 2 | > 1  | > 2 | > 0  | > -3 |  |
+------+------+-----+------+-----+------+------+--+
|      |      |     |      |     |      |      |  |
+------+------+-----+------+-----+------+------+--+
| > 1  | > 1  | > 2 | > -1 | > 1 | > -3 | 1    |  |
+------+------+-----+------+-----+------+------+--+

b.  零填充*p* = 1

> 图 5.4 卷积的步长和零填充 通常可以通过选择合适的卷积大小以及步长来使得
>
> 假设卷积层的输入神经元个数为*n*，卷积大小为*m*，步长（stride）为*s*，输入神经元两端各填补
> *p* 个零（zero padding），那么该卷积层的神经元数量为(*n* − *m* +
> 2*p*)*/s* + 1。
>
> (*n* − *m* + 2*p*)*/s* + 1 为整数。
>
> 在早期的文献中，卷积一般默认为窄卷积；而目前的文献中，卷积一般默认为等宽卷积。
>
> 更 多 的 卷 积 变 种 参 见
>
> 一般常用的卷积有以下三类：

-   窄卷积（Narrow Convolution）：步长*s* = 1，两端不补零*p* =
    > 0，卷积后输出长度为*n* − *m* + 1。

-   宽卷积（Wide Convolution）：步长*s* = 1，两端补零*p* = *m* −
    > 1，卷积后输出长度*n* + *m* − 1。

-   等宽卷积（Equal-Width Convolution）：步长*s* = 1，两端补零*p* = (*m*
    > − 1)*/*2，卷积后输出长度*n*。图[5.4b](\l)就是一个等长卷积示例。

> 第[5.5](\l)节。 **5.1.3** 卷积的数学性质
>
> 卷积有很多很好的数学性质。在本节中，我们介绍一些二维卷积的数学性
> 质，但是这些数学性质同样可以适用到一维卷积的情况。

1.  交换性

> 如果不限制两个卷积信号的长度，卷积是具有交换性的，即**x** ⊗ **y** =
> **y** ⊗
> **x**。当输入信息和卷积核有固定长度时，它们的宽卷积依然具有交换性。
>
> 对于两维图像*X* ∈ R*M* ×*N* 和卷积核*W* ∈ R*m*×*n*，对图像*X*
> 的两个维度进行零填充，两端各补*m* − 1 和*n* − 1 个零，得到全填充（Full
> Padding）的图像*X*˜ ∈ R(*M* +2*m*−2)×(*N* +2*n*−2)。图像*X*
> 和卷积核*W* 的宽卷积（Wide Convolution）定义为
>
> 参见习题[5-1](\l)。
>
> 其中⊗˜ 为宽卷积操作。
>
> 宽卷积具有交换性，即

2.  导数

> *W* ⊗˜ *X* , *W* ⊗ *X*˜*,* (5.9)
>
> *W* ⊗˜ *X* = *X*⊗˜ *W.* (5.10)
>
> 假设*Y* = *W* ⊗*X*，其中*X* ∈ R*M* ×*N* ，*W* ∈ R*m*×*n*，*Y* ∈ R(*M*
> −*m*+1)×(*N* −*n*+1)，函数*f* (*Y* ) ∈ R 为一个标量函数，则
>
> *M* −*m*+1 *N* −*n*+1
>
> [*∂f*(*Y* )]{.underline} = Σ Σ [ *∂y~ij~ ∂f*(*Y* )]{.underline}
>
> (5.11)
>
> *M* −*m*+1 *N* −*n*+1

*y*~ij~ =

> = Σ Σ
>
> *xi*+*u*−1*,j*+*v*−1

[*∂f*(*Y* )]{.underline}

> *∂y~ij~*
>
> (5.12)

Σ *w x*

*i*=1

> *j*=1 [ ]{.underline}

u,v

=

*i*=1

> Σ*j*=1
>
> *∂f* (*Y* )
>
> *∂y~ij~*

*xu*+*i*−1*,v*+*j*−1

> (5.13)
>
> 从公式([5.13](\l)) 可以看出，*f* (*Y* ) 关于*W* 的偏导数为*X* 和
> [^*∂f*(*Y*^ ^)^]{.underline} 的卷积
>
> [*∂f*(*Y* )]{.underline} = [*∂f*(*Y* )]{.underline} ⊗ *X.* (5.14)

同理得到，

> *M* −*m*+1 *N* −*n*+1
>
> [*∂f*(*Y* )]{.underline} = Σ Σ [*∂y~ij~ ∂f*(*Y* )]{.underline}
>
> (5.15)
>
> *M* −*m*+1 *N* −*n*+1

= Σ

*i*=1 *j*=1

> *ws*−*i*+1*,t*−*j*+1
>
> *,* (5.16)
>
> *∂y~ij~*
>
> 其中当(*s* − *i* + 1) *\<* 1，或(*s* − *i* + 1) *\> m*，或(*t* − *j* +
> 1) *\<* 1，或(*t* − *j* + 1) *\> n*
>
> 时，*w~s~*~−*i*+1*,t*−*j*+1~ = 0。即相当于对*W* 进行了*p* = (*M* − *m,
> N* − *n*) 的零填充。
>
> 从公式([5.16](\l)) 可以看出，*f* (*Y* ) 关于*X* 的偏导数为*W* 和
> [^*∂f*(*Y*^ ^)^]{.underline} 的宽卷积。公式([5.16](\l))
> 中的卷积是真正的卷积而不是互相关，为了一致性，我们用互相关的"卷积"，即
>
> [*∂f*(*Y* )]{.underline} = **rot180**( [*∂f*(*Y* )]{.underline})⊗˜ *W*
> (5.17)

*∂X ∂Y*

> = **rot180**(*W* ) ˜ [*∂f*(*Y* )]{.underline} *,* (5.18)
>
> *∂Y*
>
> 其中**rot180**(·) 表示旋转180 度。

#### 卷积神经网络

> 卷积神经网络一般由卷积层、汇聚层和全连接层构成。

###### 用卷积来代替全连接

> 在全连接前馈神经网络中，如果第*l* 层有*n^l^* 个神经元，第*l* − 1
> 层有*n*^(*l*−1)^ 个神经元，连接边有*n*^(*l*)\ ×\ *n*(*l*−1)^
> 个，也就是权重矩阵有*n*^(*l*)\ ×\ *n*(*l*−1)^ 个参数。当*m* 和*n*
> 都很大时，权重矩阵的参数非常多，训练的效率会非常低。
>
> 如果采用卷积来代替全连接，第*l* 层的净输入**z**(*l*) 为第*l* − 1
> 层活性值**a**(*l*−1)
>
> 和滤波器**w**(*l*) ∈ R*m* 的卷积，即
>
> **z**(*l*) = **w**(*l*) ⊗ **a**(*l*−1) + *b*(*l*)*,* (5.19)
>
> 其中滤波器**w**(*l*) 为可学习的权重向量，*b*^(*l*)^ ∈ R*nl*−1
> 为可学习的偏置。根据卷积的定义，卷积层有两个很重要的性质：
>
> 局部连接 在卷积层（假设是第*l* 层）中的每一个神经元都只和下一层（第*l*
> − 1
> 层）中某个局部窗口内的神经元相连，构成一个局部连接网络。如图[5.5b](\l)所示，
> 卷积层和下一层之间的连接数大大减少，有原来的*n^l^* × *n^l^*^−1^
> 个连接变为*n^l^* × *m* 个连接，*m* 为滤波器大小。
>
> 权重共享 从公式([5.19](\l)) 可以看出，作为参数的滤波器**w**(*l*)
> 对于第*l*
> 层的所有的神经元都是相同的。如图[5.5b](\l)中，所有的同颜色连接上的权重是相同的。

![](/root/autodl-tmp/project_knowledge/Doc_QA/Knowledge_based/1828695663060254721/image_output/7.《神经网络与深度学习》/media/image83.png)

a.  全连接层

![](/root/autodl-tmp/project_knowledge/Doc_QA/Knowledge_based/1828695663060254721/image_output/7.《神经网络与深度学习》/media/image83.png)

b.  卷积层

> 图 5.5 全连接层和卷积层对比
>
> 由于局部连接和权重共享，卷积层的参数只有一个*m* 维的权重**w**(*l*) 和1
> 维的偏置*b*^(*l*)^，共*m* + 1
> 个参数。参数个数和神经元的数量无关。此外，第*l*
> 层的神经元个数不是任意选择的，而是满足*n*^(*l*)\ =\ *n*(*l*−1)^ − *m*
> + 1。

###### 卷积层

> 卷积层的作用是提取一个局部区域的特征，不同的卷积核相当于不同的特征提取器。上一节中描述的卷积层的神经元和全连接网络一样都是一维结构。
> 既然卷积网络主要应用在图像处理上，而图像为两维结构，因此为了更充分地利用图像的局部信息，通常将神经元组织为三维结构的神经层，其大小为高度*M*
> ×宽度*N* ×深度*D*，有*D* 个*M* × *N* 大小的特征映射构成。
>
> 特征映射（Feature
> Map）为一幅图像（或其它特征映射）在经过卷积提取到的特征，每个特征映射可以作为一类抽取的图像特征。为了提高卷积网络的
>
> 表示能力，可以在每一层使用多个不同的特征映射，以更好地表示图像的特征。
>
> 在输入层，特征映射就是图像本身。如果是灰度图像，就是有一个特征映
> 射，深度*D* = 1；如果是彩色图像，分别有RGB
> 三个颜色通道的特征映射，输入层深度*D* = 3。
>
> 不失一般性，假设一个卷积层的结构如下：

-   输入特征映射组：**X** ∈ R*M* ×*N* ×*D*
    > 为三维张量（tensor），其中每个切片

> (slice) 矩阵*X^d^* ∈ R*M* ×*N* 为一个输入特征映射，1 ≤ *d* ≤ *D*；

-   输出特征映射组：**Y** ∈ R*M* ′×*N* ′×*P*
    > 为三维张量，其中每个切片矩阵*Y ^p^* ∈

> R*M* ′×*N* ′ 为一个输出特征映射，1 ≤ *p* ≤ *P* ；

-   卷积核：**W** ∈ R*m*×*n*×*D*×*P* 为四维张量，其中每个切片矩阵*W
    > ^p,d^* ∈ R*m*×*n*

> 为一个两维卷积核，1 ≤ *d* ≤ *D,* 1 ≤ *p* ≤ *P*
> 。图[5.6](\l)给出卷积层的三维结构表示。

卷积核 **Wp**

> 特征映射 *X^d^*
>
> 特征映射 *Y ^p^*
>
> 特征映射组 **X**
>
> 高度 *M*

深度 *D*

> 宽度 *N*
>
> 图 5.6 卷积层的三维结构表示
>
> 为了计算输出特征映射*Y ^p^*，用卷积核*W ^p,^*^1^*, W ^p,^*^2^*,* · · ·
> *, W ^p,D^* 分别对输入特征映射*X*^1^*, X*^2^*,* · · · *, X^D^*
> 进行卷积，然后将卷积结果相加，并加上一个标量偏置*b*
> 得到卷积层的净输入*Z^p^*，再经过非线性激活函数后得到输出特征映射*Y
> ^p^*。

*D*

> *Z^p^* = **W***p* **X** + *b^p^* = *W ^p,d^ X^d^* + *b^p^,* (5.20)
>
> *d*=1
>
> *Y ^p^* = *f* (*Z^p^*)*.* (5.21)
>
> 其中**W***p* ∈ R*m*×*n*×*D* 为三维卷积核，*f* (·)
> 为非线性激活函数，一般用ReLU
> 函数。整个计算过程如图[5.7](\l)所示。如果希望卷积层输出*P*
> 个特征映射，可以将上述计算机过程重复*P* 次，得到*P* 个输出特征映射*Y*
> ^1^*, Y* ^2^*,* · · · *, Y ^P^* 。
>
> 在输入为**X** ∈ R*M* ×*N* ×*D*，输出为**Y** ∈ R*M* ′×*N* ′×*P*
> 的卷积层中，每一个输入特征映射都需要*D*
> 个滤波器以及一个偏置。假设每个滤波器的大小为*m* × *n*， 那么共需要*P*
> × *D* × (*m* × *n*) + *P* 个参数。
>
> 输入 特征映射
>
> 输出 特征映射
>
> 滤波器 *W^p,D^*
>
> 图 5.7 卷积层中从输入特征映射组**X** 到输出特征映射*Y ^p^* 的计算示例
>
> 减少特征维数也可以通过增加卷积步长来实现。

######  汇聚层

> 汇聚层（Pooling Layer）也叫子采样层（Subsampling
> Layer），其作用是进行特征选择，降低特征数量，并从而减少参数数量。
>
> 卷积层虽然可以显著减少网络中连接的数量，但特征映射组中的神经元个
> 数并没有显著减少。如果后面接一个分类器，分类器的输入维数依然很高，很
> 容易出现过拟合。为了解决这个问题，可以在卷积层之后加上一个汇聚层，从
> 而降低特征维数，避免过拟合。
>
> 假设汇聚层的输入特征映射组为**X** ∈ R*M* ×*N*
> ×*D*，对于其中每一个特征映射
>
> *X^d^*，将其划分为很多区域*R^d^ ,* 1 ≤ *m* ≤ *M* ^′^*,* 1 ≤ *n* ≤ *N*
> ^′^，这些区域可以重叠，
>
> 也可以不重叠。汇聚(Pooling) 是指对每个区域进行下采样（Down Sampling）
> 得到一个值，作为这个区域的概括。
>
> 常用的汇聚函数有两种：

1.  最大汇聚（Maximum Pooling）：一般是取一个区域内所有神经元的最大值。

> *d m,n*
>
> = max
>
> *d m,n*
>
> *x~i~,* (5.22)
>
> 其中*x~i~* 为区域*R^d^* 内每个神经元的激活值。

2.  平均汇聚（Mean Pooling）：一般是取区域内所有神经元的平均值。

*Y d* = [ 1 ]{.underline}

> Σ *x .* (5.23)
>
> 对每一个输入特征映射*X^d^* 的*M*
> ^′\ ×\ *N*\ ′\ 个区域进行子采样，得到汇聚层的^
>
> 输出特征映射*Y ^d^* = {*Y ^d^* }*,* 1 ≤ *m* ≤ *M* ^′^*,* 1 ≤ *n* ≤ *N*
> ^′^。
>
> 图[5.8](\l)给出了采样最大汇聚进行子采样操作的示例。可以看出，汇聚层不但
> 可以有效地减少神经元的数量，还可以使得网络对一些小的局部形态改变保持
> 不变性，并拥有更大的感受野。

输入特征映射组 **X**

> max pooling
>
> 输出特征映射组 **Y**
>
> 输出特征映射 *Y ^d^*

输入特征映射 *X^d^*

> 图 5.8 汇聚层中最大汇聚过程示例
>
> 目前主流的卷积网络中，汇聚层仅包含下采样操作。但在早期的一些卷积
> 网络（比如LeNet-5）中，有时也会在汇聚层使用非线性激活函数，比如
>
> *Y* ^′*d*^ = *f w^d^* · *Y ^d^* + *b^d^ ,* (5.24)
>
> 其中*Y* ^′*d*^ 为汇聚层的输出，*f* (·) 为非线性激活函数，*w^d^*
> 和*b^d^* 为可学习的标量权重和偏置。
>
> 典型的汇聚层是将每个特征映射划分为2 × 2
> 大小的不重叠区域，然后使用最大汇聚的方式进行下采样。汇聚层也可以看做是一个特殊的卷积层，卷积核
> 大小为*m* × *m*，步长为*s* × *s*，卷积核为max 函数或mean
> 函数。过大的采样区域会急剧减少神经元的数量，会造成过多的信息损失。

###### 典型的卷积网络结构

> 一个典型的卷积网络是由卷积层、汇聚层、全连接层交叉堆叠而成。目前常用的卷积网络结构图[5.9](\l)所示。一个卷积块为连续*M*
> 个卷积层和*b* 个汇聚层（*M* 通常设置为2 ∼ 5，*b* 为0
> 或1）。一个卷积网络中可以堆叠*N* 个连续的卷积块， 然后在接着*K*
> 个全连接层（*N* 的取值区间比较大，比如1 ∼ 100 或者更大；*K* 一般为0 ∼
> 2）。
>
> 输入 softmax
>
> ×*K*
>
> ×*N*
>
> 图 5.9 典型的卷积网络结构
>
> 目前，整个网络结构趋向于使用更小的卷积核（比如1 × 1 和3 ×
> 3）以及更深的结构（比如层数大于50）。此外，由于卷积的操作性越来越灵活（比如不同的步长），汇聚层的作用变得也越来越小，因此目前比较流行的卷积网络中，
> 汇聚层的比例也逐渐降低，趋向于全卷积网络。

#### 参数学习

> 参见公式([4.60](\l))。
>
> 这里假设汇聚层中没有参数。
>
> 参见公式([5.20](\l))。
>
> 参见公式([5.14](\l))。
>
> 在卷积网络中，参数为卷积核中权重以及偏置。和全连接前馈网络类似，卷
> 积网络也可以通过误差反向传播算法来进行参数学习。
>
> 在全连接前馈神经网络中，梯度主要通过每一层的误差项*δ* 进行反向传播，
> 并进一步计算每层参数的梯度。
>
> 在卷积神经网络中，主要有两种不同功能的神经层：卷积层和汇聚层。而
> 参数为卷积核以及偏置，因此只需要计算卷积层中参数的梯度。
>
> 不失一般性，对第 *l* 层为卷积层，第 *l* − 1 层的输入特征映射为
> **X**(*l*−1) ∈ R*M* ×*N* ×*D*，通过卷积计算得到第*l*
> 层的特征映射净输入**Z**(*l*) ∈ R*M* ′×*N* ′×*P* 。第*l* 层的第*p*(1 ≤
> *p* ≤ *P* ) 个特征映射净输入
>
> *D*
>
> *Z*(*l,p*) = *W* (*l,p,d*) *X*(*l*−1*,d*) + *b*(*l,p*)*,* (5.25)
>
> *d*=1
>
> 其中*W* ^(*l,p,d*)^ 和*b*^(*l,p*)^ 为卷积核以及偏置。第*l* 层中共有*P*
> × *D* 个卷积核和*P* 个偏置，可以分别使用链式法则来计算其梯度。
>
> 根据公式([5.14](\l)) 和([5.25](\l))，损失函数关于第*l* 层的卷积核*W*
> ^(*l,p,d*)^ 的偏导数为
>
> *∂*L(*Y, Y*ˆ ) = *∂*L(*Y, Y*ˆ ) ⊗ *X*(*l*−1*,d*) (5.26)
>
> *∂W* (*l,p,d*) *∂Z*(*l,p*)
>
> = *δ*(*l,p*) ⊗ *X*(*l*−1*,d*)*,* (5.27)
>
> 其中*δ*^(*l,p*)^ = ^[*∂*L(*Y,Y*ˆ)]{.underline}^ 为损失函数关于第*l*
> 层的第*p* 个特征映射净输入*Z*^(*l,p*)^ 的偏
>
> 导数。
>
> 5.3 参数学习 2019 年 4 月 6 日 125
>
> 同理可得，损失函数关于第*l* 层的第*p* 个偏置*b*^(*l,p*)^ 的偏导数为

ˆ

[*∂*L(*Y, Y* )]{.underline} = Σ\[*δ*(*l,p*)\]

> *.* (5.28)
>
> 卷积网络中，每层参数的梯度依赖其所在层的误差项*δ*^(*l,p*)^。
>
> **5.3.1** 误差项的计算
>
> 卷积层和汇聚层中，误差项的计算有所不同，因此我们分别计算其误差项。
>
> 汇聚层 当第*l* + 1 层为汇聚层时，因为汇聚层是下采样操作，*l* + 1
> 层的每个神经元的误差项*δ* 对应于第*l* 层的相应特征映射的一个区域。*l*
> 层的第*p* 个特征映射 中的每个神经元都有一条边和 *l* + 1 层的第 *p*
> 个特征映射中的一个神经元相连。根据链式法则，第*l*
> 层的一个特征映射的误差项*δ*^(*l,p*)^，只需要将*l* + 1
> 层对应特征映射的误差项*δ*^(*l*+1*,p*)^ 进行上采样操作（和第*l*
> 层的大小一样），再和*l*
> 层特征映射的激活值偏导数逐元素相乘，就得到了*δ*^(*l,p*)^。
>
> 第*l* 层的第*p* 个特征映射的误差项*δ*^(*l,p*)\ 的具体推导过程如下：^

~(*l,p*)~ *∂*L(*Y, Y*ˆ )

*∂Z*(*l,p*)

= *∂X*(*l,p*)

*∂Z*(*l*+1*,p*)

> *∂*L(*Y, Y*ˆ )
>
> (5.29)

*∂Z*(*l,p*) ·

> *∂X*(*l,p*) · *∂Z*(*l*+1*,p*) (5.30)
>
> = *fl*′(*Z*^(*l,p*)^) ⊙ **up**(*δ*^(*l*+1*,p*)^)*,* (5.31)
>
> 其中*fl*′(·) 为第*l* 层使用的激活函数导数，**up**
> 为上采样函数（upsampling），与汇 卷积并非真正的矩阵乘积，
>
> 聚层中使用的下采样操作刚好相反。如果下采样是最大汇聚（max
> pooling），误差项
> *δ*^(*l*+1*,p*)\ 中每个值会直接传递到上一层对应区域中的最大值所对应的神经元，该区域中其它神经元的误差项的都设为0。如果下采样是平均汇聚^（mean
> pooling），误差项*δ*^(*l*+1*,p*)^
> 中每个值会被平均分配到上一层对应区域中的所有神经元上。
>
> 卷积层 当*l* + 1 层为卷积层时，假设特征映射净输入**Z**(*l*+1) ∈ R*M*
> ′×*N* ′×*P* ，其中第*p*(1 ≤ *p* ≤ *P* ) 个特征映射净输入
>
> *D*
>
> *Z*(*l*+1*,p*) = *W* (*l*+1*,p,d*) *X*(*l,d*) + *b*(*l*+1*,p*)*,*
> (5.32)
>
> *d*=1
>
> 其中*W* ^(*l*+1*,p,d*)^ 和*b*^(*l*+1*,p*)^ 为第*l*+1
> 层的卷积核以及偏置。第*l*+1 层中共有*P* ×*D*
>
> 个卷积核和*P* 个偏置。
>
> 因此这里计算的偏导数并非真正的矩阵偏导数，我们可以把*X, Z*
> 都看作向量。
>
> 参见公式([5.20](\l))。
>
> 第*l* 层的第*d* 个特征映射的误差项*δ*^(*l,d*)\ 的具体推导过程如下：^
>
> ~(*l,d*)~ *∂*L(*Y, Y*ˆ )
>
> *∂Z*(*l,d*)
>
> (5.33)
>
> *∂X*(*l,d*)
>
> *∂Z*(*l,d*) ·

= ( )

> *∂*L(*Y, Y*ˆ )
>
> *∂X*(*l,d*)
>
> Σ **rot180**(
>
> ) ˜ *∂*L(*Y, Y*ˆ )!
>
> (5.34)
>
> (5.35)

= ( )

> Σ **rot180**( ) ˜
>
> (5.36)
>
> 参见习题[5-6](\l)。

*fl*′ *Z*(*l*)

> 其中⊗˜ 为宽卷积。
>
> ⊙ *p*=1
>
> *W* (*l*+1*,p,d*) ⊗*δ*(*l*+1*,p*) *,*

#### 几种典型的卷积神经网络

> 本节介绍几种广泛使用的典型深层卷积神经网络。

##### LeNet-5

> LeNet-5\[[LeCun et al.](\l), [1998](\l)\]
> 虽然提出的时间比较早，但是是一个非常成功的神经网络模型。基于LeNet-5
> 的手写数字识别系统在90
> 年代被美国很多银行使用，用来识别支票上面的手写数字。LeNet-5
> 的网络结构如图[5.10](\l)所示。

![](/root/autodl-tmp/project_knowledge/Doc_QA/Knowledge_based/1828695663060254721/image_output/7.《神经网络与深度学习》/media/image86.png)输入图像

> C1: 卷积层
>
> C3: 卷积层

6\@14 × 14

16\@5 × 5

> 全连接层
>
> 图 5.10 LeNet-5 网络结构（图片根据\[[LeCun et al.](\l), [1998](\l)\]
> 绘制）
>
> 不计输入层，LeNet-5 共有7 层，每一层的结构为：

1.  输入层：输入图像大小为32 × 32 = 1024。

2.  C1 层是卷积层，使用6 个5 × 5 的滤波器，得到6 组大小为28 × 28 = 784
    > 的特征映射。因此，C1 层的神经元数量为6 × 784 = 4*,*
    > 704，可训练参数 数量为6 × 25 + 6 = 156，连接数为156 × 784 = 122*,*
    > 304（包括偏置在内， 下同）。

3.  S2
    > 层为汇聚层，采样窗口为2×2，使用平均汇聚，并使用一个如公式([5.24](\l))的非线性函数。神经元个数为6
    > × 14 × 14 = 1*,* 176，可训练参数数量为6 × (1 + 1) = 12，连接数为6
    > × 196 × (4 + 1) = 5*,* 880。

4.  C3 层为卷积层。LeNet-5 中用一个连接表来定义输入和输出特征映射之间

> 的依赖关系，如图[5.11](\l)所示，共使用60 个5 × 5 的滤波器，得到16
> 组大小 连接表参见公式([5.37](\l))。
>
> 为10 × 10 的特征映射。神经元数量为16 × 100 = 1*,* 600，可训练参数数量
> 如果不使用连接表，则需要
>
> 为(60 × 25) + 16 = 1*,* 516，连接数为100 × 1*,* 516 = 151*,* 600。

5.  S4 层是一个汇聚层，采样窗口为2 × 2，得到16 个5 × 5 大小的特征映射，
    > 可训练参数数量为16 × 2 = 32，连接数为16 × 25 × (4 + 1) = 2000。

> 6\. C5 层是一个卷积层，使用120 × 16 = 1*,* 920 个5 × 5 的滤波器，得到120
> 组大小为1 × 1 的特征映射。C5 层的神经元数量为120，可训练参数数量为1*,*
> 920 × 25 + 120 = 48*,* 120，连接数为120 × (16 × 25 + 1) = 48*,* 120。

7.  F6 层是一个全连接层，有84 个神经元，可训练参数数量为84×(120+1) =
    > 10*,* 164。连接数和可训练参数个数相同，为10*,* 164。

8.  输出层：输出层由10 个欧氏径向基函数（Radial Basis Function，RBF）
    > 函数组成。这里不再详述。

> 连接表 从公式([5.20](\l))
> 可以看出，卷积层的每一个输出特征映射都依赖于所有输入特征映射，相当于卷积层的输入和输出特征映射之间是全连接的关系。实际
> 上，这种全连接关系不是必须的。我们可以让每一个输出特征映射都依赖于少
> 数几个输入特征映射。定义一个连接表（Link Table）*T*
> 来描述输入和输出特征映射之间的连接关系。如果第*p*
> 个输出特征映射依赖于第*d* 个输入特征映射，则*T~p,d~* = 1，否则为0。
>
> 96 个5 × 5 的滤波器。

*Y ^p^* = *f* 

*d, T~p,d~*=1

*W ^p,d^* ⊗ *X^d^* + *b^p^* *,* (5.37)

> 其中*T* 为*P* × *D* 大小的连接表。假设连接表*T*
> 的非零个数为*K*，每个滤波器的大小为*m* × *n*，那么共需要*K* × *m* ×
> *n* + *P* 参数。
>
> 在LeNet-5 中，连接表的基本设定如图[5.11](\l)所示。C3 层的第0-5
> 个特征映射依赖于S2 层的特征映射组的每3 个连续子集，第6-11
> 个特征映射依赖于S2 层的特征映射组的每4 个连续子集，第12-14
> 个特征映射依赖于S2 层的特征映射的每4 个不连续子集，第15
> 个特征映射依赖于S2 层的所有特征映射。
>
图片识别内容
0
1
2
3
4
5
6
7
8
9
10
11
12
13
31415
0
X
XX
X
X
X
X
X
X
X
1
X
X
X
X
X
X
X
X
X
X
2
X
X
X
X
X
X
X
X
X
X
3
XX
X
X
X
XX
X
X
X
4
XXX
X
XX
X
X
X
X
5
XXX
XX
X
X
X
X
X

>
> 图 5.11 LeNet-5 中C3 层的连接表（图片来源于\[[LeCun et al.](\l),
> [1998](\l)\]）

##### AlexNet

> AlexNet\[[Krizhevsky et al.](\l), [2012](\l)\]
> 是第一个现代深度卷积网络模型，其首次使用了很多现代深度卷积网络的一些技术方法，比如使用GPU
> 进行并行训练， 采用了ReLU 作为非线性激活函数，使用Dropout
> 防止过拟合，使用数据增强 来提高模型准确率等。AlexNet 赢得了2012
> 年ImageNet 图像分类竞赛的冠军。
>
> AlexNet的结构如图[5.12](\l)所示，包括5 个卷积层、3 个全连接层和1
> 个softmax 层。因为网络规模超出了当时的单个GPU 的内存限制，AlexNet
> 将网络拆为两半，分别放在两个GPU 上，GPU 间只在某些层（比如第3
> 层）进行通讯。

图片识别内容
192
128
2048
2048
dense
48
192
128
224
dense
dense
1000
192
192
128 Max
224
Max
Max
pooling
2048
2048
Stride
pooling
128
of4
pooling
48


> 图 5.12 AlexNet 网络结构（图片来源于\[[Krizhevsky et al.](\l),
> [2012](\l)\]）
>
> 这里的卷积核使用四维张量来描述。
>
> AlexNet 的具体结构如下：
>
> 1\. 输入层，224 × 224 × 3 的图像；

2.  第一个卷积层，使用两个11 × 11 × 3 × 48 的卷积核，步长*s* = 4，零填充

> *p* = 3，得到两个55 × 55 × 48 的特征映射组。

3.  第一个汇聚层，使用大小为3 × 3 的最大汇聚操作，步长*s* =
    > 2，得到两个27 × 27 × 48 的特征映射组。

4.  第二个卷积层，使用两个 5 × 5 × 48 × 128 的卷积核，步长*s* =
    > 1，零填充

> *p* = 1，得到两个27 × 27 × 128 的特征映射组。

5.  第二个汇聚层，使用大小为3 × 3 的最大汇聚操作，步长*s* =
    > 2，得到两个13 × 13 × 128 的特征映射组。

6.  第三个卷积层为两个路径的融合，使用一个 3 × 3 × 256 × 384 的卷积核，
    > 步长*s* = 1，零填充*p* = 1，得到两个13 × 13 × 192 的特征映射组。

7.  第四个卷积层，使用两个 3 × 3 × 192 × 192 的卷积核，步长*s* =
    > 1，零填充*p* = 1，得到两个13 × 13 × 192 的特征映射组。

8.  第五个卷积层，使用两个 3 × 3 × 192 × 128 的卷积核，步长*s* =
    > 1，零填充*p* = 1，得到两个13 × 13 × 128 的特征映射组。

9.  汇聚层，使用大小为3×3 的最大汇聚操作，步长*s* = 2，得到两个6×6×128

> 的特征映射组。

10. 三个全连接层，神经元数量分别为4096，4096 和1000。

    3.  ##### Inception 网络

> 在卷积网络中，如何设置卷积层的卷积核大小是一个十分关键的问题。在
>
> Inception
> 网络中，一个卷积层包含多个不同大小的卷积操作，称为*Inception* 模
>
> 块。Inception 网络是由有多个inception 模块和少量的汇聚层堆叠而成。
> Inception 模 块 受 到
>
> Inception 模块同时使用1 × 1、3 × 3、5 × 5
> 等不同大小的卷积核，并将得到的特征映射在深度上拼接（堆叠）起来作为输出特征映射。
>
> 图[5.13](\l)给出了 v1 版本的Inception 模块，采用了 4
> 组平行的特征抽取方式， 分别为1 × 1、3 × 3、5 × 5 的卷积和3 × 3
> 的最大汇聚。同时，为了提高计算效率，减少参数数量，Inception
> 模块在进行3 × 3、5 × 5 的卷积之前、3 × 3 的最大汇聚之后，进行一次1 × 1
> 的卷积来减少特征映射的深度。如果输入特征映射
>
> "Network in network"\[[Lin](\l) [et al.](\l), [2013](\l)\] 的启发。
>
> 之间存在冗余信息，1 × 1 的卷积相当于先进行一次特征抽取。 Inception
> 模块中的卷积和最

大汇聚都是等宽的。

> 图 5.13 Inception v1 的模块结构

![](/root/autodl-tmp/project_knowledge/Doc_QA/Knowledge_based/1828695663060254721/image_output/7.《神经网络与深度学习》/media/image91.png)

图片识别内容

>
> 图[5.15](\l)给出了一个典型的残差单元示例。残差单元由多个级联的（等长）卷积层和一个跨层的直连边组成，再经过ReLU
> 激活后得到输出。
>
> 残差网络就是将很多个残差单元串联起来构成的一个非常深的网络。
>
> *f* (**x***, θ*)
>
> 图 5.15 一个简单的残差单元结构
>
> 和残差网络类似的还有highway network\[[Srivastava et al.](\l),
> [2015](\l)\]。

#### 其它卷积方式

> 在第[5.1.2](\l)节中介绍了一些卷积的变种，可以通过步长和零填充来进行不同
> 的卷积操作。本节介绍一些其它的卷积方式。

###### 转置卷积

> 我们一般可以通过卷积操作来实现高维特征到低维特征的转换。比如在一维卷积中，一个5
> 维的输入特征，经过一个大小为3 的卷积核，其输出为3
> 维特征。如果设置步长大于1，可以进一步降低输出特征的维数。但在一些任务中，
> 我们需要将低维特征映射到高维特征，并且依然希望通过卷积操作来实现。
>
> 假设有一个高维向量为**x** ∈ R*d* 和一个低维向量为**z** ∈ R*p*，*p \<
> d*。如果用仿射变换来实现高维到低维的映射，
>
> **z** = *W* **x***,* (5.39)
>
> 其中*W* ∈ R*p*×*d* 为转换矩阵。我们可以很容易地通过转置*W*
> 来实现低维到高维的反向映射，即
>
> 不失一般性，这里忽略了平移项。
>
> **x** = *W* T**z***.* (5.40)
>
> 需要说明的是，公式([5.39](\l)) 和([5.40](\l))
> 并不是逆运算，两个映射只是形式上的转置
>
> 关系。
>
> 参见公式([4.60](\l))。
>
> 参见习题[5-4](\l)。
>
> 在全连接网络中，忽略激活函数，前向计算和反向传播就是一种转置关系。
> 比如前向计算时，第*l* + 1 层的净输入为**z**(*l*+1) = *W*
> ^(*l*+1)^**z**(*l*)，反向传播时，第*l* 层的误差项为*δ*(*l*) = (*W*
> (*l*+1))T*δ*(*l*+1)。
>
> 卷积操作也可以写为仿射变换的形式。假设一个5 维向量**x**，经过大小为3
>
> 的卷积核**w** = \[*w*~1~*, w*~2~*, w*~3~\]T 进行卷积，得到3
> 维向量**z**。卷积操作可以写为
>
> **z** = **w** ⊗ **x** (5.41)
>
> *w*~1~ *w*~2~ *w*~3~ 0 0 
>
> 0 0 *w*~1~ *w*~2~ *w*~3~
>
> = *C***x***,* (5.43)
>
> 其中*C* 是一个稀疏矩阵，其非零元素来自于卷积核**w** 中的元素。
>
> 如果要实现 3 维向量 **z** 到 5 维向量 **x**
> 的映射，可以通过仿射矩阵的转置来实现。
>
> 反卷积（Deconvolution）的名字并不是适合，它不是指
>
> **x** = *C*T**z** (5.44)

*w*~1~ 0 0 

*w w* 0

> = *w*3 *w*2 *w*1 · **z** (5.45)

0 *w*~3~ *w*~2~

 0 0 *w*~3~

> = **rot180**(**w**)⊕˜ **z***,* (5.46)
>
> 其中**rot180**(·) 表示旋转180 度。
>
> 从公式([5.42](\l)) 和([5.45](\l))
> 可以看出，从仿射变换的角度来看两个卷积操作**z** = **w** ⊗ **x**
> 和**x** = **rot180**(**w**)⊕˜ **z**
> 也是形式上的转置关系。因此，我们将低维特征映射到高维特征的卷积操作称为转置卷积（Transposed
> Convolution）\[[Dumoulin](\l) [and Visin](\l),
> [2016](\l)\]，也称为反卷积（Deconvolution）\[[Zeiler et al.](\l),
> [2011](\l)\]。
>
> 卷积的逆运算。
> 和卷积网络中，卷积层的前向计算和反向传播也是一种转置关系。
>
> 参见习题[5-6](\l)。
>
> 即宽卷积。
>
> 对一个*p* 维的向量**z**，和大小为*m*
> 的卷积核，如果希望通过卷积操作来映射到高维向量，只需要对向量**z**
> 进行两端补零*p* = *m* − 1，然后进行卷积，可以得
>
> 到*p* + *m* − 1 维的向量。
>
> 转置卷积同样适用于二维卷积。图[5.16](\l)给出了一个步长 *s* =
> 1，无零填充
>
> *p* = 0 的两维卷积和其对应的转置卷积。
>
> \(a) 卷积，*s* = 1*, p* = 0 (b) 转置卷积，*s* = 1*, p* = 2
>
> 图 5.16 步长*s* = 1，无零填充*p* = 0 的两维卷积和其对应的转置卷积
>
> https://nndl.github.io/v/cnn-conv-more
>
> 微步卷积 我们可以通过增加卷积操作的步长*s \>* 1
> 来实现对输入特征的降采样操作，大幅降低特征维数。同样，我们也可以通过减少转置卷积的步长*s
> \<* 1 来实现上采样操作，大幅提高特征维数。
>
> 步长*s \<* 1 的转置卷积也称为微步卷积（Fractionally-Strided
> Convolution） \[[Long et al.](\l),
> [2015](\l)\]。为了实现微步卷积，我们可以在输入特征之间插入0 来间
> 接地使得步长变小。
>
> 如果卷积操作的步长为*s \>* 1，希望其对应的转置卷积的步长为 ^1^
> ，需要在
>
> 转 置 卷 积 的 动 图见https://nndl.github.
>
> io/v/cnn-conv-more
>
图片识别内容

>
> 输入特征之间插入*s* − 1 个0 来使得其移动的速度变慢。
>
> 以一维转置卷积为例，对一个*p* 维的向量**z**，和大小为*m*
> 的卷积核，通过对向量**z** 进行两端补零*p* = *m* −
> 1，并且在每两个向量元素之间插入*s* − 1 个0，然后进行步长为1
> 的卷积，可以得到*s* × (*p* − 1) + *m* 维的向量。
>
> 图[5.16](\l)给出了一个步长*s* = 2，无零填充*p* = 0
> 的两维卷积和其对应的转置卷积。
>
> \(a) 卷积，*s* = 2*, p* = 0 (b) 转置卷积，*s* = 1*, p* = 2
>
> 图 5.17 步长*s* = 2，无零填充*p* = 0 的两维卷积和其对应的转置卷积

###### 空洞卷积

> 对于一个卷积层，如果希望增加输出单元的感受野，一般可以通过三种方
> 式实现：（1）增加卷积核的大小；（2）增加层数；（3）在卷积之前进行汇聚操作。前两种操作会增加参数数量，而第三种会丢失一些信息。
>
> Atrous 一词来源于法语à trous，意为"空洞，多孔"。
>
> 空洞卷积（Atrous Convolution），或称为膨胀卷积（Dilated Convolution）
>
> ，是一种不增加参数数量，同时增加输出单元感受野的一种方法\[[Chen et
> al.](\l), [2018](\l), [Yu and Koltun](\l), [2015](\l)\]。
>
> 空洞卷积通过给卷积核插入"空洞"来变相地增加其大小。如果在卷积核
> 的每两个元素之间插入*d* − 1 个空洞，卷积核的有效大小为
>
> *m*^′^ = *m* + (*m* − 1) × (*d* − 1)*,* (5.47)
>
> 其中*d* 称为膨胀率（Dilation Rate）。当*d* = 1
> 时卷积核为普通的卷积核。图[5.18](\l)给出了空洞卷积的示例。

6.  总结和深入阅读 2019 年 4 月 6 日 135

图片识别内容

>
> \(a) 膨胀率*d* = 1 (b) 膨胀率*d* = 2
>
> 图 5.18 空洞卷积
>
> 空 洞 卷 积 的 动 图见https://nndl.github.
>
> io/v/cnn-conv-more
>
图片识别内容

>
> 卷积神经网络是受生物学上感受野的机制而提出。David Hubel 和Torsten
>
> Wiesel 在 1959 年发现，在猫的初级视觉皮层中存在两种细胞：简单细胞和复
> David Hubel 和 Torsten
>
> 杂细胞，这两种细胞承担不同层次的视觉感知功能 \[[Hubel and Wiesel](\l),
> [1959](\l),
> [1962](\l)\]。简单细胞的感受野是狭长型的，每个简单细胞只对感受野中特定角度
>
> （orientation）的光带敏感，而复杂细胞对于感受野中以特定方向（direction）移动的某种角度（orientation）的光带敏感。受此启发，1980
> 年，福岛邦彦（Kunihiko
>
> Wiesel 在此方面的贡献，与1981 年获得诺贝尔生理学或医学奖。
>
> Fukushima）提出了一种带卷积和子采样操作的多层神经网络：新知机（Neocognitron）
> \[[Fukushima](\l),
> [1980](\l)\]。但当时还没有反向传播算法，新知机采用了无监督学习的方
>
> 式来训练。Yann LeCun 在1989
> 年将反向传播算法引入了卷积神经网络\[[LeCun](\l) [et al.](\l),
> [1989](\l)\]，并在手写体数字识别上取得了很大的成功\[[LeCun et
> al.](\l), [1998](\l)\]。
>
> AlexNet\[[Krizhevsky et al.](\l), [2012](\l)\]
> 是第一个现代深度卷积网络模型，可以说是深度学习技术在图像分类上真正突破的开端。AlexNet
> 不用预训练和逐层训练，首次使用了很多现代深度网络的一些技术方法，比如使用GPU
> 进行并行训练，采用了ReLU 作为非线性激活函数，使用dropout
> 防止过拟合，使用数据增
> 强来提高模型准确率等。这些技术极大地推动了端到端的深度学习模型的发展。
>
> 在AlexNet 之后，出现了很多优秀的卷积网络，比如VGG 网络\[[Simonyan](\l)
> [and Zisserman](\l), [2014](\l)\]，Inception v1, v2,v4 网络\[[Szegedy
> et al.](\l), [2015](\l), [2016](\l), [2017](\l)\]，残差网络\[[He et
> al.](\l), [2016](\l)\] 等。
>
> 目前，卷积神经网络已经成为计算机视觉领域的主流模型。通过引入跨层
> 的直连边，可以训练上百层乃至上千层的卷积网络。随着网络层数的增加，卷
> 积层越来越多地使用1 × 1 和3 × 3
> 大小的小卷积核，也出现了一些不规则的卷积操作，比如空洞卷积\[[Chen et
> al.](\l), [2018](\l), [Yu and Koltun](\l), [2015](\l)\]、可变形卷积
>
> 136 2019 年 4 月 6 日 参考文献
>
> \[[Dai et al.](\l), [2017](\l)\]
> 等。网络结构也逐渐趋向于全卷积网络（Fully Convolutional
> Network，FCN）\[[Long et al.](\l),
> [2015](\l)\]，减少汇聚层和全连接层的作用。
>
> [Dumoulin and Visin](\l) \[[2016](\l)\]
> 给出了各种卷积操作的可视化示例。

#### 习题

> 习题 **5-1** 证明宽卷积具有交换性，即公式([5.10](\l))。
>
> 参见公式([5.42](\l))。
>
> 习题 **5-2** 分析卷积神经网络中用1 × 1 的滤波器的作用。
>
> 习题 **5-3** 对于一个输入为100 × 100 × 256 的特征映射组，使用3 × 3
> 的卷
>
> 积核，输出为100 × 100 × 256
> 的特征映射组的卷积层，求其时间和空间复杂度。
>
> 如果引入一个1 × 1 卷积核先得到100 × 100 × 64 的特征映射，再进行3 × 3
> 的卷
>
> 积，得到100 × 100 × 256 的特征映射组，求其时间和空间复杂度。
>
> 习题 **5-4** 对于一个两维卷积，输入为3 × 3，卷积核大小为2 ×
> 2，试将卷积操作重写为仿射变换的形式。
>
> 习题 **5-5** 在最大汇聚层中，计算函数*y* = max(*x*~1~*,* · · · *,
> x~d~*) 的梯度。函数*y* = arg max(*x*~1~*,* · · · *, x~d~*) 的梯度呢？
>
> 习题 **5-6** 忽略激活函数，分析卷积网络中卷积层的前向计算和反向传播
>
> （公式([5.36](\l))）是一种转置关系。
>
> 习题**5-7** 在空洞卷积中，当卷积核大小为*m*，膨胀率为*d*
> 时，如何设置零填充*p* 的值以使得卷积为等宽卷积。

#### 参考文献

> Liang-Chieh Chen, George Papandreou, Ia- sonas Kokkinos, Kevin Murphy,
> and Alan L Yuille. Deeplab: Semantic image segmen- tation with deep
> convolutional nets, atrous convolution, and fully connected CRFs.
> *IEEE transactions on pattern analysis and machine intelligence*,
> 40(4):834--848, 2018.
>
> Jifeng Dai, Haozhi Qi, Yuwen Xiong, Yi Li, Guodong Zhang, Han Hu, and
> Yichen Wei. Deformable convolutional networks. *CoRR, abs/1703.06211*,
> 1(2):3, 2017.
>
> Vincent Dumoulin and Francesco Visin. A guide to convolution
> arithmetic for deep learning. *ArXiv e-prints*, mar 2016.
>
> 参考文献 2019 年 4 月 6 日 137
>
> Kunihiko Fukushima. Neocognitron: A self-organizing neural network
> model for a mechanism of pattern recognition unaf- fected by shift in
> position. *Biological cyber-* *netics*, 36(4):193--202, 1980.
>
> Kaiming He, Xiangyu Zhang, Shaoqing Ren, and Jian Sun. Deep residual
> learning for image recognition. In *Proceedings of the IEEE conference
> on computer vision and* *pattern recognition*, pages 770--778, 2016.
> David H Hubel and Torsten N Wiesel. Re- ceptive ﬁelds of single
> neurones in the cat's striate cortex. *The Journal of physiology*,
> 148(3):574--591, 1959.
>
> David H Hubel and Torsten N Wiesel. Receptive ﬁelds, binocular
> interaction and functional architecture in the cat's visual cortex.
> *The Journal of physiology*, 160(1): 106--154, 1962.
>
> Alex Krizhevsky, Ilya Sutskever, and Ge- oﬀrey E Hinton. Imagenet
> classiﬁcation with deep convolutional neural networks. In *Advances in
> neural information processing* *systems*, pages 1097--1105, 2012.
>
> Yann LeCun, Bernhard Boser, John S Denker, Donnie Henderson, Richard E
> Howard, Wayne Hubbard, and Lawrence D Jackel. Backpropagation applied
> to hand- written zip code recognition. *Neural com-* *putation*,
> 1(4):541--551, 1989.
>
> Yann LeCun, Léon Bottou, Yoshua Ben- gio, and Patrick Haﬀner.
> Gradient-based learning applied to document recognition. *Proceedings
> of the IEEE*, 86(11):2278--2324, 1998.
>
> Min Lin, Qiang Chen, and Shuicheng Yan. Network in network. *arXiv
> preprint* *arXiv:1312.4400*, 2013.
>
> Jonathan Long, Evan Shelhamer, and Trevor Darrell. Fully convolutional
> net-
>
> works for semantic segmentation. In *Pro- ceedings of the IEEE
> conference on com- puter vision and pattern recognition*, pages
> 3431--3440, 2015.
>
> Karen Simonyan and Andrew Zisserman. Very deep convolutional networks
> for large- scale image recognition. *arXiv preprint*
> *arXiv:1409.1556*, 2014.
>
> Rupesh Kumar Srivastava, Klaus Greﬀ, and Jürgen Schmidhuber. Highway
> networks. *arXiv preprint arXiv:1505.00387*, 2015.
>
> Christian Szegedy, Wei Liu, Yangqing Jia, Pierre Sermanet, Scott Reed,
> Dragomir Anguelov, Dumitru Erhan, Vincent Van- houcke, and Andrew
> Rabinovich. Going deeper with convolutions. In *Proceedings of the
> IEEE Conference on Computer Vision* *and Pattern Recognition*, pages
> 1--9, 2015. Christian Szegedy, Vincent Vanhoucke, Sergey Ioﬀe, Jon
> Shlens, and Zbigniew Wo- jna. Rethinking the inception architec- ture
> for computer vision. In *Proceedings of the IEEE Conference on
> Computer Vision and Pattern Recognition*, pages 2818--2826, 2016.
>
> Christian Szegedy, Sergey Ioﬀe, Vin- cent Vanhoucke, and Alexander A
> Alemi. Inception-v4, inception-resnet and the im- pact of residual
> connections on learning. In *AAAI*, pages 4278--4284, 2017.
>
> Fisher Yu and Vladlen Koltun. Multi- scale context aggregation by
> dilated convo- lutions. *arXiv preprint arXiv:1511.07122*, 2015.
>
> Matthew D Zeiler, Graham W Taylor, and Rob Fergus. Adaptive
> deconvolutional net- works for mid and high level feature learn- ing.
> In *Proceedings of the IEEE Inter- national Conference on Computer
> Vision*, pages 2018--2025. IEEE, 2011.

第**6** 章 循环神经网络
=======================

> 经验是智慧之父，记忆是智慧之母。
>
> --- 谚语
>
> 在前馈神经网络中，信息的传递是单向的，这种限制虽然使得网络变得更容易学习，但在一定程度上也减弱了神经网络模型的能力。在生物神经网络中，
> 神经元之间的连接关系要复杂的多。前馈神经网络可以看着是一个复杂的函数，
> 每次输入都是独立的，即网络的输出只依赖于当前的输入。但是在很多现实任务中，网络的输入不仅和当前时刻的输入相关，也和其过去一段时间的输出相关。比如一个有限状态自动机，其下一个时刻的状态（输出）不仅仅和当前输入相关，也和当前状态（上一个时刻的输出）相关。此外，前馈网络难以处理时序数据，比如视频、语音、文本等。时序数据的长度一般是不固定的，而前馈神经网络要求输入和输出的维数都是固定的，不能任意改变。因此，当处理这一类和时序相关的问题时，就需要一种能力更强的模型。
>
> 循环神经网络（Recurrent Neural
> Network，RNN）是一类具有短期记忆能力的神经网络。在循环神经网络中，神经元不但可以接受其它神经元的信息，也
> 可以接受自身的信息，形成具有环路的网络结构。和前馈神经网络相比，循环神
> 经网络更加符合生物神经网络的结构。循环神经网络已经被广泛应用在语音识
> 别、语言模型以及自然语言生成等任务上。循环神经网络的参数学习可以通过
> 随时间反向传播算法\[[Werbos](\l), [1990](\l)\]
> 来学习。随时间反向传播算法即按照时间的逆序将错误信息一步步地往前传递。当输入序列比较长时，会存在梯度爆炸
> 和消失问题\[[Bengio et al.](\l), [1994](\l), [Hochreiter and
> Schmidhuber](\l), [1997](\l), [Hochreiter](\l) [et al.](\l),
> [2001](\l)\]，也称为长期依赖问题。为了解决这个问题，人们对循环神经网络进行了很多的改进，其中最有效的改进方式引入门控机制。
>
> 此外，循环神经网络可以很容易地扩展到两种更广义的记忆网络模型：递
> 归神经网络和图网络。

#### 给网络增加记忆能力

> 为了处理这些时序数据并利用其历史信息，我们需要让网络具有短期记忆
> 能力。而前馈网络是一个静态网络，不具备这种记忆能力。
>
> 此外，还有一种增加记忆能力的方法是引入外部记忆单
>
> 一般来讲，我们可以通过以下三种方法来给网络增加短期记忆能力。
>
> 元，参见第[8.3](\l)节。 **6.1.1** 延时神经网络
>
> [延时神经网络]{.underline}在时间维度上
> 共享权值，以降低参数数量。因此对于序列输入来讲，延
> 时神经网络就相当于卷积神 经网络。
>
> 一种简单的利用历史信息的方法是建立一个额外的延时单元，用来存储网
> 络的历史信息（可以包括输入、输出、隐状态等）。比较有代表性的模型是延时
> 神经网络（Time Delay Neural Network，TDNN）\[[Lang et al.](\l),
> [1990](\l), [Waibel](\l) [et al.](\l), [1989](\l)\]。
>
> 延时神经网络是在前馈网络中的非输出层都添加一个延时器，记录最近几
> 次神经元的输出。在第t 个时刻，第*l* + 1 层神经元和第*l*
> 层神经元的最近*p* 次输出相关，即

**h**(*l*+1) = *f* (**h**(*l*)*,* **h**(*l*) *,* · · · *,* **h**(*l*)

> )*.* (6.1)
>
> 通过延时器，前馈网络就具有了短期记忆的能力。

###### 有外部输入的非线性自回归模型

> 自回归模型（Autoregressive
> Model，AR）是统计学上常用的一类时间序列模型，用一个变量**y***~t~*
> 的历史信息来预测自己。
>
> *p*
>
> **y***~t~* = *w*~0~ + *w~p~***y**~*t*−*i*~ + *ϵ~t~,* (6.2)
>
> *i*=1
>
> 其中*p* 为超参数，*w~p~* 为参数，*ϵ~t~* ∼ *N* (0*, σ*^2^) 为第*t*
> 个时刻的噪声，方差*σ*^2^ 和时间无关。
>
> 有外部输入的非线性自回归模型（Nonlinear Autoregressive with Exoge-
> nous Inputs Model，NARX）\[[Leontaritis and Billings](\l),
> [1985](\l)\] 是自回归模型的扩展，在每个时刻*t*
> 都有一个外部输入**x***~t~*，产生一个输出**y***~t~*。NARX
> 通过一个延时器记录最近几次的外部输入和输出，第t 个时刻的输出**y***~t~*
> 为
>
> **y***~t~* = *f* (**x***~t~,* **x**~*t*−1~*,* · · · *,*
> **x**~*t*−*p*~*,* **y**~*t*−1~*,* **y**~*t*−2~*,* · · · *,*
> **y**~*t*−*q*~)*,* (6.3)
>
> 其中*f* (·) 表示非线性函数，可以是一个前馈网络，*p* 和*q* 为超参数。

###### 循环神经网络

> 循环神经网络通过使用带自反馈的神经元，能够处理任意长度的时序数据。
>
> 给定一个输入序列**x**~1:*T*~ = (**x**~1~*,* **x**~2~*, . . . ,*
> **x***~t~, . . . ,* **x***~T~*
> )，循环神经网络通过下面公式更新带反馈边的隐藏层的活性值**h***~t~*：
>
> **h***~t~* = *f* (**h**~*t*−1~*,* **x***~t~*)*,* (6.4)
>
> 其中**h**~0~ = 0，*f* (·)
> 为一个非线性函数，也可以是一个前馈网络。图[6.1](\l)给出了循环神经网络的示例。
>
> **h***~t~*
>
> RNN 也 经 常 被 翻 译 为
> 递归神经网络。这里为了区别与另外一种递归神经网络（Recursive Neural
> Net- work），我们称为循环神经[网络]{.underline}。
>
> **h***~t~*
>
> **x***~t~*
>
> **h***t*−1
>
> 图 6.1 循环神经网络
>
> 从数学上讲，公式([6.4](\l)) 可以看成一个动力系统。动力系统（Dynamical
> Sys-
> tem）是一个数学上的概念，指系统状态按照一定的规律随时间变化的系统。具
> 体地讲，动力系统是使用一个函数来描述一个给定空间（如某个物理系统的状
> 态空间）中所有点随时间的变化情况。因此，隐藏层的活性值**h***~t~*
> 在很多文献上也称为状态（state）或隐状态（hidden
> states）。理论上，循环神经网络可以近似任意的非线性动力系统（参见第[6.2.1](\l)节）。

#### 简单循环网络

> 简单循环网络（Simple Recurrent Network，SRN）\[[Elman](\l),
> [1990](\l)\] 是一个非常简单的循环神经网络，只有一个隐藏层的神经网络。
>
> 在一个两层的前馈神经网络中，连接存在相邻的层与层之间，隐藏层的节
> 点之间是无连接的。而简单循环网络增加了从隐藏层到隐层的反馈连接。
>
> 假设在时刻*t*
> 时，网络的输入为**x***~t~*，隐藏层状态（即隐藏层神经元活性值）
> 为**h***~t~* 不仅和当前时刻的输入**x***~t~*
> 相关，也和上一个时刻的隐藏层状态**h**~*t*−1~ 相关。
>
> **z***~t~* = *U* **h**~*t*−1~ + *W* **x***~t~* + **b***,* (6.5)
>
> **h***~t~* = *f* (**z***~t~*)*,* (6.6)
>
> 生活中很多现象都可以动力 系统来描述，比如钟摆晃动、台球轨迹等。
>
> 其中**z***~t~* 为隐藏层的净输入，*f* (·)
> 是非线性激活函数，通常为logistic 函数或tanh 函数，*U*
> 为状态*-*状态权重矩阵，*W* 为状态*-*输入权重矩阵,**b**
> 为偏置。公式([6.5](\l)) 和([6.6](\l)) 也经常直接写为
>
> **h***~t~* = *f* (*U* **h**~*t*−1~ + *W* **x***~t~* + **b**)*.* (6.7)
>
> 如果我们把每个时刻的状态都看作是前馈神经网络的一层的话，循环神经
> 网络可以看作是在时间维度上权值共享的神经网络。图[6.2](\l)给出了按时间展开的
> 循环神经网络。

· · ·

· · ·

· · ·

> 图 6.2 按时间展开的循环神经网络

###### 循环神经网络的计算能力

> 由于循环神经网络具有短期记忆能力，相当于存储装置，因此其计算能力
> 十分强大。前馈神经网络可以模拟任何连续函数，而循环神经网络可以模拟任
> 何程序。
>
> 我们先定义一个完全连接的循环神经网络，其输入为**x***~t~*，输出为**y***~t~*，
>
> **h***~t~* = *f* (*U* **h**~*t*−1~ + *W* **x***~t~* + **b**)*,* (6.8)
>
> **y***~t~* = *V* **h***~t~,* (6.9)
>
> 其中**h** 为隐状态，*f* (·) 为非线性激活函数，*U* 、*W* 、**b** 和*V*
> 为网络参数。

1.  通用近似定理

> 一个完全连接的循环网络是任何非线性动力系统的近似器。
>
> 证明*.*（1）根据通用近似定理，两层的前馈神经网络可以近似任意有界闭集上的任意连续函数。因此，动力系统的两个函数可以用两层的全连接前馈网络近似。
>
> 首先，非线性动力系统的状态转换函数**s***~t~* = *g*(**s**~*t*−1~*,*
> **x***~t~*) 可以由一个两层的神经网络**s***~t~* = *Cf* (*A***s**~*t*−1~
> + *B***x***~t~* + **b**~1~) 来近似，可以分解为

**s**′*t* = *f* (*A***s**~*t*−1~ + *B***x***~t~* + **b**) (6.12)

= *f* (*AC***s**′*t*−1 + *B***x***~t~* + **b**)*,* (6.13)

> **s***~t~* = *C***s**′*t,* (6.14)
>
> 其中*A, B, C* 为权重矩阵，**b** 为偏置向量。
>
> 同理，非线性动力系统的输出函数**y***~t~* = *o*(**s***~t~*) =
> *o*(*g*(**s**~*t*−1~*,* **x***~t~*))
> 也可以用一个两层的前馈神经网络近似。

**y***~t~*′ = *f* (*A*^′^**s**~*t*−1~ + *B*^′^**x***~t~* + **b**′)
(6.15)

= *f* (*A*^′^*C***s***~t~*′−1 + *B*^′^**x***~t~* + **b**′)*,* (6.16)

> **y***~t~* = *D***y***~t~*′ *,* (6.17)
>
> 其中*A*^′^*, B*^′^*, D* 为权重矩阵，**b**′ 为偏置向量。
>
> （2）公式([6.13](\l)) 和([6.16](\l)) 可以合并为
>
> 通 用 近 似 定 理 参 见第[4.3.1](\l)节。
>
> 本 证 明 参 考 文 献 \[[Schäfer](\l) [and Zimmermann](\l),
> [2006](\l)\]。
>
> **s**′*t*  = *f*  *AC* 0 **s***t*′−1  +  *B*  **x**
>
> \+  **b**  *.* (6.18)

**y**′   ~′~ 0 **y**′   ~′~ *t* **b**′

> 公式([6.17](\l)) 可以改写为
>
> **y** = 0 *D* **s**′*t*  *.* (6.19)
>
> 令 **h***~t~* = \[**s***~t~*′ ; **y***~t~*′
> \]，则非线性动力系统可以由下面的全连接循环神经网络来近似。
>
> **h***~t~* = *f* (*U* **h**~*t*−1~ + *W* **x***~t~* + **b**)*,* (6.20)
>
> **y***~t~* = *V* **h***~t~,* (6.21)
>
> 其中*U* =  *AC* 0，*W* =  *B* ，**b** =  **b** ，*V* = 0
> 。
>
>  ~′~   ~′~  ~′~ *D*
>
> 图灵机是一种抽象的信息处理装置，可以用来解决任所有的可计算机问题。参见第[8.3.3.2](\l)节。

2.  图灵完备

> 图灵完备（Turing
> Completeness）是指一种数据操作规则，比如一种计算机编程语言，可以实现图灵机（Turing
> Machine）的所有功能，解决所有的可计算问题。目前主流的编程语言（比如C++，Java，Python
> 等）都是图灵完备的。
>
> 因此，一个完全连接的循环神经网络可以近似解决所有的可计算问题。

#### 应用到机器学习

> 循环神经网络可以应用到很多不同类型的机器学习任务。根据这些任务的
> 特点可以分为以下几种模式：序列到类别模式、同步的序列到序列模式、异步
> 的序列到序列模式。
>
> 下面我们分别来看下这几种应用模式。

###### 序列到类别模式

> 序列到类别模式主要用于序列数据的分类问题：输入为序列，输出为类别。
> 比如在文本分类中，输入数据为单词的序列，输出为该文本的类别。
>
> 假设一个样本**x**~1:*T*~ = (**x**~1~*,* · · · *,* **x***~T~* )
> 为一个长度为*T* 的序列，输出为一个类别 *y* ∈ {1*,* · · · *,
> C*}。我们可以将样本 **x**
> 按不同时刻输入到循环神经网络中，并得到不同时刻的隐藏状态**h**~1~*,* ·
> · · *,* **h***~T~* 。我们可以将**h***~T~* 看作整个序列的最终表示
>
> （或特征），并输入给分类器*g*(·) 进行分类（如图[6.3a](\l)所示）。
>
> *y*ˆ = *g*(**h***~T~* )*,* (6.22)
>
> 其中*g*(·) 可以是简单的线性分类器（比如Logistic
> 回归）或复杂的分类器（比如多层前馈神经网络）。
>
> · · ·
>
> · · ·

a.  正常模式

b.  按时间进行平均采样模式

> 图 6.3 序列到类别模式

3.  应用到机器学习 2019 年 4 月 6 日 145

> 除了将最后时刻的状态作为序列表示之外，我们还可以对整个序列的所有
> 状态进行平均，并用这个平均状态来作为整个序列的表示（如图[6.3b](\l)所示）。
>
> [1]{.underline} Σ

*y*ˆ = *g*(

*T*

###### 同步的序列到序列模式

> *t*=1
>
> **h***~t~*)*.* (6.23)
>
> 同步的序列到序列模式主要用于序列标注（Sequence
> Labeling）任务，即每一时刻都有输入和输出，输入序列和输出序列的长度相同。比如词性标注（Part-
> of-Speech Tagging）中，每一个单词都需要标注其对应的词性标签。
>
> 在同步的序列到序列模式（如图[6.4](\l)所示）中，输入为一个长度为*T*
> 的序列**x**~1:*T*~ = (**x**~1~*,* · · · *,* **x***~T~*
> )，输出为序列*y*~1:*T*~ = (*y*~1~*,* · · · *, y~T~* )。样本**x**
> 按不同时刻输入到循环神经网络中，并得到不同时刻的隐状态**h**~1~*,* · ·
> · *,* **h***~T~* 。每个时刻的隐状态**h***~t~*
> 代表了当前时刻和历史的信息，并输入给分类器*g*(·)
> 得到当前时刻的标签*y*ˆ*~t~*。
>
> *y*ˆ*~t~* = *g*(**h***~t~*)*,* ∀*t* ∈ \[1*, T* \]*.* (6.24)
>
> 参见第**??**节。
>
> · · ·
>
> · · ·
>
> · · ·
>
> 图 6.4 同步的序列到序列模式

###### 异步的序列到序列模式

> 异步的序列到序列模式也称为编码器*-*解码器（Encoder-Decoder）模型，即输入序列和输出序列不需要有严格的对应关系，也不需要保持相同的长度。比
> 如在机器翻译中，输入为源语言的单词序列，输出为目标语言的单词序列。
>
> 在异步的序列到序列模式中（如图[6.5](\l)所示），输入为一个长度为*T*
> 的序列**x**~1:*T*~ = (**x**~1~*,* · · · *,* **x***~T~*
> )，输出为长度为*M* 的序列*y*~1:*M*~ = (*y*~1~*,* · · · *, y~M~*
> )。经常通过先编码后解码的方式来实现。先将样本**x**
> 按不同时刻输入到一个循环神经网络
>
> （编码器）中，并得到其编码**h***~T~*
> 。然后在使用另一个循环神经网络（解码器）中， 得到输出序列*y*ˆ~1:*M*~
> 。为了建立输出序列之间的依赖关系，在解码器中通常使用非线性的自回归模型。
>
> **h***~t~* = *f*~1~(**h**~*t*−1~*,* **x***~t~*)*,* ∀*t* ∈ \[1*, T* \]
> (6.25)
>
> 参见第**??**节。
>
> 自回归模型参见第[6.1.2](\l)节。

**h***~T~* ~+*t*~ = *f*~2~(**h***~T~* ~+*t*−1~*,* **y**ˆ~*t*−1~)*,* ∀*t*
∈ \[1*, M* \] (6.26)

*y*ˆ*~t~* = *g*(**h***~T~* ~+*t*~)*,* ∀*t* ∈ \[1*, M* \]*.* (6.27)

> 其中*f*~1~(·)*, f*~2~(·)
> 分别为用作编码器和解码器的循环神经网络，*g*(·) 为分类器，**y**ˆ*~t~*
>
> 为预测输出*y*ˆ*~t~* 的向量表示。
>
> · · ·
>
> · · ·
>
> 图 6.5 异步的序列到序列模式

#### 参数学习

> 不失一般性，这里我们以同步的序列到序列模式为例来介绍循环神经网络的参数学习。
>
> 循环神经网络的参数可以通过梯度下降方法来进行学习。
>
> 以随机梯度下降为例，给定一个训练样本(**x***,* **y**)，其中**x**~1:*T*~
> = (**x**~1~*,* · · · *,* **x***~T~* ) 为长度是*T*
> 的输入序列，*y*~1:*T*~ = (*y*~1~*,* · · · *, y~T~* ) 是长度为*T*
> 的标签序列。即在每个时刻*t*，都有一个监督信息*y~t~*，我们定义时刻*t*
> 的损失函数为
>
> L*~t~* = L(*y~t~, g*(**h***~t~*))*,* (6.28)
>
> 其中*g*(**h***~t~*) 为第*t* 时刻的输出，L
> 为可微分的损失函数，比如交叉熵。那么整个序列上损失函数为
>
> *T*
>
> = *~t~.* (6.29)
>
> *t*=1
>
> 整个序列的损失函数L关于参数*U* 的梯度为
>
> [*∂*L]{.underline} = Σ [*∂*L*t*]{.underline} *,* (6.30)
>
> 即每个时刻损失L*~t~* 对参数*U* 的偏导数之和。
>
> 循环神经网络中存在一个递归调用的函数*f*
> (·)，因此其计算参数梯度的方式和前馈神经网络不太相同。在循环神经网络中主要有两种计算梯度的方式：随
> 时间反向传播（BPTT）和实时循环学习（RTRL）算法。
>
> 6.4 参数学习 2019 年 4 月 6 日 147

###### 随时间反向传播算法

> 随时间反向传播（Backpropagation Through
> Time，BPTT）算法的主要思想是通过类似前馈神经网络的错误反向传播算法\[[Werbos](\l),
> [1990](\l)\] 来进行计算梯度。
>
> BPTT
> 算法将循环神经网络看作是一个展开的多层前馈网络，其中"每一层"对应循环网络中的"每个时刻"（图[6.2](\l)）。这样，循环神经网络就可以按按照前馈网络中的反向传播算法进行计算参数梯度。在"展开"的前馈网络中，
> 所有层的参数是共享的，因此参数的真实梯度是将所有"展开层"的参数梯度之和。
>
> 计算偏导数 *^[∂]{.underline}^ [t]{.underline}*

*∂U*

> 先来计算公式([6.30](\l)) 中第*t* 时刻损失对参数*U* 的偏导数
> [^*∂*L^*t*]{.underline} 。
>
> 因为参数 *U* 和隐藏层在每个时刻 *k*(1 ≤ *k* ≤ *t*) 的净输入 **z***~k~*
> = *U* **h**~*k*−1~ +
>
> *W* **x***~k~* + **b** 有关，因此第*t* 时刻损失的损失函数L*~t~*
> 关于参数*U~ij~* 的梯度为：

*∂*L = Σ ( *∂*L )

> *∂*^+^**z**
>
> (6.31)

= Σ *∂*^+^**z***~k~*

T *∂ [ ]{.underline}*L

> (6.32)

*k*=1

> *∂U~ij~*
>
> *∂***z***~k~*
>
> 其中 *^∂^*+**z***k* 表示"直接"偏导数，即公式
>
> *∂Uij*
>
> 变，对*U~ij~* 进行求偏导数，得到
>
> *k* = *U* **h***k*−1
>
> \+ *W* **x***~k~*
>
> \+ **b** 中保持**h**~*k*−1~ 不

 0

*∂*^+^**z***~k~* =  \[**h**

> 
>
> \]  , I (\[**h**
>
> \] )*,*
>
> (6.33)

*∂U~ij~*

> *k*−1 *j*
>
> *i k*−1 *j*

.

 0 

> 其中\[**h**~*k*−1~\]*~j~* 为第*k* − 1 时刻隐状态的第*j*
> 维；I*~i~*(*x*) 除了第*i* 行值为*x* 外，其余都为0 的向量。
>
> 定义*δ~t,k~* = [*∂*L*t*]{.underline} 为第*t* 时刻的损失对第*k*
> 时刻隐藏神经层的净输入**z***~k~* 的导
>
> *k*

数，则

*δt,k*

> = [*∂*L*~t~*]{.underline}
>
> *∂ ~k~*
>
> = [*∂***h***~k~ ∂***z**~*k*+1~ *∂*L*~t~ *]{.underline}
>
> (6.34)
>
> (6.35)

*∂***z***~k~*

> *∂***h***~k~*
>
> *∂***z***k*+1
>
> = diag(*f* ^′^(**z***~k~*))*U* T*δ~t,k~*~+1~*.* (6.36)
>
> 图 6.6 随时间反向传播算法示例
>
> 将公式([6.36](\l)) 和([6.33](\l)) 代入公式([6.32](\l)) 得到

[ *∂*L*~t~ *]{.underline} = Σ\[*δ*

> \] \[**h**
>
> \] *.* (6.37)
>
> 将上式写成矩阵形式为
>
> *t*

*^[t]{.underline}^* = *δ*

> *k*=1

*t,k*

> T
>
> *k*−1

*.* (6.38)

> 图[6.6](\l)给出了误差项随时间进行反向传播算法的示例。
>
> 参数梯度 将公式([6.38](\l)) 代入到将公式([6.30](\l))
> 得到整个序列的损失函数L 关于参数*U* 的梯度
>
> *T t*

[*∂*L]{.underline} = *δ*

*t*=1 *k*=1

*t,k*

> T
>
> *k*−1

*.* (6.39)

> 同理可得，L关于权重*W* 和偏置**b** 的梯度为
>
> *T t*
>
> [ *∂*L]{.underline}
>
> *∂W*
>
> = *δ*
>
> *t*=1 *k*=1

*t,k*

**x**T*,* (6.40)

> *T t*

*∂*L = *δ*

*t*=1 *k*=1

*t,k*

*.* (6.41)

> 计算复杂度 在BPTT
> 算法中，参数的梯度需要在一个完整的"前向"计算和"反向"计算后才能得到并进行参数更新。

###### 实时循环学习算法

> 与反向传播的BPTT算法不同的是，实时循环学习（Real-Time Recurrent
> Learning，RTRL）是通过前向传播的方式来计算梯度 \[[Williams and
> Zipser](\l), [1995](\l)\]。
>
> 6.5 长期依赖问题 2019 年 4 月 6 日 149
>
> 假设循环网络网络中第*t* + 1 时刻的状态**h**~*t*+1~ 为
>
> 梯度前向传播可以参考自

**h***t*+1

> = *f* (**z**

*t*+1

) = *f* (*U* **h***~t~*

> \+ *W* **x**~*t*+1~
>
> \+ **b**)*,* (6.42)
>
> 动微分中的前向模式，参见第[4.5.3](\l)节。
>
> 其关于参数*U~ij~* 的偏导数为
>
> [*∂***h***t*+1]{.underline} = [*∂***h***t*+1]{.underline}
> *∂*+**z***t*+1 +
>
> [ *∂***h***t*]{.underline} (6.43)

*∂U~ij~*

> *∂***z***t*+1
>
> *∂U~ij~*
>
> *∂U~ij~*
>
> = diag(*f* ^′^(**z** )) I (\[**h** \] ) + *U [
> ∂]{.underline}*[**h***t*]{.underline} (6.44)
>
> = *f* ^′^(**z** ) ⊙ I (\[**h** \] ) + *U [ ∂]{.underline}*[**h***t
> *]{.underline} *,* (6.45)
>
> 其中I*~i~*(*x*) 除了第*i* 行值为*x* 外，其余都为0 的向量。
>
> RTRL算法从第1
> 个时刻开始，除了计算循环神经网络的隐状态之外，还利用公式([6.45](\l))
> 依次前向计算偏导数 [ ^*∂***h**^1]{.underline} *, [
> ^∂^]{.underline}*[**^h^**2]{.underline} *, [
> ^∂^]{.underline}*[**^h^**3]{.underline} *,* · · · 。
>
> 这样，假设第*t*
> 个时刻存在一个监督信息，其损失函数为L*~t~*，就可以同时计算损失函数对*U~ij~*
> 的偏导数

[ *∂*L*~t~*]{.underline} = [ *∂***h***~t~ *]{.underline} T
[*∂*L*~t~*]{.underline}

> (6.46)

*∂U~ij~ ∂U~ij~ ∂***h***~t~*

> 这样在第*t* 时刻，可以实时地计算损失L*~t~* 关于参数*U*
> 的梯度，并更新参数。参数*W* 和**b**
> 的梯度也可以同样按上述方法实时计算。
>
> 两种算法比较
> RTRL算法和BPTT算法都是基于梯度下降的算法，分别通过前向模式和反向模式应用链式法则来计算梯度。在循环神经网络中，一般网络输
> 出维度远低于输入维度，因此BPTT 算法的计算量会更小，但是BPTT
> 算法需要保存所有时刻的中间梯度，空间复杂度较高。RTRL
> 算法不需要梯度回传，因此非常适合用于需要在线学习或无限序列的任务中。

#### 长期依赖问题

> 循环神经网络在学习过程中的主要问题是长期依赖问题。 在BPTT
> 算法中，将公式([6.36](\l)) 展开得到

*δt,k* =

> *t*−1
>
> *i*=*k*
>
> diag(*f* ^′^(**z***~i~*))*U* T
>
> *δ~t,t~.* (6.47)
>
> 如果定义*γ* ∼= ∥ diag(*f* ^′^(**z***~i~*))*U* T∥，则
>
> *δ~t,k~* = *γ^t^*^−*k*^*δ~t,t~.* (6.48)
>
> 若*γ \>* 1，当*t*−*k* → ∞时，*γ^t^*^−*k*^ →
> ∞，会造成系统不稳定，称为梯度爆炸问 题（Gradient Exploding
> Problem）；相反，若*γ \<* 1，当*t*−*k* → ∞时，*γ^t^*^−*k*^ →
> 0，会出现和深度前馈神经网络类似的梯度消失问题（gradient vanishing
> problem）
>
> 。
>
> 要注意的是，在循环神经网络中的梯度消失不是说 *^[∂]{.underline}^
> [t]{.underline}* 的梯度消失了，

*∂U*

图片识别内容

> 的梯度消失了（当*t* − *k* 比较大时）。也就是说，参数*U* 的更新
>
> 主要靠当前时刻*k* 的几个相邻状态**h***~k~* 来更新，长距离的状态对*U*
> 没有影响。
>
> 由于循环神经网络经常使用非线性激活函数为logistic 函数或tanh
> 函数作为非线性激活函数，其导数值都小于1；并且权重矩阵∥*U* ∥
> 也不会太大，因此如果时间间隔*t* − *k* 过大，*δ~t,k~*
> 会趋向于0，因此经常会出现梯度消失问题。
>
> 虽然简单循环网络理论上可以建立长时间间隔的状态之间的依赖关系，但
> 是由于梯度爆炸或消失问题，实际上只能学习到短期的依赖关系。这样，如果*t*
> 时刻的输出*y~t~* 依赖于*t*−*k* 时刻的输入**x**~*t*−*k*~，当间隔*k*
> 比较大时，简单神经网络很难建模这种长距离的依赖关系，称为长期依赖问题（Long-Term
> Dependencies Problem）。
>
> **6.5.1** 改进方案
>
> 为了避免梯度爆炸或消失问题，一种最直接的方式就是选取合适的参数，同
> 时使用非饱和的激活函数，尽量使得diag(*f* ^′^(**z***~i~*))*U* T ≈
> 1，这种方式需要足够的人工调参经验，限制了模型的广泛应用。比较有效的方式是通过改进模型或优
> 化方法来缓解循环网络的梯度爆炸和梯度消失问题。
>
> 梯度截断是一种启发式的解 决梯度爆炸问题的有效方法，
> 参见第[7.2.3.4](\l)节。
>
> 梯度爆炸
> 一般而言，循环网络的梯度爆炸问题比较容易解决，一般通过权重衰减或梯度截断来避免。
>
> 权重衰减是通过给参数增加 *ℓ*~1~ 或 *ℓ*~2~
> 范数的正则化项来限制参数的取值范围，从而使得*γ* ≤
> 1。梯度截断是另一种有效的启发式方法，当梯度的模大于一定阈值时，就将它截断成为一个较小的数。
>
> 梯度消失
> 梯度消失是循环网络的主要问题。除了使用一些优化技巧外，更有效的方式就是改变模型，比如让*U*
> = *I*，同时使用*f* ^′^(**z***~i~*) = 1，即
>
> **h***~t~* = **h**~*t*−1~ + *g*(**x***~t~*; *θ*)*,* (6.49)
>
> 其中*g*(·) 是一个非线性函数，*θ* 为参数。
>
> 公式([6.49](\l)) 中，**h***~t~* 和**h**~*t*−1~
> 之间为线性依赖关系，且权重系数为1，这样就不存在梯度爆炸或消失问题。但是，这种改变也丢失了神经元在反馈边上的非
> 线性激活的性质，因此也降低了模型的表示能力。
>
> 为了避免这个缺点，我们可以采用一个更加有效的改进策略：

**h***~t~* = **h**~*t*−1~ + *g*(**x***~t~,* **h**~*t*−1~; *θ*)*,* (6.50)

> 这样**h***~t~* 和**h**~*t*−1~
> 之间为既有线性关系，也有非线性关系，在一定程度上可以缓解梯度消失问题。但这种改进依然有一个问题就是记忆容量（memory
> capacity）
>
> 。随着**h***~t~* 不断累积存储新的输入信息，会发生饱和现象。假设*g*(·)
> 为logistic 函数，则随着时间*t* 的增长，**h***~t~*
> 会变得越来越大，从而导致**h** 变得饱和。也就是说， 隐状态**h***~t~*
> 可以存储的信息是有限的，随着记忆单元存储的内容越来越多，其丢失的信息也越来越多。
>
> 为了解决容量问题，可以有两种方法。一种是增加一些额外的存储单元：外
> 部记忆；另一种是进行选择性的遗忘，同时也进行有选择的更新。增加外部记
> 忆的方法将在第[8](\l)章中介绍，本章主要介绍后一种方法。

#### 基于门控的循环神经网络

> 为了解决上节中提到的记忆容量问题，一种非常好的解决方案是引入门
> 控[Hochreiter and Schmidhuber](\l) \[[1997](\l)\]
> 来控制信息的累积速度，包括有选择地加入新的信息，并有选择地遗忘之前累积的信息。这一类网络可以称为基于门控
> 的循环神经网络（Gated
> RNN）。本节中，主要介绍两种基于门控的循环神经网络：长短期记忆（LSTM）网络和门控循环单元（GRU）网络。

###### 长短期记忆网络

> 长短期记忆（Long Short-Term Memory，LSTM）网络\[[Gers et al.](\l),
> [2000](\l), [Hochreiter and Schmidhuber](\l), [1997](\l)\]
> 是循环神经网络的一个变体，可以有效地解决简单循环神经网络的梯度爆炸或消失问题。
>
> 在公式([6.50](\l)) 的基础上，LSTM 网络主要改进在以下两个方面：
>
> 新的内部状态 LSTM 网络引入一个新的内部状态（internal state）**c***~t~*
> 专门进行线性的循环信息传递，同时（非线性）输出信息给隐藏层的外部状态**h***~t~*。

**c***~t~* = **f***~t~* ⊙ **c**~*t*−1~ + **i***~t~* ⊙ **c**˜*~t~,*
(6.51)

**h***~t~* = **o***~t~* ⊙ tanh(**c***~t~*)*,* (6.52)

> 公 式 ([6.53](\l))∼([6.56](\l)) 中 的
>
> *W*∗*, U*∗*,* **b**∗ 为可学习的网络
>
> 其中**f***~t~*，**i***~t~* 和**o***~t~*
> 为三个门（gate）来控制信息传递的路径；⊙ 为向量元素乘积；
>
> **c**~*t*−1~ 为上一时刻的记忆单元；**c**˜*~t~*
> 是通过非线性函数得到候选状态，
>
> **c**˜*~t~* = tanh(*W~c~***x***~t~* + *U~c~***h**~*t*−1~ +
> **b***~c~*)*.* (6.53)
>
> 在每个时刻*t*，LSTM 网络的内部状态**c***~t~*
> 记录了到当前时刻为止的历史信息。
>
> 参数，其中∗ ∈ {*i, f, o, c*}。 门机制 LSTM 网络引入门机制（gating
> mechanism）来控制信息传递的路径。公式([6.51](\l)) 和([6.51](\l))
> 中三个"门"分别为输入门**i***~t~*, 遗忘门**f***~t~*
> 和输出门**o***~t~*，
>
> 在数字电路中，门（gate）为一个二值变量{0*,* 1}，0
> 代表关闭状态，不许任何信息通过；1 代表开放状态，允许所有信息通过。LSTM
> 网络中的"门"是一种"软"门，取值在(0*,* 1)
> 之间，表示以一定的比例运行信息通过。LSTM 网络中三个门的作用为

-   遗忘门**f***~t~* 控制上一个时刻的内部状态**c**~*t*−1~
    > 需要遗忘多少信息。

-   输入门**i***~t~* 控制当前时刻的候选状态**c**˜*~t~*
    > 有多少信息需要保存。

-   输出门**o***~t~* 控制当前时刻的内部状态**c***~t~*
    > 有多少信息需要输出给外部状态**h***~t~*。

> 当**f***~t~* = 0*,* **i***~t~* = 1
> 时，记忆单元将历史信息清空，并将候选状态向量**c**˜*~t~*
> 写入。但此时记忆单元**c***~t~*
> 依然和上一时刻的历史信息相关。当**f***~t~* = 1*,* **i***~t~* = 0
> 时，记忆单元将复制上一时刻的内容，不写入新的信息。
>
> 三个门的计算方式为：
>
> **i***~t~* = *σ*(*W~i~***x***~t~* + *U~i~***h**~*t*−1~ +
> **b***~i~*)*,* (6.54)
>
> **f***~t~* = *σ*(*W~f~* **x***~t~* + *U~f~* **h**~*t*−1~ + **b***~f~*
> )*,* (6.55)
>
> **o***~t~* = *σ*(*W~o~***x***~t~* + *U~o~***h**~*t*−1~ +
> **b***~o~*)*,* (6.56)
>
> 其中*σ*(·) 为logistic 函数，其输出区间为(0*,* 1)，**x***~t~*
> 为当前时刻的输入，**h**~*t*−1~ 为上一时刻的外部状态。
>
> 图[6.7](\l)给出了LSTM
> 网络的循环单元结构，其计算过程为：（1）首先利用上一时刻的外部状态**h**~*t*−1~
> 和当前时刻的输入**x***~t~*，计算出三个门，以及候选状态**c**˜*~t~*；（2）结合遗忘门**f***~t~*
> 和输入门**i***~t~*
> 来更新记忆单元**c***~t~*；（3）结合输出门**o***~t~*，将内部状态的信息传递给外部状态**h***~t~*。
>
> 图 6.7 LSTM 循环单元结构
>
> 通过LSTM
> 循环单元，整个网络可以建立较长距离的时序依赖关系。公式([6.51](\l))∼([6.56](\l))
> 可以简洁地描述为

**c**˜*t* 

> tanh

  = 

>  *W*  **x***t*
>
>  + **b** *,* (6.57)

**f***~t~*  *σ*

>  
>
> **h***t*−1 
>
> **c***~t~* = **f***~t~* ⊙ **c**~*t*−1~ + **i***~t~* ⊙ **c**˜*~t~,*
> (6.58)
>
> **h***~t~* = **o***~t~* ⊙ tanh (**c***~t~*) *,* (6.59)
>
> 其中**x***~t~* ∈ R*e* 为当前时刻的输入，*W* ∈ R4*d*×(*d*+*e*) 和**b**
> ∈ R4*d* 为网络参数。
>
> 记忆 循环神经网络中的隐状态**h**
> 存储了历史信息，可以看作是一种记忆（memory）
>
> 。在简单循环网络中，隐状态每个时刻都会被重写，因此可以看作是一种短期记忆（short-term
> memory）。在神经网络中，长期记忆（long-term memory）
> 可以看作是网络参数，隐含了从训练数据中学到的经验，并更新周期要远远慢于短期记忆。而在LSTM
> 网络中，记忆单元**c**
> 可以在某个时刻捕捉到某个关键信息，并有能力将此关键信息保存一定的时间间隔。记忆单元**c**
> 中保存信息的生命周期要长于短期记忆**h**，但又远远短于长期记忆，因此称为长的短期记忆
>
> （long short-term memory）。
>
图片识别内容

> 网络时，过小的值会使得遗忘门的值比较小。这意味着前一时刻的信息大部分都丢失了，这样网络很难捕捉到长距离的依赖信息。
> 并且相邻时间间隔的梯度会非常小，这会导致梯度弥散问题。因此遗忘的参数初始值一般都设得比较大，其偏置向量**b***~f~*
> 设为1 或2.

2.  **LSTM** 网络的各种变体

> 目前主流的LSTM
> 网络用的三个门来动态地控制内部状态的应该遗忘多少历史信息，输入多少新信息，以及输出多少信息。我们可以对门机制进行改进
> 并获得LSTM 网络的不同变体。
>
> 无遗忘门的**LSTM** 网络 [Hochreiter and Schmidhuber](\l)
> \[[1997](\l)\] 最早提出的LSTM
>
> 网络是没有遗忘门的，其内部状态的更新为

**c***~t~* = **c**~*t*−1~ + **i***~t~* ⊙ **c**˜*~t~.* (6.60)

> 如之前的分析，记忆单元**c**
> 会不断增大。当输入序列的长度非常大时，记忆单元的容量会饱和，从而大大降低LSTM
> 模型的性能。
>
> **peephole** 连接 另外一种变体是三个门不但依赖于输入 **x***~t~*
> 和上一时刻的隐状态**h**~*t*−1~，也依赖于上一个时刻的记忆单元**c**~*t*−1~。

**i***~t~* = *σ*(*W~i~***x***~t~* + *U~i~***h**~*t*−1~ +
*V~i~***c**~*t*−1~ + **b***~i~*)*,* (6.61)

**f***~t~* = *σ*(*W~f~* **x***~t~* + *U~f~* **h**~*t*−1~ + *V~f~*
**c**~*t*−1~ + **b***~f~* )*,* (6.62)

**o***~t~* = *σ*(*W~o~***x***~t~* + *U~o~***h**~*t*−1~ +
*V~o~***c***~t~* + **b***~o~*)*,* (6.63)

> 其中*V~i~*，*V~f~* 和*V~o~* 为对角阵形式的参数。
>
> 耦合输入门和遗忘门 LSTM
> 网络中的输入门和遗忘门有些互补关系，因此同时用两个门比较冗余。为了减少LSTM
> 网络的计算复杂度，将这两门合并为一个门。令

**f***~t~* = **1** − **i***~t~.* (6.64)

> 这样，内部状态的更新方式为

**c***~t~* = (**1** − **i***~t~*) ⊙ **c**~*t*−1~ + **i***~t~* ⊙
**c**˜*~t~.* (6.65)

###### 门控循环单元网络

> 门控循环单元（Gated Recurrent Unit，GRU）网络 \[[Cho et al.](\l),
> [2014](\l), [Chung](\l) [et al.](\l), [2014](\l)\] 是一种比LSTM
> 网络更加简单的循环神经网络。
>
> GRU 网络也是在公式([6.50](\l))
> 的基础上，引入门机制来控制信息更新的方式。在LSTM
> 网络中，输入门和遗忘门是互补关系，用两个门比较冗余。GRU
> 将输入门与和遗忘门合并成一个门：更新门。同时，GRU
> 也不引入额外的记忆单元， 直接在当前状态**h***~t~*
> 和历史状态**h**~*t*−1~ 之间引入线性依赖关系。
>
> 在GRU 网络中，当前时刻的候选状态**h**˜*t* 为
>
> 计算候选状态 **h**˜t 时， 使用
>
> tanh 激活函数是由于其导数

**h**˜*t*

> = tanh(*W~h~***x***~t~*
>
> \+ *U~h~*

(**r***~t~*

> ⊙ **h***t*−1

) + **b***~h~*

)*,* (6.66)

> 有比较大的值域，缓解梯度消失问题。
>
> 其中**r***~t~* ∈ \[0*,* 1\] 为重置门（reset
> gate），用来控制候选状态**h**˜*t* 的计算是否依赖
>
> 上一时刻的状态**h***t*−1。 公 式 ([6.66](\l))∼([6.69](\l)) 中 的

*W*∗*, U*∗*,* **b**∗ 为可学习的网络

**r** = *σ*(*W* **x**

> \+ *U* **h** + **b** )*,* (6.67)
>
> 参数，其中∗ ∈ {*b, r, 𝑥*}。

*t r t*

> *r t*−1 *r*
>
> 当**r***~t~* = 0 时，候选状态**h**˜*t* = tanh(*W~c~***x***~t~* +
> **b**) 只和当前输入**x***~t~* 相关，和历史状态无关。当**r***~t~* = 1
> 时，候选状态**h**˜*t* = tanh(*W~h~***x***~t~* + *U~h~***h**~*t*−1~ +
> **b***~h~*) 和当前输入**x***~t~*和历史状态**h**~*t*−1~
> 相关，和简单循环网络一致。
>
> GRU 网络的隐状态**h***~t~* 更新方式为
>
> **h***~t~* = **z***~t~* ⊙ **h**~*t*−1~ + (1 − **z***~t~*) ⊙ **h**˜*t,*
> (6.68)
>
> 其中**z** ∈ \[0*,* 1\] 为更新门（update
> gate），用来控制当前状态需要从历史状态中保留多少信息（不经过非线性变换），以及需要从候选状态中接受多少新信息。
>
> **z***~t~* = *σ*(**W***~𝑥~***x***~t~* + **U***~𝑥~***h**~*t*−1~ +
> **b***~𝑥~*)*.* (6.69)
>
> 当**z***~t~* = 0 时，当前状态**h***~t~* 和历史状态**h**~*t*−1~
> 之间为非线性函数。若同时有**z***~t~* = 0*,* **r** = 1 时，GRU
> 网络退化为简单循环网络；若同时有**z***~t~* = 0*,* **r** = 0
> 时，当前状态**h***~t~* 只和当前输入**x***~t~*
> 相关，和历史状态**h**~*t*−1~ 无关。当**z***~t~* = 1
> 时，当前状态**h***~t~* = **h**~*t*−1~)
> 等于上一时刻状态**h**~*t*−1~，和当前输入**x***~t~* 无关。
>
> 图[6.8](\l)给出了GRU 循环单元结构。
>
> 图 6.8 GRU 循环单元结构

#### 深层循环神经网络

> 如果将深度定义为网络中信息传递路径长度的话，循环神经网络可以看作
> 是既"深"又"浅"的网络。一方面来说，如果我们把循环网络按时间展开，长时间间隔的状态之间的路径很长，循环网络可以看作是一个非常深的网络了。从
> 另一方面来说，如果同一时刻网络输入到输出之间的路径**x***~t~* →
> **y***~t~*，这个网络是非常浅的。
>
> 因此，我们可以增加循环神经网络的深度从而增强循环神经网络的能力。增
> 加循环神经网络的深度主要是增加同一时刻网络输入到输出之间的路径
> **x***~t~* → *y~t~*，比如增加隐状态到输出**h***~t~* →
> **y***~t~*，以及输入到隐状态**x***~t~* → **h***~t~* 之间的路径的深度。

###### 堆叠循环神经网络

> 一种常见的做法是将多个循环网络堆叠起来，称为堆叠循环神经网络（Stacked
> Recurrent Neural Network，SRNN）。一个堆叠的简单循环网络（stacked
> SRN） 也称为循环网络循环多层感知器（Recurrent Multi-Layer
> Perceptron，RMLP） [Parlos et al.](\l) \[[1991](\l)\]。
>
> 图[6.9](\l)给出了按时间展开的堆叠循环神经网络。第*l*
> 层网络的输入是第*l* − 1
>
> 层网络的输出。我们定义**h**^(*l*)\ 为在时刻*t*\ 时第*l*\ 层的隐状态^

**h**(*l*) = *f* (*U* (*l*)**h**(*l*)

> \+ *W* ^(*l*)^**h**^(*l*−1)^ + **b**(*l*))*,* (6.70)
>
> *t t*−1 *t*
>
> 其中*U* ^(*l*)^，*W*
> ^(*l*)\ 和**b**(*l*)\ 为权重矩阵和偏置向量，**h**(0)^ = **x***~t~*。

7.  深层循环神经网络 2019 年 4 月 6 日 157

> · · ·
>
> · · ·
>
> · · ·
>
> · · ·
>
> · · ·
>
> 图 6.9 按时间展开的堆叠循环神经网络

###### 双向循环神经网络

> 在有些任务中，一个时刻的输出不但和过去时刻的信息有关，也和后续时
> 刻的信息有关。比如给定一个句子，其中一个词的词性由它的上下文决定，即
> 包含左右两边的信息。因此，在这些任务中，我们可以增加一个按照时间的逆
> 序来传递信息的网络层，来增强网络的能力。
>
> 双向循环神经网络（bidirectional recurrent neural
> network，Bi-RNN）由两层循环神经网络组成，它们的输入相同，只是信息传递的方向不同。
>
> 假设第1 层按时间顺序，第2 层按时间逆序，在时刻*t*
> 时的隐状态定义为**h**^(1)^
>
> 和**h**^(2)^，则
>
> **h**(1) = *f* (*U* (1)**h**(1)
>
> \+ *W* ^(1)^**x***~t~* + **b**(1))*,* (6.71)
>
> *t t*−1

**h**(2) = *f* (*U* (2)**h**(2)

> \+ *W* ^(2)^**x***~t~* + **b**(2))*,* (6.72)
>
> *t t*+1
>
> **h***~t~* = **h**^(1)^ ⊕ **h**^(2)^*,* (6.73)

*t t*

> 其中⊕ 为向量拼接操作。
>
> 图[6.10](\l)给出了按时间展开的双向循环神经网络。
>
> ![](/root/autodl-tmp/project_knowledge/Doc_QA/Knowledge_based/1828695663060254721/image_output/7.《神经网络与深度学习》/media/image105.png)![](/root/autodl-tmp/project_knowledge/Doc_QA/Knowledge_based/1828695663060254721/image_output/7.《神经网络与深度学习》/media/image106.png)·
> · ·
>
> · · ·
>
> · · ·
>
> · · ·
>
> · · ·
>
> 图 6.10 按时间展开的双向循环神经网络

#### 扩展到图结构

> 如果将循环神经网络按时间展开，每个时刻的隐状态**h***~t~*
> 看做一个节点，那么这些节点构成一个链式结构，每个节点*t*
> 都收到其父节点的消息（message），
> 更新自己的状态，并传递给其子节点。而链式结构是一种特殊的图结构，我们可以比较容易地将这种消息传递（message
> passing）的思想扩展到任意的图结构上。

###### 递归神经网络

图片识别内容

图片识别内容

> Network，RecNN）是循环神经网络在有向无循环图上的扩展 \[[Pollack](\l),
> [1990](\l)\]。递归神经网络的一般结构为树状的层次结构，如图[6.11a](\l)所示。

图片识别内容

图片识别内容

图片识别内容

图片识别内容

图片识别内容

图片识别内容

图片识别内容

图片识别内容

图片识别内容

图片识别内容


a.  一般结构

图 6.11 递归神经网络

b.  退化结构

> 以图[6.11a](\l)中的结构为例，有三个隐藏层**h**~1~、**h**~2~
> 和**h**~3~，其中**h**~1~ 由两个输入**x**~1~ 和**x**~2~
> 计算得到，**h**~2~ 由另外两个输入层**x**~3~ 和**x**~4~
> 计算得到，**h**~3~ 由两个隐藏层**h**~1~ 和**h**~2~ 计算得到。
>
> 对于一个节点**h***~i~*，它可以接受来自父节点集合*π~i~*
> 中所有节点的消息，并更新自己的状态。
>
> **h***~i~* = *f* (**h***~π~* )*,* (6.74)
>
> 其中**h***~π~i* 表示集合*π~i~* 中所有节点状态的拼接，*f* (·)
> 是一个和节点位置无关的非线性函数，可以为一个单层的前馈神经网络。比如图[6.11a](\l)所示的递归神经网络具体可以写为
>
> **h**~1~ = *σ*(*W* **x**1 + **b**)*,* (6.75)
>
> 6.8 扩展到图结构 2019 年 4 月 6 日 159
>
> **h**~2~ = *σ*(*W* **x**3 + **b**)*,* (6.76)
>
> **h**~3~ = *σ*(*W* **h**1 + **b**)*,* (6.77)
>
> 其中*σ*(·) 表示非线性激活函数，*W* 和**b**
> 是可学习的参数。同样，输出层*y* 可以为一个分类器，比如
>
> *y* = *g*(*W* ^′^ **h**1 + **b**′)*,* (6.78)
>
> 其中*g*(·) 为分类器，*W* ^′\ 和**b**′\ 为分类器的参数。^
>
> 当递归神经网络的结构退化为线性序列结构（图[6.11b](\l)）时，递归神经网络就等价于简单循环网络。
>
> 递归神经网络主要用来建模自然语言句子的语义\[[Socher et al.](\l),
> [2011](\l),
> [2013](\l)\]。给定一个句子的语法结构（一般为树状结构），可以使用递归神经网络来按照句法的组合关系来合成一个句子的语义。句子中每个短语成分可以在分成一些子成分，即每个短语的语义都可以由它的子成分语义组合而来，并进而合成整句的语义。
>
> 同样，我们也可以用门机制来改进递归神经网络中的长距离依赖问题，比
> 如树结构的长短期记忆模型（Tree-Structured LSTM）\[[Tai et al.](\l),
> [2015](\l), [Zhu](\l) [et al.](\l), [2015](\l)\] 就是将LSTM
> 模型的思想应用到树结构的网络中，来实现更灵活的组合函数。

###### 图网络

> 在实际应用中，很多数据是图结构的，比如知识图谱、社交网络、分子网
> 络等。而前馈网络和反馈网络很难处理图结构的数据。
>
> 图网络（Graph
> Network，GN）是将消息传递的思想扩展到图结构数据上的神经网络。
>
> 对于一个任意的图结构*G*(V*,* 𝗌)，其中V 表示节点集合，𝗌
> 表示边集合。每条边表示两个节点之间的依赖关系。节点之间的连接可以是有向的，也可以是
> 无向的。图中每个节点*v*
> 都用一组神经元来表示其状态**h**(*v*)，初始状态可以为节点*v* 的输入特征
> **x**(*v*)。每个节点可以收到来自相邻节点的消息，并更新自己的状态。
>
> 参见习题[6-5](\l)。

**m**(*v*) = Σ

> *f* **h**^(*v*)^ *,* **h**^(*u*)^ *,* **e**(*u,v*) *,* (6.79)
>
> **h**^(*v*)^ = *g* **h**^(*v*)^ *,* **m**^(*v*)^ *,* (6.80)
>
> 其中*N* (*v*) 表示节点*v*
> 的邻居，**m**^(*v*)\ 表示在第*t*\ 时刻节点*v*\ 收到的信息，**e**(*u,v*)\ 为^
>
> 注意力机制参见第[8.1](\l)节。
>
> 边*e*^(*u,v*)\ 上的特征。^
>
> 公式([6.79](\l)) 和([6.80](\l))
> 是一种同步的更新方式，所有的结构同时接受信息并更新自己的状态。而对于有向图来说，使用异步的更新方式会更有效率，比如
> 循环神经网络或递归神经网络。在整个图更新*T* 次后，可以通过一个读出函数
>
> （readout function）*g*(·) 来得到整个网络的表示。
>
> **y***~t~* = *g* {**h**^(*v*)^\|*v* ∈ V} *.* (6.81)

#### 总结和深入阅读

> 循环神经网络可以建模时间序列数据之间的相关性。和
> 延时神经网络\[[Lang](\l) [et al.](\l), [1990](\l), [Waibel et
> al.](\l), [1989](\l)\]
> 以及有外部输入的非线性自回归模型\[[Leontari-](\l) [tis and
> Billings](\l), [1985](\l)\]
> 相比，循环神经网络可以更方便地建模长时间间隔的相关性。
>
> 常用的循环神经网络的参数学习算法是BPTT 算法\[[Werbos](\l),
> [1990](\l)\]，其计算时间和空间要求会随时间线性增长。为了提高效率，当输入序列的长度比较大时，可以使用带截断（truncated）的BPTT
> 算法\[[Williams and Peng](\l), [1990](\l)\]，
> 只计算固定时间间隔内的梯度回传。
>
> 一个完全连接的循环神经网络有着强大的计算和表示能力，可以近似任何非线性动力系统以及图灵机，解决所有的可计算问题。然而由于梯度爆炸和梯度消失问题，简单循环网络存在长期依赖问题\[[Bengio
> et al.](\l), [1994](\l), [Hochreiter](\l) [et al.](\l),
> [2001](\l)\]。为了解决这个问题，人们对循环神经网络进行了很多的改进，其中最有效的改进方式为引入门控机制，比如*LSTM*
> 网络 \[[Gers et al.](\l), [2000](\l), [Hochre-](\l) [iter and
> Schmidhuber](\l), [1997](\l)\] 和*GRU* 网络\[[Chung et al.](\l),
> [2014](\l)\]。当然还有一些其它方法，比如时钟循环神经网络（Clockwork
> RNN）\[[Koutnik et al.](\l), [2014](\l)\]、乘法RNN\[[Sutskever et
> al.](\l), [2011](\l), [Wu et al.](\l), [2016](\l)\]
> 以及引入注意力机制等。
>
> LSTM 网络是目前为止最成功的循环神经网络模型，成功应用在很多领域，
> 比如语音识别、机器翻译\[[Sutskever et al.](\l),
> [2014](\l)\]、语音模型以及文本生成。LSTM
> 网络通过引入线性连接来缓解长距离依赖问题。虽然LSTM
> 网络取得了很大的成功，其结构的合理性一直受到广泛关注。人们不断有尝试对其进行改进来寻找最优结构，比如减少门的数量、提高并行能力等。关于LSTM
> 网络的分析可以参考文献\[[Greﬀ et al.](\l), [2017](\l), [Jozefowicz et
> al.](\l), [2015](\l), [Karpathy et al.](\l), [2015](\l)\]。
>
> LSTM
> 网络的线性连接以及门控机制是一种十分有效的避免梯度消失问题的方法。这种机制也可以用在深层的前馈网络中，比如残差网络\[[He
> et al.](\l), [2016](\l)\]
>
> 和高速网络\[[Srivastava et al.](\l), [2015](\l)\]
> 都通过引入线性连接来训练非常深的卷积网络。对于循环神经网格，这种机制也可以用在深度方向上，Gird
> LSTM 网络\[[Kalchbrenner et al.](\l), [2015](\l)\]、Depth Gated
> RNN\[[Chung et al.](\l), [2015](\l)\] 等。
>
> 此外，循环神经网络可以很容易地扩展到两种更广义的图结构数据上，称
> 为图网络\[[Scarselli et al.](\l),
> [2009](\l)\]。比如递归神经网络就是一种有向无环图上的图网络。图网络是目前比较新兴的研究方向，还没有比较成熟的网络模型。在不同
> 的网络结构以及任务上，都有很多不同的具体实现方式。其中比较有名图网络
> 模型有图卷积网络（Graph Convolutional Network，GCN）\[[Kipf and
> Welling](\l), [2016](\l)\]、消息传递网络（Message Passing Neural
> Network，MPNN）\[[Gilmer et al.](\l), [2017](\l)\]
> 等。关于图网络的综述可以参考文献\[[Battaglia et al.](\l),
> [2018](\l)\]。

#### 习题

> 习题 **6-1** 分析延时神经网络、卷积神经网络和循环神经网络的异同点。
>
> 习题 **6-2** 计算公式([6.40](\l)) 和公式([6.41](\l)) 中的梯度。
>
> 习题 **6-3** 计算LSTM
> 网络中参数的梯度，并分析其避免梯度消失的效果。习题 **6-4** 计算GRU
> 网络中参数的梯度，并分析其避免梯度消失的效果。习题**6-5**
> 证明当递归神经网络的结构退化为线性序列结构时，递归神经网
>
> 络就等价于简单循环神经网络。

#### 参考文献

> Peter W Battaglia, Jessica B Hamrick, Vic- tor Bapst, Alvaro
> Sanchez-Gonzalez, Vini- cius Zambaldi, Mateusz Malinowski, An- drea
> Tacchetti, David Raposo, Adam San- toro, Ryan Faulkner, et al.
> Relational induc- tive biases, deep learning, and graph net- works.
> *arXiv preprint arXiv:1806.01261*, 2018.
>
> Yoshua Bengio, Patrice Simard, and Paolo Frasconi. Learning long-term
> dependencies with gradient descent is diﬃcult. *Neural Networks, IEEE
> Transactions on*, 5(2):157--
>
> 166, 1994.
>
> Kyunghyun Cho, Bart Van Merriënboer, Caglar Gulcehre, Dzmitry
> Bahdanau, Fethi Bougares, Holger Schwenk, and Yoshua Bengio. Learning
> phrase representations using RNN encoder-decoder for statisti- cal
> machine translation. *arXiv preprint arXiv:1406.1078*, 2014.
>
> Junyoung Chung, Caglar Gulcehre, KyungHyun Cho, and Yoshua Bengio.
> Empirical evaluation of gated recurrent
>
> 162 2019 年 4 月 6 日 参考文献
>
> neural networks on sequence modeling.
>
> *arXiv preprint arXiv:1412.3555*, 2014. Junyoung Chung, Caglar
> Gulcehre, Kyunghyun Cho, and Yoshua Bengio. Gated feedback recurrent
> neural networks. In *International Conference on Machine* *Learning*,
> pages 2067--2075, 2015.
>
> Jeﬀrey L Elman. Finding structure in time.
>
> *Cognitive science*, 14(2):179--211, 1990.
>
> Felix A Gers, Jürgen Schmidhuber, and Fred Cummins. Learning to
> forget: Con- tinual prediction with lstm. *Neural Com-* *putation*,
> 2000.
>
> Justin Gilmer, Samuel S Schoenholz, Patrick F Riley, Oriol Vinyals,
> and George E Dahl. Neural message passing for quantum chemistry.
> *arXiv preprint* *arXiv:1704.01212*, 2017.
>
> Klaus Greﬀ, Rupesh K Srivastava, Jan Koutník, Bas R Steunebrink, and
> Jürgen Schmidhuber. Lstm: A search space odyssey. *IEEE transactions
> on neural net-* *works and learning systems*, 2017.
>
> Simon Haykin. *Neural networks and learn- ing machines*, volume 3.
> Pearson Upper Saddle River, NJ, USA:, 2009.
>
> Kaiming He, Xiangyu Zhang, Shaoqing Ren, and Jian Sun. Deep residual
> learning for image recognition. In *Proceedings of the IEEE conference
> on computer vision and* *pattern recognition*, pages 770--778, 2016.
>
> Sepp Hochreiter and Jürgen Schmidhuber. Long short-term memory.
> *Neural computa-* *tion*, 9(8):1735--1780, 1997.
>
> Sepp Hochreiter, Yoshua Bengio, Paolo Frasconi, and Jürgen
> Schmidhuber. Gradi- ent ﬂow in recurrent nets: the diﬃculty of
> learning long-term dependencies, 2001.
>
> Rafal Jozefowicz, Wojciech Zaremba, and Ilya Sutskever. An empirical
> exploration of recurrent network architectures. In *Pro- ceedings of
> the 32nd International Confer- ence on Machine Learning*, pages 2342--
> 2350, 2015.
>
> Nal Kalchbrenner, Ivo Danihelka, and Alex Graves. Grid long short-term
> memory. *arXiv preprint arXiv:1507.01526*, 2015.
>
> Andrej Karpathy, Justin Johnson, and Li Fei-Fei. Visualizing and
> understand- ing recurrent networks. *arXiv preprint*
> *arXiv:1506.02078*, 2015.
>
> Thomas N Kipf and Max Welling. Semi- supervised classiﬁcation with
> graph con- volutional networks. *arXiv preprint* *arXiv:1609.02907*,
> 2016.
>
> Jan Koutnik, Klaus Greﬀ, Faustino Gomez, and Juergen Schmidhuber. A
> clockwork rnn. In *Proceedings of The 31st Inter- national Conference
> on Machine Learning*, pages 1863--1871, 2014.
>
> Kevin J Lang, Alex H Waibel, and Geof- frey E Hinton. A time-delay
> neural network architecture for isolated word recognition. *Neural
> networks*, 3(1):23--43, 1990.
>
> IJ Leontaritis and Stephen A Billings. Input-output parametric models
> for non- linear systems part i: deterministic non- linear systems.
> *International journal of* *control*, 41(2):303--328, 1985.
>
> A Parlos, A Atiya, K Chong, W Tsai, and B Fernandez. Recurrent
> multilayer perceptron for nonlinear system identiﬁca- tion. In *Neural
> Networks, 1991., IJCNN- 91-Seattle International Joint Conference*
> *on*, volume 2, pages 537--540. IEEE, 1991. Jordan B Pollack.
> Recursive distributed representations. *Artiﬁcial Intelligence*, 46
> (1):77--105, 1990.
>
> Franco Scarselli, Marco Gori, Ah Chung Tsoi, Markus Hagenbuchner, and
> Gabriele Monfardini. The graph neural network model. *IEEE
> Transactions on Neural Net-* *works*, 20(1):61--80, 2009.
>
> Anton Maximilian Schäfer and Hans Georg Zimmermann. Recurrent neural
> networks are universal approximators. In *Interna- tional Conference
> on Artiﬁcial Neural Net-* *works*, pages 632--640. Springer, 2006.
>
> Hava T Siegelmann and Eduardo D Son- tag. Turing computability with
> neural nets. *Applied Mathematics Letters*, 4(6):77--80, 1991.
>
> Richard Socher, Cliﬀ C Lin, Chris Manning, and Andrew Y Ng. Parsing
> natural scenes
>
> and natural language with recursive neu- ral networks. In *Proceedings
> of the Inter- national Conference on Machine Learning*, 2011.
>
> Richard Socher, Alex Perelygin, Jean Y Wu, Jason Chuang, Christopher D
> Man- ning, Andrew Y Ng, and Christopher Potts. Recursive deep models
> for semantic com- positionality over a sentiment treebank. In
> *Proceedings of EMNLP*, 2013.
>
> Rupesh Kumar Srivastava, Klaus Greﬀ, and Jürgen Schmidhuber. Highway
> networks. *arXiv preprint arXiv:1505.00387*, 2015.
>
> Ilya Sutskever, James Martens, and Geof- frey E Hinton. Generating
> text with recur- rent neural networks. In *Proceedings of the 28th
> International Conference on Machine* *Learning*, pages 1017--1024,
> 2011.
>
> Ilya Sutskever, Oriol Vinyals, and Quoc VV Le. Sequence to sequence
> learning with neu- ral networks. In *Advances in Neural In- formation
> Processing Systems*, pages 3104-- 3112, 2014.
>
> Kai Sheng Tai, Richard Socher, and Christopher D Manning. Improved se-
> mantic representations from tree-structured long short-term memory
> networks. In *Pro- ceedings of the 53rd Annual Meeting of the
> Association for Computational Linguistics*, 2015.
>
> Alex Waibel, Toshiyuki Hanazawa, Geof- frey Hinton, Kiyohiro Shikano,
> and Kevin J Lang. Phoneme recognition using time- delay neural
> networks. *IEEE transactions on acoustics, speech, and signal
> processing*, 37(3):328--339, 1989.
>
> Paul J Werbos. Backpropagation through time: what it does and how to
> do it. *Proceedings of the IEEE*, 78(10):1550--1560, 1990.
>
> Ronald J Williams and Jing Peng. An ef- ﬁcient gradient-based
> algorithm for on-line training of recurrent network trajectories.
> *Neural computation*, 2(4):490--501, 1990.
>
> Ronald J Williams and David Zipser. Gradient-based learning algorithms
> for re- current networks and their computational complexity.
> *Backpropagation: Theory, ar- chitectures, and applications*,
> 1:433--486, 1995.
>
> Yuhuai Wu, Saizheng Zhang, Ying Zhang, Yoshua Bengio, and Ruslan R
> Salakhut- dinov. On multiplicative integration with recurrent neural
> networks. In *Advances in neural information processing systems*,
> pages 2856--2864, 2016.
>
> Xiaodan Zhu, Parinaz Sobihani, and Hongyu Guo. Long short-term memory
> over recursive structures. In *Proceedings of LCML*, pages 1604--1612,
> 2015.

第**7** 章 网络优化与正则化
===========================

> 任何数学技巧都不能弥补信息的缺失。
>
> --- Cornelius Lanczos，1964
>
> 虽然神经网络具有非常强的表达能力，但是当应用神经网络模型到机器学
> 习时依然存在一些难点。主要分为两大类：

1.  优化问题：神经网络模型是一个非凸函数，再加上在深度网络中的梯
    > 度消失问题，很难进行优化；另外，深层神经网络模型一般参数比较多，训练
    > 数据也比较大，会导致训练的效率比较低。

2.  泛化问题：因为神经网络的拟合能力强，反而容易在训练集上产生过
    > 拟合。因此，在训练深层神经网络时，同时也需要通过一定的正则化方法来改
    > 进网络的泛化能力。

> 目前，研究者从大量的实践中总结了一些经验技巧，从优化和正则化两个
> 方面来提高学习效率并得到一个好的网络模型。
>
> **7.1** 网络优化
>
> 深层神经网络是一个高度非线性的模型，其风险函数是一个非凸函数，因
> 此风险最小化是一个非凸优化问题，会存在很多局部最优点。

###### 网络优化的难点

> 有效地学习深层神经网络的参数是一个具有挑战性的问题，其主要原因有
> 以下几个方面。

1.  网络结构多样性

> 神经网络的种类非常多，比如卷积网络、循环网络等，其结构也非常不同。
> 有些比较深，有些比较宽。不同参数在网络中的作用也有很大的差异，比如连接权重和偏置的不同，以及循环网络中循环连接上的权重和其它权重的不同。
>
> 由于网络结构的多样性，我们很难找到一种通用的优化方法。不同的优化
> 方法在不同网络结构上的差异也都比较大。
>
> 此外，网络的超参数一般也比较多，这也给优化带来很大的挑战。

2.  高维变量的非凸优化

> 低维空间的非凸优化问题主要是存在一些局部最优点。基于梯度下降的优
> 化方法会陷入局部最优点，因此低维空间非凸优化的主要难点是如何选择初始
> 化参数和逃离局部最优点。深层神经网络的参数非常多，其参数学习是在非常
> 高维空间中的非凸优化问题，其挑战和在低维空间的非凸优化问题有所不同。
>
> 鞍点的叫法是因为其形状像
>
> 鞍点
> 在高维空间中，非凸优化的难点并不在于如何逃离局部最优点，而是如何逃离鞍点（Saddle
> Point）\[[Dauphin et al.](\l), [2014](\l)\]。鞍点的梯度是0，但是在一些
>
> 马鞍。 维度上是最高点，在另一些维度上是最低点，如图[7.1](\l)所示。

1

1/2

0

1/2

> 1
>
> 1/2
>
> 0
>
> 1/2
>
> 0
>
> 1/2
>
> 1 1
>
> 1
>
> 1
>
> 1/2
>
> 图 7.1 鞍点示例
>
> 在高维空间中，局部最优点要求在每一维度上都是最低点，这种概率非常
> 低。假设网络有10*,* 000
> 维参数，一个点在某一维上是局部最低点的概率为*p*，那么在整个参数空间中，局部最优点的概率为*p*^10*,*000^，这种可能性非常小。也就是说高维空间中，大部分梯度为0
> 的点都是鞍点。基于梯度下降的优化方法会在鞍点附近接近于停滞，同样很难从这些鞍点中逃离。
>
> 平坦底部
> 深层神经网络的参数非常多，并且有一定的冗余性，这导致每单个参数对最终损失的影响都比较小，这导致了损失函数在局部最优点附近是一个平坦的区域，称为平坦最小值（Flat
> Minima）\[[Hochreiter and Schmidhuber](\l), [1997](\l), [Li et
> al.](\l),
> [2017a](\l)\]。并且在非常大的神经网络中，大部分的局部最小值是相等的。虽然神经网络有一定概率收敛于比较差的局部最小值，但随着网络规模增加，网络陷入局部最小值的概率大大降低\[[Choromanska
> et al.](\l), [2015](\l)\]。图[7.2](\l)给出了一种简单的平坦底部示例。
>
> 2.00
>
> 1.75
>
> 1.50
>
> 1.25
>
> 1.00
>
> 0.75
>
> 0.50
>
> 0.25
>
> 0.00

2.0 1.5

1.0 0.5

> 0.0
>
> w1

0.5 1.0

> 1.5 2.0
>
> 2.0
>
> 1.5
>
> 1.0
>
> 0.5
>
> 0.0
>
> 0.5 w2 1.0
>
> 1.5
>
> 2.0
>
> 图 7.2 神经网络中的平坦底部示例
>
> **7.2** 优化算法
>
> 目前，深层神经网络的参数学习主要是通过梯度下降方法来寻找一组可以最小化结构风险的参数。在具体实现中，梯度下降法可以分为：批量梯度下降、
> 随机梯度下降以及小批量梯度下降三种形式。根据不同的数据量和参数量，可以选择一种具体的实现形式。除了在收敛效果和效率上的差异，这三种方法都存在一些共同的问题，比如1）如何初始化参数；2）预处理数据；3）如何选择合适的学习率，避免陷入局部最优等。

###### 小批量梯度下降

> 目前，在训练深层神经网络时，训练数据的规模比较大。如果在梯度下降时，每次迭代都要计算整个训练数据上的梯度需要比较多的计算资源。此外，大规模训练集中的数据通常也会非常冗余，也没有必要在整个训练集上计算梯度。
> 因此，在训练深层神经网络时，经常使用小批量梯度下降算法。
>
> 令*f* (**x***, θ*) 表示一个深层神经网络，*θ*
> 为网络参数，在使用小批量梯度下降进
>
> 行优化时，每次选取*K* 个训练样本I*~t~* = {(**x**(*k*)*,*
> **y**(*k*))}*K*
>
> 。第*t* 次迭代（iteration）
>
> 时损失函数关于参数*θ* 的偏导数为

g*~t~*(*θ*) =

> Σ *∂*L **y**(*k*)*, f* (**x**(*k*)*, θ*)

*,* (7.1)

> *K* (**x**(*k*)*,***y**(*k*))∈I *∂θ*
>
> 这里的损失函数忽略了正则化项。加上*ℓ*p
> 正则化的损失函数参见第[7.7.1](\l)节。
>
> 其中L(·) 为可微分的损失函数，*K* 称为批量大小（Batch Size）。第*t*
> 次更新的梯度**g***~t~* 定义为
>
> **g***~t~* , g*~t~*(*θ~t~*~−1~)*.* (7.2)
>
> 使用梯度下降来更新参数，
>
> *θ~t~* ← *θ~t~*~−1~ − *α***g***~t~,* (7.3)
>
> 值得注意的是，图[7.3](\l)中的三种批量大小对应的学习率并不一致，因此并不是严格对比。
>
> Epoch（回合） 和 Iteration
>
> （单次更新） 的关系为 1 个epoch 等于( [训练样本的数量N]{.underline} )
>
> 其中*α \>* 0 为学习率。
>
> 每次迭代时参数更新的差值∆*θ~t~* 定义为
>
> ∆*θ~t~* , *θ~t~* − *θ~t~*~−1~*.* (7.4)
>
> ∆*θ~t~* 和梯度**g***~t~* 并不需要完全一致。∆*θ~t~*
> 为每次迭代时参数的实际更新方向，即
>
> *θ~t~* = *θ~t~*~−1~ + ∆*θ~t~*。在标准的小批量梯度下降中，∆*θ~t~* =
> −*α***g***~t~*。
>
> 图[7.3](\l)给出了在MNIST
> 数据集上，批量大小对损失下降的影响。一般批量大小较小时，需要设置较小的学习率较，否则模型会不收敛。从图[7.3a](\l)可以看出，每次迭代选取的批量样本数越多，下降效果越明显，并且下降曲线越平滑。
> 当每次选取一个样本时（相当于随机梯度下降），损失整体是下降趋势，但局部看会来回震荡。从图[7.3b](\l)可以看出，如果按整个数据集上的迭代次数（Epoch）
> 的来看损失变化情况，则是批量样本数越小，下降效果越明显。
>
> 次Iterations。
>
> 批量大小K

10^1^

> 10^1^
>
> 10^0^ 10^0^
>
> 10-1 10-1
>
> 10-2 10-2

10-3

0 1000 2000 3000 4000 5000

> iterations

(a) 按每次小批量更新的损失变化

10-3

0 1 2 3 4 5 6 7 8

> epochs

(b) 按整个数据集迭代的损失变化

> 图 7.3 批量大小对损失下降的影响
>
> 为了更有效地进行训练深层神经网络，在标准的小批量梯度下降方法的基
> 础上，也经常使用一些改进方法以加快优化速度。常见的改进方法主要从以下
> 两个方面进行改进：学习率衰减和梯度方向优化。这些改进的优化方法也同样
> 可以应用在批量或随机梯度下降方法上。

###### 学习率衰减

> 在梯度下降中，学习率*α*
> 的取值非常关键，如果过大就不会收敛，如果过小则收敛速度太慢。从经验上看，学习率在一开始要保持大些来保证收敛速度，
> 在收敛到最优点附近时要小些以避免来回震荡。因此，比较简单直接的学习率调整可以通过学习率衰减（Learning
> Rate Decay）的方式来实现。
>
> 假设初始化学习率为*α*~0~，在第*t*
> 次迭代时的学习率*α~t~*。常用的衰减方式为可以设置为按迭代次数进行衰减。比如逆时衰减（inverse
> time decay）
>
> *α~t~* = *α*~0~ 1 + *β* × *t ,* (7.5)
>
> 或指数衰减（exponential decay）
>
> *α~t~* = *α*~0~*β^t^,* (7.6)
>
> 或自然指数衰减（natural exponential decay）
>
> *α~t~* = *α*~0~ exp(−*β* × *t*)*,* (7.7)
>
> 其中*β* 为衰减率，一般取值为0*.*96。
>
> 除了这些固定衰减率的调整学习率方法外，还有些自适应地调整学习率的
> 方法，比如AdaGrad、RMSprop、AdaDelta
> 等。这些方法都对每个参数设置不同的学习率。

1.  **AdaGrad** 算法

> 在标准的梯度下降方法中，每个参数在每次迭代时都使用相同的学习率。
> 由于每个参数的维度上收敛速度都不相同，因此根据不同参数的收敛情况分别设置学习率。
>
> *AdaGrad*（Adaptive Gradient）算法\[[Duchi et al.](\l), [2011](\l)\]
> 是借鉴L2 正则化的思想，每次迭代时自适应地调整每个参数的学习率。在第*t*
> 迭代时，先计算每个参数梯度平方的累计值

*t*

> *G~t~* = **g***~τ~* **g***~τ~ ,* (7.8)
>
> *τ* =1
>
> 其中⊙ 为按元素乘积，**g***~τ~* ∈ R\|*θ*\| 是第*τ* 次迭代时的梯度。
>
> AdaGrad 算法的参数更新差值为
>
> *α*
>
> ∆*θ~t~* = −√*G* + *ϵ* ⊙ **g***~t~,* (7.9)
>
> 其中*α* 是初始的学习率，*ϵ*
> 是为了保持数值稳定性而设置的非常小的常数，一般取值*e*^−7^
> 到*e*^−10^。此外，这里的开平方、除、加运算都是按元素进行的操作。
>
> 在Adagrad
> 算法中，如果某个参数的偏导数累积比较大，其学习率相对较小；相反，如果其偏导数累积较小，其学习率相对较大。但整体是随着迭代次
> 数的增加，学习率逐渐缩小。
>
> Adagrad
> 算法的缺点是在经过一定次数的迭代依然没有找到最优点时，由于这时的学习率已经非常小，很难再继续找到最优点。

2.  **RMSprop** 算法

> *RMSprop*算法是 Geoﬀ Hinton
> 提出的一种自适应学习率的方法\[[Tieleman](\l) [and Hinton](\l),
> [2012](\l)\]，可以在有些情况下避免AdaGrad
> 算法中学习率不断单调下降以至于过早衰减的缺点。
>
> RMSprop 算法首先计算每次迭代梯度**g***~t~* 平方的指数衰减移动平均，
>
> *G~t~* = *βG~t~*~−1~ + (1 − *β*)**g***~t~* ⊙ **g***~t~* (7.10)
>
> *t*
>
> = (1 *β*) *β^t^*^−*τ*^ **g***~τ~* **g***~τ~ ,* (7.11)
>
> *τ* =1
>
> 其中*β* 为衰减率，一般取值为0*.*9。

RMSprop 算法的参数更新差值为

*α*

*t*

*G*

其中*α* 是初始的学习率，比如0*.*001。

\+ *ϵ* ⊙ **g***~t~,* (7.12)

> 从上式可以看出，RMSProp 算法和Adagrad 算法的区别在于*G~t~*
> 的计算由累积方式变成了指数衰减移动平均。在迭代过程中，每个参数的学习率并不是
> 呈衰减趋势，既可以变小也可以变大。

3.  **AdaDelta** 算法

> *AdaDelta*算法\[[Zeiler](\l), [2012](\l)\] 也是 Adagrad
> 算法的一个改进。和RMSprop 算 法类似，AdaDelta
> 算法通过梯度平方的指数衰减移动平均来调整学习率。此外， AdaDelta
> 算法还引入了每次参数更新差∆*θ* 的平方的指数衰减权移动平均。
>
> 第*t* 次迭代时，每次参数更新差∆*θ~τ~ ,* 1 ≤ *τ* ≤ *t*−1
> 的指数衰减权移动平均为
>
> 2
>
> *t*−1
>
> = *β*~1~∆*X*^2^
>
> \+ (1 − *β*~1~)∆*θ~t~*~−1~ ⊙ ∆*θ~t~*~−1~*.* (7.13)
>
> 其中*β*~1~ 为衰减率。此时∆*θ~t~* 还未知，因此只能计算到∆*X~t~*~−1~。
>
> AdaDelta 算法的参数更新差值为

q∆*X*^2^ + *ϵ*

∆*θ* = −

> √ [ *t*−1]{.underline} **g**
>
> (7.14)

*^t^ G* + *ϵ t*

> 其中*G~t~* 的计算方式和RMSprop 算法一样（公式([7.10](\l))），∆*X*^2^
>
> 为参数更新差
>
> ∆*θ* 的指数衰减权移动平均。
>
> 从上式可以看出，AdaDelta 算法将RMSprop 算法中的初始学习率 *α* 改为
>
> 动态计算的q∆*X*^2^ ，在一定程度上平抑了学习率的波动。

###### 梯度方向优化

> 除了调整学习率之外，还可以通过使用最近一段时间内的平均梯度来代替当前时刻的梯度来作为参数更新的方向。从图[7.3](\l)看出，在小批量梯度下降中，
> 如果每次选取样本数量比较小，损失会呈现震荡的方式下降。有效地缓解梯度下降中的震荡的方式是通过用梯度的移动平均来代替每次的实际梯度，并提高优化速度，这就是动量法。

4.  动量法

> 动量是模拟物理中的概念。一般而言，一个物体的动量指的是这个物体在它
> 运动方向上保持运动的趋势，是物体的质量和速度的乘积。动量法（Momentum
> Method）\[[Rumelhart et al.](\l), [1988](\l)\]
> 是用之前积累动量来替代真正的梯度。每次迭代的梯度可以看作是加速度。
>
> 在第*t* 次迭代时，计算负梯度的"加权移动平均"作为参数的更新方向，
>
> ∆*θ~t~* = *ρ*∆*θ~t~*~−1~ − *α***g***~t~,* (7.15)
>
> 其中*ρ* 为动量因子，通常设为0*.*9，*α* 为学习率。
>
> 这样，每个参数的实际更新差值取决于最近一段时间内梯度的加权平均值。
> 当某个参数在最近一段时间内的梯度方向不一致时，其真实的参数更新幅度变小；相反，当在最近一段时间内的梯度方向都一致时，其真实的参数更新幅度变大，起到加速作用。一般而言，在迭代初期，梯度方法都比较一致，动量法会起到加速作用，可以更快地到达最优点。在迭代后期，梯度方法会取决不一致，在收敛值附近震荡，动量法会起到减速作用，增加稳定性。从某种角度来说，当前梯度叠加上部分的上次梯度，一定程度上可以近似看作二阶梯度。
>
> 参见习题[7-1](\l)。
>
> gt 的定义参见公式([7.1](\l))。

5.  **\
    > Nesterov** 加速梯度

> *Nesterov* 加速梯度（Nesterov Accelerated Gradient，NAG），也叫 *Nes-
> terov* 动量法（Nesterov Momentum）是一种对动量法的改进
> \[[Nesterov](\l), [2013](\l),
>
> [Sutskever et al.](\l), [2013](\l)\]。
>
> 在动量法中，实际的参数更新方向∆*θ~t~*
> 为上一步的参数更新方向∆*θ~t~*~−1~ 和当前梯度−**g***~t~*
> 的叠加。这样，∆*θ~t~* 可以被拆分为两步进行，先根据∆*θ~t~*~−1~
> 更新一次得到参数*θ*ˆ，再用**g***~t~* 进行更新。
>
> *θ*ˆ = *θ~t~*~−1~ + *ρ*∆*θ~t~*~−1~*,* (7.16)
>
> *θ~t~* = *θ*ˆ − *α***g***~t~,* (7.17)
>
> 其中梯度**g***~t~* 为点*θ~t~*~−1~
> 上的梯度，因此在第二步更新中有些不太合理。更合理的更新方向应该为*θ*ˆ上的梯度。
>
> 这样，合并后的更新方向为
>
> ∆*θ~t~* = *ρ*∆*θ~t~*~−1~ − *α*g*~t~*(*θ~t~*~−1~ + *ρ*∆*θ~t~*~−1~)*,*
> (7.18)
>
> 其中g*~t~*(*θ~t~*~−1~ + *ρ*∆*θ~t~*~−1~) 表示损失函数在点*θ*ˆ =
> *θ~t~*~−1~ + *ρ*∆*θ~t~*~−1~
> 上的偏导数。图[7.4](\l)给出了动量法和Nesterov
> 加速梯度在参数更新时的比较。

*θt*−1

> *ρ*∆*θ~t~*~−1~
>
> ◦
>
> ∆*θ~t~ t*
>
> *θt*−2
>
> •
>
> ∆*θt*−1
>
> • •
>
> −*α***g***~t~*(*θ~t~*~−1~) ◦

a.  动量法

> *θt*−1
>
> •

•

> *ρ*∆*θ~t~*~−1~
>
> *θ*ˆ
>
> ◦
>
> ∆*θ~t~*
>
> *α***g***~t~*(*θ*ˆ)
>
> *θ~t~*

◦

b.  Nesterov 加速梯度

> 图 7.4 动量法和Nesterov 加速梯度的比较

6.  **AdaM** 算法

> 自适应动量估计（Adaptive Moment Estimation，Adam）算法\[[Kingma
> and](\l) [Ba](\l), [2015](\l)\] 可以看作是动量法和RMSprop
> 的结合，不但使用动量作为参数更新方向，而且可以自适应调整学习率。
>
> Adam 算法一方面计算梯度平方 **g**2 的指数加权平均（和RMSprop 类似），
> 另一方面计算梯度**g***~t~* 的指数加权平均（和动量法类似）。

*M~t~* = *β*~1~*M~t~*~−1~ + (1 − *β*~1~)**g***~t~,* (7.19)

*G~t~* = *β*~2~*G~t~*~−1~ + (1 − *β*~2~)**g***~t~* ⊙ **g***~t~,* (7.20)

> 其中*β*~1~ 和*β*~2~ 分别为两个移动平均的衰减率，通常取值为*β*~1~ =
> 0*.*9*, β*~2~ = 0*.*99。
>
> *M~t~* 可以看作是梯度的均值（一阶矩），*G~t~*
> 可以看作是梯度的未减去均值的方差（二阶矩）。
>
> 假设*M*~0~ = 0*, G*~0~ = 0，那么在迭代初期*M~t~* 和*G~t~*
> 的值会比真实的均值和方差要小。特别是当*β*~1~ 和*β*~2~ 都接近于1
> 时，偏差会很大。因此，需要对偏差进行修正。
>
> 参见习题[7-2](\l)。
>
> *M*ˆ*t*
>
> *G*ˆ*t*
>
> Adam 算法的参数更新差值为
>
> = [* Mt *]{.underline}*,* (7.21)
>
> 1 − *β*1*t*
>
> = [* Gt *]{.underline}*.* (7.22)
>
> 1 − *β*2*t*
>
> ∆ = − [* α *]{.underline} *M*ˆ *,* (7.23)

*θt G*ˆ + *ϵ t*

> *α*~0~
>
> 其中学习率*α* 通常设为0*.*001，并且也可以进行衰减，比如*α~t~* = √*t*
> 。
>
> Adam 算法是RMSProp 与动量法的结合，因此一种自然的Adam
> 的改进方法是引入Nesterov 加速梯度，称为*Nadam* 算法 \[[Dozat](\l),
> [2016](\l)\]。

7.  梯度截断

> 在深层神经网络或循环神经网络中，除了梯度消失之外，梯度爆炸是影响学习效率的主要因素。在基于梯度下降的优化过程中，如果梯度突然增大，用大的梯度进行更新参数，反而会导致其远离最优点。为了避免这种情况，当梯度的模大于一定阈值时，就对梯度进行截断，称为梯度截断（gradient
> clipping） \[[Pascanu et al.](\l), [2013](\l)\]。
>
> 梯度截断是一种比较简单的启发式方法，把梯度的模限定在一个区间，当
> 梯度的模小于或大于这个区间时就进行截断。一般截断的方式有以下几种：
>
> 按值截断 在第*t* 次迭代时，梯度为**g***~t~*，给定一个区间\[*a,
> b*\]，如果一个参数的梯度小于*a* 时，就将其设为*a*；如果大于*b*
> 时，就将其设为*b*。
>
> **g***~t~* = max(min(**g***~t~, b*)*, a*)*.* (7.24)
>
> 按模截断
> 按模截断是将梯度的模截断到一个给定的截断阈值*b*。如果∥**g***~t~*∥2 ≤
> *b*，保持**g***~t~* 不变。如果∥**g***~t~*∥2 *\> b*，令
>
> **g** = *b*
>
> *t* ∥**g***~t~*∥

**g***~t~.* (7.25)

> 截断阈值*b*
> 是一个超参数，也可以根据一段时间内的平均梯度来自动调整。实验中发现，训练过程对阈值*b*
> 并不十分敏感，通常一个小的阈值就可以得到很好的结果\[[Pascanu et
> al.](\l), [2013](\l)\]。
>
> 在训练循环神经网络时，按模截断是避免梯度爆炸问题的有效方法。图[7.5](\l)给
> 出了一个循环神经网络的损失函数关于参数的曲面。图中的曲面为只有一个隐
> 藏神经元的循环神经网络*h~t~* = *σ*(*wh~t~*~1~ + *b*)
> 的损失函数，其中*w* 和*b* 为参数。假如*h*~0~
> 初始值为0*.*3，损失函数为L = (*h*~100~ − 0*.*65)2。

图片识别内容


0.25

4.0

4.2

4.4

4.6

W 4.8

5.0

5.2

5.4

5.6

> 1.751.501.251.00
>
> 3.002.752.50
>
> b
>
> 0.20
>
> 0.15

0.10

0.05

> 图 7.5 梯度爆炸问题示例
>
> **7.2.4** 优化算法小结
>
> 本节介绍的几种优化方法大体上可以分为两类：一是调整学习率，使得优
> 化更稳定；二是调整梯度方向，优化训练速度。
>
> 表[7.1](\l)汇总了本节介绍的几种神经网络常用优化方法。

[ Adam≈动量法+RMSprop ]{.underline}

> 表 7.1 神经网络常用优化方法的汇总
>
> 图[7.6](\l)给出了这几种优化方法在MNIST 数据集上收敛性的比较。
>
> ![](/root/autodl-tmp/project_knowledge/Doc_QA/Knowledge_based/1828695663060254721/image_output/7.《神经网络与深度学习》/media/image119.png)10^0^
>
> 10-1
>
> 10-2

10-3

0 1000 2000 3000 4000 5000

> iterations
>
> 图 7.6 不同优化方法的比较

#### 参数初始化

> 神经网络的训练过程中的参数学习是基于梯度下降法进行优化的。梯度下
> 降法需要在开始训练时给每一个参数赋一个初始值。这个初始值的选取十分关
> 键。在感知器和logistic
> 回归的训练中，我们一般将参数全部初始化为0。但是这在神经网络的训练中会存在一些问题。因为如果参数都为0，在第一遍前向
> 计算时，所有的隐层神经元的激活值都相同。这样会导致深层神经元没有区分
> 性。这种现象也称为对称权重现象。
>
> 为了打破这个平衡，比较好的方式是对每个参数都随机初始化，这样使得
> 不同神经元之间的区分性更好。
>
> 但是一个问题是如何选取随机初始化的区间呢？如果参数太小，会导致神
> 经元的输入过小。经过多层之后信号就慢慢消失了。参数过小还会使得sigmoid
>
> 型激活函数丢失非线性的能力。以logistic 函数为例，在0
> 附近基本上是近似线性的。这样多层神经网络的优势也就不存在了。如果参数取得太大，会导致输
> 入状态过大。对于sigmoid
> 型激活函数来说，激活值变得饱和，从而导致梯度接近于0。
>
> 因此，如果要高质量地训练一个网络，给参数选取一个合适的初始化区间
> 是非常重要的。一般而言，参数初始化的区间应该根据神经元的性质进行差异
> 化的设置。如果一个神经元的输入连接很多，它的每个输入连接上的权重就应
> 该小一些，以避免神经元的输出过大（当激活函数为ReLU
> 时）或过饱和（当激活函数为sigmoid 函数时）。
>
> 经常使用的初始化方法有以下几种：

1.  **Gaussian** 分布初始化

> Gaussian
> 初始化方法是最简单的初始化方法，参数从一个固定均值（比如0）和固定方差（比如0.01）的Gaussian
> 分布进行随机初始化。
>
> 初始化一个深度网络时，一个比较好的初始化方案是保持每个神经元输入
> 的方差为一个常量。当一个神经元的输入连接数量为*n~in~*
> 时，可以设置其输入
>
> 连接权重以 (0*, [ ]{.underline}*[1]{.underline} ) 的Gaussian
> 分布进行初始化。如果同时考虑输出连接
>
> *nin* [ ]{.underline}

的数量*n*

*out*

，则可以按N (0*,* r [ 2]{.underline} ) 的Gaussian 分布进行初始化。

> Xavier 初 始 化 方 法 中， Xavier 是 发 明 者 Xavier Glorot 的名字。

2.  均匀分布初始化

> 均匀分布初始化是在一个给定的区间\[−*r, r*\]
> 内采用均匀分布来初始化参数。超参数*r*
> 的设置也可以按神经元的连接数量进行自适应的调整。
>
> ***Xavier*** 初始化方法 [Glorot and Bengio](\l) \[[2010](\l)\]
> 提出一个自动计算超参数*r* 的方法，参数可以在\[−*r, r*\]
> 内采用均匀分布进行初始化。
>
> 如果神经元激活函数为logistic 函数，对于第*l* − 1 到*l*
> 层的权重参数区间*r*
>
> 可以设置为
>
> *r* = r [ 6]{.underline} *,* (7.26)
>
> 这里*n^l^* 是第*l* 层神经元个数，*n^l^*^−1^ 是第*l* − 1
> 层神经元个数。对于tanh 函数，*r* 可以设置为
>
> *r* = 4r [ 6]{.underline} *.* (7.27)
>
> 假设第*l* 层的一个隐藏层神经元*𝑥^l^*，其接受前一层的*n^l^*^−1^
> 个神经元的输出
>
> *ai* ，*i* ∈ \[1*, n*

(*l*−1)\]，

> *𝑥^l^* =
>
> *n*(*l*−1)
>
> *l* (*l*−1)*.* (7.28)
>
> 为了避免初始化参数使得激活值变得饱和，我们需要尽量使得*𝑥^l^*
> 处于激活函数的线性区间，也就是其绝对值比较小的值。这时该神经元的激活值为*a^l^*
> = *f* (*𝑥^l^*) ≈ *𝑥^l^*。
>
> 假设*w^l^* 和*a*^(*l*−1)^ 都是相互独立，并且均值都为0，则*a^l^*
> 的均值为
>
> *i i*

*n*(*l*−1)

> *n*(*l*−1)

E\[*a^l^*\] = E\[ Σ

> *~l~* (*l*−1)\] =
>
> Σ E\[**w***~i~*\]E\[ ^(*l*−1)^\] = 0*.* (7.29)
>
> *a^l^* 的方差为
>
> *wiai*
>
> *i*=1

*n*(*l*−1)

> *ai*
>
> *i*=1

var\[*a^l^*\] = var\[ Σ

> *l* (*l*−1)\] (7.30)
>
> *wiai*
>
> *i*=1 *n*(*l*−1)

= var\[*w^l^*\] var\[

*i*=1

*ai* \] (7.31)

> = *n*^(*l*−1)^ var\[*w^l^*\] var\[*ai* \]*.* (7.32)
>
> 也就是说，输入信号的方差在经过该神经元后被放大或缩小了*n*^(*l*−1)^
> var\[*w^l^*\]
> 倍。为了使得在经过多层网络后，信号不被过分放大或过分减弱，我们尽可能保持每个神经元的输入和输出的方差一致。这样*n*^(*l*−1)^
> var\[*w^l^*\] 设为1 比较合理，即
>
> var\[*w^l^*\] = [ 1]{.underline} *.* (7.33)

*i n*(*l*−1)

> 同理，为了使得在反向传播中，误差信号也不被放大或缩小，需要将*w^l^* 的
>
> 方差保持为
>
> var\[*w^l^*\] = [ 1]{.underline} *.* (7.34)

*i n*(*l*)

> 作为折中，同时考虑信号在前向和反向传播中都不被放大或缩小，可以设置
>
> var\[*w^l^*\] = [ 2]{.underline} *.* (7.35)

*i n*(*l*−1) + *n*(*l*)

> 假设随机变量*x* 在区间\[*a, b*\] 内均匀分布，则其方差为：

var\[

*x*\] =

> 2
>
> 12 *.* (7.36)
>
> 因此，若让*w^l^* ∈ \[−*r, r*\]，并且var\[*w^l^*\] = 1，则*r* 的取值为
>
> *i i*
>
> *r* = r [ 6]{.underline} *.* (7.37)

#### 数据预处理

> 一般而言，原始的训练数据中，每一维特征的来源以及度量单位不同，会
> 造成这些特征值的分布范围往往差异很大。当我们计算不同样本之间的欧氏距
> 离时，取值范围大的特征会起到主导作用。这样，对于基于相似度比较的机器
> 学习方法（比如最近邻分类器），必须先对样本进行预处理，将各个维度的特征
> 归一化到同一个取值区间，并且消除不同特征之间的相关性，才能获得比较理
> 想的结果。虽然神经网络可以通过参数的调整来适应不同特征的取值范围，但
> 是会导致训练效率比较低。
>
> 假设一个只有一层的网络 *y* = tanh(*w*~1~*x*~1~ + *w*~2~*x*~2~ +
> *b*)，其中 *x*~1~ ∈ \[0*,* 10\]， *x*~2~ ∈ \[0*,*
> 1\]。之前我们提到tanh 函数的导数在区间\[−2*,* 2\]
> 上是敏感的，其余的导数接近于0。因此，如果*w*~1~*x*~1~ + *w*~2~*x*~2~ +
> *b*
> 过大或过小，都会导致梯度过小，难以训练。为了提高训练效率，我们需要使*w*~1~*x*~1~
> + *w*~2~*x*~2~ + *b* 在\[−2*,* 2\] 区间，我们需要将*w*~1~
> 设得小一点，比如在\[−0*.*1*,* 0*.*1\]
> 之间。可以想象，如果数据维数很多时，我们很难这样精心去选择每一个参数。因此，如果每一个特征的取值范围都在相似的区间，比如\[0*,*
> 1\] 或者\[−1*,* 1\]，我们就不太需要区别对待每一个参数， 减少人工干预。
>
> 除了参数初始化之外，不同特征取值范围差异比较大时还会梯度下降法的搜索效率。图[7.7](\l)给出了数据归一化对梯度的影响。其中，图[7.7a](\l)为未归一化数据的等高线图。取值范围不同会造成在大多数位置上的梯度方向并不是最优的搜索方向。当使用梯度下降法寻求最优解时，会导致需要很多次迭代才能收敛。
> 如果我们把数据归一化为取值范围相同，如图[7.7b](\l)所示，大部分位置的梯度方向近似于最优搜索方向。这样，在梯度下降求解时，每一步梯度的方向都基本指向最小值，训练效率会大大提高。
>
> *w*~2~ *w*~2~

图片识别内容


(a) 未归一化数据的梯度

> *w*~1~

(b) 归一化数据的梯度

> 图 7.7 数据归一化对梯度的影响
>
> 归一化的方法有很多种，比如之前我们介绍的sigmoid 型函数等都可以将
>
> 7.4 数据预处理 2019 年 4 月 6 日 179
>
> 不同取值范围的特征挤压到一个比较受限的区间。这里，我们介绍几种在神经
> 网络中经常使用的归一化方法。
>
> 缩放归一化
> 缩放归一化是一种非常简单的归一化方法，通过缩放将每一个特征的取值范围归一到\[0*,*
> 1\] 或\[−1*,* 1\] 之间。对于每一维特征*x*，

*x*ˆ(*i*)

> (*i*) (*i*)
>
> max (*x*(*i*)) − min (*x*(*i*)) *,* (7.38)
>
> 其中min(*x*) 和max(*x*) 分别是特征*x* 在所有样本上的最小值和最大值。
>
> 标准归一化 标准归一化也叫z-score
> 归一化，来源于统计上的标准分数。将每一个维特征都处理为符合标准正态分布（均值为0，标准差为1）。假设有*N*
> 个样本{**x**(*i*)}*, i* = 1*,* · · · *, N*
> ，对于每一维特征*x*，我们先计算它的均值和标准差：

*N*

*µ* = *x*^(*i*)^*,*

*N*

> (7.39)
>
> *i*=1

*N*

> *σ*^2^ = (*x*^(*i*)^ *µ*)2*.* (7.40)
>
> *i*=1
>
> 然后，将特征*x*^(*i*)^
> 减去均值，并除以标准差，得到新的特征值*x*ˆ(*i*)。

*x*ˆ(*i*) =

> *x*(*i*) − *µ σ*

*,* (7.41)

> 这里*σ*
> 不能为0。如果标准差为0，说明这一维特征没有任务区分性，可以直接删掉。
>
> 在标准归一化之后，每一维特征都服从标准正态分布。
>
> 白化
> 白化（Whitening）是一种重要的预处理方法，用来降低输入数据特征之间的冗余性。输入数据经过白化处理后，特征之间相关性较低，并且所有特征
> 具有相同的方差。
>
> 白化的一个主要实现方式是使用主成分分析（Principal Component Anal-
> ysis，PCA）方法去除掉各个成分之间的相关性。
>
> 图[7.8](\l)给出了标准归一化和PCA 白化的比较。
>
> 参见第[9.1.1](\l)节。

图片识别内容

图片识别内容

图片识别内容


> 图 7.8 标准归一化和PCA 白化

#### 逐层归一化

> 在深层神经网络中，中间某一层的输入是其之前的神经层的输出。因此，其
> 之前的神经层的参数变化会导致其输入的分布发生较大的差异。在使用随机梯
> 度下降来训练网络时，每次参数更新都会导致网络中间每一层的输入的分布发
> 生改变。越深的层，其输入的分布会改变得越明显。就像一栋高楼，低楼层发
> 生一个较小的偏移，都会导致高楼层较大的偏移。
>
> 从机器学习角度来看，如果某个神经层的输入分布发生了改变，那么其参
> 数需要重新学习，这种现象叫做内部协变量偏移（Internal Covariate
> Shift）。
>
> 这里的逐层归一化方法是指可以应用在深层神经网络中的任何一个中间层。实际上并不需要对所有层进行归一化。
>
> 为了解决内部协变量偏移问题，就要使得每一个神经层的输入的分布在训
> 练过程中要保持一致。最简单直接的方法就是对每一个神经层都进行归一化操
> 作，使其分布保存稳定。下面介绍几种比较常用的逐层归一化方法：批量归一
> 化、层归一化和其它一些方法。

###### 批量归一化

> 批量归一化（Batch Normalization，BN）方法\[[Ioﬀe and Szegedy](\l),
> [2015](\l)\]
> 是一种有效的逐层归一化方法，可以对神经网络中任意的中间层进行归一化操作。
>
> 对于一个深层神经网络，令第*l*
> 层的净输入为**z**(*l*)，神经元的输出为**a**(*l*)，即
>
> **a**(*l*) = *f* (**z**(*l*)) = *f* (*W* **a**(*l*−1) + **b**)*,*
> (7.42)
>
> 其中*f* (·) 是激活函数，*W* 和**b** 是可学习的参数。
>
> 为了减少内部协变量偏移问题，就要使得净输入**z**(*l*)
> 的分布一致，比如都归一化到标准正态分布。我们可以利用第[7.4](\l)节中介绍的数据预处理方法进行对
> **z**(*l*)
> 进行归一化，相当于每一层都进行一次数据预处理，从而加速收敛速度。但是逐层归一化需要在中间层进行操作，要求效率比较高，因此复杂度比较高的
> 白化方法就不太合适。为了提高归一化效率，一般使用标准归一化，将净输入
> **z**(*l*) 的每一维都归一到标准正态分布。
>
> 虽然归一化操作可以应用在输入 **a**(l−1) 上，但其分布性质不如**z**(l)
> 稳定。因此，在实践中归一化操作一般应用仿射变换之后，在激活函数之前。

**z**ˆ(*l*) = **z**(*l*) − E\[**z**(*l*)\]

var(**z** *l* ) + *ϵ*

> (7.43)
>
> 其中E\[**z**(*l*)\] 和var(**z**(*l*)) 是指当前参数下，**z**(*l*)
> 的每一维在整个训练集上的期望和方差。因为目前主要的训练方法是基于小批量的随机梯度下降方法，所以准确
> 地计算**z**(*l*) 的期望和方差是不可行的。因此，**z**(*l*)
> 的期望和方差通常用当前小批量样本集的均值和方差近似估计。
>
> 给定一个包含 *K* 个样本的小批量样本集合，第 *l* 层神经元的净输入
> **z**(1*,l*)*,*
>
> · · · *,* **z**(*K,l*) 的均值和方差为
>
> *µ* [1]{.underline} Σ **z**(*k,l*)*,* (7.44)
>
> *k*=1

*σ*2 = [ 1]{.underline}

> Σ(**z**(

*k,l*

> − *µ*~B~) ⊙ (**z** − *µ*~B~)*.* (7.45)
>
> B *K k*=1
>
> 对净输入**z**(*l*) 的标准归一化会使得其取值集中的0
> 附近，如果使用sigmoid
> 型激活函数时，这个取值区间刚好是接近线性变换的区间，减弱了神经网络的
> 非线性性质。因此，为了使得归一化不对网络的表示能力造成负面影响，我们
> 可以通过一个附加的缩放和平移变换改变取值区间。
>
> **z**ˆ(*l*) = **z**(*l*) − *µ*B +

\+

> B
>
> (7.46)
>
> , BN*~γ,β~*(**z**(*l*))*,* (7.47)
>
> 其中*γ* 和*β*
> 分别代表缩放和平移的参数向量。从最保守的角度考虑，可以通过来标准归一化的逆变换来使得归一化后的变量可以被还原为原来的值。当*γ*
> =
>
> 2 ， = 时，**z**ˆ(*l*) = **z**(*l*)。
>
> B
>
> 批量归一化操作可以看作是一个特殊的神经层，加在每一层非线性激活函
> 数之前，即
>
> **a**(*l*) = *f* (BN*~γ,β~*(**z**(*l*))) = *f* BN*~γ,β~*(*W*
> **a**(*l*−1)) *,* (7.48)
>
> 其中因为批量归一化本身具有平移变换，因此仿射变换*W* **a**(*l*−1)
> 不再需要偏置参数。
>
> 这里要注意的是，每次小批量样本的*µ*~B~ 和方差*σ*^2^ 是净输入**z**(*l*)
> 的函数，而

2 B

> 不是常量。因此在计算参数梯度时需要考虑*µ*~B~ 和*σ*B
> 的影响。当训练完成时，用
>
> 整个数据集上的均值*µ* 和方差*σ* 来分别代替每次小批量样本的*µ*~B~
> 和方差*σ*^2^ 。在

实践中，*µ*~B~

> 和*σ*^2^ 也可以用移动平均来计算。 B B

###### 层归一化

> 参见习题[7-3](\l)。
>
> 批量归一化是对一个中间层的单个神经元进行归一化操作，因此要求小批
> 量样本的数量不能太小，否则难以计算单个神经元的统计信息。此外，如果一
> 个神经元的净输入的分布在神经网络中是动态变化的，比如循环神经网络，那
> 么就无法应用批量归一化操作。
>
> 层归一化（Layer Normalization）\[[Ba et al.](\l), [2016](\l)\]
> 是和批量归一化非常类似的方法。和批量归一化不同的是，层归一化是对一个中间层的所有神经元进
> 行归一化。
>
> 对于一个深层神经网络中，令第*l*
> 层神经的净输入为**z**(*l*)，其均值和方差为
>
> *nl*

*µ*(*l*) =

> *i*=1 *nl*
>
> (*l*)
>
> *𝑥i ,*
>
> (7.49)
>
> 其中*n^l^* 为第*l* 层神经元的数量。层归一化定义为
>
> *n k*=1

**z**ˆ(*l*) = **z**(*l*) − *µ*(*l*) +

> (7.51)
>
> √*σ*(*l*)2 + *ϵ* ⊙
>
> , LN*~γ,β~*(**z**(*l*))*,* (7.52)
>
> 其中*γ* 和*β* 分别代表缩放和平移的参数向量，和**z**(*l*) 维数相同。
>
> 参见公式([6.6](\l))。
>
> 循环神经网络中的层归一化
> 层归一化可以应用在循环神经网络中，对循环神经层进行归一化操作。假设在时刻*t*，循环神经网络的隐藏层为**h***~t~*，其层归一化的更新为
>
> **z***~t~* = *U* **h**~*t*−1~ + *W* **x***~t~,* (7.53)
>
> **h***~t~* = *f* (LN*~γ,β~*(**z***~t~*))*,* (7.54)
>
> 其中输入为**x***~t~* 为第*t* 时刻的输入，*U, W* 为网络参数。
>
> 在标准循环神经网络中，循环神经层的净输入一般会随着时间慢慢变大或
> 变小，从而导致梯度爆炸或消失。而层归一化的循环神经网络可以有效地缓解
> 这种状况。
>
> 层归一化和批量归一化整体上是十分类似的，差别在于归一化的方法不同。
> 对于*K* 个样本的一个小批量集合*Z*^(*l*)^ = \[**z**(1*,l*); · · · ;
> **z**(*K,l*)\]，层归一化是对矩阵
> *Z*^(*l*)\ 对每一列进行归一化，而批量归一化是对每一行进行归一化。一般而言，批^^量归一化是一种更好的选择。当小批量样本数量比较小时，可以选择层归一化。^

###### 其它归一化方法

> 除了上述两种归一化方法外，也有一些其它的归一化方法。

1.  权重归一化

> 权重归一化（Weight Normalization）\[[Salimans and Kingma](\l),
> [2016](\l)\]
> 是对神经网络的连接权重进行归一化，通过再参数化（Reparameterization）方法，将连接权重分解为长度和方向两种参数。假设第*l*
> 层神经元**a**(*l*) = *f* (*W* **a**(*l*−1) +**b**)， 我们将*W*
> 再参数化为

*Wi,*:

> = [* gi *]{.underline} **v** *,* 1 ≤ *i* ≤ *n^l^* (7.55)
>
> 其中*W~i,~*~:~ 表示权重*W* 的第*i* 行，*n^l^*
> 为神经元数量。新引入的参数*g~i~* 为标量，**v***~i~*
>
> 和**a**(*l*−1) 维数相同。
>
> 由于在神经网络中权重经常是共享的，权重数量往往比神经元数量要少，因
> 此权重归一化的开销会比较小。

2.  局部响应归一化

> 局部响应归一化（Local Response Normalization，LRN）\[[Krizhevsky et
> al.](\l), [2012](\l)\]
> 是一种受生物学启发的归一化方法，通常用在基于卷积的图像处理上。
>
> 假设一个卷积层的输出特征映射 **Y** ∈ R*M* ′×*N* ′×*P*
> 为三维张量，其中每个切片矩阵*Y ^p^* ∈ R*M* ′×*N* ′
> 为一个输出特征映射，1 ≤ *p* ≤ *P* 。
>
> 局部响应归一化是对邻近的特征映射进行局部归一化。
>
> 参见公式([5.21](\l))。

ˆ *p p* 

> min(*P,p*+ *[n]{.underline}* ) *β j* 2

*Y* = *Y /* *k* + *α*

(*Y* )

*j*=max(1*,p*− *n* )

> (7.56)
>
> , LRN*~n,k,α,β~*(*Y ^p^*)*,* (7.57)
>
> 其中除和幂运算都是按元素运算，*n, k, α, β* 为超参，*n*
> 为局部归一化的特征窗口大小。在AlexNet 中，这些超参的取值为*n* = 5*, k*
> = 2*, α* = 10e−4*, β* = 0*.*75。
>
> 邻近的神经元指对应同样位
>
> 局部响应归一化和层归一化都是对同层的神经元进行归一化。不同的是局
> 部响应归一化应用在激活函数之后，只是对邻近的神经元进行局部归一化，并
> 且不减去均值。
>
> 置的邻近特征映射 局部响应归一化和生物神经元中的侧抑制（lateral
> inhibition）现象比较类似，即活跃神经元对相邻神经元具有抑制作用。当使用ReLU
> 作为激活函数时，
> 神经元的活性值是没有限制的，局部响应归一化可以起到平衡和约束左右。如果一个神经元的活性值非常大，那么和它邻近的神经元就近似地归一化为0，从而起到抑制作用，增强模型的泛化能力。最大汇聚也具有侧抑制作用。但最大汇聚是对同一个特征映射中的邻近位置中的神经元进行抑制，而局部响应归一化是对同一个位置的邻近特征映射中的神经元进行抑制。
>
> 上述的归一化方法可以根据需要应用在神经网络的中间层，从而减少前面
> 网络参数更新对后面网络输入带来的内部协变量偏移问题，提高深层神经网络
> 的训练效率。同时，归一化方法也可以作为一种有效的正则化方法，从而提高
> 网络的泛化能力，避免过拟合。

#### 超参数优化

> 在神经网络中，除了可学习的参数之外，还存在很多超参数。这些超参数对
> 网络性能的影响也很大。不同的机器学习任务需要往往需要不同的超参数。常
> 见的超参数有
>
> 虽然在神经网络的超参数优化中，*f* (**x**) 的函数形式虽然已知，但*f*
> (**x**) 不是关于**x** 的

-   网络结构，包括神经元之间的连接关系、层数、每层的神经元数量、激活
    > 函数的类型等；

-   优化参数，包括优化方法、学习率、小批量的样本数量等；

-   正则化系数。

> 超参数优化（Hyperparameter Optimization）主要存在两方面的困难。（1）
> 超参数优化是一个组合优化问题，无法像一般参数那样通过梯度下降方法来优化，也没有一种通用有效的优化方法。（2）评估一组超参数配置（Conﬁguration）
> 的时间代价非常高，从而导致一些优化方法（比如演化算法（Evolution Algo-
> rithm））在超参数优化中难以应用。
>
> 假设一个神经网络中总共有*K*
> 个超参数，每个超参数配置表示为一个向量**x** ∈ X，X ⊂ R*K*
> 是超参数配置的取值空间。超参数优化的目标函数定义为 *f* (**x**) : X →
> R，*f* (**x**) 是衡量一组超参数配置**x**
> 效果的函数，一般设置为开发集上的错误率。目标函数*f* (**x**)
> 可以看作是一个黑盒（block-box）函数，不需要知道其具体形式。
>
> 对于超参数的设置，比较简单的方法有人工搜索、网格搜索和随机搜索。
>
> 邱连续锡函鹏数：《，并神且经**x**网不络同与，*f*深(**x**度) 学习》
> https://nndl.github.io/
>
> 的函数形式也不同，因此无

###### 网格搜索

> 网格搜索（grid
> search）是一种通过尝试所有超参数的组合来寻址合适一组超参数配置的方法。假设总共有*K*
> 个超参数，第*k* 个超参数的可以取*m~k~*
> 个值。那么总共的配置组合数量为*m*~1~ × *m*~2~ ×· · · ×
> *m~K~*。如果超参数是连续的，可以将超参数离散化，选择几个"经验"值。比如学习率*α*，我们可以设置
>
> *α* ∈ {0*.*01*,* 0*.*1*,* 0*.*5*,* 1*.*0}*.*
>
> 一般而言，对于连续的超参数，我们不能按等间隔的方式进行离散化，需要根
> 据超参数自身的特点进行离散化。
>
> 网格搜索根据这些超参数的不同组合分别训练一个模型，然后测试这些模
> 型在开发集上的性能，选取一组性能最好的配置。

###### 随机搜索

> 如果不同超参数对模型性能的影响有很大差异。有些超参数（比如正则化
> 系数）对模型性能的影响有限，而有些超参数（比如学习率）对模型性能影响
> 比较大。在这种情况下，采用网格搜索会在不重要的超参数上进行不必要的尝
> 试。一种在实践中比较有效的改进方法是对超参数进行随机组合，然后选取一
> 个性能最好的配置，这就是随机搜索（Random Search）\[[Bergstra and
> Bengio](\l),
> [2012](\l)\]。随机搜索在实践中更容易实现，一般会比网格搜索更加有效。
>
> 网格搜索和随机搜索都没有利用不同超参数组合之间的相关性，即如果模
> 型的超参数组合比较类似，其模型性能也是比较接近的。因此这两种搜索方式
> 一般都比较低效。下面我们介绍两种自适应的超参数优化方法：贝叶斯优化和
> 动态资源分配。

###### 贝叶斯优化

> 贝叶斯优化（Bayesian optimization）\[[Bergstra et al.](\l),
> [2011](\l), [Snoek et al.](\l), [2012](\l)\]
> 是一种自适应的超参数搜索方法，根据当前已经试验的超参数组合，来预测下一个可能带来最大收益的组合。一种比较比较常用的贝叶斯优化方法为时
> 序模型优化（Sequential Model-Based Optimization，SMBO）\[[Hutter et
> al.](\l), [2011](\l)\]。假设超参数优化的函数*f* (**x**)
> 服从高斯过程，则*p*(*f* (**x**)\|**x**) 为一个正态分
>
> 布。贝叶斯优化过程是根据已有的*N* 组试验结果H = {**x***~n~, y~n~*}*N*
> （*y~n~* 为*f* (**x***~n~*)
>
> *n*=1
>
> 的观测值）来建模高斯过程，并计算*f* (**x**) 的后验分布*p*~GP~ (*f*
> (**x**)\|**x***,* H)。 高斯过程参见第[D.3.2](\l)节。
>
> 为了使得*p*~GP~ (*f* (**x**)\|**x***,* H)
> 接近其真实分布，就需要对样本空间进行足够多的采样。但是超参数优化中每一个样本的生成成本很高，需要用尽可能少的样
> 本来使得 *p~θ~*(*f* (**x**)\|**x***,* H)
> 接近于真实分布。因此，需要通过定义一个收益函数
>
> （acquisition function）*a*(*x,* H) 来判断一个样本是否能够给建模
> *p~θ~*(*f* (**x**)\|**x***,* H)
>
> 提供更多的收益。收益越大，其修正的高斯过程会越接近目标函数的真实分布。
>
> 收益函数的定义有很多种方式，一个常用的是期望改善（Expected Im-
> provement，EI）函数。假设 *y*^∗\ =\ min{*y*^*~n~,* 1 ≤ *n* ≤ *N* }
> 是当前已有样本中的最优值，期望改善函数为，
>
> **EI**(**x***,* H) = ∞ max(*y*^∗^ − *y,* 0)*p*

−∞

(*y*\|**x***,* H)*dy.* (7.58)

> 期望改善是定义一个样本**x** 在当前模型*p*~GP~ (*f* (**x**)\|**x***,*
> H) 下，*f* (**x**)
> 超过最好结果*y*^∗\ 的期望。除了期望改善函数之外，收益函数还有其它定义形式，比如改善概^率（Probability
> of Improvement）、高斯过程置信上界（GP Upper Conﬁdence
> Bound，GP-UCB）等。
>
> 时序模型优化的过程如算法[7.1](\l)所示。
>
> 算法 **7.1:** 时序模型优化，一种贝叶斯优化方法
>
> 输入**:** 优化目标函数*f* (**x**)，迭代次数：*T* ，收益函数*a*(*x,* H)
>
> **1** H ← ∅;
>
> **2** 随机初始化高斯过程，并计算*p*~GP~ (*f* (**x**)\|**x***,* H);
>
> **3 for** *t* ← 1 **to** *T* **do**
>
> **4 x**′ ← arg max*~x~ a*(*x,* H);
>
> **5** 评价*y*^′\ =\ *f*\ (**x**′)\ ;\ //\ 代价高^
>
> **6** H ← H ∪ (**x**′*, y*^′^);
>
> **7** 根据H 重新建模高斯过程，并计算*p*~GP~ (*f* (**x**)\|**x***,* H);
>
> **8 end**
>
> [ ]{.underline} [输出**:** H ]{.underline}
>
> 贝叶斯优化的一个缺点是高斯过程建模需要计算协方差矩阵的逆，时间复
> 杂度是*O*(*n*^3^)，因此不能很好地处理高维情况。深层神经网络的超参数一般比较多，为了使用贝叶斯优化来搜索神经网络的超参数，需要一些更高效的高斯过
> 程建模。也有一些方法可以将时间复杂度降从*O*(*n*^3^)
> 降低到*O*(*n*)\[[Snoek et al.](\l), [2015](\l)\]。

###### 动态资源分配

> 多 臂 赌 博 机 问 题 参 见第[14.1.1](\l)节。
>
> 在超参数优化中，每组超参数配置的评估代价比较高。如果我们可以在较
> 早的阶段就可以估计出一组配置的效果会比较差，那么我们就可以中止这组配
> 置的评估，将更多的资源留给其它配置。这个问题可以归结为多臂赌博机问题
> 的一个泛化问题：最优臂问题（best-arm
> problem），即在给定有限的机会次数下，如何玩这些赌博机并找到收益最大的臂。和多臂赌博机类似，最优臂问题
> 也是在利用和探索之间找到最佳的平衡。
>
> 由于目前神经网络的优化方法一般都采取随机梯度下降，因此我们可以通
> 过一组超参数的学习曲线来预估这组超参数配置是否有希望得到比较好的结
> 果。如果一组超参数配置的学习曲线不收敛或者收敛比较差，我们可以应用早
> 期停止（early-stopping）策略来中止当前的训练。
>
> 动态资源分配的一种有效方法是逐次减半（successive
> halving）方法\[[Jamieson](\l) [and Talwalkar](\l),
> [2016](\l)\]，将超参数优化看作是一种非随机的最优臂问题。假设要尝试*N*
> 组超参数配置，总共可利用的资源预算（摇臂的次数）为*B*，我们可以通过
> *T* = ⌈log~2~(*N* )⌉ − 1
> 轮逐次减半的方法来选取最优的配置，具体过程如算法[7.2](\l)所示。
>
> 算法 **7.2:** 一种逐次减半的动态资源分配方法
>
> 输入**:** 预算*B*，*N* 个超参数配置{**x***~n~*}*N*
>
> **1** *T* ← ⌈log~2~(*N* )⌉ − 1;
>
> **2** 随机初始化S~0~ = {**x***~n~*}*N* ;
>
> **3 for** *t* ← 1 **to** *T* **do**
>
> [ *B *]{.underline}
>
> **4** *r~t~*
>
> *t*
>
> **5** 给*S~t~* 中的每组配置分配*r~t~* 的资源;
>
> **6** 运行*S~t~* 所有配置，评估结果为**y***~t~*;
>
> **7** 根据评估结果，选取\|*S~t~*\|*/*2 组最优的配置
>
> S*~t~* ← arg max(S*~t~,* **y***~t~,* \|S*~t~*\|*/*2) ; // arg max(S*,*
> **y***, m*) 为从集合S
>
> 中选取*m* 个元素，对应最优的*m* 个评估结果。
>
> **8 end**
>
> [ 输出]{.underline}[**:** 最优配置S*~K~ *]{.underline}
>
> 在逐次减半方法中，尝试的超参数配置数量*N* 十分关键。如果*N*
> 越大，得到最佳配置的机会也越大，但每组配置分到的资源就越少，这样早期的评估结果可能不准确。反之如果*N*
> 越小，每组超参数配置的评估会越准确，但有可能无法得到最优的配置。因此，如何设置*N*
> 是平衡"利用-探索"的一个关键因素。一种改进的方法是HyperBand 方法\[[Li
> et al.](\l), [2017b](\l)\]，通过尝试不同的*N* 来选取最优参数。
>
> **7.6.4.1** 神经架构搜索
>
> 上面介绍的超参数优化方法都是在固定（或变化比较小）的超参数空间X
> 中进行最优配置搜索，而最重要的神经网络架构一般还是需要由有经验的专家
> 来进行设计。神经架构搜索（neural architecture search，NAS）\[[Zoph and
> Le](\l), [2017](\l)\]
> 是一个新的比较有前景的研究方向，通过神经网络来自动实现网络架构的设计。一个神经网络的架构可以用一个变长的字符串来描述。利用元学习的思
> 想，神经架构搜索利用一个控制器来生成另一个子网络的架构描述。控制器可
>
> 深度学习使得机器学习中的"特征工程"问题转变为"网络架构工程"问题。
>
> 强化学习参见第[14.1](\l)节。
>
> 参见第[2.8.1](\l)节。
>
> 过度参数是指模型参数的数量远远大于训练数据的数量。
>
> 范数参见第[A.1.3](\l)节。
>
> 以由一个循环神经网络来实现。控制器的训练可以通过强化学习来完成，其奖
> 励信号为生成的子网络在开发集上的准确率。

#### 网络正则化

> 机器学习模型的关键是泛化问题，即在样本真实分布上的期望风险最小化。
> 而训练数据集上的经验风险最小化和期望风险并不一致。由于神经网络的拟合能力非常强，其在训练数据上的错误率往往都可以降到非常低，甚至可以到0，
> 从而导致过拟合。因此，如何提高神经网络的泛化能力反而成为影响模型能力的最关键因素。
>
> 正则化（Regularization）是一类通过限制模型复杂度，从而避免过拟合，提高泛化能力的方法，包括引入一些约束规则，增加先验、提前停止等。
>
> 在传统的机器学习中，提高泛化能力的方法主要是限制模型复杂度，比如采用*ℓ*~1~
> 和*ℓ*~2~ 正则化等方式。而在训练深层神经网络时，特别是在过度参数（Over-
> Parameterized）时，*ℓ*~1~ 和*ℓ*~2~
> 正则化的效果往往不如浅层机器学习模型中显著。因此训练深度学习模型时，往往还会使用其它的正则化方法，比如数据增强、提前停止、丢弃法、集成法等。

###### *ℓ*~1~ 和*ℓ*~2~ 正则化

> *ℓ*~1~ 和*ℓ*~2~
> 正则化是机器学习中最常用的正则化方法，通过约束参数的*ℓ*~1~ 和*ℓ*~2~
>
> 范数来减小模型在训练数据集上的过拟合现象。通过加入*ℓ*~1~ 和*ℓ*~2~
> 正则化，优化问题可以写为

*θ*^∗^ = arg min [ 1]{.underline} Σ L *y*

(*n*)

*, f* (**x**

(*n*)

*, θ*) + *λℓ~p~*(*θ*)*,* (7.59)

> *θ n*=1
>
> 参见第[C.1.2](\l)节。
>
> 其中L(·) 为损失函数，*N* 为训练样本数量，*f* (·)
> 为待学习的神经网络，*θ* 为其参数，*ℓ~p~* 为范数函数，*p*
> 的取值通常为{1*,* 2} 代表*ℓ*~1~ 和*ℓ*~2~ 范数，*λ* 为正则化系数。
>
> 带正则化的优化问题等价于下面带约束条件的优化问题，
>
> *θ*^∗^ = arg min [ 1]{.underline} Σ L *y*^(*n*)^*, f* (**x**(*n*)*,
> θ*) *,* (7.60)
>
> *θ n*=1
>
> subject to *ℓ~p~*(*θ*) ≤ 1*.* (7.61)
>
> 图[A.1](\l)给出了不同范数约束条件下的最优化问题示例。
>
> *p* = 1 *p* = 2 *p* = ∞
>
> 图 7.9 不同范数约束条件下的最优化问题示例，红线表示函数*ℓ~p~* = 1，F
> 为函数*f* (*θ*) 的等高线（简单起见，这里用直线表示）
>
> 从图[A.1](\l)可以看出，*ℓ*~1~
> 范数的约束通常会使得最优解位于坐标轴上，而从使得最终的参数为稀疏性向量。此外，*ℓ*~1~
> 范数在零点不可导，因此经常下式来近似：
>
> *ℓ*~1~(*θ*) = Σ q*θ*^2^ + *ϵ* (7.62)

*i*

> 其中*ϵ* 为一个非常小的常数。
>
> 一种折中的正则化方法是弹性网络正则化（Elastic Net
> Regularization）\[[Zou](\l) [and Hastie](\l),
> [2005](\l)\]，同时加入*ℓ*~1~ 和*ℓ*~2~ 正则化。

*θ*^∗^ = arg min [ 1]{.underline} Σ L *y*^(*n*)^*, f* (**x**(*n*)*, θ*)
+ *λ*~1~*ℓ*~1~(*θ*) + *λ*~2~*ℓ*~2~(*θ*)*,* (7.63)

> *θ n*=1
>
> 其中*λ*~1~ 和*λ*~2~ 分别为两个正则化项的系数。

###### 权重衰减

> 权重衰减（Weight Decay）也是一种有效的正则化手段\[[Hanson and
> Pratt](\l), [1989](\l)\]，在每次参数更新时，引入一个衰减系数。
>
> *θ~t~* ← (1 − *w*)*θ~t~*~−1~ − *α***g***~t~,* (7.64)
>
> 其中**g***~t~* 为第*t* 更新的梯度，*α* 为学习率，*w*
> 为权重衰减系数，一般取值比较小，
> 比如0*.*0005。在标准的随机梯度下降中，权重衰减正则化和*ℓ*~2~
> 正则化的效果相同。因此，权重衰减在一些深度学习框架中通过*ℓ*~2~
> 正则化来实现。但是，在较为复杂的优化方法（比如Adam）中，权重衰减和*ℓ*~2~
> 正则化并不等价\[[Loshchilov](\l) [and Hutter](\l), [2017](\l)\]。

###### 提前停止

> 提前停止（early
> stop）对于深层神经网络来说是一种简单有效的正则化方法。由于深层神经网络的拟合能力非常强，因此比较容易在训练集上过拟合。在
>
> 参见习题[7-4](\l)。
>
> 提 前 停 止 也 可 以 参 见第[2.2.3.2](\l)节。
>
> 使用梯度下降法进行优化时，我们可以使用一个和训练集独立的样本集合，称
> 为验证集（validation
> set），并用验证集上的错误来代替期望错误。当验证集上的错误率不再下降，就停止迭代。
>
> 然而在实际操作中，验证集上的错误率变化曲线并不一定是图[2.4](\l)中所示的
> 平衡曲线，很可能是先升高再降低。因此，提前停止的具体停止标准需要根据
> 实际任务上进行优化\[[Prechelt](\l), [1998](\l)\]。

###### 丢弃法

> 当训练一个深层神经网络时，我们可以随机丢弃一部分神经元（同时丢弃其对应的连接边）来避免过拟合，这种方法称为丢弃法（Dropout
> Method）\[[Sri-](\l) [vastava et al.](\l),
> [2014](\l)\]。每次选择丢弃的神经元是随机的。最简单的方法是设置一个固定的概率*p*。对每一个神经元都一个概率*p*
> 来判定要不要保留。对于一个神 经层**y** = *f* (*W* **x** +
> **b**)，我们可以引入一个丢弃函数*d*(·) 使得**y** = *f* (*Wd*(**x**) +
> **b**)。丢弃函数*d*(·) 的定义为
>
> *d*(**x**) = **m** ⊙ **x** 当训练阶段时

*p***x** 当测试阶段时

> (7.65)
>
> 其中**m** ∈ {0*,* 1}*d* 是丢弃掩码（dropout mask），通过以概率为*p*
> 的贝努力分布随机生成。*p* 可以通过验证集来选取一个最优的值。或者*p*
> 也可以设为0*.*5，这对大部分的网络和任务有比较有效。在训练时，激活神经元的平均数量为原来
> 的*p*
> 倍。而在测试时，所有的神经元都是可以激活的，这会造成训练和测试时网络的输出不一致。为了缓解这个问题，在测试时需要将每一个神经元的输出
> 乘以*p*，也相当于把不同的神经网络做了平均。
>
> 图[7.10](\l)给出了一个网络应用dropout 方法后的示例。
>
图片识别内容

> ![](/root/autodl-tmp/project_knowledge/Doc_QA/Knowledge_based/1828695663060254721/image_output/7.《神经网络与深度学习》/media/image129.png)
>
图片识别内容

>
> 图 7.10 丢弃法示例
>
> 一般来讲，对于隐藏层的神经元，其丢弃率*p* = 0*.*5 时效果最好。当*p* =
> 0*.*5
> 时，在训练时有一半的神经元被丢弃，只剩余一半的神经元是可以激活的，随
> 机生成的网络结构最具多样性。对于输入层的神经元，其丢弃率通常设为更接
> 近1
> 的数，使得输入变化不会太大。对输入层神经元进行丢弃时，相当于给数据增加噪声，以此来提高网络的鲁棒性。
>
> 丢弃法一般是针对神经元进行随机丢弃，但是也可以扩展到对神经元之间
> 的连接进行随机丢弃\[[Wan et al.](\l),
> [2013](\l)\]，或每一层进行随机丢弃。
>
> 集成学习的解释
> 每做一次丢弃，相当于从原始的网络中采样得到一个子网络。如果一个神经网络有*n*
> 个神经元，那么总共可以采样出2*n*
> 个子网络。每次迭代都相当于训练一个不同的子网络，这些子网络都共享原始网络的参数。那么，最终的网络可以近似看作是集成了指数级个不同网络的组合模型。
>
> 贝叶斯学习的解释 丢弃法也可以解释为一种贝叶斯学习的近似\[[Gal and
> Ghahra-](\l) [mani](\l), [2016a](\l)\]。用*y* = *f* (**x***, θ*)
> 来表示要学习的神经网络，贝叶斯学习是假设参数*θ*
> 为随机向量，并且先验分布为*q*(*θ*)，贝叶斯方法的预测为

E~*q*(*θ*)~\[*y*\] =

*q*

> *f* (**x***, θ*)*q*(*θ*)*dθ* (7.66)
>
> *M*

*f* (**x***, θ~m~*

> *m*=1

)*,* (7.67)

> 其中*f* (**x***, θ~m~*) 为第*m* 次应用丢弃方法后的网络，其参数*θ~m~*
> 为对全部参数*θ* 的一次采样。

1.  循环神经网络上的丢弃法

> 当在循环神经网络上应用丢弃法，不能直接对每个时刻的隐状态进行随机
> 丢弃，这样会损害循环网络在时间维度上记忆能力。一种简单的方法是对非时
> 间维度的连接（即非循环连接）进行随机丢失\[[Zaremba et al.](\l),
> [2014](\l)\]。如图[7.11](\l)所示，虚线边表示进行随机丢弃，不同的颜色表示不同的丢弃掩码。
>
> · · ·
>
> · · ·
>
> · · ·
>
> 图 7.11 针对非循环连接的丢弃法
>
> 然而根据贝叶斯学习的解释，丢弃法是一种对参数*θ*
> 的采样。每次采样的参数需要在每个时刻保持不变。因此，在对循环神经网络上使用丢弃法时，需要对参数矩阵的每个元素进行随机丢弃，并在所有时刻都使用相同的丢弃掩码。这种方法称为变分丢弃法（Variational
> Dropout）\[[Gal and Ghahramani](\l),
> [2016b](\l)\]。图[7.12](\l)给出了变分丢弃法的示例，相同颜色表示使用相同的丢弃掩码。
>
> · · ·
>
> · · ·
>
> · · ·
>
> 图 7.12 变分丢弃法

###### 数据增强

> 深层神经网络一般都需要大量的训练数据才能获得比较理想的效果。在数据量有限的情况下，可以通过数据增强（Data
> Augmentation）来增加数据量，
> 提高模型鲁棒性，避免过拟合。目前，数据增强还主要应用在图像数据上，在文本等其它类型的数据还没有太好的方法。
>
> 图像数据的增强主要是通过算法对图像进行转变，引入噪声等方法来增加
> 数据的多样性。增强的方法主要有几种：

-   旋转（Rotation）：将图像按顺时针或逆时针方向随机旋转一定角度；

    8.  总结和深入阅读 2019 年 4 月 6 日 193

<!-- -->

-   翻转（Flip）：将图像沿水平或垂直方法随机翻转一定角度；

-   缩放（Zoom In/Out）：将图像放大或缩小一定比例；

-   平移（Shift）：将图像沿水平或垂直方法平移一定步长；

-   加噪声（Noise）：加入随机噪声。

    6.  ###### 标签平滑

> 在数据增强中，我们可以给样本特征加入随机噪声来避免过拟合。同样，我
> 们也可以给样本的标签引入一定的噪声。假设训练数据集中，有一些样本的标
> 签是被错误标注的，那么最小化这些样本上的损失函数会导致过拟合。一种改
> 善的正则化方法是标签平滑（Label
> Smoothing），即在输出标签中添加噪声来避免模型过拟合\[[Szegedy et
> al.](\l), [2016](\l)\]。
>
> 一个样本**x** 的标签一般用onehot 向量表示

**y** = \[0*,* · · · *,* 0*,* 1*,* 0*, ,* 0\]T*,*

> 这种标签可以看作是硬目标（Hard Targets）。如果使用softmax 分类器并使用
> 交叉熵损失函数，最小化损失函数会使得正确类和其它类的权重差异变得很大。
> 根据softmax
> 函数的性质可知，如果要使得某一类的输出概率接近于1，其未归一化的得分需要远大于其它类的得分，可能会导致其权重越来越大，并导致过拟合。此外，如果样本标签是错误的，会导致更严重的过拟合现象。为了改善这种情况，我们可以引入一个噪声对标签进行平滑，即假设样本以*ϵ*
> 的概率为其它类。平滑后的标签为

**y**˜ = \[ [* ϵ *]{.underline}*,* · · · *,* [* ϵ *]{.underline}*,* 1 −
*ϵ,* [* ϵ *]{.underline}*,* · · · *,* [* ϵ *]{.underline} \]T*.*

*K* − 1 *K* − 1 *K* − 1 *K* − 1

> 其中*K* 为标签数量，这种标签可以看作是软目标（Soft
> Targets）。标签平滑可以避免模型的输出过拟合到硬目标上，并且通常不会损害其分类能力。
>
> 上面的标签平滑方法是给其它*K* − 1 个标签相同的概率
> [*^\ ϵ^*]{.underline}
> ，没有考虑标签之间的相关性。一种更好的做法是按照类别相关性来赋予其它标签不同的概率。比如先训练另外一个更复杂（一般为多个网络的集成）的教师网络（Teacher
> Network），并使用大网络的输出作为软目标进行训练学生网络（Student Net-
> work）。这种方法也称为知识精炼（Knowledge Distillation）\[[Hinton et
> al.](\l), [2015](\l)\]。
>
> **7.8** 总结和深入阅读
>
> 深层神经网络的优化和正则化是即对立又统一的关系。一方面我们希望优
> 化算法能找到一个全局最优解（或较好的局部最优解），另一方面我们又不希望
> 模型优化到最优解，这可能陷入过拟合。优化和正则化的统一目标是期望风险
> 最小化。
>
> 参见习题[7-6](\l)。
>
> 集成学习参见第[10.1](\l)节。
>
> 在传统的机器学习中，有一些很好的理论可以帮助我们在模型的表示能力、
> 复杂度和泛化能力之间找到比较好的平衡，比如Vapnik-Chervonenkis（VC）维\[[Vapnik](\l),
> [1998](\l)\] 和Rademacher 复杂度\[[Bartlett and Mendelson](\l),
> [2002](\l)\]。但是这些理论无法解释深层神经网络在实际应用中的泛化能力表现。目前，深层神经网络的泛化能力还没有很好的理论支持。在传统机器学习模型上比较有效的*ℓ*~1~
> 或*ℓ*~2~
> 正则化在深层神经网络中作用也比较有限，而一些经验的做法，比如使用随机梯度下降和提前停止，会更有效。
>
> 根据通用近似定理，神经网络的表示能力十分强大。从直觉上，深层神经
> 网络很容易产生过拟合现象，因为增加的抽象层使得模型能够对训练数据中较
> 为罕见的依赖关系进行建模\[[Bengio et al.](\l), [2013](\l)\]。[Zhang et
> al.](\l) \[[2016](\l)\]
> 发现，虽然深层神经网络的容量足够记住所有训练数据，但依然优先记住训练数据中的
> 一般规律，即有泛化能力的规律。
>
> 近几年来，深度学习的快速发展在一定程度上也归因于一些深层神经网络
> 的优化和正则化方法的出现。虽然这些方法往往是经验性的，但在实践中取得
> 了很好的效果，使得我们可以高效地、端到端地训练神经网络模型，不再依赖
> 早期训练神经网络时的预训练和逐层训练等比较低效的方法。

#### 习题

> 习题**7-1** 证明在动量法的更新公式([7.18](\l)) 中，∆*θ~t~*
> 实际上是相当于对− 1 *α* **g**
>
> 进行指数衰减的移动平均。
>
> 习题**7-2** 在Adam
> 算法中，说明指数加权平均的偏差修正公式(**??**)和(**??**)的合理性。
>
> 习题 **7-3** 分析为什么批量归一化不能直接应用于循环神经网络。
>
> 习题**7-4** 证明在标准的随机梯度下降中，权重衰减正则化和*ℓ*~2~
> 正则化的效果相同。并分析这一结论在动量法和Adam 算法中是否依然成立。
>
> 习题 **7-5**
> 试分析为什么不能在循环神经网络中的循环连接上直接应用丢弃法？
>
> 习题 **7-6** 若使用标签平滑正则化方法，给出其交叉熵损失函数。

#### 参考文献

> Lei Jimmy Ba, Ryan Kiros, and Geof- frey E. Hinton. Layer
> normalization. *CoRR*, abs/1607.06450, 2016. URL http://arxiv.
> org/abs/1607.06450.
>
> Peter L Bartlett and Shahar Mendel- son. Rademacher and gaussian
> complex- ities: Risk bounds and structural results. *Journal of
> Machine Learning Research*, 3 (Nov):463--482, 2002.
>
> Yoshua Bengio, Nicolas Boulanger- Lewandowski, and Razvan Pascanu.
> Advances in optimizing recurrent networks. In *2013 IEEE International
> Conference on Acoustics, Speech and Signal Processing*, pages
> 8624--8628. IEEE, 2013.
>
> James Bergstra and Yoshua Bengio. Ran- dom search for hyper-parameter
> optimiza- tion. *Journal of Machine Learning Re-* *search*,
> 13(Feb):281--305, 2012.
>
> James S Bergstra, Rémi Bardenet, Yoshua Bengio, and Balázs Kégl.
> Algorithms for hyper-parameter optimization. In *Advances in neural
> information processing systems*, pages 2546--2554, 2011.
>
> Anna Choromanska, Mikael Henaﬀ, Michael Mathieu, Gérard Ben Arous, and
> Yann LeCun. The loss surfaces of multi- layer networks. In *Artiﬁcial
> Intelligence* *and Statistics*, pages 192--204, 2015.
>
> Yann N Dauphin, Razvan Pascanu, Caglar Gulcehre, Kyunghyun Cho, Surya
> Ganguli, and Yoshua Bengio. Identifying and at- tacking the saddle
> point problem in high- dimensional non-convex optimization. In
> *Advances in neural information processing* *systems*, pages
> 2933--2941, 2014.
>
> Timothy Dozat. Incorporating nesterov mo- mentum into adam. In *ICLR
> Workshop*, 2016.
>
> John Duchi, Elad Hazan, and Yoram Singer. Adaptive subgradient methods
> for online learning and stochastic optimization. *The Journal of
> Machine Learning Research*, 12: 2121--2159, 2011.
>
> Yarin Gal and Zoubin Ghahramani. Dropout as a bayesian approximation:
> Representing model uncertainty in deep learning. In *international
> conference on* *machine learning*, pages 1050--1059, 2016a. Yarin Gal
> and Zoubin Ghahramani. A the- oretically grounded application of
> dropout in recurrent neural networks. In *Advances in neural
> information processing systems*, pages 1019--1027, 2016b.
>
> Xavier Glorot and Yoshua Bengio. Un- derstanding the diﬃculty of
> training deep feedforward neural networks. In *Interna- tional
> conference on artiﬁcial intelligence* *and statistics*, pages
> 249--256, 2010.
>
> Stephen José Hanson and Lorien Y Pratt. Comparing biases for minimal
> network con- struction with back-propagation. In *Ad- vances in neural
> information processing* *systems*, pages 177--185, 1989.
>
> Geoﬀrey Hinton, Oriol Vinyals, and Jeﬀ Dean. Distilling the knowledge
> in a neural network. *arXiv preprint arXiv:1503.02531*, 2015.
>
> Sepp Hochreiter and Jürgen Schmidhuber. Flat minima. *Neural
> Computation*, 9(1):1-- 42, 1997.
>
> Frank Hutter, Holger H Hoos, and Kevin Leyton-Brown. Sequential
> model-based op- timization for general algorithm conﬁgura- tion. In
> *International Conference on Learn- ing and Intelligent Optimization*,
> pages 507--523. Springer, 2011.
>
> Sergey Ioﬀe and Christian Szegedy. Batch normalization: Accelerating
> deep network training by reducing internal covariate shift. In
> *Proceedings of the 32nd International Conference on Machine
> Learning*, pages 448--456, 2015.
>
> Kevin Jamieson and Ameet Talwalkar. Non-stochastic best arm
> identiﬁcation and hyperparameter optimization. In *Artiﬁcial
> Intelligence and Statistics*, pages 240--248, 2016.
>
> 196 2019 年 4 月 6 日 参考文献
>
> Diederik Kingma and Jimmy Ba. Adam: A method for stochastic
> optimization. In *Proceedings of International Conference on*
> *Learning Representations*, 2015.
>
> Alex Krizhevsky, Ilya Sutskever, and Ge- oﬀrey E Hinton. Imagenet
> classiﬁcation with deep convolutional neural networks. In *Advances in
> neural information processing* *systems*, pages 1097--1105, 2012.
>
> Hao Li, Zheng Xu, Gavin Taylor, and Tom Goldstein. Visualizing the
> loss land- scape of neural nets. *arXiv preprint* *arXiv:1712.09913*,
> 2017a.
>
> Lisha Li, Kevin Jamieson, Giulia De- Salvo, Afshin Rostamizadeh, and
> Ameet Talwalkar. Hyperband: Bandit-based con- ﬁguration evaluation for
> hyperparameter optimization. In *Proceedings of 5th Inter- national
> Conference on Learning Represen-* *tations*, 2017b.
>
> Ilya Loshchilov and Frank Hutter. Fixing weight decay regularization
> in adam. *arXiv* *preprint arXiv:1711.05101*, 2017.
>
> Yu Nesterov. Gradient methods for mini- mizing composite functions.
> *Mathematical* *Programming*, 140(1):125--161, 2013.
>
> Razvan Pascanu, Tomas Mikolov, and Yoshua Bengio. On the diﬃculty of
> training recurrent neural networks. In *Proceedings of the
> International Conference on Machine* *Learning*, pages 1310--1318,
> 2013.
>
> Lutz Prechelt. Early stopping-but when? In *Neural Networks: Tricks of
> the trade*, pages 55--69. Springer, 1998.
>
> David E Rumelhart, Geoﬀrey E Hinton, and Ronald J Williams. Learning
> representa- tions by back-propagating errors. *Cognitive* *modeling*,
> 5:3, 1988.
>
> Tim Salimans and Diederik P Kingma. Weight normalization: A simple
> reparame- terization to accelerate training of deep neu- ral networks.
> In *Advances in Neural Infor- mation Processing Systems*, pages
> 901--909, 2016.
>
> Jasper Snoek, Hugo Larochelle, and Ryan P Adams. Practical bayesian
> optimization of machine learning algorithms. In *Advances*
>
> *in neural information processing systems*, pages 2951--2959, 2012.
>
> Jasper Snoek, Oren Rippel, Kevin Swersky, Ryan Kiros, Nadathur Satish,
> Narayanan Sundaram, Mostofa Patwary, Mr Prabhat, and Ryan Adams.
> Scalable bayesian opti- mization using deep neural networks. In *In-
> ternational Conference on Machine Learn-* *ing*, pages 2171--2180,
> 2015.
>
> Nitish Srivastava, Geoﬀrey Hinton, Alex Krizhevsky, Ilya Sutskever,
> and Ruslan Salakhutdinov. Dropout: A simple way to prevent neural
> networks from overﬁtting. *The Journal of Machine Learning Research*,
> 15(1):1929--1958, 2014.
>
> Ilya Sutskever, James Martens, George Dahl, and Geoﬀrey Hinton. On the
> im- portance of initialization and momentum in deep learning. In
> *International confer- ence on machine learning*, pages 1139--1147,
> 2013.
>
> Christian Szegedy, Vincent Vanhoucke, Sergey Ioﬀe, Jon Shlens, and
> Zbigniew Wo- jna. Rethinking the inception architec- ture for computer
> vision. In *Proceedings of the IEEE Conference on Computer Vision and
> Pattern Recognition*, pages 2818--2826, 2016.
>
> Tijmen Tieleman and Geoﬀrey Hinton. Lec- ture 6.5-rmsprop: Divide the
> gradient by a running average of its recent magnitude. COURSERA:
> Neural networks for machine learning, 2012.
>
> Vladimir Vapnik. *Statistical learning the-* *ory*. Wiley, New York,
> 1998.
>
> Li Wan, Matthew Zeiler, Sixin Zhang, Yann Le Cun, and Rob Fergus.
> Regularization of neural networks using dropconnect. In *In-
> ternational Conference on Machine Learn-* *ing*, pages 1058--1066,
> 2013.
>
> Wojciech Zaremba, Ilya Sutskever, and Oriol Vinyals. Recurrent neural
> net- work regularization. *arXiv preprint* *arXiv:1409.2329*, 2014.
>
> Matthew D Zeiler. Adadelta: An adap- tive learning rate method. *arXiv
> preprint arXiv:1212.5701*, 2012.
>
> Chiyuan Zhang, Samy Bengio, Moritz Hardt, Benjamin Recht, and Oriol
> Vinyals. Understanding deep learning requires re- thinking
> generalization. *arXiv preprint* *arXiv:1611.03530*, 2016.
>
> Barret Zoph and Quoc V Le. Neural archi- tecture search with
> reinforcement learning.
>
> In *Proceedings of 5th International Confer-* *ence on Learning
> Representations*, 2017.
>
> Hui Zou and Trevor Hastie. Regularization and variable selection via
> the elastic net. *Journal of the Royal Statistical Society: Se- ries B
> (Statistical Methodology)*, 67(2):301-- 320, 2005.

第**8** 章 注意力机制与外部记忆
===============================

> 智慧的艺术是知道该忽视什么。
>
> --- 威廉·詹姆斯
>
> 根据通用近似定理，前馈网络和循环网络都有很强的能力。但由于优化算
> 法和计算能力的限制，在实践中很难达到通用近似的能力。特别是在处理复杂
> 任务时，比如需要处理大量的输入信息或者复杂的计算流程时，目前计算机的
> 计算能力依然是限制神经网络发展的瓶颈。
>
> 为了减少计算复杂度，通过部分借鉴生物神经网络的一些机制，我们引入了局部连接、权重共享以及汇聚操作来简化神经网络结构。虽然这些机制可以有效缓解模型的复杂度和表达能力之间的矛盾，但是我们依然希望在不"过度"
> 增加模型复杂度（主要是模型参数）的情况下来提高模型的表达能力。以阅读理解任务为例，给定的背景文章（background
> document）一般比较长，如果用循环神经网络来将其转换为向量表示，那么这个编码向量很难反映出背景文章的所有语义。在比较简单的文本分类任务中，只需要编码一些对分类有用的信息，因此用一个向量来表示文本语义来行得通。但是在阅读理解任务中，编码时还不知道可能会接收到什么样的问句。这些问句可能会涉及到背景文章的所有信息点，因此丢失任何信息都可能导致无法正确回答问题。
>
> 神经网络中可以存储的信息量称为网络容量（Network
> Capacity）。一般来讲，利用一组神经元来存储信息的容量和神经元的数量以及网络的复杂度成
> 正比。如果要存储越多的信息，神经元数量就要越多或者网络要越复杂，进而
> 导致神经网络的参数成倍地增加。
>
> 我们人脑的生物神经网络同样存在网络容量问题，人脑中的工作记忆大概
> 只有几秒钟的时间，类似于循环神经网络中的隐状态。而人脑每个时刻接收的
> 外界输入信息非常多，包括来源于视觉、听觉、触觉的各种各样的信息。但就
> 视觉来说，眼睛每秒钟都会发送千万比特的信息给视觉神经系统。人脑在有限
>
> 阅读理解任务是让机器阅读一篇背景文章，然后询问一些相关的问题，来测试机器是否理解了这篇文章。
>
> 在循环神经网络中，丢失信息的另外一个因素是[远距离依赖问题]{.underline}。
>
> 的资源下，并不能同时处理这些过载的输入信息。大脑神经系统有两个重要机
> 制可以解决信息过载问题：注意力和记忆机制。
>
> 我们可以借鉴人脑解决信息过载的机制，从两方面来提高神经网络处理信
> 息的能力。一方面是注意力，通过自上而下的信息选择机制来过滤掉大量的无
> 关信息；另一方面是引入额外的外部记忆，优化神经网络的记忆结构来提高神
> 经网络存储信息的容量。

#### 注意力

> 在计算能力有限情况下，注意力机制（Attention
> Mechanism）是解决信息超载问题的主要手段的一种资源分配方案，将计算资源分配给更重要的任务。

###### 认知神经学中的注意力

> 注意力是一种人类不可或缺的复杂认知功能，指人可以在关注一些信息的同时忽略另一些信息的选择能力。在日常生活中，我们通过视觉、听觉、触觉等方式接收大量的感觉输入。但是人脑可以在这些外界的信息轰炸中还能有条不紊地工作，是因为人脑可以有意或无意地从这些大量输入信息中选择小部分的有用信息来重点处理，并忽略其他信息。这种能力就叫做注意力。注意力可以体现在外部的刺激（听觉、视觉、味觉等），也可以体现在内部的意识（思考、
> 回忆等）。
>
> 注意力一般分为两种：一种是自上而下的有意识的注意力，称为聚焦式
>
> （focus）注意力。聚焦式注意力是指有预定目的、依赖任务的、主动有意识地聚焦于某一对象的注意力；另一种是自下而上的无意识的注意力，称为基于显著性（saliency-based）的注意力。基于显著性的注意力是由外界刺激驱动的注意，
> 不需要主动干预，也和任务无关。如果一个对象的刺激信息不同于其周围信息，
> 一种无意识的"赢者通吃"（winner-take-all）或者门控（gating）机制就可以把注意力转向这个对象。不管这些注意力是有意还是无意，大部分的人脑活动都需要依赖注意力，比如记忆信息，阅读或思考等。
>
> 除非特别声明，本节及以后章节中注意力机制是通常指自上而下的[聚焦式注意力]{.underline}。
>
> 一个和注意力有关的例子是鸡尾酒会效应。当一个人在吵闹的鸡尾酒会上
> 和朋友聊天时，尽管周围噪音干扰很多，他还是可以听到朋友的谈话内容，而
> 忽略其他人的声音（聚焦式注意力）。同时，如果未注意到的背景声中有重要的
> 词（比如他的名字），他会马上注意到（显著性注意力）。
>
> 聚焦式注意力一般会随着环境、情景或任务的不同而选择不同的信息。比
> 如当要从人群中寻找某个人时，我们会将专注于每个人的脸部；而当要统计人
> 群的人数时，我们只需要专注于每个人的轮廓。

###### 人工神经网络中的注意力机制

> 当用神经网络来处理大量的输入信息时，也可以借鉴人脑的注意力机制，只选择一些关键的信息输入进行处理，来提高神经网络的效率。在目前的神经网络模型中，我们可以将最大汇聚（max
> pooling）、门控（gating）机制来近似地看作是自下而上的基于显著性的注意力机制。除此之外，自上而下的会聚式注意力也是一种有效的信息选择方式。以阅读理解任务为例，给定一篇很长的文章，然后就此文章的内容进行提问。提出的问题只和段落中的一两个句子相关，
> 其余部分都是无关的。为了减小神经网络的计算负担，只需要把相关的片段挑选出来让后续的神经网络来处理，而不需要把所有文章内容都输入给神经网络。
>
> 用*X* = \[**x**~1~*,* · · · *,* **x***~N~* \] 表示*N*
> 个输入信息，为了节省计算资源，不需要将所有的*N*
> 个输入信息都输入到神经网络进行计算，只需要从*X*
> 中选择一些和任务相关的信息输入给神经网络。注意力机制的计算可以分为两步：一是在所有输
> 入信息上计算注意力分布，二是根据注意力分布来计算输入信息的加权平均。
>
> 注意力机制也可称为注意力[模型]{.underline}。
>
> 注意力分布 给定一个和任务相关的查询向量**q**，我们用注意力变量*𝑥* ∈
> \[1*, N* \] 查询向量 **q** 可以是动态生成
>
> 来表示被选择信息的索引位置，即*𝑥* = *i* 表示选择了第*i*
> 个输入信息。为了方便计算，我们采用一种"软性"的信息选择机制，首先计算在给定**q**
> 和*X* 下，选择第*i* 个输入信息的概率*α~i~*，
>
> *α~i~* = *p*(*𝑥* = *i*\|*X,* **q**)
>
> = softmax *s*(**x***~i~,* **q**)
>
> 的，也可以是可学习的参数。

= exp *s*(**x***~i~,* **q**)

> (8.1)
>
> Σ*N* exp (**x q**) *,*
>
> 其中*α~i~* 称为注意力分布（Attention Distribution），*s*(**x***~i~,*
> **q**) 为注意力打分函数， 可以使用以下几种方式来计算：
>
> 加性模型 *s*(**x***~i~,* **q**) = **v**T tanh(*W* **x***~i~* + *U*
> **q**)*,* (8.2)
>
> 点积模型 *s*(**x***~i~,* **q**) = **x**T**q***,* (8.3)
>
> **x**T**q**
>
> 缩放点积模型 *s*(**x***~i~,* **q**) = *i*
>
> *d*
>
> 双线性模型 *s*(**x***~i~,* **q**) = **x**T*W* **q***,* (8.5)
>
> 其中*W, U,* **v** 为可学习的网络参数，*d*
> 为输入信息的维度。理论上，加性模型和点积模型的复杂度差不多，但是点积模型在实现上可以更好地利用矩阵乘积，从
> 而计算效率更高。但当输入信息的维度*d* 比较高，点积模型的值通常有比较大
>
> 方差，从而导致softmax 函数的梯度会比较小。因此，缩放点积模型可以较好地
> 参见习题[8.4](\l)。
>
> 解决这个问题。双线性模型可以看做是一种泛化的点积模型。假设公式([8.5](\l))中
> *W* = *U* T*V* ，双线性模型可以写为*s*(**x***~i~,* **q**) = **x**T*U*
> T*V* **q** = (*U* **x**)T(*V* **q**)，即分别对**x** 和**q**
> 进行线性变换后计算点积。相比点积模型，双线性模型在计算相似度时引入了非对称性。
>
> 加权平均 注意力分布*α~i~* 可以解释为在给定任务相关的查询**q**
> 时，第*i*
> 个信息受关注的程度。我们采用一种"软性"的信息选择机制对输入信息进行汇总，
>
> *N*
>
> **att**(*X,* **q**) = *α~i~***x***~i~,* (8.6)
>
> *i*=1
>
> = E~*𝑥*∼*p*(*𝑥*\|*X,***q**)~\[**x**\]*.* (8.7)
>
> 公式([8.7](\l)) 称为软性注意力机制（Soft Attention
> Mechanism）。图[8.1a](\l)给出软性注意力机制的示例。
>
> **a a**

**q**

a.  普通模式

> **q**
>
> **k**~1~
>
> 图 8.1 注意力机制
>
> **k**~2~

b.  键值对模式

· · · **k***N*

###### 注意力机制的变体

> 除了上面介绍的基本模式外，注意力机制还存在一些变化的模型。

1.  硬性注意力

> 公式([8.7](\l))提到的注意力是软性注意力，其选择的信息是所有输入信息在注
> 意力分布下的期望。此次，还有一种注意力是只关注到某一个位置上的信息，叫
> 做硬性注意力（Hard Attention）。
>
> 硬性注意力有两种实现方式：

1.  一种是选取最高概率的输入信息，即

> **att**(*X,* **q**) = **x***~j~,* (8.8)
>
> 其中*j* 为概率最大的输入信息的下标，即*j* = arg*^N^*max *α* 。

*i*=1

2.  另一种硬性注意力可以通过在注意力分布式上随机采样的方式实现。

> 硬性注意力的一个缺点是基于最大采样或随机采样的方式来选择信息。因
> 此最终的损失函数与注意力分布之间的函数关系不可导，因此无法使用在反向
> 传播算法进行训练。为了使用反向传播算法，一般使用软性注意力来代替硬性
> 注意力。

2.  键值对注意力

> 更一般地，我们可以用键值对（key-value
> pair）格式来表示输入信息，其中"键"用来计算注意力分布*α~i~*，"值"用来计算聚合信息。
>
> 用(*K, V* ) = \[(**k**~1~*,* **v**~1~)*,* · · · *,* (**k***~N~ ,*
> **v***~N~* )\] 表示*N* 个输入信息，给定任务相关的查询向量**q**
> 时，注意力函数为
>
> 硬性注意力需要通过强化学习来进行训练。

**att** (*K, V*

> *N*
>
> *,*
>
> *i*=1
>
> = Σ
>
> *α~i~***v***~i~,*
>
> exp *s*(**k***~i~,* **q**) **v**
>
> (8.9)
>
> (8.10)
>
> Σ exp (**k q**) *i,*
>
> 其中*s*(**k***~i~,* **q**) 为打分函数。
>
> *i*=1 *j*
>
> *s ~j~,*
>
> 图[8.1b](\l)给出键值对注意力机制的示例。当*K* = *V*
> 时，键值对模式就等价于普通的注意力机制。

3.  多头注意力

> 多头注意力（Multi-Head Attention）是利用多个查询*Q* = \[**q**~1~*,* ·
> · · *,* **q***~M~*
> \]，来平行地计算从输入信息中选取多个信息。每个注意力关注输入信息的不同部分。

**att** (*K, V* )*, Q* = **att** (*K, V* )*,* **q**~1~ ⊕ · · · ⊕ **att**
(*K, V* )*,* **q***~M~ ,* (8.11)

> 其中⊕ 表示向量拼接。

4.  结构化注意力

> 要从输入信息中选取出和任务相关的信息，主动注意力是在所有输入信息
> 上的多项分布，是一种扁平（ﬂat）结构。如果输入信息本身具有层次（hierarchical）结构，比如文本可以分为词、句子、段落、篇章等不同粒度的层次，我们可以
>
> 使用层次化的注意力来进行更好的信息选择\[[Yang et al.](\l),
> [2016](\l)\]。此外，还可以假设注意力上下文相关的二项分布，用一种图模型来构建更复杂的结构化注意
> 力分布\[[Kim et al.](\l), [2017](\l)\]。

#### 注意力机制的应用

> 注意力机制一般可以用作一个神经网络中的组件。

###### 指针网络

> 注意力机制主要是用来做信息筛选，从输入信息中选取相关的信息。注意
> 力机制可以分为两步：一是计算注意力分布*α*，二是根据*α*
> 来计算输入信息的加权平均。我们可以只利用注意力机制中的第一步，将注意力分布作为一个软
> 性的指针（pointer）来指出相关信息的位置。
>
> 指针网络（Pointer Network）\[[Vinyals et al.](\l), [2015](\l)\]
> 是一种序列到序列模型， 输入是长度为*n* 的向量序列*X* = **x**~1~*,* · ·
> · *,* **x***~n~*，输出是下标序列*c*~1:*m*~ = *c*~1~*, c*~2~*,* · · ·
> *, c~m~*， *c~i~* ∈ \[1*, n*\]*,* ∀*i*。
>
> 和一般的序列到序列任务不同，这里的输出序列是输入序列的下标（索引）。
> 比如输入一组乱序的数字，输出为按大小排序的输入数字序列的下标。比如输入为20*,*
> 5*,* 10，输出为1*,* 3*,* 2。
>
> 条件概率*p*(*c*~1:*m*~\|**x**~1:*n*~) 可以写为
>
> *m*

*p*(*c*~1:*m*~ **x**~1:*n*~) = *p*(*c~i~ c*~1:*i*−1~*,* **x**~1:*n*~)
(8.12)

> *i*=1 *m*

*p*(*c~i~* **x***~c~*1 *, ,* **x***~c~i*−1 *,* **x**~1:*n*~)*,* (8.13)

> *i*=1
>
> 其中条件概率*p*(*c~i~*\|**x***~c~*1 *,* · · · *,* **x***~c~i*−1 *,*
> **x**~1:*n*~)
> 可以通过注意力分布来计算。假设用一个循环神经网络对**x***~c~*1 *,* · ·
> · *,* **x***~c~i*−1 *,* **x**~1:*n*~ 进行编码得到向量**h***~i~*，则

*p*(*c~i~*\|*c*~1:*i*−1~*,* **x**~1:*n*~) = softmax(*s~i,j~*)*,* (8.14)

> 其中*s~i,j~* 为在解码过程的第*i*
> 步时，每个输入向量的未归一化的注意力分布， *s~i,j~* = **v**T tanh(*W*
> **x***~j~* + *U* **h***~i~*)*,* ∀*j* ∈ \[1*, n*\]*,* (8.15)
>
> 其中**v***, W, U* 为可学习的参数。
>
> 图[8.2](\l)给出了指针网络的示例。

2.  注意力机制的应用 2019 年 4 月 6 日 205

> *\<* 20 5 10 *\>* 20 10 5
>
> 编码器 解码器
>
> 图 8.2 指针网络

###### 自注意力模型

> 当使用神经网络来处理一个变长的向量序列时，我们通常可以使用卷积网
> 络或循环网络进行编码来得到一个相同长度的输出向量序列，如图[8.3](\l)所示。

a.  卷积网络 (b) 双向循环网络

> 图 8.3 基于卷积网络和循环网络的变长序列编码
>
> 基于卷积或循环网络的序列编码都是可以看做是一种局部的编码方式，只
> 建模了输入信息的局部依赖关系。虽然循环网络理论上可以建立长距离依赖关
> 系，但是由于信息传递的容量以及梯度消失问题，实际上也只能建立短距离依
> 赖关系。
>
> 如果要建立输入序列之间的长距离依赖关系，可以使用以下两种方法：一种方法是增加网络的层数，通过一个深层网络来获取远距离的信息交互另一种方法是使用全连接网络。全连接网络是一种非常直接的建模远距离依赖的模型，
> 但是无法处理变长的输入序列。不同的输入长度，其连接权重的大小也是不同的。这时我们就可以利用注意力机制来"动态"地生成不同连接的权重，这就是自注意力模型（Self-Attention
> Model）。
>
> 自注意力也称为内部注意力
>
> 假设输入序列为*X* = \[**x**~1~*,* · · · *,* **x***~N~* \] ∈ R*d*1×*N*
> ，输出序列为*H* = \[**h**~1~*,* · · · *,* **h***~N~* \]
> ∈（Intra-Attention）。
>
> R*d*2×*N* ，首先我们可以通过线性变换得到三组向量序列：
>
> *Q* = *W~Q~X* ∈ R*^d^*3×*N ,* (8.16)
>
> *K* = *W~K~X* ∈ R*^d^*3×*N ,* (8.17)
>
> *V* = *W~V~ X* ∈ R*^d^*2×*N ,* (8.18)
>
> 其中*Q, K, V* 分别为查询向量序列，键向量序列和值向量序列，*W~Q~, W~K~,
> W~V~* 分别为可学习的参数矩阵。
>
> 利用公式([8.9](\l))，可以得到输出向量**h***~i~*，
>
> **h***~i~* = **att** (*K, V* )*,* **q***~i~* (8.19)
>
> = *α~ij~***v***~j~* (8.20)
>
> *j*=1
>
> *N*
>
> = softmax *s*(**k***~j~,* **q***~i~*) **v***~j~* (8.21)
>
> *j*=1
>
> 其中*i, j* ∈ \[1*, N* \] 为输出和输入向量序列的位置，连接权重*α~ij~*
> 由注意力机制动态生成。
>
> 如果使用缩放点积来作为注意力打分函数，输出向量序列可以写为
>
> T
>
> *H* = *V* softmax( √*d*3 )*,* (8.22)
>
> 其中softmax 为按列进行归一化的函数。
>
> 图[8.4](\l)给出全连接模型和自注意力模型的对比，其中实线表示为可学习的权
> 重，虚线表示动态生成的权重。由于自注意力模型的权重是动态生成的，因此
> 可以处理变长的信息序列。

a.  全连接模型 (b) 自注意力模型

> 图 8.4 全连接模型和自注意力模型
>
> 参见习题[8-3](\l)。
>
> 自注意力模型可以作为神经网络中的一层来使用，既可以用来替换卷积层
> 和循环层\[[Vaswani et al.](\l),
> [2017](\l)\]，也可以和它们一起交替使用\[[Shen et al.](\l),
> [2018](\l)\]
>
> （比如*X* 可以是卷积层或循环层的输出）。自注意力模型计算的权重*α~ij~*
> 只依赖
>
> **q***~i~* 和**k***~j~*
> 的相关性，而忽略了输入信息的位置信息。因此在单独使用时，自注意力模型一般需要加入位置编码信息来进行修正\[[Vaswani
> et al.](\l), [2017](\l)\]。

#### 外部记忆

> 为了增强网络容量，我们可以引入辅助记忆单元，将一些信息保存辅助记
> 忆中，在需要时再进行读取，这样可以有效地增加网络容量。这个引入辅助记
> 忆单元一般称为外部记忆（External
> Memory），以区别与循环神经网络的内部记忆（即隐状态）。

###### 人脑中的记忆

> 在生物神经网络中，记忆是外界信息在人脑中存储机制。大脑记忆毫无疑问是通过生物神经网络实现的。虽然其机理目前还无法解释，但直观上记忆机制和神经网络的连接形态以及神经元的活动相关。生理学家发现信息是作为一种整体效应（collective
> eﬀect）存储在大脑组织中。当大脑皮层的不同部位损伤时，其导致的不同行为表现似乎取决于损伤的程度而不是损伤的确切位置\[[Kohonen](\l),
> [2012](\l)\]。大脑组织的每个部分似乎都携带一些导致相似行为的信息。也就是说，记忆在大脑皮层是分布式存储的，而不是存储于某个局部区域\[[Thompson](\l),
> [1975](\l)\]。
>
> 人脑中的记忆具有周期性和联想性。
>
> 记忆周期
> 虽然人脑记忆的存储机制还不清楚，但是在我们已经大概可以确定不同脑区参与了记忆形成的几个阶段。人脑记忆的一个特点记忆一般分为长期
> 记忆和短期记忆。长期记忆（Long-Term Memory），也称为结构记忆或知识
>
> （Knowledge），体现为神经元之间的连接形态，其更新速度比较慢。短期记忆
>
> （Short-Term
> Memory）体现为神经元的活动，更新较快，维持时间为几秒至几分钟。短期记忆是神经连接的暂时性强化，通过不断巩固、强化可形成长期记
> 忆。短期记忆、长期记忆的动态更新过程称为演化（Evolution）过程。
>
> 因此，长期记忆可以类比于人工神经网络中的权重参数，而短期记忆可以
> 类比于人工神经网络中的隐状态。
>
> 除了长期记忆和短期记忆，人脑中还会存在一个"缓存"，称为工作记忆
>
> （Working
> Memory）。在执行某个认知行为（比如记下电话号码，算术运算）时，
> 工作记忆是一个记忆的临时存储和处理系统，维持时间通常为几秒钟。从时间上看，工作记忆也是一种短期记忆，但和短期记忆的内涵不同。短期记忆一般指外界的输入信息在人脑中的表示和短期存储，不关心这些记忆如何被使用；而工作记忆是一个和任务相关的"容器"，可以临时存放和某项任务相关的短期记忆和其它相关的内在记忆。工作记忆的容量一般都比较小，一般可以容纳4
> 组项目。
>
> 以循环神经网络为例，其内部记忆可以类比于计算机的[寄存器]{.underline}，[外部记忆]{.underline}可以类比于计算机的内存。
>
> 事实上，人脑记忆周期的划分并没有清晰的界限，也存在其它的划分方法。
>
> 联想记忆是一个人工智能、计算机科学和认知科学等多
> 个交叉领域的热点研究问题， 不同学科中的内涵也不太相 同。
>
> 作为不严格的类比，现代计算机的存储也可以按照不同的周期分为不同的
> 存储单元，比如寄存器、内存、外存（比如硬盘等）。
>
> 联想记忆
> 大脑记忆的一个主要特点是通过联想来进行检索的。联想记忆（Associative
> Memory）是指一种学习和记住不同对象之间关系的能力，比如看见一个人然
>
> 后想起他的名字，或记住某种食物的味道等。联想记忆是指一种可以通过内容
> 匹配的方法进行寻址的信息存储方式，也称为基于内容寻址的存储（Content-
> Addressable
> Memory，CAM）。作为对比，现代计算机的存储方式根据地址来进行存储的，称为随机访问存储（Random
> Access Memory，RAM）。
>
> 和之前介绍的LSTM 中的记忆单元相比，外部记忆可以存储更多的信息，
> 并且不直接参与计算，通过读写接口来进行操作。而LSTM 模型中的记忆单元
> 包含了信息存储和计算两种功能，不能存储太多的信息。因此，LSTM
> 中的记忆单元可以类比于计算机中寄存器，而外部记忆可以类比于计算机中的存储器：
> 内存、磁带或硬盘等。
>
> 借鉴人脑中工作记忆，可以在神经网络中引入一个外部记忆单元来提高网
> 络容量。外部记忆的实现途径有两种：一种是结构化的记忆，这种记忆和计算
> 机中的信息存储方法比较类似，可以分为多个记忆片段，并按照一定的结构来
> 存储；另一种是基于神经动力学的联想记忆，这种记忆方式具有更好的生物学
> 解释性。
>
> 图[8.1](\l)给出了不同领域中记忆模型的不严格类比。

+----------+------------+------------+----------------------+
| 记忆周期 | > 计算机   | > 人脑     | > 神经网络           |
+----------+------------+------------+----------------------+
| 短期     | > 寄存器   | > 短期记忆 | > 状态（神经元活性） |
+----------+------------+------------+----------------------+
| 中期     | > 内存     | > 工作记忆 | > 外部记忆           |
+----------+------------+------------+----------------------+
| 长期     | > 外存     | > 长期记忆 | > 可学习参数         |
+----------+------------+------------+----------------------+
| 存储方式 | > 随机寻址 | > 内容寻址 | > 内容寻址为主       |
+----------+------------+------------+----------------------+

> 表 8.1 不同领域中记忆模型的不严格类比

###### 结构化的外部记忆

> 为了增强网络容量，一种比较简单的方式是引入结构化的记忆模块，将和任
> 务相关的短期记忆保存在记忆中，需要时再进行读取。这种装备外部记忆的神经
> 网络也称为记忆网络（Memory Network，MN）或记忆增强神经网络（Memory
> Augmented Neural Network，MANN）。
>
> 记忆网络结构如图[8.5](\l)所示，一般有以下几个模块构成：
>
> 外部记忆 M

+---------+---------+---------+---------+---------+---------+---------+
|         |         |         |         |         |         |         |
+---------+---------+---------+---------+---------+---------+---------+
| > 操作  | > ![](/ |         |         |         |         |         |
| > R     | root/au |         |         |         |         |         |
|         | todl-tm |         |         |         |         |         |
|         | p/proje |         |         |         |         |         |
|         | ct_know |         |         |         |         |         |
|         | ledge/D |         |         |         |         |         |
|         | oc_QA/K |         |         |         |         |         |
|         | nowledg |         |         |         |         |         |
|         | e_based |         |         |         |         |         |
|         | /182869 |         |         |         |         |         |
|         | 5663060 |         |         |         |         |         |
|         | 254721/ |         |         |         |         |         |
|         | image_o |         |         |         |         |         |
|         | utput/7 |         |         |         |         |         |
|         | .《神经网络与 |   |         |         |         |         |
|         | 深度学习》/m |    |         |         |         |         |
|         | edia/im |         |         |         |         |         |
|         | age136. |         |         |         |         |         |
|         | png){wi |         |         |         |         |         |
|         | dth="9. |         |         |         |         |         |
|         | 0972222 |         |         |         |         |         |
|         | 2222222 |         |         |         |         |         |
|         | 2e-2in" |         |         |         |         |         |
|         | > heigh |         |         |         |         |         |
|         | t="0.12 |         |         |         |         |         |
|         | 1527777 |         |         |         |         |         |
|         | 7777777 |         |         |         |         |         |
|         | 8in"}   |         |         |         |         |         |
+---------+---------+---------+---------+---------+---------+---------+

**x y**

> 图 8.5 记忆网络结构

1.  主网络*C*：也称为控制器（Controller），负责信息处理，并与外界的交互（接受外界的输入信息并产生输出到外界）。主网络还同时通过读写模
    > 块和外部记忆进行交互。

2.  外部记忆单元*M*
    > ：外部记忆单元用来存储信息，一般可以分为很多记忆片段（Memory
    > Segment），这些记忆片段按照一定的结构来进行组织。记忆片段一般用向量来表示，外部记忆单元可以用一组向量**m**~1:*N*~
    > = \[**m**~1~*,* · · · *,* **m***~N~* \]
    > 来表示。这些向量的组织方式可以是集合、树、栈或队列等。大部分信息存储于外部记忆中，不需要全时参与主网络的运算。

3.  读取模块*R*：根据主网络生成的查询向量**q***~r~*，从外部记忆单元中读取相应的信息**r**
    > = *R*(**m**~1:*N*~ *,* **q***~r~*)。

4.  写入模块*W* ：根据主网络生成的查询向量**q***~w~* 和要写入的信息**a**
    > 来更新外部记忆**m**~1:*N*~ = *W* (**m**~1:*N*~ *,* **q***~w~,*
    > **a**)。

> 这种结构化的外部记忆是带有地址的，即每个记忆片段都可以按地址读取
> 和写入。要实现类似于人脑神经网络的联想记忆能力，就需要按内容寻址的方
> 式进行定位，然后进行读取或写入操作。按内容寻址通常使用注意力机制来进
> 行。通过注意力机制可以实现一种"软性"的寻址方式，即计算一个在所有记
> 忆片段上的分布，而不是一个单一的绝对地址。比如读取模型*R*
> 的实现方式可以为：

*N*

> **r** = *α~i~***m***~i~* (8.23)
>
> *i*=1
>
> *α~i~* = softmax *s*(**m***~i~,* **q***~r~*) *,* (8.24)
>
> 其中**q***~r~* 是主网络生成的查询向量，*s*(·*,* ·)
> 为打分函数。类比于计算机的存储器读取，计算注意力分布的过程相当于是计算机的"寻址"过程，信息加权平均
>
> 的过程相当于计算机的"内容读取"过程。因此，结构化的外部记忆也是一种
> 联想记忆，只是其结构以及读写的操作方式更像是受计算机架构的启发。
>
> 通过引入外部记忆，可以将神经网络的参数和记忆容量的"分离"，即在少
> 量增加网络参数的条件下可以大幅增加网络容量。注意力机制可以看做是一个
> 接口，将信息的存储与计算分离。

###### 典型的记忆网络

> 简单起见，这两组记忆单元
>
> 外部记忆从记忆结构、读写方式等方面可以演变出很多模型。比较典型的
> 结构化外部记忆模型包括端到端记忆网络、神经图灵机等。

1.  端到端记忆网络

> 端到端记忆网络（End-To-End Memory Network，MemN2N）\[[Sukhbaatar](\l)
> [et al.](\l), [2015](\l)\]
> 采用一种可微的网络结构，可以多次从外部记忆中读取信息。在端到端记忆网络中，外部记忆单元是只读的。
>
> 给定一组需要存储的信息*m*~1:*N*~ = {*m*~1~*,* · · · *, m~N~*
> }，首先将转换成两组记忆片段*A* = \[**a**~1~*,* · · · *,* **a***~N~* \]
> 和*C* = \[**c**~1~*,* · · · *,* **c***~N~*
> \]，分别存放在两个外部记忆单元中， 其中*A* 用来进行寻址，*C*
> 用来进行输出。
>
> 可以合并，即*A* = *C*。 主网络根据输入**x**
> 生成**q**，并使用注意力机制来从外部记忆中读取相关信息**r**，
>
> *N*
>
> T
>
> *i*

并产生输出

> *i*=1
>
> **y** = *f* (**q** + **r**)*,* (8.26)
>
> 其中*f* (·) 为预测函数。当应用到分类任务时，*f* (·) 可以设为softmax
> 函数。
>
> 多跳操作
> 为了实现更新复杂的计算，我们可以让主网络和外部记忆进行多轮交互。在第*k*
> 轮交互中，主网络根据上次从外部记忆中读取的信息**r**(*k*−1)，产生新的查询向量
>
> **q**(*k*) = **r**(*k*−1) + **q**(*k*−1)*,* (8.27)
>
> 其中**q**(0) 为初始的查询向量，**r**(0) = 0。
>
> 假设第*k*
> 轮交互的外部记忆为*A*^(*k*)\ 和*C*(*k*)^，主网络从外部记忆读取信息为
>
> **r**(*k*) = Σ softmax((**a**^(*k*)^)T**q**(*k*))**c**^(*k*)^*.*
> (8.28)
>
> 在*K* 轮交互后，用**y** = *f* (**q**(*K*) + **r**(*K*))
> 进行预测。这种多轮的交互方式也称为多跳（Multi-Hop）操作。多跳操作中的参数一般是共享的。为了简化起见，每轮交互的外部记忆也可以共享使用，比如*A*^(1)^
> = · · · = *A*^(*K*)\ 和*C*(1)^ = · · · = *C*^(*K*)^。
>
> 端到端记忆网络结构如图[8.6](\l)所示。
>
> *m*1:*N*
>
> *A*(1) *C*(1) *A*(2) *C*(2) *A*(3) *C*(3)

**x y**

> 图 8.6 端到端记忆网络

2.  神经图灵机

> 图灵机 图灵机（Turing Machine）是图灵在1936 年提出的一种抽象数学模型，
> 可以用来模拟任何可计算问题\[[Turing](\l),
> [1937](\l)\]。图灵机有以下几个组件构成：

1.  一条无限长的纸带：纸带上有一个个方格组成，每个方格可以存储一个
    > 符号；

2.  一个符号表：纸带上可能出现的所有符号的集合，包含一个特殊的空白符。

3.  一个读写头：指向纸带上某个方格的指针，每次可以向左或右移动一个位
    > 置，并可以读取、擦除、写入当前方格中的内容；

4.  一个状态寄存器：用来保存图灵机当前所处的状态，其中包含两个特殊的
    > 状态：起始状态和终止状态；

5.  一套控制规则：根据当前机器所处的状态以及当前读写头所指的方格上的
    > 符号来确定读写头下一步的动作，令机器进入一个新的状态。

> 图灵机的结构如图[8.7](\l)所示，其中控制器包括状态寄存器、控制规则。

####### 纸带

> ... ...

####### 读写头

> 图 8.7 图灵机结构示例
>
> 神经图灵机 神经图灵机（Neural Turing machine，NTM）\[[Graves et
> al.](\l), [2014](\l)\]
> 主要由两个部件构成：控制器和外部记忆。外部记忆定义为矩阵*M* ∈ R*d*×*N*
> ，这里*N* 是记忆片段的数量，*d*
> 是每个记忆片段的大小。控制器为一个前馈或循环神经网络。神经图灵机中的外部记忆是可以可读写的，其结构如图[8.8](\l)所示。
>
> 图 8.8 神经图灵机示例
>
> 在每个时刻*t*，控制器接受当前时刻的输入**x***~t~*，上一时刻的输出**h**~*t*−1~
> 和上一时刻从外部记忆中读取的信息**r**~*t*−1~，并产生输出**h***~t~*，同时生成和读写外部记忆相关的三个向量：查询向量**q***~t~*，删除向量**e***~t~*
> 和增加向量**a***~t~*。然后对外部记忆M*~t~*
> 进行读写操作，生成读向量**r***~t~*，和新的外部记忆*M~t~*~+1~。
>
> 读操作 在时刻*t*, 外部记忆的内容记为*M~t~* = \[**m**~*t,*1~*,* · · ·
> *,* **m***~t,n~*\]，读操作为从外部记忆M*~t~* 中读取信息**r***~t~* ∈
> R*d*。
>
> 首先通过注意力机制来进行基于内容的寻找，即
>
> *α~t,i~* = softmax(*s*(**m***~t,i~,* **q***~t~*)) (8.29)
>
> 其中**q***~t~*
> 为控制器产生的查询向量，用来进行基于内容的寻址。*s*(·*,* ·) 为加性或乘
>
> 神经图灵机中还实现了比较
> 复杂的基于位置的寻址方式。这里我们只介绍比较简单的
> 基于内容寻址方式，整个框 架不变。
>
> 性的打分函数。注意力分布*α~t,i~* 是记忆片段**m***~t,i~*
> 对应的权重，并满足 Σ*n*
>
> *αt,i* =
>
> 1。
>
> 根据注意力分布*α~t~*，可以计算读向量（read vector）**r***~t~*
> 作为下一个时刻控
>
> 制器的输入。
>
> *n*
>
> **r***~t~* = *α~i~***m***~t,i~.* (8.30)
>
> *i*=1
>
> 写操作 外部记忆的写操作可以分解为两个子操作：删除和增加。
>
> 首先，控制器产生删除向量（erase vector）**e***~t~* 和增加向量（add
> vector）**a***~t~*， 分别为要从外部记忆中删除的信息和要增加的信息。
>
> 删除操作是根据注意力分布来按比例地在每个记忆片段中删除**e***~t~*，增加操作根据注意力分布来进行按比例地给每个记忆片段加入**a***~t~*。
>
> **m**~*t*+1*,i*~ = **m***~t,i~*(**1** − *α~t,i~***e***~t~*) +
> *α~t,i~***a***~t~,* ∀*i* ∈ \[1*, n*\]*.* (8.31)
>
> 通过写操作得到下一时刻的外部记忆M~*t*+1~。

###### 基于神经动力学的联想记忆

> 结构化的外部记忆更多是受现代计算机架构的启发，将计算和存储功能进
> 行分离，这些外部记忆的结构也缺乏生物学的解释性。为了具有更好的生物学
> 解释性，还可以将基于神经动力学（Neurodynamics）的联想记忆模型引入到神
> 经网络以增加网络容量。
>
> 联想记忆模型（Associative Memory
> Model）主要是通过神经网络的动态演化来进行联想，有两种应用场景：1）输入的模式和输出的模式在同一空间，这种模型叫做自联想记忆模型（Auto-Associative
> Model）。自联想模型可以通过前馈神经网络或者循环神经网络来实现，也经常称为自编码器（Auto-Encoder）
>
> ；2）输入的模式和输出的模式不在同一空间，这种模型叫做异联想记忆模型
>
> （Hetero-Associative
> Model）。从广义上讲，大部分模式识别问题都可以看作是异联想，因此异联想记忆模型可以作为分类器使用。
>
> 联想记忆模型可以看做是一种循环神经网络，基于神经动力学来实现按内
> 容寻址的信息存储和检索。一个经典的联想记忆模型为Hopﬁeld 网络。
>
> 神经动力学是将神经网络作为非线性动力系统，研究其随时间变化的规律以及稳定性等问题。

1.  **Hopﬁeld** 网络

> 本书中之前介绍的神经网络都是作为一种机器学习模型的输入-输出映射
> 函数，其参数学习方法是通过梯度下降方法来最小化损失函数。除了作为机器
> 学习模型外，神经网络还可以作为一种记忆的存储和检索模型。
>
> *Hopﬁeld* 网络（Hopﬁeld
> Network）是一种循环神经网络模型，由一组相互连接的神经元组成。Hopﬁeld
> 网络也可以认为是所有神经元都相互连接的不分层的神经网络。每个神经元既是输入单元，又是输出单元，没有隐藏神经元。一个神经元和自身没有反馈相连，不同神经元之间连接权重是对称的。
>
> 图[8.9](\l)给出了Hopﬁeld 网络的结构示例。
>
> 这里我们只介绍离散 Hop- ﬁeld 网络， 神经元状态为
>
> +1*,* −1 两种。除此之外，还
>
> 图 8.9 四个节点的Hopﬁeld 网络
>
> 假设一个Hopﬁeld 网络有*m* 个神经元，第*i* 个神经元的更新规则为
>
> 有连续Hopﬁeld 网络，即神经元状态为连续值。

*s~i~* =

>  +1 if Σ*m*
>
> *w~ij~s~j~* + *b~i~* ≥ 0*,*
>
> (8.32)
>
>  −1 otherwise,
>
> 其中*w~ij~* 为神经元*i* 和*j* 之间的连接权重，*b~i~*
> 为偏置。连接权重*w~ij~* 有以下性质
>
> *w~ii~* = 0 ∀*i* ∈ \[1*, m*\] *w~ij~* = *w~ji~* ∀*i, j* ∈ \[1*,
> m*\]*.*
>
> (8.33)
>
> Hopﬁeld
> 网络的更新可以分为异步和同步两种方式。异步更新是每次更新一个神经元。神经元的更新顺序可以是随机或事先固定的。同步更新是指一次
>
> 更新所有的神经元，需要有一个时钟来进行同步。第*t*
> 时刻的神经元状态为**s***~t~* = \[**s**~*t,*1~*,* **s**~*t,*2~*,* · · ·
> *,* **s***~t,m~*\]T，其更新规则为
>
> **s***~t~* = *f* (*W* **s**~*t*−1~ + **b**)*,* (8.34)
>
> 其中**s**~0~ = **x**，*W* = \[*w~ij~*\]~*m*×*m*~ 为连接权重，**b** =
> \[*b~i~*\]~*m*×1~ 为偏置向量，*f* (·) 为非线性阶跃函数。
>
> 能量函数 在Hopﬁeld 网络中，我们给每个不同的网络状态定义一个标量属性，
> 称为"能量"。

*E* = − [1]{.underline} Σ *w*

> *s s* − Σ *b s*
>
> (8.35)
>
> = − [1]{.underline} **s**T*W* **s** − **b**T**s***.* (8.36)
>
> Hopﬁeld
> 网络是稳定的，即能量函数经过多次迭代后会达到收敛状态。权重对称是一个重要特征，因为它保证了能量函数在神经元激活时单调递减，而不对
> 称的权重可能导致周期性震荡或者混乱。
>
> 给定一个外部输入，网络经过演化，会达到某个稳定状态。这些稳定状态
> 称为吸引点（Attractor）。一个Hopﬁeld
> 网络中，通常有多个吸引点，每个吸引点为一个能量的局部最优点。
>
> 图[8.10](\l)给出了Hopﬁeld
> 网络的能量函数。红线为网络能量的演化方向，蓝点为吸引点。
>
> 能量函数 *E* 是 Hopﬁeld 网络的 Lyapunov 函数。Lya- punov
> 定理是非线性动力系统中保证系统稳定性的充分条件。
>
> *E*

**s**

> 图 8.10 Hopﬁeld 网络的能量函数
>
> 联想记忆 Hopﬁeld
> 网络存在有限的吸引点（Attractor），即能量函数的局部最小点。每个吸引点**u**
> 都对应一个"管辖"区域𝑌**~u~**，如果输入向量**x**
> 落入这个区域，网络最终会收敛到**u**。因此，吸引点可以看作是网络中存储的信息。将网
> 络输入**x** 作为起始状态，随时间收敛到吸引点**u**
> 上的过程作为检索过程。即使输入向量**x**
> 是有部分信息或有噪声，只用其位于对应存储模式的"吸引"区域
>
> 内，那么随着时间演化，网络最终会收敛到其对应的存储模式。因此，Hopﬁeld
> 的检索是基于内容寻址的检索，具有联想记忆能力。
>
> 信息存储 信息存储是指将一组向量 **x**~1~*,* · · · *,* **x***~N~*
> 存储在网络中的过程。存储过程主要是调整神经元之间的连接权重，因此可以看做是一种学习过程。Hopﬁeld
> 网络的学习规则有很多种。一种最简单的学习方式为：神经元 *i* 和 *j*
> 之间的连接权重

*w* = [1]{.underline} Σ

> (*n*)
>
> (*n*)
>
> (8.37)
>
> *~ij~ xi xj ,*
>
> *n*=1
>
> 其中*x*^(*n*)\ 是第*n*\ 个输入向量的第*i*\ 维特征。如果*x*^*~i~*
> 和*x~j~* 在输入向量中相同的概率越多，则*w~ij~*
> 越大。这种学习规则和人脑神经网络的学习方式十分类似。在人脑神经网络中，如果两个神经元经常同时激活，则它们之间的连接加强；如果
> 经常不同时激活，则连接消失。这种学习方式称为*Hebbian* 法则。
>
> 存储容量
> 对于联想记忆模型来说，存储容量为其能够可靠地存储和检索模式的最大数量。对于数量为*m*
> 的相互连接的二值神经元网络，其总状态数2*m*，其中可以作为有效稳定点的状态数量就是其存储容量。模型容量一般与网络结构和学习方式有关。Hopﬁeld
> 最大的网络容量为0*.*14*m*，玻尔兹曼机的容量为0*.*6*m*，
> 但是其学习效率比较低，需要非常长时间的演化才能达到均衡状态。通过改进学习算法，Hopﬁeld
> 网络的最大容量可以达到*O*(*m*)。如果允许高阶（阶数为*K*）
> 连接，比如三个神经元连接关系，其稳定存储的最大容量为
> *O*(*m^K^*^−1^)。[Plate](\l) \[[1995](\l)\]
> 引入复数运算，有效地提高了网络容量。总体上讲，通过改进网络结构、学习方式以及引入更复杂的运算（比如复数、量子操作），联想记忆网络的容量可以有效改善。

2.  使用联想记忆增加网络容量

> 既然联想记忆具有存储和检索功能，我们可以利用联想记忆来增加网络容
> 量。和结构化的外部记忆相比，联想记忆具有更好的生物学解释性。[Danihelka](\l)
> [et al.](\l) \[[2016](\l)\] 将一个联想记忆模型作为部件引入LSTM
> 网络中，而从在不引入额外参数的情况下增加网络容量。[Ba et al.](\l)
> \[[2016](\l)\]
> 将循环神经网络中的部分连接权重作为短期记忆，并通过一个联想记忆模型进行更新，而从提高网络性能。在
> 上述的网络中，联想记忆都是作为一个更大网络的组件，用来增加短期记忆的
> 容量。联想记忆组件的参数可以使用Hebbian
> 方式来学习，也可以作为整个网络参数的一部分来进行学习。
>
> 8.4 总结和深入阅读 2019 年 4 月 6 日 217
>
> **8.4** 总结和深入阅读
>
> 注意力机制是一种（不严格的）受人类神经系统启发的信息处理机制。比
> 如人视觉神经系统并不会一次性地处理所有接受到的视觉信息。
>
> 注意力机制最早在计算机视觉中提出。在神经网络中，[Mnih et al.](\l)
> \[[2014](\l)\]
> 在循环神经网络模型上使用了注意力机制来进行图像分类。[Bahdanau et
> al.](\l) \[[2014](\l)\]
> 使用注意力机制在机器翻译任务上将翻译和对齐同时进行。[Xu et al.](\l)
> \[[2015](\l)\]
> 利用注意力机制来进行图片的内容描述。目前，注意力机制已经在语音识别、图像标题生成、阅读理解、文本分类、机器翻译等多个任务上取得了很好的效果，也变得越来越流行。注意力机制的一个重要应用是自注意力。自注意力可以作为神经网络中的一层来使用，有效地建模长距离依赖问题\[[Vaswani
> et al.](\l), [2017](\l)\]。
>
> 通过引入外部记忆，神经网络在一定程度上可以解决模型容量问题。外部记忆的代表性模型有神经图灵机\[[Graves
> et al.](\l), [2014](\l)\]、端到端记忆网络\[[Sukhbaatar](\l) [et
> al.](\l), [2015](\l)\]、动态记忆网络\[[Kumar et al.](\l), [2016](\l)\]
> 等。这类引入外部记忆的模型也称为记忆增强网络（Memory-Enhanced
> Networks）。此外，基于神经动力学的联想记忆也可以作为一种外部记忆，并具有更好的生物学解释性。[Hopﬁeld](\l)
> \[[1984](\l)\] 将能量函数的概念引入到神经网络模型中，提出了Hopﬁeld
> 网络。Hopﬁeld 网络在旅行商问题上获得当时最好结果，引起轰动。[Danihelka
> et al.](\l) \[[2016](\l)\] 将一个联想记忆模型作为部件引入LSTM
> 网络中，而从在不引入额外参数的情况下增加网络容量。[Ba et al.](\l)
> \[[2016](\l)\] 将循环神经网络中的部分连接权重作为短期记忆，
> 并通过一个联想记忆模型进行更新，而从提高网络性能。目前人工神经网络中的外部记忆模型结构还比较简单，需要借鉴神经科学的研究成果，提出更有效的记忆模型，增加网络容量。

#### 习题

> 习题 **8-1** 分析LSTM 模型中，隐藏层神经元数量与参数数量之间的关系。
>
> 习题 **8-2** 分析缩放点积模型可以缓解softmax 函数梯度消失的原因。
>
> 习题**8-3**
> 当用自注意力模型作为一个神经层使用时，分析它和卷积层以及循环层在建模长距离依赖关系的效率和计算复杂度方面的差异。
>
> 习题 **8-4** 证明Hopﬁeld 网络的能量函数随时间单调递减。
>
> 参见公式([8.4](\l))。
>
> 参见第[8.2.2](\l)节。
>
> 218 2019 年 4 月 6 日 参考文献

#### 参考文献

> Jimmy Ba, Geoﬀrey E Hinton, Volodymyr Mnih, Joel Z Leibo, and Catalin
> Ionescu. Using fast weights to attend to the recent past. In *Advances
> In Neural Information* *Processing Systems*, pages 4331--4339, 2016.
>
> Dzmitry Bahdanau, Kyunghyun Cho, and Yoshua Bengio. Neural machine
> translation by jointly learning to align and translate. *ArXiv
> e-prints*, September 2014.
>
> Ivo Danihelka, Greg Wayne, Benigno Uria, Nal Kalchbrenner, and Alex
> Graves. As- sociative long short-term memory. In *Pro- ceedings of the
> 33nd International Confer- ence on Machine Learning*, pages 1986--
> 1994, 2016.
>
> Alex Graves, Greg Wayne, and Ivo Dani- helka. Neural turing machines.
> *arXiv* *preprint arXiv:1410.5401*, 2014.
>
> John J Hopﬁeld. Neurons with graded re- sponse have collective
> computational prop- erties like those of two-state neurons. *Pro-
> ceedings of the national academy of sci-* *ences*, 81(10):3088--3092,
> 1984.
>
> Yoon Kim, Carl Denton, Luong Hoang, and Alexander M Rush. Structured
> attention networks. *arXiv preprint* *arXiv:1702.00887*, 2017.
>
> Teuvo Kohonen. *Self-organization and as- sociative memory*, volume 8.
> Springer Sci- ence & Business Media, 2012.
>
> Ankit Kumar, Ozan Irsoy, Peter Ondruska, Mohit Iyyer, James Bradbury,
> Ishaan Gul- rajani, Victor Zhong, Romain Paulus, and Richard Socher.
> Ask me anything: Dynamic memory networks for natural language pro-
> cessing. In *Proceedings of the 33nd Inter- national Conference on
> Machine Learning*, pages 1378--1387, 2016.
>
> Volodymyr Mnih, Nicolas Heess, Alex Graves, et al. Recurrent models of
> visual attention. In *Advances in Neural Informa- tion Processing
> Systems*, pages 2204--2212, 2014.
>
> Tony A Plate. Holographic reduced repre- sentations. *IEEE
> Transactions on Neural* *networks*, 6(3):623--641, 1995.
>
> Tao Shen, Tianyi Zhou, Guodong Long, Jing Jiang, Shirui Pan, and
> Chengqi Zhang. DiSAN: Directional self-attention network for
> RNN/CNN-free language understand- ing. In *Proceedings of the
> Thirty-Second AAAI Conference on Artiﬁcial Intelligence*, pages
> 5446--5455, 2018.
>
> Sainbayar Sukhbaatar, Jason Weston, Rob Fergus, et al. End-to-end
> memory networks. In *Advances in Neural Information Process-* *ing
> Systems*, pages 2431--2439, 2015.
>
> Richard F Thompson. *Introduction to phys- iological psychology*.
> HarperCollins Publish- ers, 1975.
>
> Alan M Turing. On computable num- bers, with an application to the
> entschei- dungsproblem. *Proceedings of the London* *mathematical
> society*, 2(1):230--265, 1937. Ashish Vaswani, Noam Shazeer, Niki
> Parmar, Jakob Uszkoreit, Llion Jones, Aidan N. Gomez, Lukasz Kaiser,
> and Illia Polosukhin. Attention is all you need. In *Advances in
> Neural Information Processing* *Systems*, pages 6000--6010, 2017.
>
> Oriol Vinyals, Meire Fortunato, and Navdeep Jaitly. Pointer networks.
> In *Ad- vances in Neural Information Processing* *Systems*, pages
> 2692--2700, 2015.
>
> Kelvin Xu, Jimmy Ba, Ryan Kiros, Kyunghyun Cho, Aaron Courville, Rus-
> lan Salakhudinov, Rich Zemel, and Yoshua Bengio. Show, attend and
> tell: Neural im- age caption generation with visual atten- tion. In
> *Proceedings of the International Conference on Machine Learning*,
> pages 2048--2057, 2015.
>
> Zichao Yang, Diyi Yang, Chris Dyer, Xi- aodong He, Alexander J Smola,
> and Ed- uard H Hovy. Hierarchical attention net- works for document
> classiﬁcation. In *HLT- NAACL*, pages 1480--1489, 2016.

第**9** 章 无监督学习
=====================

> 大脑有大约1014 个突触，我们只能活大约109
> 秒。所以我们有比数据更多的参数。这启发了我们必须进行大量无监督学习
> 的想法，因为感知输入（包括本体感受）是我们可以获得每秒 105
> 维约束的唯一途径。
>
> --- Geoﬀrey Hinton, 2014 AMA on Reddit 更早的正式描述见\[[Hinton](\l)

[et al.](\l), [1999](\l)\]

> 无监督学习（Unsupervised
> Learning）是指从无标签的数据中学习出一些有用的模式。无监督学习算法一般直接从原始数据中学习，不借助于任何人工给出标签或者反馈等指导信息。如果监督学习是建立输入*-*输出之间的映射关
> 系，无监督学习就是发现隐藏的数据中的有价值信息，包括有效的特征、类别、
> 结构以及概率分布等。
>
> 典型的无监督学习问题可以分为以下几类：
>
> 无监督特征学习 无监督特征学习（Unsupervised Feature
> Learning）是从无标签的训练数据中挖掘有效的特征或表示。无监督特征学习一般用来进行
> 降维、数据可视化或监督学习前期的数据预处理。
>
> 密度估计 密度估计（Density
> Estimation）是根据一组训练样本来估计样本空间的概率密度。密度估计可以分为参数密度估计和非参数密度估计。参
> 数密度估计是假设数据服从某个已知概率密度函数形式的分布（比如高
> 斯分布），然后根据训练样本去估计概率密度函数的参数。非参数密度估计是不假设数据服从某个已知分布，只利用训练样本对密度进行估计，可
> 以进行任意形状密度的估计。非参数密度估计的方法有直方图、核密度估
> 计等。
>
> 聚类
> 聚类（Clustering）是将一组样本根据一定的准则划分到不同的组（也称为集群（Cluster））。一个比较通用的准则是组内的样本的相似性要高于组间样本的相似性。常见的聚类算法包括K-Means
> 算法、谱聚类等。
>
> 特征学习也包含很多的监督学习算法，比如线性判别分析等。
>
> 和监督学习一样，无监督学习方法也包含三个基本要素：模型、学习准则和优化算法。无监督学习的准则非常多，比如最大似然估计、最小重构错误等。
> 在无监督特征学习中，经常使用的准则为最小化重构错误，同时也经常对特征进行一些约束，比如独立性、非负性或稀释性等。而在密度估计中，经常采用最大似然估计来进行学习。
>
> 本章介绍两种无监督学习问题：无监督特征学习和密度估计。
>
> **9.1** 无监督特征学习
>
> 无监督特征学习是指从无标注的数据中自动学习有效的数据表示，从而能
> 够帮助后续的机器学习模型更快速地达到更好的性能。无监督特征学习主要方
> 法有主成分分析、稀疏编码、自编码器等。

###### 主成分分析

> 主成份分析（Principal Component
> Analysis，PCA）一种最常用的数据降维方法，使得在转换后的空间中数据的方差最大。如图[9.1](\l)所示的两维数据，如
> 果将这些数据投影到一维空间中，选择数据方差最大的方向进行投影，才能最
> 大化数据的差异性，保留更多的原始数据信息。
>
> 图 9.1 主成分分析
>
> 假设有一组*d* 维的样本**x**(*n*) ∈ R*d,* 1 ≤ *n* ≤ *N*
> ，我们希望将其投影到一维空间中，投影向量为 **w** ∈
> R*d*。不失一般性，我们限制**w** 的模为1，即**w**T**w** = 1。
>
> 每个样本点 **x**(*n*) 投影之后的表示为
>
> *𝑥*^(*n*)^ = **w**T**x**(*n*)*.* (9.1)
>
> 我们用矩阵*X* = \[**x**(1)*,* **x**(2)*,* · · · *,* **x**(*N* )\]
> 表示输入样本，**x**¯ = [ 1]{.underline} Σ*N*
>
> **x**(*n*) 为原始

*σ*(*X*; **w**) =

> Σ(**w**T**x**(*n*) − **w**T**x**¯)2 (9.2)
>
> *N n*=1
>
> = [ 1]{.underline} (**w**T*X* − **w**T*X*¯ )(**w**T*X* − **w**T*X*¯ )T
> (9.3)
>
> = **w**T*S***w***,* (9.4)
>
> 其中*X*¯ = **x**¯**1**T 为*d* 列**x**¯ 组成的矩阵，*S* = [
> 1]{.underline} (*X* − *X*¯ )(*X* − *X*¯ )T 是原始样本的协
>
> *d N*
>
> 方差矩阵。
>
> 最大化投影方差*σ*(*X*; *w*) 并满足**w**T**w** =
> 1，利用拉格朗日方法转换为无约束优化问题，
>
> max **w**T*S***w** + *λ*(1 **w**T**w**)*,* (9.5)

**w**

> 其中*λ* 为拉格朗日乘子。对上式求导并令导数等于0，可得

*S***w** = *λ***w***.* (9.6)

> 从上式可知，**w** 是协方差矩阵*S* 的特征向量，*λ* 为特征值。同时

*σ*(*X*; *w*) = **w**T*S***w** = **w**T*λ***w** = *λ.* (9.7)

> *λ* 也是投影后样本的方差。因此，主成分分析可以转换成一个矩阵特征值分解
> 问题，投影向量**w** 为矩阵*S* 的最大特征对应的特征向量。
>
> 如果要通过投影矩阵*W* ∈ *R^d^*^×*d*^′
> 将样本投到*d*^′\ 维空间，投影矩阵满足*W*\ T*W*\ =\ **I**，只需要将*S*\ 的特征值从大到小排列，保留前*d*′\ 个特征向量，其对应的特征向量即使最优的投影矩阵。^
>
> *SW* = *W* diag(Λ)*,* (9.8)
>
> 其中Λ = \[*λ*~1~*,* · · · *, λ~d~*′ \] 为*S*
> 的前*d*^′\ 个最大的特征值。^
>
> 主成分分析是一种无监督学习方法，可以作为监督学习的数据预处理方法，
> 用来去除噪声并减少特征之间的相关性，但是它并不能保证投影后数据的类别可分性更好。提高两类可分性的方法一般为监督学习方法，比如线性判别分析
>
> （Linear Discriminant Analysis，LDA）。
>
> 参见习题[9-3](\l)。
>
> 带通滤波（bandpass ﬁlter） 是指容许某个频率范围的信
> 号通过，同时屏蔽其他频段 的设备。

######  稀疏编码

> 稀疏编码（Sparse
> Coding）也是一种受哺乳动物视觉系统中简单细胞感受野而启发的模型。在哺乳动物的初级视觉皮层（primary
> visual
> cortex）中，每个神经元仅对处于其感受野中特定的刺激信号做出响应，比如特定方向的边缘、
> 条纹等特征。局部感受野可以被描述为具有空间局部性、方向性和带通性（即不同尺度下空间结构的敏感性）\[[Olshausen
> et al.](\l),
> [1996](\l)\]。也就是说，外界信息经过编码后仅有一小部分神经元激活，即外界刺激在视觉神经系统的表示具有很高的稀疏性。编码的稀疏性在一定程度上符合生物学的低功耗特性。
>
> 在数学上，（线性）编码是指给定一组基向量*A* = \[**a**~1~*,* · · · *,*
> **a***~p~*\]，将输入样本**x** ∈ R*d* 表示为这些基向量的线性组合

*p*

**x** = *𝑥~i~***a***~i~* (9.9)

> *i*=1

= *A***z***,* (9.10)

> 其中基向量的系数**z** = \[*𝑥*~1~*,* · · · *, 𝑥~p~*\] 称为输入样本**x**
> 的编码（encoding），基向量*A* 也称为字典（dictionary）。
>
> 编码是对*d* 维空间中的样本**x** 找到其在*p*
> 维空间中的表示（或投影），其目标通常是编码的各个维度都是统计独立的，并且可以重构出输入样本。编码的
> 关键是找到一组"完备"的基向量*A*，比如主成分分析等。但是主成分分析得到编码通常是稠密向量，没有稀疏性。
>
> 为了得到稀疏的编码，我们需要找到一组"超完备"的基向量（即*p \> d*）
> 来进行编码。在超完备基向量之间往往会存在一些冗余性，因此对于一个输入样本，会存在很多有效的编码。如果加上稀疏性限制，就可以减少解空间的大小，得到"唯一"的稀疏编码。
>
> 给定一组*N* 个输入向量**x**(1)*,* · · · *,* **x**(*N*
> )，其稀疏编码的目标函数定义为：

( ) = Σ

> ¨**x**( )
>
> **z**( )¨ +
>
> (**z**( ))
>
> (9.11)
>
> 其中*ρ*(·) 是一个稀疏性衡量函数，*η*
> 是一个超参数，用来控制稀疏性的强度。对于一个向量**z** ∈
> R*p*，其稀疏性定义为非零元素的比例。如果一个向量只
>
> 有很少的几个非零元素，就说这个向量是稀疏的。稀疏性衡量函数*ρ*(**z**)
> 是给向量**z** 一个标量分数。**z** 越稀疏，*ρ*(**z**) 越小。
>
> 稀疏性衡量函数有多种选择，最直接的衡量向量**z** 稀疏性的函数是*ℓ*~0~
> 范式
>
> *ρ*(**z**) = Σ **I**(\|*𝑥~i~*\| *\>* 0)) (9.12)
>
> 严格的稀疏向量有时比较难 以得到，因此如果一个向量
> 只有少数几个远大于零的元
> 素，其它元素都接近于0，我们也称这个向量为稀疏向量。
>
> *i*=1
>
> 但*ℓ*~0~
> 范数不满足连续可导，因此很难进行优化。在实际中，稀疏性衡量函数通常使用*ℓ*~1~
> 范数
>
> 或对数函数
>
> *p*
>
> *ρ*(**z**) = *𝑥~i~* (9.13)
>
> *i*=1

*p*

> 2
>
> *i*
>
> *i*=1
>
> 或指数函数

*p*

> 2
>
> *i*

1.  训练方法

> *i*=1
>
> 给定一组*N* 个输入向量**x**(1)*,* · · · *,* **x**(*N*
> )，需要同时学习基向量*A* 以及每个输入样本对应的稀疏编码**z**(1)*,* · ·
> · *,* **z**(*N* )。
>
> 稀疏编码的训练过程一般用交替优化的方法进行。

1.  固定基向量*A*，对每个输入**x**(*n*)，计算其对应的最优编码

> **x**(*n*) ¨

2.  固定上一步得到的编码**z**(1)*,* · · · *,* **z**(*N*
    > )，计算其最优的基向量

min Σ

> ¨**x**(*n*)
>
> **z**(*n*)¨2 + [1]{.underline} 2
>
> (9.17)
>
> *A n*=1 ¨ − ¨

*A*

> *λ* 2 ∥*A*∥ *,*
>
> 其中第二项为正则化项，*λ* 为正则化项系数。

2.  稀疏编码的优点

> 稀疏编码的每一维都可以看作是一种特征。和基于稠密向量的分布式表示
> 相比，稀疏编码具有更小的计算量和更好的可解释性等优点。
>
> 计算量 稀疏性带来的最大好处就是可以极大地降低计算量。
>
> 可解释性
> 因为稀疏编码只有少数的非零元素，相当于将一个输入样本表示为少数几个相关的特征。这样我们可以更好地描述其特征，并易于理解。
>
> 特征选择
> 稀疏性带来的另外一个好处是可以实现特征的自动选择，只选择和输入样本相关的最少特征，从而可以更好地表示输入样本，降低噪声并减轻过
> 拟合。

###### 自编码器

> 自编码器（Auto-Encoder，AE）是通过无监督的方式来学习一组数据的有
> 效编码（或表示）。
>
> 假设有一组*d* 维的样本**x**(*n*) ∈ R*d,* 1 ≤ *n* ≤ *N*
> ，自编码器将这组数据映射到特征空间得到每个样本的编码**z**(*n*) ∈ R*p,*
> 1 ≤ *n* ≤ *N* ，并且希望这组编码可以重构出原来的样本。
>
> 自编码器的结构可分为两部分：
>
> 编码器（encoder）
>
> 和解码器（decoder）
>
> *f* : R*^d^* → R*^p^,* (9.18)
>
> *g* : R*^p^* → R*^d^.* (9.19)
>
> 自编码器的学习目标是最小化重构错误（reconstruction errors）
>
> *N*
>
> = **x**(*n*) *g*(*f* (**x**(*n*))) 2 (9.20)
>
> *n*=1 *N*
>
> = **x**(*n*) *f g*(**x**(*n*)) 2*.* (9.21)
>
> *n*=1
>
> 单位函数*I*(*x*) = *x*。
>
> 如果特征空间的维度*p*
> 小于原始空间的维度*d*，自编码器相当于是一种降维或特征抽取方法。如果*p*
> ≥ *d*，一定可以找到一组或多组解使得*f* ◦ *g* 为单位函数（Identity
> Function），并使得重构错误为0。但是，这样的解并没有太多的意义。但是如果再加上一些附加的约束，就可以得到一些有意义的解，比如编
>
> 码的稀疏性、取值范围，*f* 和*g* 的具体形式等。如果我们让编码只能取*k*
> 个不同的值(*k \< N* )，那么自编码器就可以转换为一个*k*
> 类的聚类（Clustering）问题。
>
> 最简单的自编码器是如图[9.2](\l)所示的两层神经网络。输入层到隐藏层用来编
> 码，隐藏层到输出层用来解码，层与层之间互相全连接。

####### ![](/root/autodl-tmp/project_knowledge/Doc_QA/Knowledge_based/1828695663060254721/image_output/7.《神经网络与深度学习》/media/image160.png)编码器 解码器

> 图 9.2 两层网络结构的自编码器对于样本**x**，中间隐藏层为编码
>
> **z** = *s*(*W* ^(1)^**x** + *b*^(1)^)*,* (9.22)
>
> 输出为重构的数据
>
> **x**′ = *s*(*W* ^(2)^**z** + *b*^(2)^)*,* (9.23)
>
> 其中*W, b* 为网络参数，*s*(·) 为激活函数。如果令*W* ^(2)^ 等于*W*
> ^(1)^ 的转置，即*W* ^(2)^ =
>
> *W* ^(1)^T，称为捆绑权重（tied weights）。
>
> 给定一组样本**x**(*n*) ∈ \[0*,* 1\]*d,* 1 ≤ *n* ≤ *N* ，其重构错误为

*N*

> (*n*) (*n*) 2 2
>
> *F*
>
> *n*=1
>
> 其中*λ* 为正则化项系数。通过最小化重构错误，可以有效地学习网络的参数。
>
> 我们使用自编码器是为了得到有效的数据表示，因此在训练结束后，我们
> 一般去掉解码器，只保留编码器。编码器的输出可以直接作为后续机器学习模
> 型的输入。

###### 稀疏自编码器

> 自编码器除了可以学习低维编码之外，也学习高维的稀疏编码。假设中间
> 隐藏层**z** 的维度为*p* 大于输入样本**x** 的维度*d*，并让**z**
> 尽量稀疏，这就是稀疏自
>
> 编码器（Sparse
> Auto-Encoder）。和稀疏编码一样，稀疏自编码器的优点是有很高的可解释性，并同时进行了隐式的特征选择。
>
> 通过给自编码器中隐藏层单元**z**
> 加上稀疏性限制，自编码器可以学习到数据中一些有用的结构。

*N*

> = **x**(*n*) **x**′(*n*)) 2 + *ηρ*(**z**(*n*))) + *λ W* ^2^*,* (9.25)
>
> *n*=1
>
> 其中*ρ*(·) 为稀疏性度量函数，*W* 表示自编码器中的参数。
>
> 稀疏性度量函数*ρ*(·) 除了可以选择公式([9.13](\l))∼([9.15](\l))
> 的定义外，还可以定义为一组训练样本中每一个神经元激活的频率。
>
> 给定*N* 个训练样本，隐藏层第*j* 个神经元平均活性值为

*ρ*ˆ*~j~*

> = [1]{.underline}
>
> *N*
>
> *n*Σ=1

*𝑥*(*n*)*,*

> (9.26)
>
> *ρ*ˆ*~j~* 可以近似地看作是第*j* 个神经元激活的概率。我们希望*ρ*ˆ*~j~*
> 接近于一个事先给定的值*ρ*^∗^，比如0*.*05，可以通过KL
> 距离来衡量*ρ*ˆ*~j~* 和*ρ*^∗^ 的差异，即
>
> KL(*ρ*^∗^\|\|*ρ*ˆ ) = *ρ*^∗^ log *ρ*∗ + (1 − *ρ*^∗^) log 1 − *ρ*∗ *.*
> (9.27)

*j*

> 如果*ρ*ˆ*~j~* = *ρ*^∗^，则KL(*ρ*^∗^\|\|*ρ*ˆ*~j~*) =
> 0。稀疏性度量函数定义为
>
> *ρ*ˆ*~j~*
>
> 1 − *ρ*ˆ*~j~*
>
> *p*
>
> *ρ*(**z**(*n*)) = KL(*ρ*^∗^ *ρ*ˆ*~j~*)*.* (9.28)
>
> *j*=1

###### 堆叠自编码器

> 对于很多数据来说，仅使用两层神经网络的自编码器还不足以获取一种好
> 的数据表示。为了获取更好的数据表示，我们可以使用更深层的神经网络。深
> 层神经网络作为自编码器提取的数据表示一般会更加抽象，能够更好地捕捉到
> 数据的语义信息。在实践中经常使用逐层堆叠的方式来训练一个深层的自编码
> 器，称为堆叠自编码器（Stacked
> Auto-Encoder，SAE）。堆叠自编码一般可以采用逐层训练（layer-wise
> training）来学习网络参数\[[Bengio et al.](\l), [2007](\l)\]。

###### 降噪自编码器

> 我们使用自编码器是为了得到有效的数据表示，而有效的数据表示除了具
> 有最小重构错误或稀疏性等性质之外，我们还可以要求其具备其它性质，比如
> 对数据部分损坏（partial
> destruction）的鲁棒性。高维数据（比如图像）一般
>
> 都具有一定的信息冗余，比如我们可以根据一张部分破损的图像联想出其完整
> 内容。因此，我们希望自编码器也能够从部分损坏的数据中得到有效的数据表
> 示，并能够恢复出完整的原始信息。
>
> 降噪自编码器（Denoising
> Autoencoder）就是一种通过引入噪声来增加编码鲁棒性的自编码器\[[Vincent
> et al.](\l), [2008](\l)\]。对于一个向量**x**，我们首先根据一个比例*µ*
> 随机将**x**
> 的一些维度的值设置为0，得到一个被损坏的向量**x**˜。然后将被损坏的向量**x**˜
> 输入给自编码器得到编码**z**，并重构出原始的无损输入**x**。
>
> 图[9.3](\l)给出了自编码器和降噪自编码器的对比，其中*f~θ~*
> 为编码器，*g~θ~*′ 为解码器，L(**x***,* **x**′) 为重构错误。
>
> 损坏比例 *µ* 一般不超过 0.5。也可以使用其它的方法来损
> 坏数据，比如引入高斯噪声。
>
> *f*θ
>
> ![](/root/autodl-tmp/project_knowledge/Doc_QA/Knowledge_based/1828695663060254721/image_output/7.《神经网络与深度学习》/media/image167.png)
> ![](/root/autodl-tmp/project_knowledge/Doc_QA/Knowledge_based/1828695663060254721/image_output/7.《神经网络与深度学习》/media/image168.png)
> ![](/root/autodl-tmp/project_knowledge/Doc_QA/Knowledge_based/1828695663060254721/image_output/7.《神经网络与深度学习》/media/image168.png)

L(**x***,* **x**′)

(a) 自编码器

> L(**x***,* **x**′)

图片识别内容


> 图 9.3 自编码器和降噪自编码器
>
> 降噪自编码器的思想十分简单，通过引入噪声来学习更鲁棒性的数据编码，
> 并提高模型的泛化能力。

2.  概率密度估计

> 概率密度估计（Probabilistic Density
> Estimation），简称密度估计（Density
> Estimation），是基于一些观测样本来估计一个随机变量的概率密度函数。密
> 度估计在数据建模、机器学习中使用广泛。
>
> 密度估计方法可以分为两类：参数密度估计和非参数密度估计。

###### 参数密度估计

> 参数密度估计（Parametric Density
> Estimation）是根据先验知识假设随机变量服从某种分布，然后通过训练样本来估计分布的参数。
>
> 令D = {**x**(*n*)}*N*
>
> 为从某个未知分布中独立抽取的*N* 个训练样本，假设这
>
> 些样本服从一个概率分布函数*p*(**x**\|*θ*)，其对数似然函数为
>
> *N*
>
> log *p*( *θ*) = log *p*(**x**(*n*) *θ*)*.* (9.29)
>
> *n*=1
>
> 我们要估计一个参数*θ^ML^* 来使得
>
> *θ^ML^* = arg max Σ log *p*(**x**(*n*)\|*θ*)*.* (9.30)
>
> 这样参数估计问题就转化为最优化问题。

1.  正态分布

> 假设样本**x** ∈ R*d* 服从正态分布
>
> N(**x**\|***µ**,* Σ) = [ 1]{.underline} exp − [1]{.underline} (**x** −
> ***µ***)TΣ−1(**x** − ***µ***) *,* (9.31)
>
> 其中***µ*** 和Σ 分别为正态分布的均值和方差。其对数似然函数为

log (

> Σ) =
>
> *[N]{.underline}* log (2
>
> )2 Σ
>
> [1]{.underline} Σ*N* (**x**
>
> ) Σ 1(**x** )
>
> (9.32)
>
> 分别上式关于***µ**,* Σ 的偏导数，并令其等于0。可得，

*~ML~* [1]{.underline}

> Σ **x**(*n*)*,* (9.33)
>
> *n*=1

Σ*ML*

> = [ 1]{.underline}
>
> Σ(**x** − ***µ***)(**x** − ***µ***)T

*.* (9.34)

> *n*=1
>
> 多项分布参见第[D.2.2.1](\l)节。

2.  多项分布

> 假设样本服从*K* 个状态的多项分布，令onehot 向量**x** ∈ \[0*,* 1\]*K*
> 来表示第*k*
>
> 个状态，即*x~k~* = 1，其余*x~i,i~*~≠~ *~k~* = 0。样本**x**
> 的概率密度函数为

*K*

> *x~k~ k*
>
> *k*=1
>
> 其中*µ~k~* 为第*k* 个状态的概率，并满足Σ*K µ~k~* = 1。
>
> 这里没有多项式系数。
>
> 数据集D = {**x**(*n*)}*N* 的对数似然函数为
>
> *N K*

log *p*( ***µ***) =

*n*=1 *k*=1

*xk* log(*µ~k~*)*.* (9.36)

> 多项分布的参数估计为约束优化问题。引入拉格朗日乘子*λ*，将原问题转
>
> 换为无约束优化问题。 拉格朗日乘子参考**??**。
>
> max
>
> ***µ**,λ*
>
> Σ *xk* log(*µ~k~*) +
>
> Σ*K*
>
> *µ~k~* −
>
> 1 *.*
>
> (9.37)

*n*=1 *k*=1 *k*=1

> 分别上式关于*µ~k~, λ* 的偏导数，并令其等于0。可得，
>
> *µ^ML^* = *[mk]{.underline} ,* 1 ≤ *k* ≤ *K* (9.38)
>
> 其中*m~k~* = Σ*N* (*n*) 为数据集中取值为第*k* 个状态的样本数量。
>
> *n*=1 *xk*
>
> 在实际应用中，参数密度估计一般存在以下问题：

1.  模型选择问题：即如何选择数据分布的密度函数。实际数据的分布往
    > 往是非常复杂的，而不是简单的正态分布或多项分布。

2.  不可观测变量问题：即我们用来训练的样本只包含部分的可观测变量，
    > 还有一些非常关键的变量是无法观测的，这导致我们很难准确估计数据的真实分布。

3.  维度灾难问题：即高维数据的参数估计十分困难。随着维度的增加，
    > 估计参数所需要的样本数量指数增加。在样本不足时会出现过拟合。

    2.  ###### 非参数密度估计

> 非参数密度估计（Nonparametric Density
> Estimation）是不假设数据服从某种分布，通过将样本空间划分为不同的区域并估计每个区域的概率来近似数
> 据的概率密度函数。
>
> 对于高维空间中的一个随机向量**x**，假设其服从一个未知分布*p*(**x**)，则**x**
> 落入空间中的小区域𝑌的概率为
>
> 包含不可观测变量的密度估计问题一般需要使用EM
> 算法，参见第[11.4.2.1](\l)节。
>
> *P* = *p*(**x**)*d***x***.* (9.39)
>
> 𝑌
>
> 给定*N* 个训练样本D = {**x**(*n*)}*N* ，落入区域𝑌的样本数量*K*
> 服从二项分布
>
> *P* = *N P^K^*(1 − *P* )1−*K,* (9.40)
>
> 其中*K/N* 的期望为E\[*K/N* \] = *P* ，方差为var(*K/N* ) = *P* (1 − *P*
> )*/N* 。当*N* 非常大时，我们可以近似认为
>
> *P* ≈ *N .* (9.41)
>
> Histogram 源自希腊语his- tos（竖立）和gramma（描
>
> 假设区域𝑌足够小，其内部的概率密度是相同的，则有
>
> *P* ≈ *p*(**x**)*V,* (9.42)
>
> 其中*V* 为区域𝑌的体积。结合上述两个公式，得到
>
> *p*(**x**) ≈ *NV .* (9.43)
>
> 根据公式([9.43](\l))，要准确地估计*p*(**x**) 需要尽量使得样本数量*N*
> 足够大，区域体积*V*
> 尽可能地小。但在具体应用中，样本数量一般是有限的，过小的区域会导致落入该区域的样本比较少，这样估计的概率密度就不太准确。因此，实
> 践中非参数密度估计通常使用两种方式：（1）固定区域大小*V*
> ，统计落入不同区域的数量，这种方式包括直方图方法和核方法两种。（2）改变区域大小以使
> 得落入每个区域的样本数量为*K*，这种方式称为K 近邻方法。

1.  直方图方法

> 直方图方法（Histogram
> Method）是一种非常直观的估计连续变量密度函数的方法，可以表示为一种柱状图。
>
> 以一维随机变量为例，首先将其取值范围分成*M* 个连续的、不重叠的区间
>
> 绘），由英国统计学家卡尔·
>
> 皮尔逊于1895 年提出。
>
> （bin），每个区间的宽度为∆*~m~*。给定*N* 个训练样本D = {*x*^(*n*)^}*N*
> ，我们统计
>
> 这些样本落入每个区间的数量*K~m~*，然后将它们归一化为密度函数。
>
> *p* = [* Km *]{.underline}*,* 1 ≤ *m* ≤ *M* (9.44)
>
> 其中区间宽度∆*~m~*
> 通常设为相同的值∆。直方图方法的关键问题是如何选取一个合适的区间宽度∆。如果∆
> 太小，那么落入每个区间的样本数量会比较少，其估计的区间密度也具有很大的随机性。如果∆
> 太大，其估计的密度函数变得十分平滑，很难反映出真实的数据分布。图[9.4](\l)给出了直方图密度估计的例子，其
> 中蓝线表示真实的密度函数，红色的柱状图为直方图方法估计的密度。

a.  10 个区间（bin） (b) 30 个区间（bin）

> 图 9.4 直方图密度估计
>
> 直方图通常用来处理低维变量，可以非常快速地对数据的分布进行可视化，
> 但其缺点是很难扩展到高维变量。假设一个*d*
> 维的随机向量，如果每一维都划分为*M*
> 个区间，那么整个空间的区间数量为*M^d^*
> 个。直方图方法需要的样本数量会随着维度*d*
> 的增加而指数增长，从而导致维度灾难（Curse of Dimensionality） 问题。

2.  核方法

> 核密度估计（Kernel Density Estimation），也叫Parzen
> 窗方法，是一种直方图方法的改进。
>
> 假设𝑌为*d* 维空间中的一个以点**x** 为中心的"超立方体"，并定义核函数
>
> [**z** −]{.underline} **[x]{.underline}** =  1 if \|*𝑥~i~* −
> *x~i~*\| *\< ^[h]{.underline}^ ,* 1 ≤ *i* ≤ *d*
>
> (9.45)
>
> *ϕ* 2
>
> *h*  0 else
>
> 来表示一个样本**z** 是否落入该超立方体中，其中*h*
> 为超立方体的边长，也称为核函数的宽度。
>
> 给定*N* 个训练样本D = {**x**(*n*)}*N*
>
> ，落入区域𝑌的样本数量*K* 为
>
> 则点**x** 的密度估计为
>
> *K* =

*n*=1

> **x**(*n*) **x**

*ϕ*

> *h*
>
> *,* (9.46)

*p*(**x**) =

> [* K*]{.underline} *Nhd*
>
> [ 1]{.underline} *^N^ d*

*n*=1

> **x**(*n*) **x**

*ϕ*

> *h*
>
> *,* (9.47)
>
> 其中*h^d^* 表示区域𝑌的体积。
>
> 除了超立方体的核函数之外，我们还可以选择更加平滑的核函数，比如高
> 斯核函数，

[**z** −]{.underline} **[x]{.underline}** [ 1]{.underline} ∥**z** −
**x**∥2

> 其中*h*^2^ 可以看做是高斯核函数的方差。这样点**x** 的密度估计为

*p*(**x**) =

*N*

3.  **K** 近邻方法

> *n*Σ=1
>
> [ 1]{.underline} (2*π*)1*/*2*h*
>
> ∥**z** − **x**∥2

*.* (9.49)

> 核密度估计方法中的核宽度是固定的，因此同一个宽度可能对高密度的区域过大，而对低密度区域过小。一种更灵活的方式是设置一种可变宽度的区域，
>
> K 近邻方法并不是一个严格的密度函数估计方法，参见习题[9-5](\l)。
>
> 参见习题[9-6](\l)。
>
> 并使得落入每个区域中样本数量为固定的*K*。要估计点**x**
> 的密度，首先找到一个以**x**
> 为中心的球体，使得落入球体的样本数量为*K*，然后根据公式([9.43](\l))，就可以计算出点**x**
> 的密度。因为落入球体的样本也是离**x** 最近的*K*
> 个样本，所以这种方法称为*K* 近邻（K-Nearest Neighbor）方法。
>
> 在K 近邻方法中，*K* 的选择也十分关键。如果*K*
> 太小，无法有效地估计密度函数，而*K*
> 太大也会使得局部的密度不准确，并且增加计算开销。
>
> K 近邻方法也经常用于分类问题，称为*K* 近邻分类器。当*K* = 1
> 也称为最近邻分类器。最近邻分类器的一个性质是，当*N* → ∞
> 时，其分类错误率不超过最优分类器错误率的两倍\[[Cover and Hart](\l),
> [1967](\l)\]。

#### 总结和深入阅读

> 无监督学习是一种十分重要的机器学习方法。广义上讲，监督学习也可以看作是一个类特殊的无监督学习，即估计条件概率*p*(*y*\|**x**)。条件概率*p*(*y*\|**x**)
> 可以通过贝叶斯公式转为估计概率*p*(*y*)
> 和*p*(**x**\|*y*)，并通过无监督密度估计来求解。
>
> 无监督学习问题主要可以分为聚类、特征学习、密度估计等几种类型。关
> 于聚类方面的内容，可以参考《机器学习》\[[周志华](\l), [2016](\l)\]
> 中的第9
> 章。无监督特征学习是一种十分重要的表示学习方法。当一个监督学习任务的数据比较少
> 时，可以通过大规模的无标注数据，学习到一种有效的数据表示，并有效提高
> 监督学习的性能。关于无监督特征学习的内容，可以参考《机器学习》\[[周志华](\l),
> [2016](\l)\] 中的第10 章和《Pattern Classiﬁcation》\[[Duda et
> al.](\l), [2001](\l)\] 的第10 章。
>
> 本章简单介绍了两种概率密度估计方法：参数方法和非参数方法。参数方
> 法是假设数据分布服从某种参数化的模型。我们在本书的后面章节会陆续介绍
> 更多的参数密度估计模型。在第[11](\l)章中，我们通过概率图模型介绍更一般的参数密度估计方法，包括含隐变量的参数估计方法。当估计出一个数据分布的参
> 数化模型后，我们可以根据这个模型来生成数据，因此这些模型也称为生成模
> 型。第[12](\l)章介绍两种比较复杂的生成模型：玻尔兹曼机和深度信念网络。第[13](\l)章
> 介绍了两种深度生成模型：变分自编码器和对抗生成网络。第[15](\l)章介绍了几种序列数据的生成模型。
>
> 关于非参数密度估计的方法一般性介绍可以参考\[[Duda et al.](\l),
> [2001](\l)\] 和\[[Bishop](\l),
> [2007](\l)\]，理论性介绍可以参考\[[Devroye and Gyorﬁ](\l),
> [1985](\l)\]。
>
> 但目前无监督学习并没有像监督学习那样取得广泛的成功，主要原因在于
> 无监督学习缺少有效的客观评价方法，导致很难衡量一个无监督学习方法的
> 好坏。
>
> 参考文献 2019 年 4 月 6 日 233

#### 习题

> 习题 **9-1** 分析主成分分析为什么具有数据降噪能力？
>
> 习题**9-2** 证明对于*N* 个样本（样本维数*d \> N*
> ）组成的数据集，主成分分析的有效投影子空间不超过*N* − 1 维。
>
> 习题**9-3**
> 对于一个两类分类问题，试举例分析什么样的数据分布会使得主成分分析得到的特征反而会使得分类性能下降。
>
> 习题**9-4** 若数据矩阵*X*^′^ = *X* − *X*¯ ，则对*X*^′^
> 奇异值分解*X*^′^ = *U* Σ*V* ，则*U*
>
> 为主成分分析的投影矩阵。
>
> 习题**9-5** 举例说明，K 近邻方法估计的密度函数不是严格的概率密度函数，
> 其在整个空间上的积分不等于1。
>
> 习题 **9-6** 对于一个*C* 类的分类问题，使用K 近邻方法估计每个类 *c* (1
> ≤
>
> *c* ≤ *C*)
> 的密度函数*p*(**x**\|*c*)，并使用贝叶斯公式计算每个类的后验概率*p*(*c*\|**x**)。

#### 参考文献

> 周志华. 机器学习. 清华大学出版社, 北京, 2016. ISBN 978-7-302-206853-6.
>
> Yoshua Bengio, Pascal Lamblin, Dan Popovici, and Hugo Larochelle.
> Greedy layer-wise training of deep networks. In *Advances in neural
> information processing*
>
> *systems*, pages 153--160, 2007.
>
> Christopher M. Bishop. *Pattern recogni- tion and machine learning,
> 5th Edition*. In- formation science and statistics. Springer,
>
> 2007\. ISBN 9780387310732.
>
> Thomas Cover and Peter Hart. Nearest neighbor pattern classiﬁcation.
> *IEEE trans- actions on information theory*, 13(1):21--27,
>
> 1967.
>
> Luc Devroye and Laszlo Gyorﬁ. *Nonpara- metric Density Estimation: The
> L*~1~ *View*. Wiley Series in Probability and Statistics. Wiley，New
> York, 1985.
>
> Richard O. Duda, Peter E. Hart, and David G. Stork. *Pattern
> classiﬁcation, 2nd Edition*. Wiley, 2001. ISBN 9780471056690.
>
> Geoﬀrey E Hinton, Terrence Joseph Se- jnowski, and Tomaso A Poggio.
> *Unsuper- vised learning: foundations of neural com- putation*. MIT
> press, 1999.
>
> Bruno A Olshausen et al. Emergence of simple-cell receptive ﬁeld
> properties by learning a sparse code for natural images. *Nature*,
> 381(6583):607--609, 1996.
>
> Pascal Vincent, Hugo Larochelle, Yoshua Bengio, and Pierre-Antoine
> Manzagol. Ex- tracting and composing robust features with denoising
> autoencoders. In *Proceedings of the International Conference on
> Machine Learning*, pages 1096--1103. ACM, 2008.

第**10** 章 模型独立的学习方式
==============================

> 在前面的章节中，介绍了机器学习的几种学习方式，包括监督学习、无监督
> 学习等。这些学习方式分别可以由不同的模型和算法实现，比如神经网络、线
> 性分类器等。针对一个给定的任务，首先要准备一定规模的训练数据，这些训练
> 数据需要和真实数据的分布一致，然后设定一个目标函数和优化方法，在训练
> 数据上学习一个模型。此外，不同任务的模型往往都是从零开始来训练的，一
> 切知识都需要从训练数据中得到。这也导致了每个任务都需要准备大量的训练
> 数据。在实际应用中，我们面对的任务往往难以满足上述要求，比如训练任务
> 和目标任务的数据分布不一致，训练数据过少等。这时机器学习的应用会受到
> 很大的局限。因此，人们开始关注一些新的学习方式的任务，现在的深度学习
> 因为无法快速适应新的任务，就没办法来替代人类的工作。
>
> 本章介绍一些"模型独立的学习方式"，比如集成学习、协同学习、自学习、
> 多任务学习、迁移学习、终身学习、小样本学习、元学习等。这里"模型独立"
> 是指这些学习方式不限于具体的模型，不管是前馈神经网络、循环神经网络还是其他模型。然而一种学习方式往往会对符合某种特性的模型更加青睐，比如集成学习往往和方差大的模型组合时效果显著。

#### 集成学习

> 给定一个学习任务，假设输入**x** 和输出**y** 的真实关系为**y** =
> *h*(**x**)。对于*M*
>
> 个不同的模型*f*~1~(**x**)*,* · · · *, f~M~*
> (**x**)，每个模型的期望错误为

𝑌(*f~m~*

) = E**~x~**

h *fm*

(**x**) − *h*(**x**) 2i (10.1)

> = E**~x~**h*ϵ~m~*(**x**)2i*,* (10.2)
>
> 其中*ϵ~m~*(**x**) = *f~m~*(**x**) − *h*(**x**) 为模型*m* 在样本**x**
> 上的错误。那么所有的模型的平均错误为
>
> ¯ [1]{.underline} Σ **x** 2

𝑌(*f* ) = *M*

E

> *m*=1
>
> \[*ϵ~m~*(**x**) \]*.* (10.3)
>
> 集成学习（Ensemble Learning）就是通过某种策略将多个模型集成起来，
> 通过群体决策来提高决策准确率。集成学习首要的问题是如何集成多个模型。比较常用的集成策略有直接平均、加权平均等。
>
> 最直接的集成学习策略就是直接平均，即"投票"。基于投票的集成模型
>
> *f* ^(*c*)(**x**)\ 为^

*M*

*F* (**x**) = *f*

> (**x**)*.* (10.4)
>
> *m*
>
> *m*=1
>
> 证明*.* 根据定义，集成模型的期望错误为

h [ 1]{.underline} Σ*M*

> ~2~i

= [ 1]{.underline} E**x**

*M*

> *M*
>
> *m*=1

*ϵ* (**x**) 2i (10.6)

= [ 1]{.underline} E**x**

*M*

h Σ*M* Σ

> *ϵ~m~*(**x**)*ϵ~n~*(**x**)i (10.7)
>
> *m*=1 *n*=1
>
> [ 1]{.underline} *^M^*
>
> *M* 2
>
> E**~x~**h*ϵ~m~*

(**x**)*ϵ~n~*

(x) i*,*

> (10.8)
>
> *m*=1 *n*=1
>
> 其中E**~x~**\[*ϵ~m~*(**x**)*ϵ~n~*(**x**)\]
> 为两个不同模型错误的相关性。如果每个模型的错误不相关，即∀*m* ̸= *n,*
> E**~x~**\[*ϵ~m~*(**x**)*ϵ~n~*(**x**)\] =
> 0。如果每个模型的错误都是相同的，则
>
> ∀*m* ̸= *n, ϵ~m~*(**x**) = *ϵ~n~*(**x**)。并且由于*ϵ~m~*(**x**) ≥ 0*,*
> ∀*m*，可以得到

𝑌¯ (*f* ) ≥ 𝑌(*F* )

> ≥ *M* 𝑌(*f* )*,* (10.9)
>
> 即集成模型的期望错误是大于等于所有模型的平均期望错误的1*/M*
> ，小于等于所有模型的平均期望错误。
>
> 从定理[10.1](\l)可知，为了得到更好的集成效果，要求每个模型之间具备一定的差异性。并且随着模型数量的增多，其错误率也会下降，并趋近于0。
>
> 集成学习的思想可以用一句古老的谚语来描述："三个臭皮匠赛过诸葛亮"。但是一个有效的集成需要各个基模型的差异尽可能大。为了增加模型之间的差异性，可以采取Bagging
> 类和Boosting 类两类方法。
>
> 10.1 集成学习 2019 年 4 月 6 日 237
>
> **Bagging** 类方法 Bagging
> 类方法是通过随机构造训练样本、随机选择特征等方法来提高每个基模型的独立性，代表性方法有Bagging
> 和随机森林等。
>
> *Bagging*（Bootstrap
> Aggregating）是一个通过不同模型的训练数据集的独立性来提高不同模型之间的独立性。我们在原始训练集上进行有放回的随机采
> 样，得到*M* 比较小的训练集并训练*M*
> 个模型，然后通过投票的方法进行模型集成。
>
> 随机森林（Random Forest）\[[Breiman](\l), [2001](\l)\] 是在Bagging
> 的基础上再引入了随机特征，进一步提高每个基模型之间的独立性。在随机森林中，每个基模
> 型都是一棵决策树。
>
> **Boosting** 类方法 Boosting
> 类方法是按照一定的顺序来先后训练不同的基模型，每个模型都针对前序模型的错误进行专门训练。根据前序模型的结果，来
> 调整训练训练样本的权重，从而增加不同基模型之间的差异性。Boosting
> 类方法是一种非常强大的集成方法，只要基模型的准确率比随机猜测好，就可以通
> 过集成方法来显著地提高集成模型的准确率。Boosting
> 类方法的代表性方法有AdaBoost\[[Freund et al.](\l), [1996](\l)\] 等。

##### 10.1.1 AdaBoost 算法

> Boosting 类集成模型的目标是学习一个加性模型（additive model）

*M*

*F* (**x**) = *α~m~f~m~*(**x**)*,* (10.10)

> *m*=1

其中*f~m~*(**x**) 为弱分类器（Weak Classiﬁer），或基分类器（Base
Classiﬁer），*α~m~*

> 为弱分类器的集成权重，*F* (**x**) 称为强分类器（Strong Classiﬁer）。
>
> Boosting类方法的关键是如何训练每个弱分类器*f~m~*(**x**)
> 以及对应的权重*α~m~*。为了提高集成的效果，应当尽量使得每个弱分类器的差异尽可能大。一种有效的
> 算法是迭代的方法来学习每个弱分类器，即按照一定的顺序依次训练每个弱分
> 类器。在学习了第*m* 个弱分类器后，增加其分错样本的权重，使得第*m* + 1
> 个弱分类器"更关注"于前面弱分类器分错的样本。这样增加每个弱分类器的差异，
> 最终提升的集成分类器的准确率。这种方法称为*AdaBoost*（Adaptive
> Boosting） 算法。
>
> AdaBoost
> 算法是一种迭代式的训练算法，通过改变数据分布来提高弱分类器的差异。在每一轮训练中，增加分错样本的权重，减少分对样本的权重，从
> 而得到一个新的数据分布。
>
> 以两类分类为例，弱分类器*f~m~*(*x*) ∈ {+1*,* −1}，AdaBoost
> 算法的训练过程如算法[10.1](\l)所示。最初赋予每个样本同样的权重。在每一轮迭代中，根据当前
>
> 的样本权重训练一个新的弱分类器。然后根据这个弱分类器的错误率来计算其
> 集成权重，并调整样本权重。
>
> 算法 **10.1:** 两类分类的AdaBoost 算法
>
> 输入**:** 训练集{(**x**(*n*)*, y*^(*n*))}*N*\ ，迭代次数*M*^
>
> **1**
> 初始样本权重：*w*^(*n*)\ ←\ [\ 1]{.underline}\ *,*\ ∀*n*\ ∈\ \[1*,\ N*\ \];^
>
> 1 *N*
>
> **2 for** *m* = 1 · · · *M* **do**
>
> **3** 按照样本权重*w*^(1)^*,* · · · *, w*^(*N*)^，学习弱分类器*f* ;
>
> **4** 计算弱分类器*f~m~* 在数据集上的加权错误为*ϵ~m~*;
>
> **5** 计算分类器的集成权重：
>
> *α* ← [1]{.underline} log [1 − *ϵm*]{.underline} ;
>
> *^m^* 2 *ϵ~m~*
>
> **6** 调整样本权重：

**7 end**

> (*n*)
>
> *m*+1
>
> ← *w*^(*n*)^ exp − *α~m~y*^(*n*)^*f~m~*(**x**(*n*)) *,* ∀*n* ∈ \[1*,
> N* \];
>
> 输出**:** *F* (**x**) = sgn Σ*M α~m~f~m~*(**x**)
>
> **AdaBoost** 算法的统计学解释 AdaBoost
> 算法可以看做是一种分步（stage-wise） 优化的加性模型\[[Friedman et
> al.](\l), [2000](\l)\]，其损失函数定义为

L(*F* ) = exp − *yF* (**x**) (10.11)

= exp − *y* Σ *α~m~f~m~*(**x**) *,* (10.12)

> 其中*y, f~m~*(**x**) ∈ {+1*,* −1}。
>
> 假设经过*m* − 1 次迭代，得到
>
> *m*−1
>
> *F~m~*~−1~(**x**) = *α~t~f~t~*(**x**)*,* (10.13)
>
> *t*=1
>
> 则第*m* 次迭代的目标是找一个*α~m~* 和*f~m~*(**x**)
> 使得下面的损失函数最小。

L(*α~m~, f~m~*(**x**)) =

> *n*Σ=1

exp

> − *y*(*n*)

*F~m~*~−1~(**x**

(*n*)

) + *α~m~f~m~*(**x**

(*n*))

*.* (10.14)

> 令*w*^(*n*)\ =\ exp\ −^ *y*^(*n*)^*F*

*m*−1 *N*

(**x**(*n*)) ，则损失函数可以写为

> L(*α~m~, f~m~*(**x**)) = Σ *w*^(*n*)^ exp −
> *α~m~y*^(*n*)^*f~m~*(**x**(*n*)) *.* (10.15)
>
> *n*=1
>
> 因为*y, f~m~*(**x**) ∈ {+1*,* −1}，有

*yf~m~*(**x**) = 1 − 2*I*(*y*

> *f~m~*(**x**))*,* (10.16)
>
> 其中*I*(*x*) 为指示函数。
>
> 将损失函数在*f~m~*(**x**) = 0 处进行二阶泰勒展开，有
>
> *N*
>
> 指数函数exp(*x*) 在*x* = 0 处的二阶泰勒展开公式为 1 +

L(*α , f*

> (**x**)) = Σ *w*^(*n*)^ 1 − *α*
>
> *y*(*n*)*f*
>
> (**x**(*n*)) + *α*^2^ (10.17)
>
> *x* + x2 。
>
> *m m m m m m* 2!
>
> *n*=1

*N*

𝖺 *αm* Σ *w*(*n*)*I y*(*n*)

> *f~m~*(**x**(*n*)) *.* (10.18)
>
> *n*=1
>
> 从上式可以看出，当*α~m~ \>* 0 时，最优的分类器*f~m~*(**x**)
> 为使得在样本权重为*w*^(*n*)^*,* 1 ≤ *n* ≤ *N*
> 时的加权错误率最小的分类器。
>
> 在求解出*f~m~*(**x**) 之后，公式([10.15](\l))可以写为
>
> L(*α~m~, f~m~*(**x**)) = Σ
>
> *w*^(*n*)^ exp(−*α~m~*) + Σ
>
> *w*^(*n*)^ exp(*α~m~*)

*y*(*n*)=*fm*(**x**(*n*))

*y*(*n*)

> *fm*(**x**(*n*))
>
> (10.19)
>
> 𝖺 (1 − *ϵ~m~*) exp(−*α~m~*) + *ϵ~m~* exp(*α~m~*)*,* (10.20)
>
> 其中*ϵ~m~* 为分类器*f~m~*(**x**) 的加权错误率，

Σ ( )=

> (**x**( )) *w*(*n*)

*m* (*n*)

> *n m*
>
> 求上式关于*α~m~* 的导数并令其为0，得到
>
> *α* = [1]{.underline} log [1 − *ϵm*]{.underline} *.* (10.22)

*^m^* 2 *ϵ~m~*

#### 自训练和协同训练

> 监督学习往往需要大量的标注数据，而标注数据的成本比较高，因此如何利
> 用大量的无标注数据来提高监督学习的效果，有十分重要的意义。这种利用少量
> 标注数据和大量无标注数据进行学习的方式称为半监督学习（Semi-Supervised
> Learning，SSL）。
>
> 本节介绍两种半监督学习算法：自训练和协同训练。

###### 自训练

> 这里的bootstrapping 和统计中的概念不同。
>
> 自训练（Self-Training），也叫自训练（Self-Teaching）或自举法（Bootstrapping）
>
> ，是一种非常简单的半监督学习算法\[[Scudder](\l), [1965](\l),
> [Yarowsky](\l), [1995](\l)\]。
>
> 自训练是首先使用标注数据来训练一个模型，并使用这个模型来预测无标注样本的标签，把预测置信度比较高的样本及其预测的伪标签加入训练集，然后重新训练新的模型，并不断重复这个过程。算法[10.2](\l)给出了自训练的训练过程。
>
> 算法 **10.2:** 自训练的训练过程
>
> 输入**:** 标注数据集L = {(**x**(*n*)*, y*^(*n*))}*N*\ ;^
>
> 无标注数据集𝐶 = {**x**(*m*)}*M* ;
>
> 迭代次数*T* ; 每次迭代增加样本数量*P* ;
>
> **1 for** *t* = 1 · · · *T* **do**
>
> **2** 根据训练集L，训练模型*f* ;
>
> **3** 使用模型*f* 对未标记数据集𝐶 的样本进行预测，选出预测置信度
>
> 高的*P* 个样本P = {(**x**(*p*)*, f* (**x**(*p*)))}*P* ;
>
> **4** 更新训练集：
>
> L ← L ∪ P*,* 𝐶 ← 𝐶 − P*.*
>
> 参见习题[10-2](\l)。
>
> **5 end**
>
> 输出**:** 模型*f*
>
> 自训练和密度估计中EM
> 算法有一定的相似之处，通过不断地迭代来提高模型能力。但自训练的缺点是无法保证每次加入训练集的样本的伪标签是正确
> 的。如果选择样本的伪标签是错误的，反而会损害模型的预测能力。因此，自
> 训练最关键的步骤是如何设置挑选样本的标准。

###### 协同训练

> 协同训练（Co-Training）是自训练的一种改进方法，通过两个基于不同视
> 角（view）的分类器来相互促进。很多数据都有相对独立的不同视角。比如互
> 联网上的每个网页都由两种视角组成：文字内容（text）和指向其它网页的链接（hyperlink）。如果要确定一个网页的类别，可以根据文字内容来判断，也可根据网页之间的链接关系来判断。
>
> 假设一个样本**x** = \[**x**~1~*,* **x**~2~\]，其中**x**~1~ 和**x**~2~
> 分别表示两种不同视角*V*~1~ 和*V*~2~
> 的特征，并满足下面两个假设：（1）条件独立性：给定样本标签*y*
> 时，两种特征条件独立*p*(**x**~1~*,* **x**~2~\|*y*) =
> *p*(**x**~1~\|*y*)*p*(**x**~2~\|*y*)；（2）充足和冗余性：当数据充分时，每种视角的特征都可以足以单独训练出一个正确的分类器。令*y*
> = *g*(**x**) 为需要学习
>
> 的真实映射函数，*f*~1~ 和*f*~2~ 分别为两个视角的分类器，有
>
> ∃*f*~1~*, f*~2~*,* ∀**x** ∈ X *, f*~1~(**x**~1~) = *f*~2~(**x**~2~) =
> *g*(**x**)*,* (10.23)
>
> 其中X 为样本**x** 的取值空间。
>
> 由于不同视角的条件独立性，在不同视角上训练出来的模型就相当于从不同视角来理解问题，具有一定的互补性。协同训练就是利用这种互补性来来进行自训练的一种方法。首先在训练集上根据不同视角分别训练两个模型*f*~1~
> 和*f*~2~， 然后用*f*~1~ 和*f*~2~
> 在无标记数据集上进行预测，各选取预测置信度比较高的样本加入训练集，重新训练两个不同视角的模型，并不断重复这个过程。
>
> 算法[10.3](\l)给出了协同训练的训练过程。
>
> 算法 **10.3:** 协同训练的训练过程
>
> 输入**:** 标注数据集L = {(**x**(*n*)*, y*^(*n*))}*N*\ ;^
>
> 无标注数据集𝐶 = {**x**(*m*)}*M* ;
>
> 迭代次数*T* ; 候选池大小*K*; 每次迭代增加样本数量2*P* ;
>
> **1 for** *t* = 1 · · · *T* **do**
>
> **2** 根据训练集L的视角*V*~1~ 训练训练模型*f*~1~;
>
> **3** 根据训练集L的视角*V*~2~ 训练训练模型*f*~2~;
>
> **4** 从无标记数据集 𝐶 上随机选取一些样本放入候选池 𝐶 ′，使得
>
> \|𝐶 ′\| = *K*;
>
> **5 for** *f* ∈ *f*~1~*, f*~2~ **do**
>
> **6** 使用模型*f* 预测候选池𝐶′ 中的样本的伪标签;
>
> **7 for** *p* = 1 · · · *P* **do**
>
> **8** 根据标签分布，随机选取一个标签*y*;
>
> **9** 从𝐶′ 中选出伪标签为*y*，并且预测置信度最高的样本**x**;
>
> **10** 更新训练集：
>
> L ← L ∪ {(**x***, y*)}*,* 𝐶 ′ ← 𝐶 ′ − {(**x***, y*)}*.*
>
> **11 end**
>
> **12 end**
>
> **13 end**
>
> [ 输出]{.underline}[**:** 模型*f*~1~,*f*~2~ ]{.underline}
>
> 协同算法要求两种视图是条件独立的。如果两种视图完全一样，则协同训
> 练退化成自训练算法。

#### 多任务学习

> 一般的机器学习模型都是针对单一的特定任务，比如手写体数字识别、物体检测等。不同任务的模型都是在各自的训练集上单独学习得到的。如果有两个任务比较相关，它们之间会存在一定的共享知识，这些知识对两个任务都会有所帮助。这些共享的知识可以是表示（特征）、模型参数或学习算法等。目前，
> 主流的多任务学习方法主要关注于表示层面的共享。
>
> 多任务学习（Multi-task Learning）是指同时学习多个相关任务，让这些
> 任务在学习过程中共享知识，利用多个任务之间的相关性来改进模型在每个
> 任务的性能和泛化能力。多任务学习可以看作是一种归纳迁移学习（Inductive
> Transfer
> Learning），即通过利用包含在相关任务中的信息作为归纳偏置（Inductive
> Bias）来提高泛化能力\[[Caruana](\l), [1997](\l)\]。
>
> 共享机制
> 多任务学习的主要挑战在于如何设计多任务之间的共享机制。在传统的机器学习算法中，引入共享的信息是比较困难的，通常会导致模型变得复杂。
> 但是在神经网络模型中，模型共享变得相对比较容易。深层神经网络模型提供了一种很方便的信息共享方式，可以很容易地进行多任务学习。多任务学习的共享机制比较灵活，有非常多种的共享模型。图[10.1](\l)给出了多任务学习中四种常见的共享模式。

-   硬共享模式：让不同任务的神经网络模型共同使用一些共享模块（一般是
    > 低层）来提取一些通用特征，然后再针对每个不同的任务设置一些私有模
    > 块（一般是高层）来提取一些任务特定的特征。

-   软共享模式：不显式地设置共享模块，但每个任务都可以从其它任务中
    > "窃取"一些信息来提高自己的能力。窃取的方式包括直接复制使用其它
    > 任务的隐状态，或使用注意力机制来主动选取有用的信息。

-   层次共享模式：一般神经网络中不同层抽取的特征类型不同。底层一般抽
    > 取一些低级的局部特征，高层抽取一些高级的抽象语义特征。因此如果多
    > 任务学习中不同任务也有级别高低之分，那么一个合理的共享模式是让低
    > 级任务在底层输出，高级任务在高层输出。

-   共享-私有模式：一个更加分工明确的方式是将共享模块和任务特定（私
    > 有）模块的责任分开。共享模块捕捉一些跨任务的共享特征，而私有模块
    > 只捕捉和特定任务相关的特征。最终的表示由共享特征和私有特征共同
    > 构成。

> 学习步骤
> 在多任务学习中，每个任务都可以有自己单独的训练集。为了让所有任务同时学习，我们通常会使用交替训练的方式来"近似"地实现同时学习。
>
> 10.3 多任务学习 2019 年 4 月 6 日 243
>
> \(a) 硬共享模式 (b) 软共享模式

(c) 层次共享模式 (d) 共享-私有模式

> 图 10.1 多任务学习中四种常见的共享模式
>
> 假设有*M* 个相关任务，第*m* 个任务的训练集为D*~m~*，包含*N~m~*
> 个样本。

D*~m~* = {(**x**

(*m,n*)

*, y*(*m,n*)

)}*Nm ,* (10.24)

> 其中**x**(*m,n*)
> 和*y*^(*m,n*)\ 表示第*m*\ 个任务中的第*n*\ 个样本以及它的标签。^
>
> 假设这*M* 任务对应的模型分别为*f~m~*(**x***, θ*)*,* 1 ≤ *m* ≤ *M*
> ，多任务学习的联合目标函数为所有任务损失函数的线性加权。

L(*θ*) = Σ

> *Nm*
>
> *η~m~*L*~m~*
>
> *f~m~*(*x*^(^

*m,n*)

*, θ*)*, y*

(*m,n*

) *,* (10.25)

> *m*=1 *n*=1
>
> 其中L*~m~*(·) 为第*m* 个任务的损失函数，*η~m~* 是第*m*
> 个任务的权重，*θ*
> 表示包含了共享模块和私有模块在内的所有参数。权重可以根据不同任务的重要程度来赋
>
> 值，也可以根据任务的难易程度来赋值。通常情况下，所有任务设置相同的权
> 重，即*η~m~* = 1*,* 1 ≤ *m* ≤ *M* 。
>
> 多任务学习的流程可以分为两个阶段：（1）联合训练阶段：每次迭代时，随机挑选一个任务，然后从这个任务中随机选择一些训练样本，计算梯度并更新参数；（2）单任务精调阶段：基于多任务的学习到的参数，分别在每个单独任务进行精调。其中单任务精调阶段为可选阶段。当多个任务的差异性比较大时，
> 在每个单任务上继续优化参数可以进一步提升模型能力。
>
> 多任务学习中联合训练阶段的具体过程如算法[10.4](\l)所示。
>
> 算法 **10.4:** 多任务学习中联合训练过程
>
> 输入**:** *M* 个任务的数据集D*~m~,* 1 ≤ *m* ≤ *M* ;
> 每个任务的批量大小*K~m~,* 1 ≤ *m* ≤ *M* ; 最大迭代次数*T* ，学习率*α*;
>
> **1** 随机初始化参数*θ*~0~;
>
> **2 for** *t* = 1 · · · *T* **do**
>
> // 准备*M* 个任务的数据
>
> **3 for** *m* = 1 · · · *M* **do**
>
> **4** 将任务*m* 的训练集D*~m~* 中随机划分为*c* = *[Nm]{.underline}*
> 个小批量集合：

**5 end**

> B*~m~* = {I~*m,*1~*,* · · · *,* I*~m,c~*};
>
> **6** 合并所有小批量样本B¯ = B~1~ ∪ B~2~ ∪ · · · ∪ B*~M~* ;
>
> **7** 随机排序B¯;
>
> **8 foreach** I ∈ B¯ **do**
>
> **9** 计算小批量样本I 上的损失L(*θ*) ; // 只计算I 在对应任务上的损失
>
> **10** 更新参数：*θ~t~* ← *θ~t~*~−1~ − *α* · 𝖮*~θ~*L(*θ*);
>
> **11 end**
>
> **12 end**
>
> [ 输出]{.underline}[**:** 模型*f~m~,* 1 ≤ *m* ≤ *M *]{.underline}
>
> 多任务学习通常可以获得比单任务学习更好的泛化能力，主要由于以下几
> 个原因：

1.  多任务学习在多个任务的数据集上进行训练，比单任务学习的训练集更
    > 大。由于多个任务之间有一定的相关性，因此多任务学习相当于是一种隐
    > 式的数据增强，可以提高模型的泛化能力。

2.  多任务学习中的共享模块需要兼顾所有任务，这在一定程度上避免了模型
    > 过拟合到单个任务的训练集，可以看作是一种正则化。

3.  既然一个好的表示通常需要适用于多个不同任务，多任务学习的机制使得
    > 它会比单任务学习可以获得一个更好的表示。

4.  在多任务学习中，每个任务都可以"选择性"利用其他任务中学习到的隐
    > 藏特征，从而提高自身的能力。

#### 迁移学习

> 参见第[1.4](\l)节。
>
> 标准机器学习的前提假设是训练数据和测试数据的分布是相同的。如果不
> 满足这个假设，在训练集上学习到的模型在测试集上的表现会比较差。而在很
> 多实际场景中，经常碰到的问题是由标注数据的成本十分高，无法为一个目标
> 任务准备足够多相同分布的训练数据。因此，如果有一个相关任务已经有了大
> 量的训练数据，虽然这些训练数据的分布和目标任务不同，但是由于训练数据
> 的规模比较大，我们假设可以从中学习某些可以泛化的知识，那么这些知识对
> 目标任务会有一定的帮助。如何将相关任务的训练数据中的可泛化知识迁移到
> 目标任务上，就是迁移学习（Transfer Learning）要解决的问题。
>
> 具体而言，假设一个机器学习任务𝘧 的样本空间为X × Y，其中X 为输入
>
> 空间和Y 为输出空间，其概率密度函数为*p*(**x***, y*)。简单起见，这里设X
> 为*d* 维 *p*(**x***, y*) = *P* (*X* = **x***, Y* =
>
> 实数空间的一个子集，Y 为一个离散的集合。
>
> 一个样本空间及其分布可以称为一个领域（Domain）：D = (X *,* Y*,
> p*(**x***,
> y*))。给定两个领域，如果它们的输入空间、输出空间或概率分布中至少一个不同，那么这两个领域就被认为是不同的。从统计学习的观点来看，一个机器学习任务
>
> 𝘧 定义为在一个领域D 上的条件概率*p*(*y*\|**x**) 的建模问题。
>
> 迁移学习是指两个不同领域的知识迁移过程，利用源领域（Source Domain）
>
> ）D*~S~* 中学到的知识用来帮助目标领域（Target Domain）D*~T~*
> 上的学习任务。源领域的训练样本数量一般远大于目标领域。
>
> 表[10.1](\l)给出了迁移学习和标准机器学习的比较。
>
> *y*)*.*
>
> 学习类型 样本空间 概率分布
>
> 标准机器学习 XS = XT *,* YS = YT *p*S(**x***, y*) = *p*T (**x***, y*)
>
> 迁移学习 XS
>
> XT 或YS ̸= YT 或*p*S(**x***, y*) ̸= *p*T (**x***, y*)
>
> 表 10.1 迁移学习类型
>
> 迁移学习根据不同的迁移方式又分为两个类型：归纳迁移学习（Inductive
> Transfer Learning）和推导迁移学习（Transductive Transfer
> Learning）。这两
>
> 期望风险参见第[2.2.2](\l)节。
>
> 自编码器参见第[9.1.3](\l)节。
>
> 个类型分别对应两个机器学习的范式：归纳学习（Inductive
> Learning）和转导学习（Transductive Learning）\[[Vapnik](\l),
> [1998](\l)\]。一般的机器学习都是指归纳学习，即希望在训练数据集上学习到使得期望风险（即真实数据分布上的错误率）
> 最小的模型。而转导学习的目标是学习一种在给定测试集上错误率最小的模型，
> 在训练阶段可以利用测试集的信息。
>
> 归纳迁移学习是指在源领域和任务上学习出一般的规律，然后将这个规律
> 迁移到目标领域和任务上；而转导迁移学习是一种从样本到样本的迁移，直接
> 利用源领域和目标领域的样本进行迁移学习。

1.  归纳迁移学习

> 在归纳迁移学习中，源领域和目标领域有相同的输入空间X*~S~* = X*~T~*
> ，输出空间可以相同也可以不同，源任务和目标任务一般都不相同𝘧*~S~* ̸=
> 𝘧*~T~* ，即*p~S~*(*y*\|**x**) ̸= *p~T~*
> (*y*\|**x**)。一般而言，归纳迁移学习要求源领域和目标领域是相关的，
> 并且源领域D*~S~*
> 有大量的训练样本，这些样本可以是有标注的样本也可以是无标注样本。

1.  当源领域只有大量无标注数据时，源任务可以转换为无监督学习任务，比如自编码和密度估计任务。通过这些无监督任务学习一种可迁移的表示，然后在将这种表示迁移到目标任务上。这种学习方式和自学习（Self-Taught
    > Learning）

> 概率密度估计参见第[9.2](\l)节。 \[[Raina et al.](\l), [2007](\l)\]
> 以及半监督学习比较类似。比如在自然语言处理领域，由于语言相关任务的标注成本比较高，很多自然语言处理任务的标注数据都比较少，
>
> 这导致了在这些自然语言处理任务上经常会受限于训练样本数量而无法充分发挥深度学习模型的能力。同时，由于我们可以低成本地获取大规模的无标注自然语言文本，因此一种自然的迁移学习方式是将大规模文本上的无监督学习（比如语言模型）中学到的知识迁移到一个新的目标任务上。从早期的预训练词向量（比如word2vec
> \[[Mikolov et al.](\l), [2013](\l)\] 和GloVe \[[Pennington et
> al.](\l), [2014](\l)\] 等） 到句子级表示（比如ELMO \[[Peters et
> al.](\l), [2018](\l)\]、OpenAI GPT \[[Radford et al.](\l),
> [2018](\l)\] 以及BERT\[[Devlin et al.](\l), [2018](\l)\]
> 等）都对自然语言处理任务有很大的促进作用。
>
> 2）当源领域有大量的标注数据时，可以直接将源领域上训练的模型迁移
> 到目标领域上。比如在计算机视觉领域有大规模的图像分类数据集ImageNet
> \[[Deng et al.](\l), [2009](\l)\]。由于在ImageNet
> 数据集上有很多预训练的图像分类模型， 比如AlexNet\[[Krizhevsky et
> al.](\l), [2012](\l)\]、VGG \[[Simonyan and Zisserman](\l),
> [2014](\l)\] 和ResNet\[[He et al.](\l), [2016](\l)\]
> 等，我们可以将这些预训练模型迁移到目标任务上。
>
> 在归纳迁移学习中，由于源领域的训练数据规模非常大，这些预训练模型
> 通常有比较好的泛化性，其学习到的表示通常也适用于目标任务。归纳迁移学
> 习一般有下面两种迁移方式：

1.  基于特征的方式：将预训练模型的输出或者是中间隐藏层的输出作为特
    > 征直接加入到目标任务的学习模型中。目标任务的学习模型可以是一般
    > 的浅层分类器（比如支持向量机等）或一个新的神经网络模型。

2.  精调的方式：在目标任务上复用预训练模型的部分组件，并对其参数进行
    > 精调（ﬁne-tuning）。

> 假设预训练的模型是一个深层神经网络，不同层的可迁移性也不尽相同\[[Yosinski
> et al.](\l),
> [2014](\l)\]。通常来说，网络的低层学习一些通用的低层特征，中层或高层学习抽象的高级语义特征，而最后几层一般学习和特定任务相关的特
> 征。因此，根据目标任务的自身特点以及和源任务的相关性，可以针对性地选
> 择预训练模型的不同层来迁移到目标任务中。
>
> 将预训练模型迁移目标任务上通常会比从零开始学习的方式更好，主要体
> 现在以下三点\[[Torrey and Shavlik](\l),
> [2010](\l)\]：（1）初始模型的性能一般比随机初始化的模型要好；（2）训练时模型的学习速度比从零开始学习要快，收敛性更好；（3）模型的最终性能更好，具有更好的泛化性。
>
> 归纳迁移学习和多任务学习也比较类似，但有下面两点区别：（1）多任务学习是同时学习多个不同任务，而归纳迁移学习是通常分为两个阶段，即源任
> 务上的学习阶段，和目标任务上的迁移学习阶段；（2）归纳迁移学习是单向的知识迁移，希望提高模型在目标任务上的性能，而多任务学习是希望提高所有
> 任务的性能。

2.  转导迁移学习

> 转导迁移学习是一种从样本到样本的迁移，直接利用源领域和目标领域的
> 样本进行迁移学习\[[Arnold et al.](\l),
> [2007](\l)\]。转导迁移学习可以看作一个种特殊的转导学习（Transductive
> Learning）\[[Joachims](\l),
> [1999](\l)\]。转导迁移学习通常假设源领域有大量的标注数据，而目标领域没有（或有少量）标注数据，但是有大
> 量的无标注数据。目标领域的数据在训练阶段是可见的。
>
> 转导迁移学习的一个常见子问题是领域适应（Domain
> Adaptation）。在领域适应问题中，一般假设源领域和目标领域有相同的样本空间，但是数据分布
>
> 不同*p~S~*(**x***, y*) *p~T~* (**x***, y*)。
>
> 根据贝叶斯公式，*p*(**x***, y*) = *p*(**x**\|*y*)*p*(*y*) =
> *p*(*y*\|**x**)*p*(**x**)，因此数据分布的不一致通常由三种情况造成：

1.  协变量偏移（Covariate Shift）：源领域和目标领域的输入边际分布不同

> *p~S~*(**x**) ̸= *p~T~* (**x**)，但后验分布相同 *p~S~*(*y*\|**x**) =
> *p~T~* (*y*\|**x**)，即学习任务相同
>
> 𝘧*~S~* = 𝘧*~T~* 。

2.  概念偏移（Concept Shift）：输入边际分布相同*p~S~*(**x**) = *p~T~*
    > (**x**)，但后验

> 分布不同*p~S~*(*y*\|**x**) ̸= *p~T~* (*y*\|**x**)，即学习任务不同𝘧*~S~*
> 𝘧*~T~* 。

3.  先验偏移（Prior Shift）：源领域和目标领域中的输出 *y*
    > 先验分布不同*p~S~*(*y*) ̸= *p~T~* (*y*)，条件分布相同
    > *p~S~*(**x**\|*y*) = *p~T~*
    > (**x**\|*y*)。在这样情况下，目标领域必须提供一定数量的标注样本。

> 广义的领域适应问题可能包含上述一种或多种偏移情况。目前，大多数的
> 领域适应问题主要关注于协变量偏移，这样领域适应问题在关键就在于如何学
> 习领域无关（Domain-Invariant）的表示。假设*p~S~*(*y*\|**x**) = *p~T~*
> (*y*\|**x**)，领域适应的目标是学习一个模型*f* : X → Y 使得
>
> 𝑌*~T~* (*θ~f~* ) = E~(**x***,y*)∼*p*~*T* (**x***,y*)\[L(*f* (**x***,
> θ~f~* )*, y*)\] (10.26)

[*p~T~* (**x***, y*)]{.underline}

*,y* ∼*p~S~ ,y pS* (**x***, y*)

> *~f~* )*, y*)\] (10.27)
>
> = E~(**x**~ ~)~ ~(**x**~ ~)~ [*pT* (**x**)]{.underline} \[L(*f*
> (**x***, θ*

)*, y*)\]*,* (10.28)

> 其中L(·) 为损失函数，*θ~f~* 为模型参数。
>
> 如果我们可以学习一个映射函数 *g* : X → R*d*，将 **x**
> 映射到一个特征空间中，并在这个特征空间中使得源领域和目标领域的边际分布相同*p~S~
> g*(**x***, θ~g~*) = *p~T~ g*(**x***, θ~g~*) *,* ∀**x** ∈ X，其中*θ~g~*
> 为映射函数的参数，那么目标函数可以近似为
>
> 𝑌*~T~* (*θ~f~ , θ~g~*) = E~(**x***,y*)∼*p*~*S* (**x***,y*)\"L *f*
> *g*(**x***, θ~g~*)*, θ~f~* *, y* \# + *γd~g~*(*S, T* ) (10.29)
>
> = 𝑌*~S~*(*θ~f~ , θ~g~*) + *γd~g~*(*S, T* )*,* (10.30)
>
> 其中𝑌*~S~*(*θ~f~ , θ~g~*) 为源领域上的期望风险函数，*d~g~*(*S, T* )
> 是一个分布差异的度量函数，用来计算在映射特征空间中源领域和目标领域的样本分布的距离，*γ*
> 为一个超参数用来平衡两个子目标的重要性比例。这样，学习的目标是优化参数*θ~f~
> , θ~g~*使得提取的特征是领域无关的，并且在源领域上损失最小。
>
> 令
>
> (*n*) (*n*) *N*
>
> D*~S~* = {(**x***S , yS* )}~*n*=1~ ∼ *p~S~*(**x***, y*)*,* (10.31)

(m) *M*

> D*~T~* = {**x***T* }~*m*=1~ ∼ *p~T~* (**x***, y*)*,* (10.32)
>
> 分别为源领域和目标领域的训练数据，我们首先用映射函数 *g*(**x***,
> θ~g~*) 将两个领域中训练样本的输入**x**
> 映射到特征空间，并优化参数*θ~g~*
> 使得映射后两个领域的输入分布差异最小。分布差异一般可以通过一些度量函数来计算，比如
> MMD
>
> （Maximum Mean Discrepancy）\[[Gretton et al.](\l),
> [2007](\l)\]、CMD（Central Moment
>
> Discrepancy）\[[Zellinger et al.](\l), [2017](\l)\]
> 等，也可以通过领域对抗学习来得到领域无关的表示 \[[Bousmalis et
> al.](\l), [2016](\l), [Ganin et al.](\l), [2016](\l)\]。
>
> 以对抗学习为例，我们可以引入一个领域判别器*c*
> 来判断一个样本是来自于哪个领域。如果领域判别器*c*
> 无法判断一个映射特征的领域信息，就可以认为这个特征是一种领域无关的表示。
>
> 对于训练集中的每一个样本**x**，我们都赋予*𝑥* ∈ {1*,* 0}
> 表示它是来自于源领域还是目标领域，领域判别器*c* **h***, θ~c~*
> 根据其映射特征**h** = *g*(**x***, θ~g~*)
> 来预测它自于源领域的概率*p*(*𝑥* =
> 1\|**x**)。由于领域判别是一个两分类问题，**h** 来自于目标领域的概率为1
> − *c* **h***, θ~c~* 。
>
> 因此，领域判别器的损失函数为：

L (*θ , θ* ) = Σ log *c*(**h**^(^ ^)^*, θ* ) + [ 1]{.underline} Σ log 1
− *c*(**x**^(*m*)^*, θ* ) *,* (10.33)

> 其中**h**^(*n*)^ = *g*(**x**^(*n*)^*, θ~g~*)，**h**^(*m*)^ =
> *g*(**x**^(*m*)^*, θ~g~*) 分别为样本**x**^(*n*)^ 和**x**^(*m*)^
> 的特征向量。
>
> *S S D D S D*
>
> 这样，领域迁移的目标函数可以分解为两个对抗的目标。一方面，要学习
> 参数*θ~c~* 使得领域判别器*c*(**h***, θ~c~*) 尽可能区分出一个表示**h**
> = *g*(**x***, θ~g~*) 是来自于哪个领域；另一方面，要学习参数*θ~g~*
> 使得提取的表示**h** 无法被领域判别器*c*(**h***, θ~c~*)
> 预测出来，并同时学习参数*θ~g~* 使得模型*f* (**h***, θ~f~* )
> 在源领域的损失最小。
>
> min
>
> *θc*
>
> L*~c~*(*θ~f~ , θ~c~*)*,* (10.34)

min Σ

> (**x**(*n*) )
>
> (*n*)! ( )
>
> (10.35)

*θ ,θ*

> L *f g S , θ~g~ , θ~f~ , yS* − *γ*L*~c~ θ~f~ , θ~c~ .*

*^f^ ^g^ n*=1

#### 终生学习

> 虽然深度学习在很多任务上取得了成功，前提是训练数据和测试数据的分布要相同，一但训练结束模型就保持固定，不再进行迭代更新。并且，要想一个模型同时在很多不同任务上都取得成功依然是一件十分困难的事情。比如在围棋任务上训练的AlphaGo
> 只会下围棋，对象棋一窍不通。如果将让AlphaGo
> 去学习象棋，可能会损害其下围棋的能力，这显然不符合人类的学习过程。我们在学会了围棋之后，再去学象棋，不会忘记围棋的下法。人类的学习是一直持续的，人脑可以通过记忆不断地累积学习到的知识，这些知识累积可以在不同的任务中持续进行。在大脑的海马系统上，新的知识在以往知识的基础上被快速建立起来；之后经过长时间的处理，在大脑皮质区形成较难遗忘的长时记忆。由于不断的知识累积，人脑在学习新的任务时一般不需要太多的标注数据。
>
> 终生学习（Lifelong Learning），也叫持续学习（Continuous Learning），
> 是指像人类一样具有持续不断的学习能力，根据历史任务中学到的经验和知识
>
> 来帮助学习不断出现的新任务，并且这些经验和知识是持续累积的，不会因为
> 新的任务而忘记旧的知识\[[Chen and Liu](\l), [2016](\l), [Thrun](\l),
> [1998](\l)\]。
>
> 在终生学习中，假设一个终生学习算法已经在历史任务𝘧~1~*,* 𝘧~2~*,* · · ·
> *,* 𝘧*~m~* 上学习到一个模型，当出现一个新任务𝘧~*m*+1~
> 时，这个算法可以根据过去在*m* 个任务上学习的知识来帮助第*m* + 1
> 个任务，同时累积所有的*m* + 1
> 个任务上的知识。这个设定和归纳迁移学习十分类似，但归纳迁移学习的目标是优化目标任务的性能，而不关心知识的累积。而终生学习的目标是持续的学习和知识累积。另外，
> 也和多任务学习的不同之处在于终生学习并不在所有任务上同时学习。多任务学习是在使用所有任务的数据进行联合学习，并不是持续的一个一个的学习。
>
> 在终生学习中，一个关键的问题是如何避免灾难性遗忘（Catastrophic For-
> getting），即按照一定顺序学习多个任务时，在学习新任务的同时不忘记先前
> 学会的历史任务\[[French](\l), [1999](\l), [Kirkpatrick et al.](\l),
> [2017](\l)\]。比如在神经网络模型中，一些参数对任务𝘧*~A~*
> 非常重要，如果在学任务𝘧*~B~* 时被改变了，就可能给任务𝘧*~A~*
> 造成不好的影响。
>
> 在网络容量有限时，学习一个新的任务一般需要遗忘一些历史任务的知识。
> 而目前的神经网络往往都是过参数化的，对于任务𝘧*~A~*
> 而言有很多参数组合都可以达到最好的性能。这样在学习任务𝘧*~B~*
> 时，可以找到一组不影响任务𝘧*~A~* 而又能使得任务𝘧*~B~* 最优的参数。
>
> 解决灾难性遗忘的方法有很多。我们这里介绍一种 弹性权重巩固（Elastic
> Weight Consolidation）方法\[[Kirkpatrick et al.](\l), [2017](\l)\]。
>
> 不失一般性，以两个任务的持续学习为例，假设任务𝘧*~A~* 和任务𝘧*~B~*
> 的数据集分别为D*~A~*
> 和D*~B~*。从贝叶斯的角度来看，我们希望计算给定两个任务时参数的后验分布：
>
> 参考\[[Bishop](\l), [2007](\l)\] 中第4 章

log *p*(*θ*\|D) = log *p*(D\|*θ*) + log *p*(*θ*) − log *p*(D)*,* (10.36)

> 其中D = D*~A~* ∪ D*~B~*，*θ*
> 为模型参数。根据独立同分布假设，上式可以写为
>
> log *p*(*θ*\|D) = [log *p*(D*~A~*\|*θ*)]{.underline} + log
> *p*(D*~B~*\|*θ*) + [log *p*(*θ*)]{.underline} − [log
> *p*(D*~A~*)]{.underline} − log *p*(D*~B~*)*,*

(10.37)

= log *p*(D*~B~*\|*θ*) + log *p*(*θ*\|D*~A~*) − log *p*(D*~B~*)*,*
(10.38)

> 其中*p*(*θ*\|D*~A~*) 包含了所有从任务𝘧*~A~*
> 的学习的信息。当顺序地学习任务𝘧*~B~*
> 时，参数在两个任务上的后验分布和其在任务𝘧*~A~* 的后验分布有关。
>
> 由于后验分布比较难以建模，我们可以通过一个近似的方法来估计。假设
>
> 中的拉普拉斯近似。 *p*(*θ*\|D*~A~*) 为高斯分布，期望为在任务𝘧*~A~*
> 上学习到的参数*θA*∗ ，精度矩阵（即协方差矩阵的逆）是用参数*θ* 的Fisher
> 信息矩阵来衡量。
>
> *p*(*θ*\|D*~A~*) = N(*θA*∗ *, F* ^−1^)*,* (10.39)
>
> 其中*F* 为Fisher 信息矩阵。为了提高计算效率，*F*
> 可以简化为对角阵，由Fisher
>
> 信息矩阵对角线构成。
>
> **Fisher** 信息矩阵 *Fisher* 信息矩阵（Fisher Information
> Matrix）是一种测量可观察一个似然函数*p*(*x*\|*θ*) 携带的关于参数*θ*
> 的信息量的方法。通常一个参数对分布的影响可以通过对数似然函数的梯度来衡量。我们定义打分函数*s*(*θ*)
> 为
>
> *s*(*θ*) = 𝖮*~θ~* log *p*(*x*\|*θ*)*,* (10.40)
>
> 则*s*(*θ*) 的期望为0。
>
> 证明*.*
>
> E\[*s*(*θ*)\] = ∫ 𝖮*~θ~* log *p*(*x*\|*θ*)*p*(*x*\|*θ*)d*x* (10.41)
>
> = ∫ [𝖮*θp*(*x*\|*θ*)]{.underline} *p*(*x*\|*θ*)d*x* (10.42)
>
> = ∫ 𝖮*~θ~p*(*x*\|*θ*)d*x* (10.43)
>
> = 𝖮*~θ~* ∫ *p*(*x*\|*θ*)d*x* (10.44)
>
> = 𝖮*~θ~*1 = 0*.* (10.45)
>
> *s*(*θ*) 的协方差矩阵称为Fisher 信息矩阵，可以衡量参数*θ*
> 的估计的不确定性。
>
> *F* (*θ*) = E\[*s*(*θ*)*s*(*θ*)T\] (10.46)
>
> = E\[𝖮*~θ~* log *p*(*x*\|*θ*)(𝖮*~θ~* log *p*(*x*\|*θ*))T\]*.* (10.47)
>
> 通常我们不知道似然函数*p*(*x*\|*θ*) 的具体形式，Fisher
> 信息矩阵可以用经验的分布来进度估计。给定一个数据集{*x*^(1)^*,* · · ·
> *, x*^(*N*)^}，Fisher 信息矩阵可以近似为

*F* (*θ*) =

*N*

> *n*Σ=1 𝖮
>
> log *p*(*x*^(*n*)^\|*θ*)(𝖮*~θ~*
>
> log *p*(*x*^(*n*)^\|*θ*))T*.* (10.48)
>
> Fisher
> 信息矩阵的对角线的值反映了对应参数在通过最大似然进行估计时的不确定性，其值越大表示该参数估计值的方差越小，估计更可靠性，其携带
> 的关于数据分布的信息越多。
>
> 因此，对于任务𝘧*~A~* 的数据集D*~A~*，我们可以用Fisher
> 信息矩阵来衡量一个参数携带的关于D*~A~* 的信息量。

*F* (*θ*) =

*N*

> (**x***,y*Σ)∈D*~A~*
>
> 𝖮*~θ~*
>
> log *p*(*y*\|**x***, θ*)(𝖮*~θ~*
>
> log *p*(*y*\|**x***, θ*))T*.* (10.49)
>
> 通过上面的近似，在训练任务𝘧*~B~* 时的损失函数为
>
> *N*
>
> L(*θ*) = L (*θ*) + Σ *[λ]{.underline} F^A^* · (*θ* − *θ*^∗^
>
> )2*,* (10.50)
>
> 参见习题[10-3](\l)。
>
> 其中L*~B~*(*θ*) 为任务*p*(*θ*\|D*~B~*) 的损失函数，*F^A^* 为Fisher
> 信息矩阵的第*i* 个对角线元素，*λ* 为平衡两个任务重要性的超参数，*N*
> 为参数的总数量。

#### 元学习

> 根据没有免费午餐定理，没有一种通用的学习算法在所有任务上都有效。
> 因此，当使用机器学习算法实现某个任务时，我们通常需要"就事论事"，根据任务的特定来选择合适的模型、损失函数、优化算法以及超参数。那么，我们是否可以有一套自动方法，根据不同任务来动态地选择合适的模型或动态地调整超参数呢？事实上，人脑中的学习机制就具备这种能力。在面对不同的任务时，
> 人脑的学习机制并不相同。即使面对一个新的任务，人们往往也可以很快找到其学习方式。这种可以动态调整学习方式的能力，称为元学习（Meta-Learning）
>
> ，也称为学习的学习（Learning to Learn）\[[Thrun and Pratt](\l),
> [2012](\l)\]。
>
> 元学习的目的是从已有任务中学习一种学习方法或元知识，可以加速新任
> 务的学习。从这个角度来说，元学习十分类似于归纳迁移学习，但元学习更侧
> 重从多种不同（甚至是不相关）的任务中归纳出一种学习方法。
>
> 和元学习比较相关的另一个机器学习问题是小样本学习（Few-shot Learn-
> ing），即在小样本上的快速学习能力。每个类只有*K* 个标注样本，*K*
> 非常小。如果*K* = 1，称为单样本学习（One-shot Learning），如果*K* =
> 0，称为零样本学习（One-shot Learning）。
>
> 这里我们主要介绍两种典型的元学习方法：基于优化器的元学习和模型无
> 关的元学习。

###### 基于优化器的元学习

> 目前神经网络的学习方法主要是定义一个目标损失函数L(*θ*)，并通过梯度下降算法来最小化L(*θ*)，
>
> *θ~t~* ← *θ~t~*~−1~ − *α*𝖮L(*θ~t~*~−1~) (10.51)
>
> 10.6 元学习 2019 年 4 月 6 日 253
>
> 其中*θ~t~* 为第*t* 步时的模型参数，𝖮L(*θ~t~*~−1~) 为梯度，*α*
> 为学习率。根据没有免费午餐定理，没有一种通用的优化算法在所有任务上都有效。因此在不同的任务上，我们需要选择不同的学习率以及不同的优化方法，比如动量法，Adam
> 等。这些选择对具体一个学习的影响非常大。对于一个新的任务，我们往往通过经
>
> 验或超参搜索来选择一个合适的设置。
>
> 不同的优化算法的区别在于更新参数的规则不同，因此一种很自然的元学
> 习就是自动学习一种更新参数的规则，即通过另一个神经网络（比如循环神经
> 网络）来建模梯度下降的过程\[[Andrychowicz et al.](\l), [2016](\l),
> [Schmidhuber](\l), [1992](\l), [Younger et al.](\l),
> [2001](\l)\]。图[10.2](\l)给出了基于优化器的元学习的示例。
>
> 参见第[7.2](\l)节。

(n) (*n*) *N n*=1

新任务

> A*~ϕ~*∗

学习算法

> *f* (**x***, θ*^∗^)
>
> 模型
>
> T~1~*,* T~2~*,* · · · *,* T*~M~*

######## A

> 元学习算法
>
> 图 10.2 基于优化器的元学习
>
> 我们用函数*g~t~*(·) 来预测第*t* 步时参数更新的差值∆*θ~t~* = *θ~t~*
> −*θ~t~*~−1~。函数*g~t~*(·)称为优化器，输入是当前时刻的梯度值，输出是参数的更新差值∆*θ~t~*。这样第*t*
> 步的更新规则可以写为
>
> *θ~t~*~+1~ = *θ~t~* + *g~t~* 𝖮L(*θ~t~*)*, ϕ* (10.52)
>
> 其中*ϕ* 为优化器*g~t~*(·) 的参数。
>
> 学习优化器*g~t~*(·)
> 的过程可以看做是一种元学习过程，其目标是找到一个适用于多个不同任务的优化器。在标准梯度下降中，每步迭代的目标是使得L(*θ*)
> 下降。而在优化器的元学习中，我们希望在每步迭代的目标是L(*θ*)
> 最小，具体的目标函数为

*T*

> (*ϕ*) = E*~f~ w~t~* (*θ~t~*) *,* (10.53)
>
> *t*=1
>
> *θ~t~* = *θ~t~*~−1~ + **g***~t~,* (10.54)
>
> \[**g***~t~*; **h***~t~*\] = **LSTM** 𝖮L(*θ~t~*~−1~)*,* **h**~*t*−1~*,
> ϕ* *,* (10.55)
>
> 其中*T* 为最大迭代次数，*w~t~ \>* 0 为每一步的权重，一般可以设置*w~t~*
> = 1*,* ∀*t*。由于LSTM
> 网络可以记忆梯度的历史信息，学习到的优化器可以看做是一个高阶的优化方法。
>
> 在每步训练时，随机初始化模型参数，计算每一步的L(*θ~t~*)，以及元学习的损失函数L(*ϕ*)，并使用梯度下降更新参数。由于神经网络的参数非常多，导致LSTM
> 网络的输入和输出都是非常高维的，训练这样一个巨大的网络是不可行的。因此，一种简化的方法是为每个参数都使用一个共享的LSTM
> 网络来进行更新，这样可以使用一个非常小的共享LSTM 网络来更新参数。

###### 模型无关的元学习

> 既然元学习的目标之一是快速学习的能力，即在多个不同的任务上学习学
> 习一个模型，让其在新任务上经过少量的迭代，甚至是单步迭代，就可以达到
> 一个非常好的性能，并且避免在新任务上的过拟合。
>
> 模型无关的元学习（Model-Agnostic
> Meta-Learning，MAML）是一个简单的模型无关、任务无关的元学习算法\[[Finn
> et al.](\l),
> [2017](\l)\]。假设所有的任务都来自于一个任务空间，其分布为*p*(𝘧
> )，我们可以在这个任务空间的所有任务上学习一种通用的表示，这种表示可以经过梯度下降方法在一个特定的单任务上进行精调。假设一个模型为*f*
> (*θ*)，如果我们让这个模型适应到一个新任务𝘧*~m~* 上，
> 通过一步或多步的梯度下降更新，学习到的任务适配参数为

*θm*′

> = *θ* − *α*𝖮*~θ~*L~𝘧~*m* (*f~θ~*)*,* (10.56)
>
> 其中*α* 为学习率。这里*θm*′
>
> 可以理解为关于*θ* 的函数，而不是真正的参数更新。
>
> MAML 的目标是学习一个参数*θ*
> 使得其经过一个梯度迭代就可以在新任务上达到最好的性能。
>
> min
>
> *θ*

𝘧*m*Σ∼*p*(𝘧 )

L~𝘧~*m f* (*θm*′ ) =

> 𝘧*m*∼*p*(𝘧 )

L~𝘧~*m f [θ ]{.underline}*[− *α*𝖮*~θ~*L~𝘧~*m* (*f~θ~*)]{.underline}
(10.57)

> 在所有任务上的元优化（Meta-Optimization）也采用梯度下降来进行优化，
>
> 即
>
> *M*
>
> *θ θ β ~θ~* ~𝘧~*m* (*f~θ~m*′ )*,* (10.58)
>
> *m*=1
>
> 其中*β* 为元学习率，这里为一个真正的参数更新步骤。这里需要计算关于*θ*
> 的二阶梯度，但用一级近似通常也可以达到比较好的性能。

7.  总结和深入阅读 2019 年 4 月 6 日 255

> MAML 的具体过程如算法[10.5](\l)所示。
>
> 算法 **10.5:** 模型无关的元学习
>
> 输入**:** 任务分布*p*(𝘧 );
>
> 最大迭代次数*T* ，学习率*α, β*;
>
> **1** 随机初始化参数*θ*;
>
> **2 for** *t* = 1 · · · *T* **do**
>
> **3** 根据*p*(𝘧 ) 采样一个任务集合{𝘧*~m~*}*M*
>
> **for** *m* = 1 · · · *M* **do**
>
> **4** 计算𝖮*~θ~*L~𝘧~*m* (*f~θ~*);
>
> **5** 计算任务适配的参数：*θm*′
>
> **6 end**
>
> ← *θ* − *α*𝖮*~θ~*L~𝘧~*m* (*f~θ~*);
>
> **7** 更新参数：*θ* ← *θ* − *β*𝖮*~θ~* Σ*M*
>
> L𝘧*m*

(*f~θ~*′ );

> **8 end**
>
> [ 输出]{.underline}[**:** 模型*f~θ~ *]{.underline}
>
> **10.7** 总结和深入阅读
>
> 目前，神经网络的学习机制主要是以监督学习为主，这种学习方式得到的模型往往是任务定向的，也是孤立的。每个任务的模型都是从零开始来训练的，
> 一切知识都需要从训练数据中得到，导致每个任务都大量的训练数据。这些学习过程和人脑的学习方式是不同，人脑的学习过程一般不太需要太多的标注数据，并且是持续的学习，可以通过记忆不断地累积学习到的知识。本章主要介绍了一些和模型无关的学习方式。
>
> 关于集成学习可以参考《Pattern Recognition and Machine
> Learning》\[[Bishop](\l), [2007](\l)\] 和综述文献\[[Zhou](\l),
> [2012](\l)\]。在训练神经网络时采用的Dropout
> 方法在一定程度上也是一个模型集成。集成学习通过汇总多个模型来提高预测准确率的有
> 效方法，代表性模型有随机森林\[[Breiman](\l), [2001](\l)\]
> 和AdaBoost\[[Freund et al.](\l), [1996](\l)\]。
>
> 半监督学习研究的主要内容就是如何高效的利用少量标记数据和大量的
> 未标记数据来训练分类器。相比于监督学习，半监督学习一般需要更少的标注数据，因此在理论和实际在运用中均受到了广泛关注。半监督学习可以参考综述\[[Zhu](\l),
> [2006](\l)\]。最早在训练中运用未标记数据的方法是自训练（Self-Training）
> \[[Scudder](\l), [1965](\l)\]：在自训练的基础上，[Blum and
> Mitchell](\l) \[[1998](\l)\] 提出了由两个分类器协同训练的算法
> Co-Training。该工作获得了国际机器学习会议ICML 2008 的10 年最佳论文。
>
> 关于多任务学习是一种利用多个相关任务来提高模型泛化性的方法，可以
> 参考文献\[[Caruana](\l), [1997](\l), [Zhang and Yang](\l),
> [2017](\l)\]。
>
> 关于迁移学习是研究如何将在一个领域上训练的模型，迁移到新的领域，使
> 得新模型不用从零开始学习。但在迁移学习中需要避免将领域相关的特征迁移
> 到新的领域\[[Ganin et al.](\l), [2016](\l), [Pan and Yang](\l),
> [2010](\l)\]。迁移学习的一个主要研究问题是领域适应\[[Ben-David et
> al.](\l), [2010](\l), [Zhang et al.](\l), [2013](\l)\]。
>
> 终生学习是一种持续地学习方式，学习系统可以不断累积在先前任务中学
> 到的知识，并在未来新的任务中能够利用这些知识\[[Chen and Liu](\l),
> [2016](\l), [Good-](\l) [fellow et al.](\l), [2013](\l), [Kirkpatrick
> et al.](\l), [2017](\l)\]。
>
> 元学习是主要关注于如何在多个不同任务上学习一种可泛化的快速学习能
> 力\[[Thrun and Pratt](\l), [2012](\l)\]。
>
> 上述这些方式都是目前深度学习中的前沿研究问题。

#### 习题

> 习题 **10-1** 集成学习是否可以避免过拟合？
>
> 习题 **10-2** 分析自训练和EM 算法之间的联系。
>
> 习题 **10-3** 根据最大后验估计来推导公式([10.50](\l))。

#### 参考文献

> Marcin Andrychowicz, Misha Denil, Sergio Gomez, Matthew W Hoﬀman,
> David Pfau, Tom Schaul, and Nando de Freitas. Learn- ing to learn by
> gradient descent by gradient descent. In *Advances in Neural
> Information Processing Systems*, pages 3981--3989, 2016.
>
> Andrew Arnold, Ramesh Nallapati, and William W Cohen. A comparative
> study of methods for transductive transfer learning. In *icdmw*, pages
> 77--82. IEEE, 2007.
>
> Shai Ben-David, John Blitzer, Koby Cram- mer, Alex Kulesza, Fernando
> Pereira, and Jennifer Wortman Vaughan. A theory of learning from
> diﬀerent domains. *Machine learning*, 79(1-2):151--175, 2010.
>
> Christopher M. Bishop. *Pattern recogni- tion and machine learning,
> 5th Edition*. In-
>
> formation science and statistics. Springer, 2007. ISBN 9780387310732.
>
> Avrim Blum and Tom Mitchell. Combining labeled and unlabeled data with
> co-training. In *Proceedings of the eleventh annual con- ference on
> Computational learning theory*, pages 92--100, 1998.
>
> Konstantinos Bousmalis, George Trigeorgis, Nathan Silberman, Dilip
> Krishnan, and Du- mitru Erhan. Domain separation networks. In
> *Advances in Neural Information Process-* *ing Systems*, pages
> 343--351, 2016.
>
> Leo Breiman. Random forests. *Machine* *learning*, 45(1):5--32, 2001.
>
> R. Caruana. Multi-task learning. *Machine* *Learning*, 28(1):41--75,
> 1997.
>
> Zhiyuan Chen and Bing Liu. Lifelong ma- chine learning. *Synthesis
> Lectures on Ar-*
>
> 参考文献 2019 年 4 月 6 日 257
>
> *tiﬁcial Intelligence and Machine Learning*, 10(3):1--145, 2016.
>
> Jia Deng, Wei Dong, Richard Socher, Li- Jia Li, Kai Li, and Li
> Fei-Fei. Imagenet: A large-scale hierarchical image database. In
> *Computer Vision and Pattern Recogni- tion, 2009. CVPR 2009. IEEE
> Conference*
>
> *on*, pages 248--255. IEEE, 2009.
>
> Jacob Devlin, Ming-Wei Chang, Kenton Lee, and Kristina Toutanova.
> Bert: Pre- training of deep bidirectional transformers for language
> understanding. *arXiv preprint* *arXiv:1810.04805*, 2018.
>
> Chelsea Finn, Pieter Abbeel, and Sergey Levine. Model-agnostic
> meta-learning for fast adaptation of deep networks. In *Pro- ceedings
> of the 34th International Con- ference on Machine Learning-Volume 70*,
> pages 1126--1135. JMLR. org, 2017.
>
> Robert M French. Catastrophic forgetting in connectionist networks.
> *Trends in cogni-* *tive sciences*, 3(4):128--135, 1999.
>
> Yoav Freund, Robert E Schapire, et al. Ex- periments with a new
> boosting algorithm. In *Proceedings of the International Con- ference
> on Machine Learning*, volume 96, pages 148--156. Citeseer, 1996.
>
> Jerome Friedman, Trevor Hastie, Robert Tibshirani, et al. Additive
> logistic regres- sion: a statistical view of boosting. *The* *annals
> of statistics*, 28(2):337--407, 2000.
>
> Yaroslav Ganin, Evgeniya Ustinova, Hana Ajakan, Pascal Germain, Hugo
> Larochelle, François Laviolette, Mario Marchand, and Victor Lempitsky.
> Domain-adversarial training of neural networks. *Journal of Machine
> Learning Research*, 17(59):1--35, 2016.
>
> Ian J Goodfellow, Mehdi Mirza, Da Xiao, Aaron Courville, and Yoshua
> Bengio. An empirical investigation of catastrophic for- getting in
> gradient-based neural networks. *arXiv preprint arXiv:1312.6211*,
> 2013.
>
> Arthur Gretton, Karsten M Borgwardt, Malte Rasch, Bernhard Schölkopf,
> and Alex J Smola. A kernel method for the two-sample-problem. In
> *Advances in neural*
>
> *information processing systems*, pages 513-- 520, 2007.
>
> Kaiming He, Xiangyu Zhang, Shaoqing
>
> Ren, and Jian Sun. Deep residual learning for image recognition. In
> *Proceedings of the IEEE conference on computer vision and* *pattern
> recognition*, pages 770--778, 2016.
>
> Thorsten Joachims. Transductive inference
>
> for text classiﬁcation using support vector machines. In *ICML*,
> volume 99, pages 200-- 209, 1999.
>
> James Kirkpatrick, Razvan Pascanu, Neil
>
> Rabinowitz, Joel Veness, Guillaume Des- jardins, Andrei A Rusu, Kieran
> Milan, John Quan, Tiago Ramalho, Agnieszka Grabska- Barwinska, et al.
> Overcoming catastrophic forgetting in neural networks. *Proceedings of
> the national academy of sciences*, 114 (13):3521--3526, 2017.
>
> Alex Krizhevsky, Ilya Sutskever, and Ge-
>
> oﬀrey E Hinton. Imagenet classiﬁcation with deep convolutional neural
> networks. In *Advances in neural information processing* *systems*,
> pages 1097--1105, 2012.
>
> Tomas Mikolov, Ilya Sutskever, Kai Chen,
>
> Greg S Corrado, and Jeﬀ Dean. Distributed representations of words and
> phrases and their compositionality. In *Advances in neu- ral
> information processing systems*, pages 3111--3119, 2013.
>
> Sinno Jialin Pan and Qiang Yang. A sur-
>
> vey on transfer learning. *IEEE Transac- tions on knowledge and data
> engineering*, 22(10):1345--1359, 2010.
>
> Jeﬀrey Pennington, Richard Socher, and
>
> Christopher Manning. Glove: Global vec- tors for word representation.
> In *Proceed- ings of the 2014 conference on empiri- cal methods in
> natural language processing* *(EMNLP)*, pages 1532--1543, 2014.
>
> Matthew E Peters, Mark Neumann, Mo-
>
> hit Iyyer, Matt Gardner, Christopher Clark, Kenton Lee, and Luke
> Zettlemoyer. Deep contextualized word representations. *arXiv*
> *preprint arXiv:1802.05365*, 2018.
>
> Alec Radford, Karthik Narasimhan, Tim
>
> Salimans, and Ilya Sutskever. Improving language understanding by
> generative
>
> pre-training. *URL https://s3-us-west-2. amazonaws.
> com/openai-assets/research- covers/languageunsupervised/language*
> *understanding paper. pdf*, 2018.
>
> Rajat Raina, Alexis Battle, Honglak Lee, Benjamin Packer, and Andrew Y
> Ng. Self- taught learning: transfer learning from un- labeled data. In
> *Proceedings of the 24th international conference on Machine learn-*
> *ing*, pages 759--766, 2007.
>
> Jürgen Schmidhuber. Learning to control fast-weight memories: An
> alternative to dy- namic recurrent networks. *Neural Compu-* *tation*,
> 4(1):131--139, 1992.
>
> H Scudder. Probability of error of some adaptive pattern-recognition
> ma- chines. *IEEE Transactions on Information* *Theory*,
> 11(3):363--371, 1965.
>
> Karen Simonyan and Andrew Zisserman. Very deep convolutional networks
> for large- scale image recognition. *arXiv preprint*
> *arXiv:1409.1556*, 2014.
>
> Sebastian Thrun. Lifelong learning algo- rithms. In *Learning to
> learn*, pages 181--209. Springer, 1998.
>
> Sebastian Thrun and Lorien Pratt. *Learn- ing to learn*. Springer
> Science & Business Media, 2012.
>
> Lisa Torrey and Jude Shavlik. Trans- fer learning. In *Handbook of
> Research on Machine Learning Applications and Trends: Algorithms,
> Methods, and Tech-* *niques*, pages 242--264. IGI Global, 2010.
>
> Vladimir Vapnik. *Statistical learning the- ory*. Wiley, New York,
> 1998.
>
> David Yarowsky. Unsupervised word sense disambiguation rivaling
> supervised meth- ods. In *Proceedings of the 33rd annual meeting on
> Association for Computational* *Linguistics*, pages 189--196, 1995.
>
> Jason Yosinski, Jeﬀ Clune, Yoshua Bengio, and Hod Lipson. How
> transferable are fea- tures in deep neural networks? In *Advances in
> neural information processing systems*, pages 3320--3328, 2014.
>
> A Steven Younger, Sepp Hochreiter, and Peter R Conwell. Meta-learning
> with back- propagation. In *Proceedings of Interna- tional Joint
> Conference on Neural Net-* *works*, volume 3. IEEE, 2001.
>
> Werner Zellinger, Thomas Grubinger, Ed- win Lughofer, Thomas
> Natschläger, and Susanne Saminger-Platz. Central moment discrepancy
> (cmd) for domain-invariant representation learning. *arXiv preprint*
> *arXiv:1702.08811*, 2017.
>
> Kun Zhang, Bernhard Schölkopf, Krikamol Muandet, and Zhikun Wang.
> Domain adap- tation under target and conditional shift. In
> *International Conference on Machine* *Learning*, pages 819--827,
> 2013.
>
> Yu Zhang and Qiang Yang. A survey on multi-task learning. *arXiv
> preprint* *arXiv:1707.08114*, 2017.
>
> Zhi-Hua Zhou. *Ensemble methods: founda- tions and algorithms*.
> Chapman and Hal- l/CRC, 2012.
>
> Xiaojin Zhu. Semi-supervised learning liter- ature survey. *Computer
> Science, University of Wisconsin-Madison*, 2(3):4, 2006.

第三部分进阶模型
================

> 第**11** 章 概率图模型
>
> 概率论只不过是把常识归纳为计算问题。
>
> --- 皮诶尔·西蒙·拉普拉斯
>
> 概率图模型（Probabilistic Graphical
> Model，PGM），简称图模型（Graphical
> Model，GM），是指一种用图结构来描述多元随机变量之间条件独立关系的概
> 率模型，从而给研究高维空间中的概率模型带来了很大的便捷性。
>
> 对于一个*K* 维随机向量**X** = \[*X*~1~*, X*~2~*,* · · · *,
> X~K~*\]T，其联合概率为高维空间中的分布，一般难以直接建模。假设每个变量为离散变量并有*m*
> 个取值，在不作任何独立假设条件下，则需要*m^K^* − 1
> 个参数才能表示其概率分布。当*m* = 2*, K* = 100
> 时，参数量约为1030，远远超出了目前计算机的存储能力。
>
> 一种有效减少参数量的方法是独立性假设。*K*
> 维随机向量的联合概率分解为*K* 个条件概率的乘积，
>
> *p*(**x**) , *P* (**X** = **x**) (11.1)

= *p*(*x*~1~)*p*(*x*~2~\|*x*~1~) · · · *p*(*x~K~*\|*x*~1~*,* · · · *,
x~K~*~−1~)*,* (11.2)

*K*

= *p*(*x~k~ x*~1~*, , x~k~*~−1~)*,* (11.3)

> *k*=1
>
> 其中*x~k~* 表示变量*X~k~*
> 的取值。如果某些变量之间存在条件独立，其参数量就可以大幅减少。
>
> 假设有四个二值变量*X*~1~*, X*~2~*, X*~3~*,
> X*~4~，在不知道这几个变量依赖关系的情况下，可以用一个联合概率表来记录每一种取值的概率*p*(**x**~1:4~)，共需要24
> −1 = 15个参数。假设在已知*X*~1~ 时，*X*~2~ 和*X*~3~ 独立，即有

*p*(*x*~2~\|*x*~1~*, x*~3~) = *p*(*x*~2~\|*x*~1~)*,* (11.4)

*p*(*x*~3~\|*x*~1~*, x*~2~) = *p*(*x*~3~\|*x*~1~)*.* (11.5)

> 在已知*X*~2~ 和*X*~3~ 时，*X*~4~ 也和*X*~1~ 独立，即有

*p*(*x*~4~\|*x*~1~*, x*~2~*, x*~3~) = *p*(*x*~4~\|*x*~2~*, x*~3~)*,*
(11.6)

> 那么其联合概率*p*(**x**) 可以分解为

*p*(**x**) = *p*(*x*~1~)*p*(*x*~2~\|*x*~1~)*p*(*x*~3~\|*x*~1~*,
x*~2~)*p*(*x*~4~\|*x*~1~*, x*~2~*, x*~3~)*,* (11.7)

= *p*(*x*~1~)*p*(*x*~2~\|*x*~1~)*p*(*x*~3~\|*x*~1~)*p*(*x*~4~\|*x*~2~*,
x*~3~)*,* (11.8)

> 是4 个局部条件概率的乘积。如果分别用4 个表格来记录这4 个条件概率的话，
> 只需要1 + 2 + 2 + 4 = 9 个独立参数。
>
> 当概率模型中的变量数量比较多时，其条件依赖关系也比较复杂。我们可
> 以使用图结构的方式将概率模型可视化，以一种直观、简单的方式描述随机变
> 量之间的条件独立性的性质，并可以将一个复杂的联合概率模型分解为一些简
> 单条件概率模型的组合。图[11.1](\l)给出了上述例子中4
> 个变量之间的条件独立性的图形化描述。图中每个节点表示一个变量，每条连边变量之间的依赖关系。对
> 于一个非全连接的图，都存在一个或多个条件独立性假设，可以根据条件独立
> 性将联合概率分布进行分解，表示为一组局部条件概率分布的乘积。
>
> 图 11.1 变量*X*~1~*, X*~2~*, X*~3~*, X*~4~ 之间条件独立性的图形化表示
>
> 图模型的基本问题 图模型有三个基本问题：

1.  表示问题：对于一个概率模型，如何通过图结构来描述变量之间的依赖
    > 关系。

2.  推断问题：在已知部分变量时，计算其它变量的后验概率分布。

3.  学习问题：图模型的学习包括图结构的学习和参数的学习。在本章我们只
    > 关注在给定图结构时的参数学习，即参数估计问题。

> 图模型与机器学习
> 很多机器学习模型都可以归结为概率模型，即建模输入和输出之间的条件概率分布。因此，图模型提供了一种新的角度来解释机器学习模型，并且这种角度有很多优点，比如了解不同机器学习模型之间的联系，方便设计新模型等。在机器学习中，图模型越来越多地用来设计和分析各种学习算法。
>
> **11.1** 模型表示
>
> 图由一组节点和节点之间的边组成。在概率图模型中，每个节点都表示一
> 个随机变量（或一组随机变量），边表示这些随机变量之间的概率依赖关系。
>
> 常见的概率图模型可以分为两类：有向图模型和无向图模型。有向图模型
> 的图结构为有向非循环图，如果两个节点之间有连边，表示对于的两个变量为
> 因果关系。无向图模型使用无向图来描述变量之间的关系。每条边代表两个变
> 量之间有概率依赖关系，但是并不一定是因果关系。
>
> 图[11.2](\l)给出了两个代表性图模型（有向图和无向图）的示例，分别表示了四个变量{*X*~1~*,
> X*~2~*, X*~3~*, X*~4~} 之间的依赖关系

(a) 有向图：贝叶斯网络 (b) 无向图：马尔可夫随机场

> 图 11.2
> 有向图和无向图示例。带阴影的节点表示可观测到的变量，不带阴影的节点表示隐变量，连边表示两变量间的条件依赖关系

###### 有向图模型

> 有向图模型（Directed Graphical model），也称为贝叶斯网络（Bayesian
> Network），或信念网络（Belief
> Network，BN），是指用有向图来表示概率分布的图模型。假设一个有向图*G*(V*,*
> 𝗌)，节点集合V = {*X*~1~*, X*~2~*,* · · · *, X~K~*} 表示*K*
> 个随机变量，节点*k* 对应随机变量*X~k~*。𝗌
> 为边的集合，每条边表示两个变量之间的因果关系。
>
> 在本章后文中，"节点"
> 与"随机变量"、"变量"的概念会经常混用。每个节点对应一个随机变量。
>
> 条件独立性
> 在贝叶斯网络中，如果两个节点是直接连接的，它们肯定是非条件独立的，是直接因果关系。父节点是"因"，子节点是"果"。
>
> 如果两个节点不是直接连接的，但是它们之间有一条经过其它节点的路径
> 来连接，那么这两个节点之间的条件独立性就比较复杂。以三个节点的贝叶斯
> 网络为例，给定三个节点*X*~1~*, X*~2~*, X*~3~，*X*~1~ 和*X*~3~
> 是不直接连接的，可以通过节点*X*~2~
> 连接。这三个节点之间可以有四种连接关系，如图[11.3](\l)所示。

(a)

(b) (c) (d) 

> 图 11.3 三个变量的依赖关系示例。在(a)(b) 中，*X*~1~ ⊥
> *X*~3~\|∅，但*X*~1~ ⊥ *X*~3~\|*X*~2~； 在(c) 中，*X*~1~ ⊥
> *X*~3~\|∅，但*X*~1~ ⊥ *X*~3~\|*X*~2~；在(d) 中，*X*~1~ ⊥
> *X*~3~\|∅，但*X*~1~ ⊥ *X*~3~\|*X*~2~
>
> 间接因果关系（图[**11.3a**](\l)） 当*X*~2~ 已知时，*X*~1~ 和*X*~3~
> 为条件独立，即*X*~1~ ⊥
> *X*~3~\|*X*~2~；间接果因关系（图[**11.3b**](\l)） 当*X*~2~
> 已知时，*X*~1~ 和*X*~3~ 为条件独立，即*X*~1~ ⊥
> *X*~3~\|*X*~2~；共因关系（图[**11.3c**](\l)） 当*X*~2~ 未知时，*X*~1~
> 和 *X*~3~ 是不独立的；当*X*~2~ 已知时，*X*~1~
>
> 和 *X*~3~ 条件独立，即*X*~1~ ⊥ *X*~3~\|*X*~2~；
>
> 共果关系（图[**11.3d**](\l)） 当*X*~2~ 未知时，*X*~1~ 和 *X*~3~
> 是独立的；当*X*~2~ 已知时，*X*~1~ 和*X*~3~ 不独立，即*X*~1~ ⊥
> *X*~3~\|*X*~2~。
>
> 局部马尔可夫性质
> 对一个更一般的贝叶斯网络，其局部马尔可夫性质为：每个随机变量在给定父节点的情况下，条件独立于它的非后代节点。
>
> *X~k~* ⊥ *Z*\|*X~π~k ,* (11.10)
>
> 从公式([11.3](\l)) 和([11.9](\l)) 可得到。参见习题[11-3](\l)。
>
> 其中*Z* 为*X~k~* 的非后代变量。

###### 常见的有向图模型

> 很多经典的机器学习模型可以使用有向图模型来描述，比如朴素贝叶斯分
> 类器、隐马尔可夫模型、深度信念网络等。

1.  **sigmoid** 信念网络

> 为了减少模型参数，可以使用参数化模型来建模有向图模型中的条件概率
> 分布。一种简单的参数化模型为sigmoid 信念网络\[[Neal](\l),
> [1992](\l)\]。*sigmoid* 信念网络（sigmoid belief
> network，SBN）中的变量取值为{0*,* 1}。对于变量*X~k~*
> 和它的父节点集合*π~k~*，其条件概率分布表示为
>
> 深度信念网络参见第**??**节。
>
> 更复杂的深度信念网络，参见第**??**节。
>
> *P* (*X~k~* = 1\|**x***~π~k , θ*) = *σ*(*θ*~0~ +

*xi*∈**x***πk*

> *θ~i~x~i~*)*,* (11.11)
>
> 其中*σ*(·) 是Logistic sigmoid 函数，*θ~i~*
> 是可学习的参数。假设变量*X~k~* 的父节点数量为*M*
> ，如果使用表格来记录条件概率需要2*M*
> 个参数，如果使用参数化模型只需要*M* + 1
> 个参数。如果对不同的变量的条件概率都共享使用一个参数化模型，其参数数量又可以大幅减少。
>
> 值得一提的是，Sigmoid 信念网络与Logistic 回归模型都采用Logistic
> 函数来计算条件概率。如果假设Sigmoid
> 信念网络中只有一个叶子节点，其所有的父节点之间没有连接，且取值为实数，那么sigmoid
> 信念网络的网络结构和Logistic
> 回归模型类似，如图[11.4](\l)所示。但是，这两个模型区别在于Logistic
> 回归模型中
>
> 的**x** 作为一种确定性的参数，而非变量。因此，Logistic
> 回归模型只建模条件概 Logistic 回归模型也经常解
>
> 率*p*(*y*\|**x**)，是一种判别模型；而sigmoid 信念网络建模*p*(**x***,
> y*)，是一种生成模型。

2.  朴素贝叶斯分类器

> 朴素贝叶斯分类器（Naive Bayes
> Classiﬁer，NB）是一类简单的概率分类器，在强（朴素）独立性假设的条件下运用贝叶斯公式来计算每个类别的后验
> 概率。
>
> 释一种条件无向图模型。
>
> *X*1 · · · *Xi* · · · *XM*

a.  只有一层的简单sigmoid 信念网络

> *Y*

b.  Logistic 回归

> 图 11.4 sigmoid 信念网络和Logistic 回归模型的比较
>
> 给定一个有*d* 维特征的样本**x** 和类别*y*，类别的后验概率为
>
> [*p*(*x*~1~*,* ·]{.underline} [·]{.underline} [· *,
> x~d~*\|*y*)*p*(*y*)]{.underline}
>
> *p*(*x*~1~*,* · · · *, x~d~*)
>
> (11.12)
>
> 其中*θ* 为概率分布的参数。
>
> 𝖺 *p*(*x*~1~*,* · · · *, x~d~*\|*y, θ*)*p*(*y*\|*θ*)*,* (11.13)
>
> 在朴素贝叶斯分类器中，假设在给定 *Y* 的情况下，*X~i~*
> 之间是条件独立的， 即*X~i~* ⊥ *X~j~*\|*Y,* ∀*i* ̸=
> *j*。图[11.5](\l)给出了朴素贝叶斯分类器的图形表示。
>
> 图 11.5 朴素贝叶斯模型的图模型表示
>
> 条件概率分布*p*(*y*\|**x**) 可以分解为
>
> *d*
>
> *p*(*y*\|**x***, θ*) 𝖺 *p*(*y*\|*θ~c~*) Y *p*(*x~i~*\|*y, θ~i,y~*)*,*
> (11.14)
>
> 其中*θ~c~* 是*y* 的先验概率分布的参数，*θ~i,y~*
> 是条件概率分布*p*(*x~i~*\|*y, θ~i,y~*) 的参数。如果*x~i~*
> 为连续值，*p*(*x~i~*\|*y, θ~i,y~*) 可以用高斯分布建模。如果*x~i~*
> 为离散值，*p*(*x~i~*\|*y, θ~i,y~*)可以用多项分布建模。
>
> 虽然朴素贝叶斯分类器的条件独立性假设太强，但是在实际应用中，朴素
> 贝叶斯分类器在很多任务上也能得到很好的结果，并且模型简单，可以有效防
> 止过拟合。

3.  隐马尔可夫模型

> 隐马尔可夫模型（Hidden Markov Model，HMM）\[[Baum and Petrie](\l),
> [1966](\l)\]
>
> 是一种含有隐变量的马尔可夫过程。图[11.6](\l)给出隐马尔可夫模型的图模型表示。
>
> · · ·
>
> · · ·
>
> 图 11.6 隐马尔可夫模型隐马尔可夫模型的联合概率可以分解为
>
> *T*
>
> *p*(**x***,* **y***, θ*) = *p*(*y~t~ y~t~*~−1~*, θ~s~*)*p*(*x~t~ y~t~,
> θ~t~*)*,* (11.15)
>
> *t*=1
>
> 其中*p*(*x~t~*\|*y~t~, θ~t~*) 为输出概率，*p*(*y~t~*\|*y~t~*~−1~*,
> θ~s~*) 为转移概率，*θ~s~, θ~t~* 分别表示两类条件概率的参数。

###### 无向图模型

> 无向图模型，也称为马尔可夫随机场（Markov Random
> Field，MRF）或马尔可夫网络（Markov
> Network），是一类用无向图来描述一组具有局部马尔可夫性质的随机向量**X**
> 的联合概率分布的模型。
>
> 这里 *p*(*y*~1~\|*y*~0~) 一般简化为
>
> *p*(*y*~1~)。
>
> 无向图的马尔可夫性 无向图中的马尔可夫性可以表示为
>
> *Xk* ⊥ **X**K*N* (*k*)*,*K*k* \| **X***N* (*k*)*,*
>
> 其中**X**~K*N*(*k*)*,*K*k*~ 表示除**X**~*N*(*k*)\ 和*Xk*~
> 外的其它变量。
>
> 对于图[11.2b](\l)中的4 个变量，根据马尔可夫性质，可以得到 *X*~1~ ⊥
> *X*~4~\|*X*~2~*, X*~3~
>
> 和*X*~2~ ⊥ *X*~3~\|*X*~1~*, X*~4~。

###### 无向图模型的概率分解

> 团
> 由于无向图模型并不提供一个变量的拓扑顺序，因此无法用链式法则对*p*(**x**)
> 进行逐一分解。无向图模型的联合概率一般以全连通子图为单位进行分解。无向图中的一个全连通子图，称为团（Clique），即团内的所有节点之间都连边。图[11.7](\l)中共有7
> 个团，包括{*X*~1~*, X*~2~}，{*X*~1~*, X*~3~}，{*X*~2~*,
> X*~3~}，{*X*~3~*, X*~4~}，{*X*~2~*, X*~4~}，
>
> {*X*~1~*, X*~2~*, X*~3~}，{*X*~2~*, X*~3~*, X*~4~}。
>
> 在所有团中，如果一个团不能被其它的团包含，这个团就是一个最大团
>
> （Maximal Clique）。
>
> 图 11.7 无向图模型中的团和最大团
>
> 因子分解
> 无向图中的的联合概率可以分解为一系列定义在最大团上的非负函数的乘积形式。
>
> Hammersley-Cliﬀord 定理的证明可以参考\[[Koller and Friedman](\l),
> [2009](\l)\]。无向图模型与有向图模型的一个重要区别是有配分函数*Z*。配分函数的计算复杂度是指数级的，因此在推断和参数学习时都需要重点考虑。
>
> 吉布斯分布 公式([11.17](\l)) 中定义的分布形式也称为吉布斯分布（Gibbs
> distribu- tion）。根据Hammersley-Cliﬀord
> 定理，无向图模型和吉布斯分布是一致的。吉布斯分布一定满足马尔可夫随机场的条件独立性质，并且马尔可夫随机场的概
> 率分布一定可以表示成吉布斯分布。
>
> 由于势能函数必须为正的，因此我们一般定义为
>
> *ϕ~c~*(**x***~c~*) = exp(−*E~c~*(**x***~c~*))*,* (11.19)
>
> 其中*E*(**x***~c~*) 为能量函数（energy function）。
>
> 因此，无向图上定义的概率分布可以表示为：
>
> *P* (**x**) = [ 1]{.underline} Y exp(−*E* (**x** )) (11.20)
>
> 配 分 函 数 的 计 算 参 见第[11.2.2](\l)节。
>
> 这里的负号是遵从物理上习惯，即能量越低意味着概率越高。
>
> = [ 1]{.underline} exp(Σ −*E* (**x** )) (11.21)
>
> 这种形式的分布又称为玻尔兹曼分布（Boltzmann
> Distribution）。任何一个无向图模型都可以用公式([11.21](\l))
> 来表示其联合概率。

###### 常见的无向图模型

> 很多经典的机器学习模型可以使用无向图模型来描述，比如对数线性模型
>
> （也叫最大熵模型）、条件随机场、玻尔兹曼机、受限玻尔兹曼机等。

4.  对数线性模型

> 势能函数一般定义为
>
> *ϕ~c~*(**x***~c~*\|*θ~c~*) = exp *θ*T*f~c~*(**x***~c~*) *,* (11.22)
>
> 其中函数*f~c~*(**x***~c~*) 为定义在**x***~c~* 上的特征向量，*θ~c~*
> 为权重向量。这样联合概率*p*(**x**)
>
> 的对数形式为
>
> 玻尔兹曼分布参见定义[**??**](\l)。
>
> 玻尔兹曼机参见第[12.1](\l)节。
>
> 受 限 玻 尔 兹 曼 机 参 见第[12.2](\l)节。
>
> log *p*(**x**\|*θ*) = Σ *θ*T*f~c~*(**x***~c~*) − log *Z*(*θ*)*,*
> (11.23)
>
> *c*∈*C*
>
> 其中*θ*
> 代表所有势能函数中的参数*θ~c~*。这种形式的无向图模型也称为对数线性模型（Log-Linear
> Model）或最大熵模型（Maximum Entropy Model）\[[Berger](\l) [et
> al.](\l), [1996](\l), [Della Pietra et al.](\l), [1997](\l)\]。
>
> softmax 回 归 模 型 参 见
>
> 如果用对数线性模型来建模条件概率*p*(*y*\|**x**)，
>
> *p*(*y*\|**x***, θ*) = [ 1]{.underline} exp *θ*T*f* (**x***, y*) *,*
> (11.24)
>
> 其中*Z*(**x***, θ*) = *y* exp(*θ*T*f~y~*(**x***,
> y*))。这种对数线性模型也称为条件最大熵模型
>
> 或*softmax* 回归模型。
>
> 第[3.3](\l)节。 **11.1.5.2** 条件随机场
>
> 条件随机场（Conditional Random Field，CRF）\[[Laﬀerty et al.](\l),
> [2001](\l)\] 是一种直接建模条件概率的无向图模型。
>
> 和最大熵模型不同，条件随机场建模的条件概率*p*(**y**\|**x**) 中，**y**
> 一般为随机向量，因此需要对*p*(**y**\|**x**)
> 进行因子分解。假设条件随机场的最大团集合为C，其条件概率为

*p*(**y**\|**x***, θ*) =

> ( 1 ) exp Σ *θ*T*f* (**x***,* **y** ) *,* (11.25)
>
> 其中*Z*(**x***, θ*) = *y* exp( *c*∈C *f~c~*(**x***,*
> **y***~c~*)T*θ~c~*) 为归一化项。
>
> 一个最常用的条件随机场为图[11.8b](\l)中所示的链式结构，其条件概率为

*p*(**y**\|**x***, θ*

) = [ 1]{.underline} exp Σ*T*

> *θ*T*f*~1~

(**x***, y~t~*

> *T* −1

) +

*θ*T*f*~2~

(**x***, y~t~, y~t~*~+1~

) *,*

> (11.26)

*Z , θ*)

> 1
>
> *t*=1
>
> 2
>
> *t*=1
>
> 其中*f*~1~(**x***, y~t~*) 为状态特征，一般和位置*t*
> 相关，*f*~2~(**x***, y~t~, y~t~*~+1~)
> 为转移特征，一般可以简化为*f*~2~(*y~t~, y~t~*~+1~)
> 并使用状态转移矩阵来表示。

c.  最大熵模型 (b) 线性链的条件随机场

> 图 11.8 最大熵模型和线性链的条件随机场

###### 有向图和无向图之间的转换

> 无向图模型可以表示有向图模型无法表示的一些依赖关系，比如循环依赖；
> 但它不能表示有向图模型能够表示的某些关系，比如因果关系。
>
> 以图[11.9a](\l)中的有向图为例，其联合概率分布可以分解为
>
> *p*(**x**) = *p*(*x*~1~)*p*(*x*~2~)*p*(*x*~3~)*p*(*x*~4~\|*x*~1~*,
> x*~2~*, x*~3~)*,* (11.27)
>
> 其中*p*(*x*~4~\|*x*~1~*, x*~2~*, x*~3~)
> 和四个变量都相关。如果要转换为无向图，需要将这四个变量都归属于一个团中。因此需要将*x*~4~
> 的三个父节点之间都加上连边，如图[11.9b](\l)所示。这个过程称为道德化（Moralization）。转换后的无向图称为道德图（Moral
> Graph）。在道德化的过程中，原来有向图的一些独立性会丢失，比如上面例子中*X*~1~
> ⊥ *X*~2~ ⊥ *X*~2~\|∅ 在道德图中不再成立。
>
> 道德化的名称来源是：有共同儿子的父节点都必须结婚
>
> （即有连边）。
>
> \(a) 有向图 (b) 道德图
>
> 图 11.9 具有共果关系的有向图的道德化示例

2.  推断

> 在图模型中，推断（inference）是指在观测到部分变量**e** = {*e*~1~*,
> e*~2~*,* · · · *, e~m~*}
>
> 时，计算其它变量的某个子集**q** = {*q*~1~*, q*~2~*,* · · · *, q~n~*}
> 的后验概率*p*(**q**\|**e**)。
>
> 假设一个图模型中，除了变量**e**、**q**
> 外，其余变量表示为**z**。根据贝叶斯公
>
> 式有

[*p*(**q***,* **e**)]{.underline}

*p* \| *p*(**e**)

(11.28)

> 不失一般性，这里假设所有变量都为离散变量。
>
> **~z~** *p*(**q***,* **e***,* **z**)
>
> ~**q***,***z**~ *p*(**q***,* **e***,* **z**)
>
> 因此，图模型的推断问题可以转换为求任意一个变量子集的边际概率分布
> 问题。
>
> 在图模型中，常用的推断方法可以分为精确推断和近似推断两类。
> 本节介绍两种精确推断算法，下一节介绍近似推断算法。

###### 变量消除法

> 以图[11.2a](\l)的有向图为例，假设推断问题为计算后验概率*p*(*x*~1~\|*x*~4~)，需要计算两个边际概率*p*(*x*~1~*,
> x*~4~) 和*p*(*x*~4~)。
>
> 根据条件独立性假设，有
>
> *p*(*x*~1~*, x*~4~) =
> *p*(*x*~1~)*p*(*x*~2~\|*x*~1~)*p*(*x*~3~\|*x*~1~)*p*(*x*~4~\|*x*~2~*,
> x*~3~)*,* (11.30)
>
> *x*2*,x*3
>
> 假设每个变量取 *K* 个值，计算上面的边际分布需要 *K*^2^ 次加法以及
> *K*^2^ × 3 次乘法。
>
> 根据乘法的分配律，
>
> *ab* + *ac* = *a*(*b* + *c*)*,* (11.31)
>
> 边际概率*p*(*x*~1~*, x*~4~) 可以写为
>
> *p*(*x*~1~*, x*~4~) = *p*(*x*~1~) Σ *p*(*x*~3~\|*x*~1~) Σ
> *p*(*x*~2~\|*x*~1~)*p*(*x*~4~\|*x*~2~*, x*~3~)*.* (11.32)
>
> 这样计算量可以减少到*K*^2^ + *K* 次加法和*K*^2^ + *K* + 1 次乘法。
>
> 这种方法是利用动态规划的思想，每次消除一个变量，来减少计算边际分
> 布的计算复杂度，称为变量消除法（variable elimination
> algorithm）。随着图模型规模的增长，变量消除法的收益越大。
>
> 变量消除法可以按照不同的顺序来消除变量。比如上面的推断问题也可以
> 按照*x*~3~，*x*~2~ 的消除顺序进行计算。
>
> 同理，边际概率*p*(*x*~4~) 可以通过以下方式计算：
>
> *p*(*x*~4~) = Σ Σ *p*(*x*~4~\|*x*~2~*, x*~3~) Σ
> *p*(*x*~3~\|*x*~1~)*p*(*x*~2~\|*x*~1~)*p*(*x*~1~)*.* (11.33)
>
> 本节以无向图为例来介绍信念传播，但其同样适用于有向图。
>
> 变量消除法的一个缺点是在计算多个边际分布时存在很多重复的计算。比
> 如在上面的图模型中，计算边际概率*p*(*x*~4~) 和*p*(*x*~3~)
> 时很多局部的求和计算是一样的。

###### 信念传播算法

> 信念传播（Belief
> Propagation，BP）算法，也称为和积（Sum-Product）算法或消息传递（Message
> Passing）算法，是将变量消除法中的和积（Sum-Product）
> 操作看作是消息，并保存起来，这样可以节省大量的计算资源。

1.  链式结构上的的信念传播算法

· · ·

> 图 11.10 无向马尔科夫链的消息传递过程
>
> 以图[11.10](\l)所示的无向马尔可夫链为例，其联合概率*p*(**x**) 为

*Z c c*

> *c*∈C
>
> *T* −1

= [ 1]{.underline}

*Z*

> *ϕ*(*x~t~, x*
>
> *t*=1

*t*+1

) (11.35)

> 其中*ϕ*(*x~t~, x~t~*~+1~) 是定义在团(*x~t~, x~t~*~+1~)
> 的势能函数。第*t* 个变量的边际概率*p*(*x~t~*) 为
>
> *p*(*x~t~*) = Σ · · · Σ Σ · · · Σ *p*(**x**) (11.36)

*x*1 *xt*−1 *xt*+1 *xT*

> *T* −1
>
> = [ 1]{.underline} Σ · · · Σ Σ · · · Σ Y *ϕ*(*x , x* )*.* (11.37)
>
> 假设每个变量取*K* 个值，不考虑归一化项，通过公式([11.37](\l))
> 计算边际分布需要
>
> *K^T^* ^−1^ 次加法以及*K^T^* ^−1^ × (*T* − 1) 次乘法。
>
> 根据乘法的分配律，边际概率*p*(*x~t~*) 可以通过下面方式进行计算：

[1]{.underline} Σ

*t*−1

>  Σ
>
> *T* −1 

= [ 1]{.underline}  Σ *ϕ*(*x , x* ) · · · Σ *ϕ*(*x , x* ) Σ *ϕ*(*x ,
x* )  ·

>  Σ *ϕ*(*x~t~, x~t~*~+1~) · · · Σ *ϕ*(*x~T~* ~−2~*, x~T~* ~−1~) Σ
> *ϕ*(*x~T~* ~−1~*, x~T~* ) 

= [ 1]{.underline} *µ*

> (*x* )*µ*
>
> (*x* )*,* (11.38)

*Z t*−1*,t t*

> *t*+1*,t t*
>
> 其中*µ~t~*~−1*,t*~(*x~t~*) 定义为变量*X~t~*~−1~ 向变量*X~t~*
> 传递的消息。*µ~t~*~−1*,t*~(*x~t~*) 是关于变量*X~t~*
> 的函数，可以递归计算：
>
> *µ~t~*~−1*,t*~(*x~t~*) , *ϕ*(*x~t~*~−1~*,
> x~t~*)*µ~t~*~−2*,t*−1~(*x~t~*~−1~)*.* (11.39)
>
> *xt*−1
>
> *µ~t~*~+1*,t*~(*x~t~*) 是变量*X~t~*~+1~ 向变量*X~t~*
> 传递的消息，定义为
>
> *µ~t~*~+1*,t*~(*x~t~*) , *ϕ*(*x~t~,
> x~t~*~+1~)*µ~t~*~+2*,t*+2~(*x~t~*~+1~)*.* (11.40)
>
> *xt*+1
>
> 边际概率*p*(*x~t~*)
> 的计算复杂度减少为*O*(*TK*^2^)。如果要计算整个序列上所有变量的边际概率，不需要将消息传递的过程重复*T*
> 次，因为其中每两个相邻节点上的消息是相同的。
>
> 链式结构图模型的信念传播过程为

1.  依次计算前向传递的消息*µ~t~*~−1*,t*~(*x~t~*)，*t* = 1*,* · · · *, T*
    > − 1；

2.  依次计算反向传递的消息*µ~t~*~+1*,t*~(*x~t~*)，*t* = *T* − 1*,* · · ·
    > *,* 1；

3.  在任意节点*t* 上计算配分函数*Z*，

> *Z* = *µ~t~*~−1*,t*~(*x~t~*)*µ~t~*~+1*,t*~(*x~t~*)*.* (11.41)
>
> *xt*
>
> 这样就可以通过公式（[11.38](\l)）计算所有变量的边际概率了。

2.  树结构上的信念传播算法

> 信念传播算法也可以推广到具有树结构的图模型上。如果一个有向图满足
> 任意两个变量只有一条路径（忽略方向），且只有一个没有父节点的节点，那么
> 这个有向图为树结构，其中唯一没有父节点的节点称为根节点。如果一个无向
> 图满足任意两个变量只有一条路径，那么这个无向图也为树结构。在树结构的
> 无向图中，任意一个节点都可以作为根节点。
>
> 树结构图模型的信念传播过程为：1）从叶子节点到根节点依次计算并传递消息；2）从根节点开始到叶子节点，依次计算并传递消息；3）在每个节点上
> 计算所有接收消息的乘积（如果是无向图还需要归一化），就得到了所有变量的
> 边际概率。
>
> 如果图结构中存在环路，可以使用联合树算法（Junction Tree Algorithm）
> \[[Lauritzen and Spiegelhalter](\l), [1988](\l)\]
> 来将图结构转换为无环图。

#### 近似推断

> 在实际应用中，精确推断一般用于结构比较简单的推断问题。当图模型的
> 结构比较复杂时，精确推断的计算开销会比较大。此外，如果图模型中的变量
> 是连续的，并且其积分函数没有闭型（closed-form）解时，也无法使用精确推
> 断。因此，在很多情况下也常常采用近似的方法来进行推断。
>
> 近似推断（Approximate Inference）主要有以下三种方法：

1.  环路信念传播：当图模型中存在环路时，使用和积算法时，消息会在环路中一直传递，可能收敛或不收敛。环路信念传播（Loopy
    > Belief Propagation，
    > LBP）是在具有环路的图上依然使用和积算法，即使得到不精确解，在某些任务上也可以近似精确解。

2.  变分法：图模型中有些变量的局部条件分布可能非常复杂，或其积分无法
    > 计算。变分法（Variational
    > Method）是引入一个变分分布（通常是比较简单的分布）来近似这些条件概率，然后通过迭代的方法进行计算。首先
    > 是更新变分分布的参数来最小化变分分布和真实分布的差异（比如交叉
    > 熵或KL 距离），然后再根据变分分布来进行推断。

3.  采样法： 采样法（Sampling
    > Method）是通过模拟的方式来采集符合某个分布*p*(**x**)
    > 的一些样本，并通过这些样本来估计和这个分布有关的运算，比如期望等。

> 本节主要介绍基于采样法的近似推断。

###### 蒙特卡罗方法

> 采样法（Sampling Method），也叫蒙特卡罗方法（Monte Carlo Method）
> 或统计模拟方法，是20 世纪40
> 年代中期提出的一种通过随机采样的方法来近似估计一些计算问题的数值解。随机采样指从给定概率密度函数*p*(*x*)
> 中抽取出符合其概率分布的样本。由于电子计算机的出现和快速发展，这种方法作为一种独立方法被提出来，使得当时很多难以计算的问题都可以通过随机模拟的方法来进行估计。
>
> 蒙特卡罗方法的一个最简单的应用例子是计算圆周率*π*。我们知道半径为 *r*
> 的圆的面积为*πr*^2^，而直径为2*r*
> 的正方形的面积为4*r*^2^。当我们用正方形去嵌套一个相切的圆时，它们的面积之比是
> ^1^ *π*。当不知道*π*
> 时，我们无法计算圆的面积。因此，需要通过模拟的方法来进行近似估计。首先在正方形内部按均值
> 采样的方式随机生成若干点，计算它们与圆心点的距离，从而判断是否落在圆
> 的内部。然后去统计落在圆内部的点占到所有点的比例。当有足够的点时，这
> 个比例应该接近于 ^1^ *π*，而从近似估算出*π* 的值。
>
> 蒙特卡罗方法的基本思想可以归结为根据一个已知概率密度函数为*p*(*x*)
> 的分布来计算函数*f* (*x*) 的期望
>
> E\[*f* (*x*)\] = *f* (*x*)*p*(*x*)*dx.* (11.42)
>
> *x*
>
> 采样也叫抽样。
>
> 蒙特卡罗方法诞生于 20 世纪40
> 年代美国的"曼哈顿计划"，其名字来源于摩纳哥的一个以赌博业闻名的城市蒙特卡罗，象征概率。
>
> 当*p*(*x*) 比较复杂时，很难用解析的方法来计算这个期望。为了计算E\[*f*
> (*x*)\]，我们可以通过数值解法的方法来近似计算。首先从*p*(*x*)
> 中独立抽取的*N* 个样本*x*^(1)^*, x*^(2)^*,* · · · *, x*^(*N*)^，*f*
> (*x*) 的期望可以用这*N* 个样本的均值*f*ˆ*N* 来近似。
>
> 本节中假设*x* 为连续变量，如果 *x* 是离散变量，可以将积分替换为求和。
>
> *f*ˆ*N* = *f* (*x*^(1)^) + · · · + *f* (*x*^(*N*)^) *.* (11.43)

[ 1]{.underline}

> 根据大数定律，当*N* 趋向于无穷大时，样本均值收敛于期望值。

*f*ˆ*N*

> −*^P^*→ E \[*f* (*x*)\] 当 *N* → ∞*.* (11.44)
>
> 这就是蒙特卡罗方法的理论依据。
>
> 参见习题[11-4](\l)。

[ 1]{.underline}

> 随机采样
> 蒙特卡罗方法的难点是如何进行随机采样，即如何让计算机生成满足概率密度函数*p*(*x*)
> 的样本。我们知道，计算机可以比较容易地随机生成一个在\[0*,* 1\]
> 区间上均布分布的样本*ξ*，*p*(*ξ*)=1。如果要随机生成服从某个非均匀分布的样本，就需要一些间接的采样方法。
>
> 如果一个分布的概率密度函数为*p*(*x*)，其累积分布函数cdf(*x*)
> 为连续的严格增函数，且存在逆函数cdf^−1^(*y*)*, y* ∈ \[0*,*
> 1\]，那么我们可以利用累积分布函数的逆函数来生成服从该随机分布的样本。假设*ξ*
> 是\[0*,* 1\] 区间上均匀分布的随机变量，则cdf^−1^(*ξ*)
> 服从概率密度函数为*p*(*x*) 的分布。

但当*p*(*x*)
非常复杂，其累积分布函数的逆函数难以计算，或者不知道*p*(*x*)

的精确值，只知道未归一化的分布*p*ˆ(*x*)，那么就难以直接对*p*(*x*)
进行采样，往

> *p*(*x*) = *p*ˆ(*x*)，其中*Z* 为配分函数。
>
> 为了简化起见，我们把概率密度函数为*p*(*x*)
> 为分布简称为分布*p*(*x*)，下同。
>
> 提议分布在很多文献中也翻
>
> 往需要使用一些间接的采样策略，比如拒绝采样、重要性采样、马尔可夫链蒙
> 特卡罗采样等。这些方法一般是先根据一个比较容易采样的分布进行采样，然
> 后通过一些策略来间接得到符合*p*(*x*) 分布的样本。

###### 拒绝采样

> 拒绝采样（Rejection
> Sampling），也叫接受*-*拒绝采样（Acceptance-Rejection Sampling）。
>
> 假设原始分布*p*(*x*)
> 难以直接采样，我们可以引入一个容易采样的分布*q*(*x*)，
> 一般称为提议分布（Proposal
> Distribution），然后以某个标准来拒绝一部分的样本使得最终采集的样本服从分布*p*(*x*)。
>
> 译为参考分布。 在拒绝采样中，已知未归一化的分布
> *p*ˆ(*x*)，我们需要构建一个提议分布
>
> *q*(*x*) 和一个常数 *k*，使得 *kq*(*x*) 可以覆盖函数 *p*ˆ(*x*)，即
> *kq*(*x*) ≥
>
> 图[11.11](\l)所示。
>
> *p*ˆ(*x*)*,* ∀*x*。如
>
> 0*.*4
>
> 0*.*3
>
> 0*.*2
>
> 0*.*1
>
> 0
>
> −6 −4 −2 *x*ˆ
>
> 0 2 4 6
>
> 图 11.11 拒绝采样。
>
> 对于每次抽取的样本*x*ˆ，计算接受概率（acceptance probability）：
>
> *p*ˆ(*x*ˆ)

*α*(*x*ˆ) =

> *kq*(*x*ˆ)

*,* (11.45)

> 并以概率*αx*ˆ
> 来接受样本*x*ˆ。拒绝采样的采样过程如下算法[11.1](\l)所示。
>
> 算法 **11.1:** 拒绝采样
>
> 输入**:** 提议分布*q*(**x**);
>
> 常数*k*;
>
> 样本集合V = ∅;
>
> **1 repeat**
>
> **2** 根据*q*(*x*) 随机生成一个样本*x*ˆ;
>
> **3** 计算接受概率*α*(*x*ˆ);
>
> **4** 从(0*,* 1) 的均匀分布中随机生成一个值*𝑥*;
>
> **5 if** *𝑥* ≤ *α*(*x*ˆ) **then** /\* 以*α*(*x*ˆ) 的概率接受**x**ˆ \*/
>
> **6** V = V ∪ {*x*ˆ};
>
> **7 end**
>
> **8 until** 直到获得 *N* 个样本(\|V\| = *N* );
>
> [ ]{.underline} [输出**:** 样本集合V ]{.underline}
>
> 判断一个拒绝采样方法的好坏就是看其采样效率，即总体的接受率。如果 函数
> *kq*(*x*) 远大于原始分布函数
> *p*ˆ(*x*)，拒绝率会比较高，采样效率会非常不理想。但要找到一个和*p*ˆ(*x*)
> 比较接近的提议分布往往比较困难。特别是在高维空间中，其采样率会非常低，导致很难应用到实际问题中。

###### 重要性采样

> 如果采样的目的是计算分布*p*(*x*) 下函数*f* (*x*)
> 的期望，那么实际上抽取的样本不需要严格服从分布*p*(*x*)。也可以通过另一个分布，即提议分布*q*(*x*)，直接采样并估计E*~p~*\[*f*
> (*x*)\]。
>
> 函数*f* (*x*) 在分布*p*(*x*) 下的期望可以写为

E*~p~*\[*f* (*x*)\] = ∫

= ∫

=

*x*

> *f* (*x*)*p*(*x*)*dx* (11.46)
>
> [*p*(*x*)]{.underline}
>
> *q*(*x*)
>
> *f* (*x*)*w*(*x*)*q*(*x*)*dx* (11.48)
>
> = E*~q~*\[*f* (*x*)*w*(*x*)\]*.* (11.49)
>
> 其中*w*(*x*) 称为重要性权重。
>
> 重要性采样（Importance Sampling）是通过引入重要性权重，将分布*p*(*x*)
>
> 下*f* (*x*) 的期望变为在分布*q*(*x*) 下*f* (*x*)*w*(*x*)
> 的期望，从而可以近似为
>
> *f*ˆ*N* = *f* (*x*^(1)^)*w*(*x*^(1)^) + · · · + *f*
> (*x*^(*N*)^)*w*(*x*^(*N*)^) *,* (11.50)

[ 1]{.underline}

> *p*(*x*) = ^p\ [\ ˆ(x)]{.underline}^ ，*Z* 为配分函数。
>
> 其中*x*^(1)^*,* · · · *, x*^(*N*)\ 为独立从*q*(*x*)\ 中随机抽取的点。^
>
> 重要性采样也可以在只知道未归一化的分布 *p*ˆ(*x*) 的情况下计算函数 *f*
> (*x*)
>
> 的期望。
>
> Z

E*~p~*\[*f* (*x*)\] =

> *f* (*x*)
>
> *x*

*p*[ˆ(*x*)]{.underline} *Z*

*dx* (11.51)

*p*ˆ(*x*)*f* (*x*)*dx*

Σ∫*x p*ˆ(*x*)*dx*

> (11.52)
>
> 其中*w*ˆ(*x*) = ^*p*ˆ(*x*)^ ，*x*^(1)^*,* · · · *, x*^(*N*)^
> 为独立从*q*(*x*) 中随机抽取的点。

###### 马尔可夫链蒙特卡罗方法

> 马 尔 可 夫 链 参 见
>
> 在高维空间中，拒绝采样和重要性采样的效率随空间维数的增加而指数降
> 低。马尔可夫链蒙特卡罗（Markov Chain Monte
> Carlo，MCMC）方法是一种更好的采样方法，可以很容易地对高维变量进行采样。
>
> MCMC
> 方法也有很多不同的具体采样方法，但其核心思想是将采样过程看作是一个马尔可夫链。
>
> 第[D.3.1.1](\l)节。 **x**~1~*,* **x**~2~*,* · · · *,* **x**~*t*−1~*,*
> **x***~t~, ,* **x**~*t*+1~*,* · · ·
>
> 第 *t* + 1 次采样依赖于第 *t* 次抽取的样本 **x***~t~*
> 以及状态转移分布（即提议分布）
> *q*(**x**\|**x***~t~*)。如果这个马尔可夫链的平稳分布为*p*(**x**)，那么在状态平稳时抽取的样本就服从*p*(**x**)
> 的分布。
>
> MCMC 方法的关键是如何构造出平稳分布为 *p*(**x**)
> 的马尔可夫链，并且该马尔可夫链的状态转移分布*q*(**x**\|**x**′)
> 一般为比较容易采样的分布。当**x** 为离散变量时，*q*(**x**\|**x**′)
> 可以是一个状态转移矩阵；当**x** 为连续变量时，*q*(**x**\|**x**′)
> 可以是参数密度函数，比如各向同性的高斯分布 *q*(**x**\|**x**′) =
> N(**x**\|**x**′*, σ*^2^*I*)，其中 *σ*^2^ 为超参数。
>
> 使用 MCMC
> 方法进行采样时需要注意两点：一是马尔可夫链需要经过一段时间的随机游走才能达到平稳状态，这段时间称为预烧期（Burn-in
> Period）
>
> 。预烧期内的采样点并不服从分布*p*(**x**)，需要丢弃；二是基于马尔可夫链抽取
>
> 的相邻样本是高度相关的。而在机器学习中，我们一般需要抽取的样本是独立
> 同分布的。为了使得抽取的样本之间独立，我们可以每间隔*M*
> 次随机游走，抽取一个样本。如果*M* 足够大，可以认为抽取的样本是独立的。

1.  **Metropolis-Hastings** 算法

> *Metropolis-Hastings* 算法，简称MH 算法，是一种应用广泛的MCMC
> 方法。在MH
> 算法中，马尔可夫链的状态转移分布*q*(**x**\|**x**′)，其平稳分布往往不是*p*(**x**)。因此，MH
> 算法引入拒绝采样的思想来修正提议分布，使得最终采样的分布为*p*(**x**)。
>
> 在MH 算法中，假设第*t*
> 次采样的样本为**x***~t~*，首先根据提议分布*q*(**x**\|**x***~t~*)
> 抽取一个样本**x**ˆ，并以概率*A*(**x**ˆ*,* **x***~t~*) 来接受**x**ˆ
> 作为第*t* + 1 次的采样样本**x**~*t*+1~，

*t p*(**x***~t~*)*q*(**x**ˆ\|**x***~t~*)

> 因为每次*q*(**x**\|**x***~t~*)
> 随机生成一个样本**x**ˆ，并以概率*A*(**x**ˆ*,* **x***~t~*)
> 的方式接受，因此修正马尔可夫链的状态转移概率为
>
> *q*^′^(**x**ˆ\|**x***~t~*) = *q*(**x**ˆ\|**x***~t~*)*A*(**x**ˆ*,*
> **x***~t~*)*,* (11.55)
>
> 该修正马尔可夫链可以达到平稳状态，且平稳分为*p*(**x**)。
>
> 证明*.* 根据马尔可夫链的细致平稳条件，有
>
> *p*(**x***~t~*)*q*^′^(**x**ˆ\|**x***~t~*) =
> *p*(**x***~t~*)*q*(**x**ˆ\|**x***~t~*)*A*(**x**ˆ*,* **x***~t~*)
> (11.56)
>
> = *p*(**x** )*q*(**x**ˆ\|**x** ) min 1*,* [
> *p*(**x**ˆ)*q*(**x***t*\|**x**ˆ)]{.underline} (11.57)
>
> 细致平稳条件参见定理[D.1](\l)。
>
> *t t p*(**x***~t~*)*q*(**x**ˆ\|**x***~t~*)
>
> = min *p*(**x***~t~*)*q*(**x**ˆ\|**x***~t~*)*,
> p*(**x**ˆ)*q*(**x***~t~*\|**x**ˆ) (11.58)
>
> *t p*(**x**ˆ)*q*(**x***~t~*\|**x**ˆ)
>
> = *p*(**x**ˆ)*q*(**x***~t~*\|**x**ˆ)*A*(**x***~t~,* **x**ˆ) (11.60)
>
> = *p*(**x**ˆ)*q*^′^(**x***~t~*\|**x**ˆ)*.* (11.61)
>
> 因此，*p*(**x**) 是状态转移概率为*q*^′^(**x**ˆ\|**x***~t~*)
> 的马尔可夫链的平稳分布。
>
> MH 算法的采样过程如算法[11.2](\l)所示。
>
> 算法 **11.2:** Metropolis-Hastings 算法
>
> 输入**:** 提议分布*q*(**x**\|**x**′);
>
> 采样间隔*M* ;
>
> 样本集合V = ∅;
>
> **1** 随机初始化**x**~0~;
>
> **2** *t* = 0;
>
> **3 repeat**
>
> // 预热过程
>
> **4** 根据*q*(**x**\|**x***~t~*) 随机生成一个样本**x**ˆ;
>
> **5** 计算接受概率*A*(**x**ˆ*,* **x***~t~*);
>
> **6** 从(0*,* 1) 的均匀分布中随机生成一个值*𝑥*;
>
> **7 if** *𝑥* ≤ *α* **then** /\* 以*A*(**x**ˆ*,* **x***~t~*)
> 的概率接受**x**ˆ \*/
>
> **8 x**~*t*+1~ = **x**ˆ;
>
> **9 else** /\* 拒绝接受**x**ˆ \*/
>
> **10 x***t*+1 = **x***t*;
>
> **11 end**
>
> **12** *t*++;
>
> **13 if** 未到平稳状态 **then**
>
> **14** continue;
>
> **15 end**
>
> // 采样过程，每隔*M* 次采一个样本
>
> **16 if** *t* mod *M* = 0 **then**
>
> **17** V = V ∪ {**x***~t~*};
>
> **18 end**
>
> **19 until** 直到获得 *N* 个样本(\|V\| = *N* );
>
> [ ]{.underline} [输出**:** 样本集合V ]{.underline}

2.  **Metropolis** 算法

> 如果MH 算法中的提议分布是对称的，即*q*(**x**ˆ\|**x***~t~*) =
> *q*(**x***~t~*\|**x**ˆ)，第*t* + 1 次采样的接受率可以简化为

*t*

> 这种MCMC 方法称为*Metropolis* 算法。

3.  吉布斯采样

*p*(**x***~t~*)

> 吉布斯采样（Gibbs
> Sampling）是一种有效地对高维空间中的分布进行采样的MCMC
> 方法，可以看作是Metropolis-Hastings
> 算法的特例。吉布斯采样使用全条件概率（Full Conditional
> Probability）作为提议分布来依次对每个维度进行采样，并设置接受率为*A* =
> 1。
>
> 对于一个*M* 维的随机向量**X** = \[*X*~1~*, X*~2~*,* · · · *, X~M~*
> \]T，其第*i* 个变量*X~i~* 的全条件概率为
>
> *p*(*x~i~*\|**x**~−*i*~) , *P* (*X~i~* = *x~i~*\|*X*~−*i*~ =
> **x**~−*i*~) (11.63)
>
> = *p*(*x~i~*\|*x*~1~*, x*~2~*,* · · · *, x~i~*-1*, x~i~*~+1~*,* · · ·
> *, x~M~* )*,* (11.64)
>
> 其中**x**~−*i*~ = \[*x*~1~*, x*~2~*,* · · · *, x~i~*-1*, x~i~*~+1~*,*
> · · · *, x~M~* \]T 表示除*X~i~* 外其它变量的取值。
>
> 吉布斯采样可以按照任意的顺序根据全条件分布依次对每个变量进行采
> 样。假设从一个随机的初始化状态 **x**(0) = \[*x*^(0)^*, x*^(0)^*,* · ·
> · *, x*^(0)^\]T 开始，按照下
>
> 标顺序依次对*M* 个变量进行采样。
>
> 1 2 *M*

(1)

(0)

> (0)
>
> (0)
>
> *x*1 ∼ *p*(*x*~1~\|*x*2 *, x*3 *,* · · · *, xM* )*,* (11.65)

(1)

(1)

> (0)
>
> (0)
>
> *x*2 ∼ *p*(*x*~2~\|*x*1 *, x*3 · · · *, xM* )*,* (11.66)

.

(1)

(1)

> (1)
>
> (1)
>
> *xM* ∼ *p*(*x~M~* \|*x*1 *, x*2 · · · *, xM* −1)*,* (11.67)

.

(*t*)

(*t*−1)

> (*t*−1)
>
> (*t*−1)
>
> *x*1 ∼ *p*(*x*~1~\|*x*2 *, x*3 *,* · · · *, xM* )*,* (11.68)

(*t*)

(*t*)

> (*t*−1)
>
> (*t*−1)
>
> *x*2 ∼ *p*(*x*~2~\|*x*1 *, x*3 · · · *, xM* )*,* (11.69)

.

(*t*)

(*t*)

> (*t*)
>
> (*t*)
>
> *xM* ∼ *p*(*x~M~* \|*x*1 *, x*2 · · · *, xM* −1)*,* (11.70)
>
> 其中*x*^(*t*)\ 是第*t*\ 次迭代时变量*X*^*~i~* 的采样。
>
> 吉布斯采样的每单步采样也构成一个马尔可夫链。假设每个单步（采样维
> 度为第*i* 维）的状态转移概率*q*(**x**\|**x**′) 为



> [ *p*(**x**) ]{.underline}
>
> if **x**
>
> = **x**′
>
>  0 otherwise*,*

其中边际分布*p*(**x**′

> ) = Σ ′ *p*(**x**′)，等式**x**~−*i*~ = **x**′ 表示*x~j~* =
> *x*^′\ *,*\ ∀*j*\ ̸=^ ^*i*，因此^

有*p*(**x**′

−*i*

) = *p*(**x**~−*i*~)，并可以得到

> *p*(**x**′)*q*(**x**\|**x**′) = *p*(**x**′) [ *p*(**x**)]{.underline}
> = *p*(**x**) *p*(**x**′)
>
> = *p*(**x**)*q*(**x**′\|**x**)*.* (11.72)

*p*(**x**′ )

−*i*

> *p*(**x**~−*i*~)
>
> 根据细致平稳条件，公式([11.71](\l))
> 中定义的状态转移概率*q*(**x**\|**x**′)
> 的马尔可夫链的平稳分布为*p*(**x**)。随着迭代次数*t*
> 的增加，样本**x**(*t*) = \[*x*^(*t*)^*, x*^(*t*)^ · · · *,
> x*^(*t*)^\]T
>
> 将收敛于概率分布*p*(**x**)。

#### 学习

> 1 2 *M*
>
> 图模型的学习可以分为两部分：一是网络结构学习，即寻找最优的网络结
> 构；二是网络参数估计，即已知网络结构，估计每个条件概率分布的参数。
>
> 网络结构学习一般比较困难，一般是由领域专家来构建。本节只讨论在给
> 定网络结构条件下的参数估计问题。图模型的参数估计问题又分为不包含隐变
> 量时的参数估计问题和包含隐变量时的参数估计问题。

###### 不含隐变量的参数估计

> 如果图模型中不包含隐变量，即所有变量都是可观测的，那么网络参数一
> 般可以直接通过最大似然来进行估计。
>
> 有向图模型 在有向图模型中，所有变量**x**
> 的联合概率分布可以分解为每个随机变量*x~k~*
> 的局部条件概率*p*(*x~k~*\|*x~π~k , θ~k~*) 的连乘形式，其中*θ~k~*
> 为第*k* 个变量的局部条件概率的参数。
>
> 给定*N* 个训练样本D = {**x**(*i*)}*,* 1 ≤ *i* ≤ *N* ，其对数似然函数为
>
> *N*
>
> ( *θ*) = log *p*(**x**(*i*)*, θ*) (11.73)
>
> *i*=1

= [ 1]{.underline} Σ Σ log *p*(

i.  (*i*) )

> (11.74)

*i*=1 *k*=1

> 其中*θ~k~* 为模型中的所有参数。
>
> *xk* \|*xπk , θ~k~ ,*
>
> 因为所有变量都是可观测的，最大化对数似然L(D\|*θ*))，只需要分别地最大化每个变量的条件似然来估计其参数。
>
> *θ~k~* = arg max Σ log *p*(
>
> \|*x , θ~k~*)*.* (11.75)
>
> 如果变量**x**
> 是离散的，直接简单的方式是在训练集上统计每个变量的条件概率表。但是条件概率表需要的参数比较多。假设条件概率*p*(*x~k~*\|*x~π~k*
> ) 的父节点数量为*M* ，所有变量为二值变量，其条件概率表需要2*M*
> 个参数。为了减少参数数量，可以使用参数化的模型，比如*sigmoid*
> 信念网络。如果变量**x** 是连续的，
> 可以使用高斯函数来表示条件概率分布，称为高斯信念网络。在此基础上，还可以通过让所有的条件概率分布共享使用同一组参数来进一步减少参数的数量。
>
> 无向图模型 在无向图模型中，所有变量**x**
> 的联合概率分布可以分解为定义在最大团上的势能函数的连乘形式。以对数线性模型为例，
>
> 其中*Z*(*θ*) = Σ**x**
>
> exp(Σ*c*∈C
>
> *Z*(*θ*)
>
> *θ*T*f~c~*(**x***~c~*))。
>
> *c c c*
>
> *c*∈C
>
> 给定*N* 个训练样本D = {**x**(*i*)}*,* 1 ≤ *i* ≤ *N* ，其对数似然函数为
>
> L(D\|*θ*) = [ 1]{.underline} Σ log *p*(**x**( )*, θ*) (11.77)

*i*=1

= [ 1]{.underline} Σ*N*

*i*

> Σ *θ*T*f~c~*

(**x**(*i*))

> − log

*Z*(*θ*)*,*

> (11.78)

*N i*=1

> *c c*
>
> *c*∈*C*
>
> 其中*θ~c~* 为定义在团*c* 上的势能函数的参数。
>
> 如果采用梯度上升方法进行最大似然估计，L(D\|*θ*) 关于参数*θ~c~*
> 的偏导数为

[*∂*L(D\|*θ*)]{.underline} = [ 1]{.underline} Σ*N*

> *f~c~*(**x**(*i*)) −
>
> [log *Z*(*θ*)]{.underline}
>
> (11.79)

*∂θ~c~*

> 其中
>
> *N i*=1
>
> *∂θ~c~*
>
> [log *Z*(*θ*)]{.underline} = Σ [ 1]{.underline} · exp Σ *θ*T*f* (**x**
> ) · *f* (**x** ) (11.80)

因此，

= Σ *p*(**x**\|*θ*)*f~c~*(**x***~c~*) ,
E~**x**∼*p*(**x**\|*θ*)~h*f~c~*(**x***~c~*)i*.* (11.81)

[*∂*L(D\|*θ*)]{.underline} = [ 1]{.underline} Σ*N*

> *f~c~*(**x**(*i*))
>
> − E**x**∼*p*(**x**\|*θ*)

*fc*

(**x***~c~*) (11.82)

*∂θ~c~*

> *N i*=1
>
> 边 际 似 然 也 称 为 证 据
>
> = E~**x**∼*p*˜(**x**)~ *f~c~*(**x***~c~*) − E~**x**∼*p*(**x**\|*θ*)~
> *f~c~*(**x***~c~*) *,* (11.83)
>
> 其中*p*˜(**x**)
> 定义为经验数据分布。由于在最优点时梯度为0，因此无向图的最大似然估计的优化目标等价于：对于每个团*c*
> 上的特征*f~c~*(**x***~c~*)，其在经验分布*p*˜(**x**)下的期望等于模型分布*p*(**x**\|*θ*)
> 下的期望。
>
> 对比公式([11.75](\l)) 和公式([11.83](\l))
> 可以看出，无向图模型的参数估计要比有向图更为复杂。在有向图中，每个局部条件概率的参数是独立的；而在无向图
> 中，所有的参数都是相关的，无法分解。
>
> 对于一般的无向图模型，公式([11.83](\l))
> 中的E~**x**∼*p*(**x**\|*θ*)~\[*f~c~*(**x***~c~*)\]
> 往往很难计算，因为涉及到在联合概率空间*p*(**x**\|*θ*)
> 计算期望。当模型变量比较多时，这个计算往往无法实现。因此，无向图的参数估计通常采用近似的方法。一是利用采样来近似计算这个期望；二是坐标上升法，即固定其它参数，来优化一个势能函数的参数。

###### 含隐变量的参数估计

> 如果图模型中包含隐变量，即有部分变量是不可观测的，就需要用EM
> 算法进行参数估计。

1.  **EM** 算法

> 在一个包含隐变量的图模型中，令**X** 定义可观测变量集合，令**Z**
> 定义隐变量集合，一个样本**x** 的边际似然函数（marginal likelihood）为
>
> （evidence）。 *p*(**x**\|*θ*) = Σ *p*(**x***,* **z**\|*θ*)*,* (11.84)
>
> 其中*θ*
> 为模型参数。图[11.12](\l)给出了带隐变量的贝叶斯网络的图模型结构。

*θ*

> 图 11.12 带隐变量的贝叶斯网络。图中的矩形表示其中的变量重复*N*
> 次。这种表示方法称为盘子表示法（plate
> notation），是图模型中表示重复变量的方法
>
> 给定*N* 个训练样本D = {**x**(*i*)}*,* 1 ≤ *i* ≤ *N*
> ，其训练集的对数边际似然为

*N*

> ( *θ*) = log *p*(**x**(*i*)*, θ*) (11.85)
>
> *i*=1
>
> = [ 1]{.underline} Σ log Σ *p*(**x**(*i*)*,* **z**\|*θ*)*.* (11.86)

*i*=1 **z**

> 通过最大化整个训练集的对数边际似然L(D\|*θ*)，可以估计出最优的参数*θ*^∗^。然而计算边际似然函数时涉及*p*(*x*)
> 的推断问题，需要在对数函数的内部进行求和（或积分）。这样，当计算参数
> *θ* 的梯度时，这个求和操作依然存在。除非 *p*(**x***,* **z**\|*θ*)
> 的形式非常简单，否则这个求和难以直接计算。
>
> 为了计算log
> *p*(**x**\|*θ*)，我们引入一个额外的变分函数*q*(**z**)，*q*(**z**)
> 为定义在隐变量**Z** 上的分布。样本**x** 的对数边际似然函数为

log *p*(**x**\|*θ*) = log Σ *q*(**z**) [*p*(**x***,*
**z**\|*θ*)]{.underline}

≥ Σ *q*(**z**) log [*p*(**x***,* **z**\|*θ*)]{.underline}

, *ELBO*(*q,* **x**\|*θ*)*,*

(11.87)

(11.88)

(11.89)

> 利用Jensen 不等式。
>
> 其中*ELBO*(*q,* **x**\|*θ*) 为对数边际似然函数log *p*(**x**\|*θ*)
> 的下界，称为证据下界（Evidence
>
> Lower Bound，ELBO）。公式([11.88](\l)) 使用了Jensen
> 不等式（即对于凸函数*g*， 有*g* (E\[*X*\]) ≤ E
> \[*g*(*X*)\]）。由Jensen 不等式的性质可知，仅当*q*(**z**) =
> *p*(**z**\|**x***, θ*) 时，
>
> Jensen 不 等 式 参 见第[D.2.6.1](\l)节。
>
> 对数边际似然函数log *p*(**x**\|*θ*) 和其下界*ELBO*(*q,* **x**\|*θ*)
> 相等， 参见习题[11-5](\l)。
>
> log *p*(**x**\|*θ*) = *ELBO*(*q,* **x**\|*θ*)*.*
>
> 这样最大化对数边际似然函数log *p*(**x**\|*θ*)
> 的过程可以分解为两个步骤：（1） 先找到近似分布*q*(**z**) 使得log
> *p*(**x**\|*θ*) = *ELBO*(*q,* **x**\|*θ*)；（2）再寻找参数*θ*
> 最大化*ELBO*(*q,*
> **x**\|*θ*)。这就是期望最大化（Expectation-Maximum，EM）算法。
>
> *EM*
> 算法是含隐变量图模型的常用参数估计方法，通过迭代的方法来最大化边际似然。EM
> 算法具体分为两个步骤：E 步和M
> 步。这两步不断重复，直到收敛到某个局部最优解。在第*t* 步更新时，E
> 步和M 步分布为：

1.  E 步（Expectation
    step）：固定参数*θ~t~*，找到一个分布使得*ELBO*(*q,* **x**\|*θ~t~*)

> 最大，即等于log *p*(**x**\|*θ~t~*)。
>
> *q~t~*~+1~(**z**) = arg max *ELBO*(*q,* **x** *θ~t~*)*.* (11.90)

*q*

> 根据Jensen 不等式的性质，*q*(**z**) = *p*(**z**\|**x***, θ~t~*)
> 时，*ELBO*(*q,* **x**\|*θ~t~*) 最大。因此，E
> 步可以看作是一种推断问题，计算后验概率*p*(**z**\|**x***, θ~t~*)。

2.  M 步（Maximization
    > step）：固定*q~t~*~+1~(**z**)，找到一组参数使得证据下界最大，即

> 变分自编码器参见第[13.2](\l)节。
>
> *θ~t~*~+1~ = arg max *ELBO*(*q~t~*~+1~*,* **x** *θ*)*.* (11.91)

*θ*

> 这一步可以看作是全观测变量图模型的参数估计问题，可以使用第[11.4.1](\l)节中方法进行参数估计。
>
> 收敛性证明 假设在第*t* 步时参数为*θ~t~*，在E
> 步时找到一个变分分布*q~t~*~+1~(**z**) 使得log *p*(**x**\|*θ~t~*) =
> *ELBO*(*q,* **x**\|*θ~t~*)。在M 步时固定*q~t~*~+1~(**z**)
> 找到一组参数*θ~t~*~+1~，使得*ELBO*(*q~t~*~+1~*,* **x**\|*θ~t~*~+1~) ≥
> *ELBO*(*q~t~*~+1~*,* **x**\|*θ~t~*)。因此有
>
> log *p*(**x**\|*θ*t+1) ≥ *ELBO*(*q*t+1*,* **x**\|*θ*t+1) ≥
> *ELBO*(*q*t+1*,* **x**\|*θ*t) = log *p*(**x**\|*θ*t)*,* (11.92)
>
> 即每经过一次迭代对数边际似然增加，log *p*(**x**\|*θ~t~*~+1~) ≥ log
> *p*(**x**\|*θ~t~*)。
>
> 在E 步中，最理想的变分分布*q*(**z**) 是等于后验分布*p*(**z**\|**x***,
> θ*)。而后验分布*p*(**z**\|**x***, θ*) 是一个推断问题。如果**z**
> 是有限的一维离散变量（比如混合高斯模型），计算起来还比较容易。否则，*p*(**z**\|**x***,
> θ*)
> 一般情况下很难计算。因此需要通过近似推断的方法来进行估计，比如变分自编码器。
>
> 信息论的视角 对数边际似然可以通过下面方式进行分解：
>
> Σ**z** *q*(**z**) = 1*.*
>
> *p*(**x***,* **z**\|*θ*) = *p*(**z**\|**x***, θ*)*p*(**x**\|*θ*)*.*
>
> 参见第[E.3.2](\l)节。
>
> log *p*(**x**\|*θ*) = Σ *q*(**z**) log *p*(**x**\|*θ*)
>
> = Σ *q*(**z**) log *p*(**x***,* **z**\|*θ*) − log *p*(**z**\|**x***,
> θ*)
>
> = Σ *q*(**z**) log [*p*(**x***,* **z**\|*θ*)]{.underline} − Σ
> *q*(**z**) log [*p*(**z**\|**x***, θ*))]{.underline}
>
> = *ELBO*(*q,* **x**\|*θ*) + *D*~KL~(*q*(**z**)∥*p*(**z**\|**x***,
> θ*))*,*
>
> 其中*D*~KL~(*q*(**z**)∥*p*(**z**\|**x***, θ*)) 为分布*q*(**z**)
> 和后验分布*p*(**z**\|**x***, θ*) 的KL 散度。
>
> (11.93)
>
> (11.94)
>
> (11.95)
>
> (11.96)
>
> 由于 *D*~KL~(*q*(**z**)∥*p*(**z**\|**x***, θ*)) ≥ 0，并当且仅当
> *q*(**z**) = *p*(**z**\|**x***, θ*) 为 0，因此
>
> *ELBO*(*q,* **x**\|*θ*) 为log *p*(**x**\|*θ*) 的一个下界。

2.  高斯混合模型

> 本节介绍一个EM 算法的应用例子：高斯混合模型。高斯混合模型（Gaussian
> Mixture
> Model，GMM）是由多个高斯分布组成的模型，其密度函数为多个高斯密度函数的加权组合。
>
> 不失一般性，这里考虑一维的情况。假设样本*x* 是从*K*
> 个高斯分布中生成的。每个高斯分布为

[ 1 ]{.underline}

*x µ~k~, σ~k~*

*k*

> exp
>
> (*x µ~k~*)2
>
> − 2*σ*^2^
>
> *,* (11.97)
>
> 其中*µ~k~* 和*σ~k~* 分别为第*k*
> 个高斯分布的均值和方差。图[11.14](\l)给出了高斯混合模型的图模型表示。

######### π

> 图 11.13 高斯混合模型
>
> 高斯混合模型的概率密度函数为

*K*

> *p*(*x*) = *π~k~* (*x µ~k~, σ~k~*)*,* (11.98)
>
> *k*=1
>
> 其中*π~k~* 表示第*k* 个高斯分布的权重系数并满足*π~k~* ≥ 0*,* Σ*K π~k~*
> = 1，即样本*x*
>
> 由第*k* 个高斯分布产生的先验概率。
>
> 高斯混合模型的生成过程可以分为两步：

1.  首先按*π*~1~*, π*~2~*,* · · · *, π~K~*
    > 的分布，随机选取一个高斯分布；

2.  假设选中第*k* 个高斯分布，再从高斯分布N(*x*\|*µ~k~, σ~k~*)
    > 中选取一个样本*x*。

> 参数估计 给定*N* 个由高斯混合模型生成的训练样本*x*^(1)^*, x*^(2)^*,* ·
> · · *, x*^(*N*)^，希望能学习其中的参数*π~k~, µ~k~, σ~k~,* 1 ≤ *k* ≤
> *K*。由于我们无法观测样本*x*^(*n*)\ 是从哪个高斯分布生成的，因此无法直接用最大似然来进行参数估计。我们引入一个隐\ 变量*𝑥*(*n*)^
> ∈ \[1*, K*\] 来表示其来自于哪个高斯分布，*𝑥*^(*n*)^
> 服从多项分布，其多项分布的参数为*π*~1~*, π*~2~*,* · · · *, π~K~*，即
>
> *p*(*𝑥*^(*n*)^ = *k*) = *π~k~.* (11.99)
>
> 对每个样本*x*^(*n*)^，其对数边际分布为
>
> log *p*(*x*^(*n*)^) = log *p*(*𝑥*^(*n*)^)*p*(*x*^(*n*)^\|*𝑥*^(*n*)^)
> (11.100)
>
> *𝑥*(*n*) *K*
>
> = log *π~k~* (*x*^(*n*)^ *µ~k~, σ~k~*)*.* (11.101)
>
> *k*=1
>
> 根据EM 算法，参数估计可以分为两步进行迭代：
>
> **E** 步 先固定参数*µ, σ*，计算后验分布*p*(*𝑥*^(*n*)^\|*x*^(*n*))^
>
> *γ~nk~* , *p*(*𝑥*^(*n*)^ = *k*\|*x*^(*n*)^) (11.102)
>
> *p*(*𝑥*^(*n*)^)*p*(*x*^(*n*)^\|*𝑥*^(*n*)^)
>
> *p*(*x*(*n*))
>
> = *π~k~*N(*x*^(*n*)^\|*µ~k~, σ~k~*)
>
> (11.103)
>
> *,* (11.104)
>
> *K*
>
> *k*=1
>
> *π~k~*N(*x*(*n*)\|*µ~k~, σ~k~*)
>
> 其中*γ~nk~* 定义了样本*x*^(*n*)\ 属于第*k*\ 个高斯分布的后验概率。^
>
> **M** 步 令*q*(*𝑥* = *k*) = *γ~nk~*，训练集D 的证据下界为
>
> *N K* (*n*) (*n*)
>
> *ELBO*(*γ,* D\|*π, µ, σ*) = Σ Σ *γ~nk~*
>
> log [*p*(*x , 𝑥* = *k*)]{.underline}
>
> *γnk*
>
> (11.105)

= Σ Σ

> log
>
> *n*=1 *k*=1
>
> ( ( )
>
> ) + log [* π*]{.underline} (11.106)

= Σ Σ

> −(*x* − *µ* )2
>
> log
>
> \+ log +
>
> (11.107)
>
> 其中*C* 为和参数无关的常数。
>
> 将参数估计问题转为优化问题：
>
> max *ELBO*(*γ, π, µ, σ*)*,*
>
> *π,µ,σ*
>
> *K*
>
> *s.t. π~k~* = 1*.* (11.108)
>
> *k*=1
>
> 利用拉格朗日方法，分别求 *ELBO*(*γ,* D\|*π, µ, σ*) + *λ*(Σ*K*
>
> *π~k~* − 1) 关于
>
> *π~k~, µ~k~, σ~k~* 的偏导数，并令其等于0。可得，
>
> *π* = *[Nk]{.underline} ,* (11.109)
>
> *N*
>
> *N*
>
> *µ γ x*^(*n*)^*,* (11.110)
>
> *nk*
>
> *k n*=1
>
> *N*
>
> *σ γ* (*x*^(*n*)^ − *µ* )2*,* (11.111)
>
> *nk k*
>
> *k n*=1
>
> 参见习题[11-6](\l)。 其中
>
> *N*
>
> *N~k~* = *γ~nk~.* (11.112)
>
> *n*=1
>
> 高斯混合模型的参数学习过程如算法[11.3](\l)所示。
>
> 算法 **11.3:** 高斯混合模型的参数学习算法
>
> 输入**:** 训练样本：*x*^(1)^*, x*^(2)^*,* · · · *, x*^(*N*);^
>
> **1** 随机初始化参数：*π~k~, µ~k~, σ~k~*，1 ≤ *k* ≤ *K*;
>
> **2 repeat**
>
> // E 步
>
> **3** 固定参数，根据公式([11.104](\l)) 计算*γ~nk~*，1 ≤ *k* ≤ *K*， 1
> ≤ *n* ≤ *N* ;
>
> // M 步
>
> **4** 固定*γ~nk~*，根据公式([11.109](\l))，([11.110](\l))
> 和([11.111](\l))，计算*π~k~, µ~k~, σ~k~*，
>
> 1 ≤ *k* ≤ *K*;
>
> **5 until** 对数边际分布Σ*N* log *p*(*x*^(*n*)^) 收敛;
>
> 输出**:** *π~k~, µ~k~, σ~k~*，1 ≤ *k* ≤ *K*
>
> 图[11.14](\l)给出一个高斯混合模型训练过程的简单示例。给定一组数据，我们用两个高斯分布来估计这组数据的分布情况。
>
> 0.50 0.50

(a) 初始化

> 10 11 12

(b) 第1 次迭代

> 10 11 12
>
> 0.50 0.50
>
> ![](/root/autodl-tmp/project_knowledge/Doc_QA/Knowledge_based/1828695663060254721/image_output/7.《神经网络与深度学习》/media/image193.png)
> ![](/root/autodl-tmp/project_knowledge/Doc_QA/Knowledge_based/1828695663060254721/image_output/7.《神经网络与深度学习》/media/image194.png)

(c) 第4 次迭代

> 10 11 12

(d) 第8 次迭代

> 10 11 12
>
> 0.50 0.50
>
> ![](/root/autodl-tmp/project_knowledge/Doc_QA/Knowledge_based/1828695663060254721/image_output/7.《神经网络与深度学习》/media/image195.png)

(e) 第12 次迭代

> 10 11 12

(f) 第16 次迭代

> 10 11 12
>
> 图 11.14 高斯混合模型示例

#### 总结和深入阅读

> 概率图模型提供了一个用图形来描述概率模型的框架，这种可视化方法使
> 我们可以更加容易地理解复杂模型的内在性质。目前，概率图模型已经是一个
>
> 非常庞大的研究领域，涉及众多的模型和算法。很多机器学习模型也都可以用
> 概率图模型来描述。图[11.15](\l)给出了概率图模型所涵盖的内容。

![](/root/autodl-tmp/project_knowledge/Doc_QA/Knowledge_based/1828695663060254721/image_output/7.《神经网络与深度学习》/media/image196.png)

> 图 11.15 概率图模型所涵盖内容的简单概括
>
> 在本章中，我们只介绍了部分内容。要更全面深入地了解概率图模型，可以
> 阅读《Probabilistic Graphical Models: Principles and
> Techniques》\[[Koller and](\l) [Friedman](\l),
> [2009](\l)\]，《Probabilistic Reasoning in Intelligent Systems:
> Networks of Plausible Inference》\[[Pearl](\l),
> [2014](\l)\]，或机器学习书籍中的相关章节\[[Bishop](\l), [2007](\l)\]。
>
> 概率图模型中最基本的假设是条件独立性。图形化表示直观地描述了随机
> 变量之间的条件独立性，有利于将复杂的概率模型分解为简单模型的组合，并
> 更好地理解概率模型的表示、推断、学习等方法。
>
> 20 世纪90 年代末，概率图模型的研究逐步成熟。到21
> 世纪，图模型在机器学习、计算机视觉、自然语言处理等领域开始不断的发展壮大。其中比较有代
> 表性的模型有：条件随机场\[[Laﬀerty et al.](\l),
> [2001](\l)\]、潜在狄利克雷分配（Latent Dirichlet Allocation）[Blei et
> al.](\l) \[[2003](\l)\]
> 等。此外，图模型的结构学习也一直是非常重要但极具挑战性的研究方向。
>
> 图模型与神经网络的关系
> 图模型和神经网络有着类似的网络结构，但两者也有很大的不同。图模型的节点是随机变量，其图结构的主要功能是用来描述变量
> 之间的依赖关系，一般是稀疏连接。使用图模型的好处是可以有效进行统计推
> 断。而神经网络中的节点是神经元，是一个计算节点。如果将神经网络中每个
> 神经元看做是一个二值随机变量，那神经网络就变成一个sigmoid 信念网络。
>
> 图模型中的每个变量一般有着明确的解释，变量之间依赖关系一般是人工
> 来定义。而神经网络中的单个神经元则没有直观的解释。
>
> 神经网络是判别模型，直接用来分类。而图模型不但可以是判别模型，也
> 可以是生成模型。生成模型不但可以用来生成样本，也可以通过贝叶斯公式用
> 来做分类。图模型的参数学习的目标函数为似然函数或条件似然函数，若包含
>
> 隐变量则通常通过EM
> 算法来求解。而神经网络参数学习的目标为交叉熵或平方误差等损失函数。
>
> 目前，神经网络和概率图模型的结合越来越进行紧密。一方面我们可以利用神经网络强大的表示能力来建模图模型中的推断问题（比如变分自编码器，
> 第[13.2](\l)节），生成问题（比如生成对抗网络，第[13.3](\l)节），或势能函数（比如LSTM+CRF模型\[[Lample
> et al.](\l), [2016](\l), [Ma and Hovy](\l),
> [2016](\l)\]）；另一方面可以利用图模型的算法来解决复杂结构神经网络中的学习和推断问题，比如图结构神经网络（Graph
> Neural Network）\[[Gilmer et al.](\l), [2017](\l), [Li et al.](\l),
> [2015](\l), [Scarselli](\l)
>
> [et al.](\l), [2009](\l)\] 和结构化注意力\[[Kim et al.](\l),
> [2017](\l)\]。

#### 习题

> 习题 **11-1** 证明公式([11.10](\l))。
>
> 习题**11-2**
> 在图[11.2a](\l)的有向图，分析按不同的消除顺序计算边际概率*p*(*x*~3~)
>
> 时的计算复杂度。
>
> 习题 **11-3** 在树结构的图模型上应用信念传播时，推导其消息计算公式。
>
> 习题**11-4** 证明若分布*p*(*x*) 存在累积分布函数的逆函数cdf^−1^(*y*)*,
> y* ∈ \[0*,* 1\]， 且随机变量*ξ* 为\[0*,* 1\]
> 区间上的均匀分布，则cdf^−1^(*ξ*) 服从分布*p*(*x*)。
>
> 习题**11-5** 证明仅当*q*(**z**) = *p*(**z**\|**x***, θ*)
> 时，对数边际似然函数log *p*(**x**\|*θ*) 和其下界*ELBO*(*q,*
> **x**\|*θ*) 相等。
>
> 习题 **11-6** 在高斯混合分布的参数估计中，证明M 步中的参数更新公式，
> 即公式([11.109](\l))，([11.110](\l)) 和([11.111](\l))。
>
> 习题 **11-7** 考虑一个伯努利混合分布，即
>
> 参见公式([11.10](\l))。
>
> 参见第[11.3.1](\l)节。
>
> *K*
>
> *p*(*x µ, π*) = *π~k~p*(*x µ~k~*)*,* (11.113)
>
> *k*=1
>
> 其中*p*(*x*\|*µ~k~*) = *µ^x^*(1 − *µ~k~*)(1−*x*) 为伯努利分布。
>
> 给定一组训练集合*D* = {*x*^(1)^*, x*^(2)^*,* · · · *,
> x*^(*N*)^}，若用EM 算法来进行参数估计时，推导其每步的参数更新公式。
>
> 伯 努 利 混 合 分 布 参 见第[D.2.1.1](\l)节。
>
> 292 2019 年 4 月 6 日 参考文献

#### 参考文献

> Leonard E Baum and Ted Petrie. Statistical inference for probabilistic
> functions of ﬁnite state markov chains. *The annals of mathe- matical
> statistics*, 37(6):1554--1563, 1966.
>
> Adam L Berger, Vincent J Della Pietra, and Stephen A Della Pietra. A
> maximum en- tropy approach to natural language process- ing.
> *Computational linguistics*, 22(1):39--71, 1996.
>
> Christopher M. Bishop. *Pattern recogni- tion and machine learning,
> 5th Edition*. In- formation science and statistics. Springer, 2007.
> ISBN 9780387310732.
>
> David M Blei, Andrew Y Ng, and Michael I Jordan. Latent dirichlet
> allocation. *Jour- nal of machine Learning research*, 3(Jan):
> 993--1022, 2003.
>
> Stephen Della Pietra, Vincent Della Pietra, and John Laﬀerty. Inducing
> features of ran- dom ﬁelds. *IEEE transactions on pattern analysis and
> machine intelligence*, 19(4): 380--393, 1997.
>
> Justin Gilmer, Samuel S Schoenholz, Patrick F Riley, Oriol Vinyals,
> and George E Dahl. Neural message passing for quantum chemistry.
> *arXiv preprint arXiv:1704.01212*, 2017.
>
> Yoon Kim, Carl Denton, Luong Hoang, and Alexander M Rush. Structured
> attention networks. *arXiv preprint arXiv:1702.00887*, 2017.
>
> Daphne Koller and Nir Friedman. *Prob- abilistic graphical models:
> principles and techniques*. MIT press, 2009.
>
> John D. Laﬀerty, Andrew McCallum, and Fernando C. N. Pereira.
> Conditional ran- dom ﬁelds: Probabilistic models for seg- menting and
> labeling sequence data. In *Proceedings of the Eighteenth
> International* *Conference on Machine Learning*, 2001.
>
> Guillaume Lample, Miguel Ballesteros, Sandeep Subramanian, Kazuya
> Kawakami, and Chris Dyer. Neural architectures for named entity
> recognition. *arXiv preprint* *arXiv:1603.01360*, 2016.
>
> Steﬀen L Lauritzen and David J Spiegelhal- ter. Local computations
> with probabilities on graphical structures and their applica- tion to
> expert systems. *Journal of the Royal Statistical Society. Series B
> (Methodologi-* *cal)*, pages 157--224, 1988.
>
> Yujia Li, Daniel Tarlow, Marc Brockschmidt, and Richard Zemel. Gated
> graph sequence neural networks. *arXiv* *preprint arXiv:1511.05493*,
> 2015.
>
> Xuezhe Ma and Eduard Hovy. End-to-end sequence labeling via
> bi-directional lstm- cnns-crf. *arXiv preprint arXiv:1603.01354*,
> 2016.
>
> Radford M Neal. Connectionist learning of belief networks. *Artiﬁcial
> intelligence*, 56 (1):71--113, 1992.
>
> Judea Pearl. *Probabilistic reasoning in in- telligent systems:
> networks of plausible in-* *ference*. Elsevier, 2014.
>
> Franco Scarselli, Marco Gori, Ah Chung Tsoi, Markus Hagenbuchner, and
> Gabriele Monfardini. The graph neural network model. *IEEE
> Transactions on Neural Net- works*, 20(1):61--80, 2009.
>
> 第**12** 章 深度信念网络
>
> 计算的目的不在于数据，而在于洞察事物。
>
> --- 理查德·卫斯里·汉明
>
> 对于一个复杂的数据分布，我们往往只能观测到有限的局部特征，并且这
> 些特征通常会包含一定的噪声。如果要对这个数据分布进行建模，就需要挖掘
> 出可观测变量之间复杂的依赖关系，以及可观测变量背后隐藏的内部表示。
>
> 本章介绍一种可以有效学习变量之间复杂依赖关系的概率图模型（深度信
> 念网络）以及两种相关的基础模型（玻尔兹曼机和受限玻尔兹曼机）。深度信念
> 网络中包含很多层的隐变量，可以有效地学习数据的内部特征表示，也可以作
> 为一种有效的非线性降维方法。这些学习到的内部特征表示包含了数据的更高
> 级的、有价值的信息，因此十分有助于后续的分类和回归等任务。
>
> 玻尔兹曼机和深度信念网络都是生成模型，借助隐变量来描述复杂的数据分布。作为概率图模型，玻尔兹曼机和深度信念网络的共同问题是推断和学习问题。因为这两种模型都比较复杂，并且都包含隐变量，它们的推断和学习一般通过MCMC
> 方法来进行近似估计。这两种模型和神经网络有很强的对应关系，
> 在一定程度上也称为随机神经网络（Stochastic Neural Network，SNN）。

#### 玻尔兹曼机

> 玻尔兹曼机（Boltzmann Machine）可以看做是一个随机动力系统（Stochastic
> Dynamical
> System），每个变量的状态都以一定的概率受到其它变量的影响。玻尔兹曼机可以用概率无向图模型来描述。一个具有*K*
> 个节点（变量）的玻尔兹曼机满足以下三个性质：

1.  每个随机变量是二值的，所有随机变量可以用一个二值的随机向量 **X** ∈

> {0*,* 1}*K* 来表示，其中可观测变量表示为**V**，隐变量表示为**H**；
>
> 动力系统是数学上的一个概念，用一个函数来描述一个空间中所有点随时间的变化情况，比如钟摆晃动、水的流动等。

2.  所有节点之间是全连接的。每个变量*X~i~*
    > 的取值依赖于所有其它变量**X**~K*i*~；

3.  每两个变量之间的相互影响（*X~i~* → *X~j~* 和*X~j~* →
    > *X~i~*）是对称的。

> 图[12.1](\l)给出了一个包含3 个可观测变量和3 个隐变量的玻尔兹曼机。
>
> 图 12.1 一个有六个变量的玻尔兹曼机
>
> 这也是玻尔兹曼机名称的由来。为了简单起见，这里我
>
> 变量**X** 的联合概率由玻尔兹曼分布得到，即
>
> *p*(**x**) = [ 1]{.underline} exp [−*E*(**x**)]{.underline} *,* (12.1)
>
> 们把玻尔兹曼常数 *k* 吸收到 *Z T*
>
> 温度*T* 中。
>
> 其中*Z* 为配分函数，能量函数*E*(**x**) 的定义为
>
> *E*(**x**) , *E*(**X** = **x**)
>
> = − Σ *w~ij~ x~i~ x~j~* + Σ *b~i~ x~i~* *,* (12.2)
>
> 其中*w~ij~* 是两个变量*x~i~* 和*x~j~* 之间的连接权重，*x~i~* ∈ {0*,*
> 1} 表示状态，*b~i~* 是变量
>
> *x~i~* 的偏置。
>
> 如果两个变量*X~i~* 和*X~j~* 的取值都为1 时，一个正的权重*w~ij~ \>* 0
> 会使得玻尔兹曼机的能量下降，发生的概率变大；相反，一个负的权重会使得能量上升，发生的概率变小。因此，如果令玻尔兹曼机中的每个变量*X~i~*
> 代表一个基本假设， 其取值为1 或0
> 分别表示模型接受或拒绝该假设，那么变量之间连接的权重为可正可负的实数，代表了两个假设之间的弱约束关系\[[Ackley
> et al.](\l),
> [1985](\l)\]。一个正的权重表示两个假设可以相互支持。也就是说，如果一个假设被接受，另一个也很可能被接受。相反，一个负的权重表示两个假设不能同时被接受。
>
> 德维希·玻尔兹曼（Ludwig Boltzmann，1844 --1906），
> 奥地利物理学家、哲学家。主要贡献为分子动力学。
>
> 玻尔兹曼机可以用来解决两类问题。一类是搜索问题。当给定变量之间的
> 连接权重，需要找到一组二值向量，使得整个网络的能量最低。另一类是学习
> 问题。当给一组定部分变量的观测值时，计算一组最优的权重。

###### 生成模型

> 在玻尔兹曼机中，配分函数*Z* 通常难以计算，因此，联合概率分布*p*(**x**)
> 一般通过MCMC 方法来近似，生成一组服从*p*(**x**)
> 分布的样本。本节介绍基于吉布斯采样的样本生成方法。

1.  全条件概率

> 吉布斯采样需要计算每个变量*X~i~*
> 的全条件概率*p*(*x~i~*\|**x**~\\*i*~)，其中**x**~\\*i*~
> 表示除变量*X~i~* 外其它变量的取值。
>
> 吉 布 斯 采 样 参 见第[11.3.4.3](\l)节。
>
> 证明*.* 首先，保持其它变量**x**~\\*i*~ 不变，改变变量*X~i~*
> 的状态，从0（关闭）和1（打开）之间的能量差异（Energy Gap）为
>
> ∆*E~i~*(**x**~\\*i*~) = *E*(*x~i~* = 0*,* **x**~\\*i*~) − *E*(*x~i~* =
> 1*,* **x**~\\*i*~) (12.8)
>
> = *w~ij~ x~j~* + *b~i~,* (12.9)
>
> *j*
>
> 其中*w~ii~* = 0。
>
> 又根据玻尔兹曼机的定义可得
>
> *E*(**x**) = −*T* log *p*(**x**) − *T* log *Z,* (12.10)

因此有

> ∆*E~i~*(**x**~\\*i*~) = −*T* ln *p*(*x~i~* = 0*,* **x**~\\*i*~) −
> (−*T* ln *p*(*x~i~* = 1*,* **x**~\\*i*~)) (12.11)

= *T* ln [*p*(*x~i~* = 1*,* **x**~\\*i*~)]{.underline}

*p*(*x~i~* = 0*,* **x**~\\*i*~)

= *T* ln [*p*(*x~i~* = 1\|**x**~\\*i*~)]{.underline}

*p*(*x~i~* = 0\|**x**~\\*i*~)

> (12.12)
>
> (12.13)
>
> = *T* ln [ *p*(*xi* = 1*,* \|**x**\\*i*)]{.underline} *,* (12.14)
>
> 1 − *p*(*x~i~* = 1\|**x**~\\*i*~)
>
> 结合公式([12.14](\l)) 和([12.14](\l))，得到

( = 1\|**x**

> ) = [ 1 ]{.underline}
>
> (12.15)

*p x~i~*

> \\*i* 1 + exp −

[∆*E~i~*(**x**~\\*i*~)]{.underline}

*T*

> = *σ* Σ*j wij xj* + *bi* *.* (12.16)

2.  吉布斯采样

> 玻尔兹曼机的吉布斯采样过程为：随机选择一个变量*X~i~*，然后根据其全条件概率*p*(*x~i~*\|**x**~\\*i*~)
> 来设置其状态，即以*p*(*x~i~* = 1\|**x**~\\*i*~) 的概率将变量*X~i~*
> 设为1，否则为0。在固定温度*T*
> 的情况下，在运行足够时间之后，玻尔兹曼机会达到热平
>
> 曼机达到热平衡时，
>
> 衡。此时，任何全局状态的概率服从玻尔兹曼分布*p*(**x**)，只与系统的能量有关，
> 与初始状态无关。

味其能量最低。热平是在所有状态上的一

> 要使得玻尔兹曼机达到热平衡，其收敛速度和温度*T*
> 相关。当系统温度非常高*T* → ∞时，*p*(*x~i~* = 1\|**x**~\\*i*~) →
> 0*.*5，即每个变量状态的改变十分容易，每一种系统状态都是一样的，而从很快可以达到热平衡。当系统温度非常低*T*
> → 0 时，如果∆*E~i~*(**x**~\\*i*~) *\>* 0 则*p*(*x~i~* =
> 1\|**x**~\\*i*~) → 1，如果∆*E~i~*(**x**~\\*i*~) *\<* 0 则*p*(*x~i~* =
> 1\|**x**~\\*i*~) → 0，即
>
> *x* =  1 if Σ*j w~ij~x~j~* + *b~i~* ≥ 0*,*
>
>  0 otherwise,
>
> (12.17)
>
> 因此，当*T* → 0 时，随机性方法变成了确定性方法。这时，玻尔兹曼机退化为
>
> 一个Hopﬁeld 网络。 Hopﬁeld 网 络 参 见

第[8.3.4.1](\l)节。

> Hopﬁeld
> 网络是一种确定性的动力系统，而玻尔兹曼机是一种随机性的动力系统。Hopﬁeld
> 网络的每次的状态更新都会使得系统的能量降低，而玻尔兹曼机则以一定的概率使得系统的能量上升。图[12.2](\l)给出了Hopﬁeld
> 网络和玻尔兹曼机在运行时系统能量变化的对比。

*E*

a.  Hopﬁeld 网络

*E*

b.  玻尔兹曼机

> 图 12.2 Hopﬁeld 网络和玻尔兹曼机运行时，系统能量变化对比

###### 能量最小化与模拟退火

> 特别地，离散状态的能量最
>
> 在一个动力系统中，找到一个状态使得系统能量最小是一个十分重要的优
> 化问题。如果这个动力系统是确定性的，比如Hopﬁeld 网络，一个简单（但是
>
> 小化是一个组合优化问题。
> 低效）的能量最小化方法是随机选择一个变量，在其它变量保持不变的情况下，
>
> 将这个变量设为会导致整个网络能量更低的状态。当每个变量*X~i~*
> 取值为{0*,* 1}
>
> 时，如果能量差异∆*E~i~*(**x**~\\*i*~) 大于0，就设*X~i~* =
> 1，否则就设*X~i~* = 0。
>
> 这种简单、确定性的方法在运行一定时间之后总是可以收敛到一个解。但
> 是这个解是局部最优的，不是全局最优。为了跳出局部最优，就必须允许"偶
> 尔"可以将一个变量设置为使得能量变高的状态。这样，我们就需要引入一定
>
> 局部最优在Hopﬁeld 网络中不是一个缺点。相反，Hop- ﬁeld
> 网络是通过利用局部最优点来存储信息。
>
> *T i*
>
> 和玻尔兹曼机的吉布斯采样过程十分类似。
>
> 要使得动力系统达到热平衡，温度*T*
> 的选择十分关键。一个比较好的折中方法是让系统刚开始在一个比较高的温度下运行达到热平衡，然后逐渐降低，
> 直到系统在一个比较低的温度下达到热平衡。这样我们就能够得到一个能量全
>
> 局最小的分布。这个过程被称为模拟退火（Simulated
> Annealing）\[[Kirkpatrick](\l) [et al.](\l), [1983](\l)\]。
>
> 模拟退火是一种寻找全局最优的近似方法，其名字来自冶金学的专有名词"退火"，即将材料加热后再以一定的速度退火冷却，可以减少晶格中的缺陷。
> 固体中的内部粒子会停留在使内能有局部最小值的位置，加热时能量变大，粒
> 子会变得无序并随机移动。退火冷却时速度较慢，使得粒子在每个温度都达到
> 平衡态。最后在常温时，粒子以很大的概率达到内能比原先更低的位置。可以
> 证明，模拟退火算法所得解依概率收敛到全局最优解。

###### 参数学习

> 不失一般性，假设玻尔兹曼机中的变量分为可观测变量**v** ∈ {0*,* 1}*m*
> 和隐变量**h** ∈ {0*,* 1}*n*。
>
> 给定一组可观测的向量D = {**v**ˆ(1)*,* **v**ˆ(2)*,* · · · *,*
> **v**ˆ(*N* )} 作为训练集，我们要学习玻尔兹曼机的参数*W* 和**b**
> 使得训练集中所有样本的对数似然函数最大。训练集的对数似然函数定义为

L(D\|*W,* **b**) =

> Σ log *p*(**v**ˆ(*n*)\|*W, b*) (12.18)
>
> *n*=1

= [ 1]{.underline}

> Σ log Σ *p*(**v**ˆ(*n*)*,* **h**\|*W,* **b**) (12.19)

*N*

= [ 1]{.underline}

> *n*=1
>
> Σ

log

> **h**
>
> Σ**h** exp − *E*(**v**ˆ(*n*)*,* **h**)

*.* (12.20)

*n*=1

> Σ**v***,***h** exp − *E*(**v***,* **h**)
>
> 对数似然函数L(D\|*W,* **b**) 对参数*θ* 的偏导数为 *θ* 为*W* 或**b**。
>
> [L(D\|*W,* **b**)]{.underline} =

*∂θ*

> [1]{.underline} ^N^
>
> *N*
>
> n=1
>
> [* ∂*]{.underline} log
>
> *∂θ*
>
> *p*(**v**ˆ^(n)^*,* **h**\|*W,* **b**) (12.21)
>
> **h**

[1]{.underline} ΣN

> [* ∂*]{.underline} Σ
>
> ( ) Σ
>
> [1]{.underline} ^N^
>
> *N*

n=1 **h**

exp *E*(**v**ˆ^(n)^*,* **h**)

> Σ**h** exp − *E*(**v**ˆ(n)*,* **h**)
>
> *∂E*(**v**ˆ^(n)^*,* **h**)
>
> *∂θ*
>
> [ ]{.underline} Σ Σe[xp − *E*(**v**]{.underline}*,* **h**)
>
> h [*∂E*(**v***,* **h**)]{.underline} i (12.23)
>
> N
>
> =

*N*

> n=1 **h**
>
> (**h v**ˆ(n))h *∂E*(**v**ˆ^(n)^*,* **h**) i
>
> Σ**v**,**h**

*p*(**v***,* **h**) [*∂E*(**v***,* **h**)]{.underline}

*∂θ*

> (12.24)

= Epˆ(**v**)

Ep(**h**\|**v**)

h [*∂E*(**v***,* **h**)]{.underline} i − E

p(**v**,**h**)

> [*∂E*(**v***,* **h**)]{.underline} *,* (12.25)
>
> *∂θ*
>
> 其中*p*ˆ(**v**)
> 表示可观测向量在训练集是上的实际分布，*p*(**h**\|**v**) 和*p*(**v***,*
> **h**) 为在当前参数*W,* **b** 条件下玻尔兹曼机的条件概率和联合概率。
>
> 因此，整个训练集的对数似然函数L(D\|*W,* **b**) 对每个权重 *w~ij~*
> 和偏置 *b~i~* 的偏导数为

[*∂*L(D\|*W,* **b**)]{.underline} = E E

> \[*x x* \] − E
>
> \[*x x* \]*,* (12.26)

*∂w~ij~*

*p*ˆ(**v**)

> *p*(**h**\|**v**) *i j*
>
> *p*(**v***,***h**) *i j*

[*∂*L(D\|*W,* **b**)]{.underline} = E

*∂b~i~*

*p*ˆ(**v**)

E*p*(**h**\|**v**)

\[*xi*\] − E

*p*(**v***,***h**)

\[*x~i~*\]*,* (12.27)

> 其中*i, j* ∈ \[1*,
> K*\]。这两个公式涉及到计算配分函数和期望，很难精确计算。对于一个*K*
> 维的随机向量**X**，其取值空间大小为2*K* 。当*K*
> 比较大时，配分函数以及期望的计算会十分耗时。因此，玻尔兹曼机一般通过MCMC
> 方法（如吉布斯采样）来进行近似求解。
>
> 以参数*w~ij~* 的梯度为例，公式([12.26](\l))
> 中第一项为在给定可观测变量为训练集中的样本时，*x~i~x~j~*
> 的期望。为了近似近似这个期望，我们可以固定住可观测变量，只对**h**
> 进行吉布斯采样。当玻尔兹曼机达到热平衡状态时，采样*x~i~x~j~*
> 的值。在训练集上所有的训练样本上重复此过程，得到*x~i~x~j~*
> 的近似期望⟨*x~i~x~j~*⟩~data~。公式([12.25](\l))
> 中的第二项为玻尔兹曼机在没有任何限制时，*x~i~x~j~*
> 的期望。我们可以对所有变量进行吉布斯采样。当玻尔兹曼机达到热平衡状态时，采样*x~i~x~j~*
> 的值， 得到近似期望⟨*x~i~x~j~*⟩~model~。
>
> 这样当采用梯度上升法时，权重*w~ij~* 可以用下面公式近似地更新
>
> *w~ij~* ← *w~ij~* + *α* ⟨*x~i~x~j~*⟩~data~ − ⟨*x~i~x~j~*⟩~model~ *.*
> (12.28)
>
> 其中*α \>* 0
> 为学习率。这个更新方法的一个特点是仅仅使用了局部信息。也就是说，虽然我们优化目标是整个网络的能量最低，但是每个权重的更新只依赖
> 于它连接的相关变量的状态。这种学习方式和人脑神经网络的学习方式，赫布
> 规则（Hebbian Rule），十分类似。
>
> 玻尔兹曼机可以用在监督学习和无监督学习中。在监督学习中，可观测的
> 变量**v**
> 又进一步可以分为输入和输出变量，隐变量则隐式地描述了输入和输出变量之间复杂的约束关系。在无监督学习中，隐变量可以看做是可观测变量的
> 内部特征表示。玻尔兹曼机也可以看做是一种随机型的神经网络，是Hopﬁeld
> 神经网络的扩展，并且可以生成的相应的Hopﬁeld
> 神经网络。在没有时间限制时，玻尔兹曼机还可以用来解决复杂的组合优化问题。

#### 受限玻尔兹曼机

> 全连接的玻尔兹曼机在理论上十分有趣，但是由于其复杂性，目前为止并
> 没有被广泛使用。虽然基于采样的方法在很大程度提高了学习效率，但是每更
>
> 新一次权重，就需要网络重新达到热平衡状态，这个过程依然比较低效，需要
> 很长时间。在实际应用中，使用比较广泛的一种带限制的版本，也就是受限玻
> 尔兹曼机。
>
> 受限玻尔兹曼机（Restricted Boltzmann
> Machine，RBM）是一个二分图结构的无向图模型，如图[12.3](\l)所示。受限玻尔兹曼机中的变量也分为隐藏变量
> 和可观测变量。我们分别用可观测层和隐藏层来表示这两组变量。同一层中的
> 节点之间没有连接，而不同层一个层中的节点与另一层中的所有节点连接，这
> 和两层的全连接神经网络的结构相同。
>
> 受限玻尔兹曼机因其结构最初称为簧风琴模型，2000
> 年后受限玻兹曼机的名称才变得流行。
>
> 图 12.3 一个有7 个变量的受限玻尔兹曼机
>
> 一个受限玻尔兹曼机由 *m*~1~ 个可观测变量和*m*~2~
> 个隐变量组成，其定义如下：

-   可观测的随机向量**v** = \[*v*~1~*,* · · · *, v~m~*1 \]T；

-   隐藏的随机向量**h** = \[*h*~1~*,* · · · *, h~m~*2 \]T；

-   权重矩阵*W* ∈ R*m*1×*m*2 ，其中每个元素*w~ij~* 为可观测变量 *v~i~*
    > 和隐变量*h~j~*

> 之间边的权重；

-   偏置**a** ∈ R*m*1 和**b** ∈ R*m*2 ，其中*a~i~* 为每个可观测的变量
    > *v~i~* 的偏置，*b~j~* 为每个隐变量*h~j~* 的偏置。

> 受限玻尔兹曼机的能量函数定义为
>
> *E*(**v***,* **h**) = − Σ *a~i~v~i~* − Σ *b~j~h~j~* − Σ Σ
> *v~i~w~ij~h~j~* (12.29)
>
> = −**a**T**v** − **b**T**h** − **v**T*W* **h***,* (12.30)
>
> 受限玻尔兹曼机的联合概率分布*p*(**v***,* **h**) 定义为

*p*(**v***,* **h**) = *Z* exp(−*E*(**v***,* **h**)) (12.31)

= [ 1]{.underline} exp(**a**T**v**) exp(**b**T**h**) exp(**v**T*W*
**h**)*,* (12.32)

*Z*

> 其中*Z* = Σ**v***,***h** exp(−*E*(**v***,* **h**)) 为配分函数。

###### 生成模型

> 吉 布 斯 采 样 参 见第[11.3.4.3](\l)节。
>
> 受限玻尔兹曼机的联合概率分布 *p*(**h***,* **v**)
> 一般也通过吉布斯采样的方法来近似，生成一组服从*p*(**h***,* **v**)
> 分布的样本。

1.  全条件概率

> 吉布斯采样需要计算每个变量*V~i~* 和*H~j~*
> 的全条件概率。受限玻尔兹曼机中同层的变量之间没有连接。从无向图的性质可知，在给定可观测变量时，隐变量之间相互条件独立。同样在给定隐变量时，可观测变量之间也相互条件独立。
> 即有
>
> *p*(*v~i~*\|**v**~\\*i*~*,* **h**) = *p*(*v~i~*\|**h**)*,* (12.33)
>
> *p*(*h~j~*\|**v***,* **h**~\\*j*~) = *p*(*h~j~*\|**v**)*,* (12.34)
>
> 其中**v**~\\*i*~ 为除变量*V~i~* 外其它可观测变量的取值，**h**~\\*j*~
> 为除变量*H~j~* 外其它隐变量的取值。因此，*V~i~*
> 的全条件概率只需要计算*p*(*v~i~*\|**h**)，而*H~j~*
> 的全条件概率只需要计算*p*(*h~j~*\|**v**)。
>
> 证明*.*（1）我们先证明*p*(*v~i~* = 1\|**h**)。
>
> 可观测层变量**v** 的边际概率为
>
> *P* (**v**) = Σ *P* (**v***,* **h**) = [ 1]{.underline} Σ
> exp(−*E*(**v***,* **h**))
>
> = [ 1]{.underline} Σ exp **a**T**v** + Σ *b h* + Σ Σ *v w*
>
> *h* 
>
> (12.37)
>
> (12.38)
>
> = exp(**a**T**v**) exp

*Z* **h**

> *h~j~*(*b~j~* +
>
> *j i*
>
> *wijvi*

)

> (12.39)
>
> = exp(**a**T**v**) Σ Y exp ( + Σ )!
>
> (12.40)
>
> = exp(**a**T**v**) Σ Σ
>
> Σ Y exp ( + Σ
>
> )! (12.41)
>
> 利用分配律
>
> exp(**a**T**v**) Y Σ
>
> Σ ! 将 *h*
>
> 为 0 或 1 的 取 值 代
>
> = exp(**a**T**v**) Y 1 + exp( + Σ )!
>
> (12.43)
>
> 固定*h~j~* = 1 时，*p*(*h~j~* = 1*,* **v**) 的边际概率为

*p*(*h~j~*

> = 1*,* **v**) = [ 1]{.underline}

*Z*

> **h***,*Σ*hj* =1

exp (−*E*(**v***,* **h**)) (12.44)

> = exp(**a**T**v**)

*Z*

> *k*Y*,k*̸=*j*
>
> 1 + exp(*b~k~* +

*i*

> *wikvi*

) exp(*b~j~* +

*i*

> *w~ij~v~i~*)*.*
>
> (12.45)
>
> 由公式([12.43](\l)) 和( [12.45](\l))，可以计算隐藏单元*h~j~*
> 的条件概率为：
>
> [*p*(*h~i~* = 1*,* **v**)]{.underline}

*p*(*h~j~* = 1\|**v**) =

> (12.46)
>
> *p*
>
> exp(*b* + *w v* )
>
> 1 + exp(*b~j~* + Σ*i w~ij~v~i~*)
>
> (12.47)
>
> = *σ* *b~j~* + Σ *w~ij~v~i~*! *.* (12.48)
>
> （2）同理，条件概率*p*(*v~i~* = 1\|**h**) 为
>
> *p*(*v~i~* = 1\|**h**) = *σ* *a~i~* + Σ *w~ij~h~j~* *.* (12.49)
>
> 公式([12.48](\l)) 和([12.49](\l)) 也可以写为向量形式。
>
> *p*(**h** = **1**\|**v**) = *σ* (*W* T**v** + **b**) (12.50)
>
> *p*(**v** = **1**\|**h**) = *σ* (*W* **h** + **a**) *.* (12.51)
>
> 因此，受限玻尔兹曼机可以并行地对所有的可观测变量（或所有的隐变量）
> 同时进行采样，而从可以更快地达到热平衡状态。

2.  吉布斯采样

> 受限玻尔兹曼机的采样过程如下：

-   （给定）或随机初始化一个可观测的向量**v**~0~,
    > 计算隐变量的概率，并从中采样一个隐向量**h**~0~；

-   基于**h**~0~，计算可观测变量的概率，并从中采样一个个可观测的向量**v**~1~；

-   重复*t* 次后，获得(**v***~t~,* **h***~t~*)；

-   当*t* → ∞ 时, (**v***~t~,* **h***~t~*) 的采样服从*p*(**v***,* **h**)
    > 分布。图[12.4](\l)也给出了上述过程的示例。

> · · ·
>
> 图 12.4 受限玻尔兹曼机的采样过程

###### 参数学习

> 和玻尔兹曼机一样，受限玻尔兹曼机通过最大化似然函数来找到最优的参
> 数*W,* **a***,* **b**。给定一组训练样本D = {**v**ˆ(1)*,* **v**ˆ(2)*,*
> · · · *,* **v**ˆ(*N* )}，其对数似然函数为

L(D\|*W,* **a***,* **b**) =

> Σ log *p*(**v**ˆ( )\|*W,* **a***,* **b**)*.* (12.52)

*n*

> *n*=1
>
> 参见公式([12.25](\l))。
>
> 和玻尔兹曼机类似，在受限玻尔兹曼机中，对数似然函数L(D\|*W,* **b**)
> 对参数*w~ij~, a~i~, b~j~* 的偏导数为

[*∂*L(D\|*W,* **a***,* **b**)]{.underline} = E E

> \[*v h* \] − E
>
> \[*v h* \]*,* (12.53)

*∂w~ij~*

*p*ˆ(**v**)

> *p*(**h**\|**v**) *i j*
>
> *p*(**v***,***h**) *i j*
>
> [*∂*L(D\|*W,* **a***,* **b**)]{.underline} = E

*∂a~i~*

*p*ˆ(**v**)

E*p*(**h**\|**v**)

vi. − E

*p*(**v***,***h**)

\[*v~i~*\]*,* (12.54)

> [*∂*L(D\|*W,* **a***,* **b**)]{.underline} = E

*∂b~j~*

*p*ˆ(**v**)

E*p*(**h**\|**v**)

\[*h~j~*\] − E

*p*(**v***,***h**)

\[*h~j~*\]*,* (12.55)

> 其中*p*ˆ(**v**) 为训练数据集上**v** 的实际分布。
>
> 公式([12.53](\l))、([12.54](\l)) 和([12.55](\l))
> 中都需要计算配分函数*Z* 以及两个期望E~*p*(**h**\|**v**)~
>
> 和E~*p*(**h***,***v**)~，因此很难计算，一般需要通过MCMC
> 方法来近似计算。
>
> 首先，将可观测向量**v**
> 设为训练样本中的值并固定，然后根据条件概率对隐向量 **h**
> 进行采样，这时受限玻尔兹曼机的值记为⟨·⟩~data~。然后在不固定可观测向量**v**，通过吉布斯采样来轮流更新**v**
> 和**h**。当达到热平衡状态时，采集**v** 和**h** 的值，记为⟨·⟩~model~。
>
> 采用梯度上升法时，参数*W,* **a***,* **b** 可以用下面公式近似地更新
>
> *w~ij~* ← *w~ij~* + *α* ⟨*v~i~h~j~*⟩~data~ − ⟨*v~i~h~j~*⟩~model~ *,*
> (12.56)
>
> *a~i~* ← *a~i~* + *α* ⟨*v~i~*⟩~data~ − ⟨*v~i~*⟩~model~ *,* (12.57)
>
> *b~j~* ← *b~j~* + *α* ⟨*h~j~*⟩~data~ − ⟨*h~j~*⟩~model~ *,* (12.58)
>
> 其中*α \>* 0 为学习率。
>
> 根据受限玻尔兹曼机的条件独立性，可以对可观测变量和隐变量进行分组
> 轮流采样，如图[12.4](\l)中所示。这样受限玻尔兹曼机的采样效率会比一般的玻尔
> 兹曼机有很大提高，但一般还是需要通过很多步采样才可以采集到符合真实分
> 布的样本。
>
> **12.2.2.1** 对比散度学习算法
>
> 由于受限玻尔兹曼机的特殊结构，因此可以使用一种比吉布斯采样更有效
> 的学习算法，即对比散度 （Contrastive Divergence）\[[Hinton](\l),
> [2002](\l)\]。对比散度算法仅需*k* 步吉布斯采样。
>
> 为了提高效率，对比散度算法用一个训练样本作为可观测向量的初始值。
> 然后，交替对可观测向量和隐藏向量进行吉布斯采样，不需要等到收敛，只需要*k*
> 步就足够了。这就是CD-*k* 算法。通常，*k* = 1
> 就可以学得很好。对比散度的流程如算法[12.1](\l)所示。

###### 受限玻尔兹曼机的类型

> 在具体的不同任务中，需要处理的数据类型不一定都是二值的，也可能是
> 连续值。为了能够处理这些数据，就需要根据输入或输出的数据类型来设计新
> 的能量函数。
>
> 参见习题[12-3](\l)。
>
> 算法 **12.1:** 单步对比散度算法
>
> 输入**:** 训练集: **v**ˆ(*n*)*, n* = 1*,* · · · *, N* ;
>
> 学习率：*α*
>
> **1** 初始化：*W* ← 0, **a** ← 0, **b** ← 0 ;
>
> **2 for** *t* = 1 · · · *T* **do**
>
> **3 for** *n* = 1 · · · *N* **do**
>
> **4** 选取一个样本**v**ˆ(*n*)，用公式([12.48](\l)) 计算*p*(**h** =
> **1**\|**v**ˆ(*n*))，并根据这个分布采集一个隐向量**h**;
>
> **5** 计算正向梯度**v**ˆ(*n*)**h**T;
>
> **6** 根据**h**，用公式([12.49](\l)) 计算*p*(**v** =
> **1**\|**h**)，并根据这个分布采集重构的可见变量**v**′;
>
> **7** 根据**v**′，重新计算*p*(**h** = **1**\|**v**′) 并采样一个**h**′;
>
> **8** 计算反向梯度**v**′**h**′T;
>
> **9** 更新参数：
>
> *W* ← *W* + *α*(**v**ˆ(*n*)**h**T − **v**′**h**′T) ;
>
> **10 a** ← **a** + *α*(**v**ˆ(*n*) − **v**′) ;
>
> **11 b** ← **b** + *α*(**h** − **h**′) ;
>
> **12 end**
>
> **13 end**
>
> 输出**:** *W,* **a***,* **b**
>
> 一般来说，常见的受限玻尔兹曼机有以下三种：
>
> "伯努利**-**伯努利"受限玻尔兹曼机"伯努利-伯努利"受限玻尔兹曼机（Bernoulli-
> Bernoulli RBM,
> BB-RBM）就是上面介绍的可观测变量和隐变量都为二值类型的受限玻尔兹曼机。
>
> "高斯**-**伯努利"受限玻尔兹曼机 "高斯-伯努利"受限玻尔兹曼机（Gaussian-
> Bernoulli RBM,
> GB-RBM）是假设可观测变量为高斯分布，隐变量为伯努利分布，其能量函数定义为

*E*(**v***,* **h**) = Σ (*vi* 2− *µi*)

> − Σ *b h*
>
> − Σ Σ *[vi]{.underline} w*
>
> *h ,* (12.59)
>
> 参见习题[12-5](\l)。
>
> 其中每个可观测变量*v~i~* 服从(*µ~i~, σ~i~*) 的高斯分布。
>
> "伯努利**-**高斯"受限玻尔兹曼机
> "伯努利-高斯"受限玻尔兹曼机（Bernoulli- Gaussian RBM,
> BG-RBM）是假设可观测变量为伯努利分布，隐变量为高斯分
>
> 布，其能量函数定义为
>
> *E*(**v***,* **h**) = Σ *a v*
>
> − Σ (*h~j~* 2− *µ~j~*)
>
> − Σ Σ *v w*
>
> *[hj]{.underline} ,* (12.60)
>
> 其中每个隐变量*h**~j~* 服从(*µ~j~, σ~j~*) 的高斯分布。

#### 深度信念网络

> 深度信念网络（Deep Belief
> Network，DBN）是一种深层的概率有向图模型，其图结构由多层的节点构成。每层节点的内部没有连接，相邻两层的节点
> 之间为全连接。网络的最底层为可观测变量，其它层节点都为隐变量。最顶部
> 的两层间的连接是无向的，其他层之间的连接是有向的。图[12.5](\l)给出了一个深
> 度信念网络的示例。
>
> 和全连接的前馈神经网络结构相同。

*q*(**h**(2)\|**h**(1))

*q*(**h**(1)\|**v**)

> **h**(3)
>
> **h**(2)
>
> **h**(1)
>
> **v**

*W* (3)

*W* (2)

*W* (1)

> *p*(**h**(2)*,* **h**(3))
>
> *p*(**h**(1)\|**h**(2))
>
> *p*(**v**\|**h**(1))
>
> 图 12.5 一个有4 层结构的深度信念网络
>
> 对一个有*L* 层隐变量的深度信念网络，令**v** = **h**(0) 表示最底层（第0
> 层）为可观测变量，**h**(1)*,* · · · *,* **h**(*L*)
> 表示其余每层的变量。顶部的两层是一个无向图，可以看做是一个受限玻尔兹曼机，用来产生*p*(**h**(*L*−1))
> 的先验分布。除了最顶上两层外，每一层变量**h**(*l*)
> 依赖于其上面一层**h**(*l*+1)，即
>
> *p*(**h**(*l*)\|**h**(*l*+1)*,* · · · *,* **h**(*L*)) =
> *p*(**h**(*l*)\|**h**(*l*+1))*,* (12.61)
>
> 其中*l* = {0*,* · · · *, L* − 2}。
>
> 深度信念网络中所有变量的联合概率可以分解为

\(1) ( )

(1)

> *L*Y−2
>
> ( ) ( +1) !
>
> ( 1) ( )

= *L*Y−1

> (**h**( ) **h**( +1))!
>
> (**h**(
>
> 1\) **h**( ))
>
> (12.63)
>
> Sigmoid 信 念 网 络 参 见
>
> 其中*p*(**h**(*l*)\|**h**(*l*+1)) 为Sigmoid 型条件概率分布为
>
> *p*(**h**(*l*)\|**h**(*l*+1)) = *σ* **a**(*l*) + *W*
> (*l*+1)**h**(*l*+1) *,* (12.64)
>
> 其中*σ*(·) 为按位计算的logistic sigmoid 函数，**a**(*l*)
> 为偏置参数，*W* ^(*l*+1)^
> 为权重参数。这样，每一个层都可以看作是一个Sigmoid 信念网络。
>
> 第[11.1.2.1](\l)节。 **12.3.1** 生成模型
>
> 深度信念网络是一个生成模型，可以用来生成符合特定分布的样本。隐变
> 量用来描述在可观测变量之间的高阶相关性。假如训练数据服从分布*p*(**v**)，通过训练得到一个深度信念网络。
>
> 在生成样本时，首先在最顶两层进行足够多次的吉布斯采样，生成**h**(*L*−1)，
> 然后依次计算下一层隐变量的分布。因为在给定上一层变量取值时，下一层的变量是条件独立的，因为可以独立采样。这样，我们可以从第*L*
> − 1 层开始，自顶向下进行逐层采样，最终得到可观测层的样本。
>
> **12.3.2** 参数学习
>
> 深度信念网络最直接的训练方式可以通过最大似然方法使得可观测变量的
> 边际分布*p*(**v**)
> 在训练集合上的似然达到最大。但在深度信念网络中，隐变量**h**
> 之间的关系十分复杂，由于"贡献度分配问题"，很难直接学习。即使对于简单
> 的单层Sigmoid 信念网络
>
> "逐层训练"是能够有效训练
>
> *p*(*v* = 1\|**h**) = *σ* (*b* + **w**T**h**) *,* (12.65)
>
> 在已知可观测变量时，其隐变量的联合后验概率*p*(**h**\|*v*)
> 不再相互独立，因此很难精确估计所有隐变量的后验概率。早期深度信念网络的后验概率一般通过蒙
> 特卡罗方法或变分方法来近似估计，但是效率比较低，而导致其参数学习比较
> 困难。
>
> 为了有效地训练深度信念网络，我们将每一层的Sigmoid
> 信念网络转换为受限玻尔兹曼机。这样做的好处是隐变量的后验概率是相互独立的，从而可以
> 很容易地进行采样。这样，深度信念网络可以看作是由多个受限玻尔兹曼机从
> 下到上进行堆叠，第*l* 层受限玻尔兹曼机的隐层作为第*l* + 1
> 层受限玻尔兹曼机的可观测层。进一步地，深度信念网络可以采用逐层训练的方式来快速训练，即
> 从最底层开始，每次只训练一层，直到最后一层\[[Hinton et al.](\l),
> [2006](\l)\]。
>
> 深度模型的最早的方法。
> 深度信念网络的训练过程可以分为预训练和精调两个阶段。先通过逐层预
> 训练将模型的参数初始化为较优的值，再通过传统学习方法对参数进行精调。

1.  逐层预训练

> 在预训练阶段，采用逐层训练的方式，将深度信念网络的训练简化为对多
> 个受限玻尔兹曼机的训练。图[12.6](\l)给出了深度信念网络的逐层预训练过程。
>
> RBM

RBM

> *W* (3)
>
> 采样

RBM

> *W* (2)
>
> 采样

训练样本

> *W* (1)
>
> 图 12.6 深度信念网络的逐层预训练过程
>
> 具体的逐层训练过程为自下而上依次训练每一层的受限玻尔兹曼机。假设
> 我们已经训练好了前*l* − 1
> 层的受限玻尔兹曼机，那么可以计算隐变量自下而上的条件概率

*p*(**h**(*i*)\|**h**(*i*−1)) = *σ* **b**(*i*) + *W* ^(*i*)^**h**(*i*−1)
*,* 1 ≤ *i* ≤ (*l* − 1) (12.66)

> 其中**b**(*i*) 为第*i* 层受限玻尔兹曼机的偏置，*W*
> ^(*i*)\ 为连接权重。这样，我们可以按照\ **v**\ =\ **h**(0)\ \~\ **h**(1)\ \~\ ·\ ·\ ·\ \~\ **h**(*l*−1)\ 的顺序生成一组\ **h**(*l*−1)\ 的样本，记为**H**ˆ\ (*l*−1)\ =\ {**h**ˆ(*l,*1)*,*\ ·\ ·\ ·\ *,*\ **h**ˆ(*l,M*\ )}。然后，将**h**(*l*−1)\ 和**h**(*l*)\ 组成一个受限玻尔兹曼机，用**H**ˆ\ (*l*−1)\ 作为训练集充分训练第*l*\ 层的受限玻尔兹曼机。^
>
> 算法[12.2](\l)给出一种深度信念网络的逐层预训练方法。大量的实践表明，逐
> 层预训练可以产生非常好的参数初始值，从而极大地降低了模型的学习难度。

2.  精调

> 经过预训练之后，再结合具体的任务（监督学习或无监督学习），通过传
> 统的全局学习算法对网络进行精调（ﬁne-tuning），使模型收敛到更好的局部最优点。
>
> 作为生成模型的精调
> 除了顶层的受限玻尔兹曼机，其它层之间的权重被分成向上的认知权重（recognition
> weights）*W* ^′\ 和向下的生成权重（generative\ weights）^
>
> 算法 **12.2:** 深度信念网络的逐层训练方法
>
> 输入**:** 训练集: **v**ˆ(*n*)*, n* = 1*,* · · · *, N* ;
>
> 学习率：*α*, 深度信念网络层数:*L*, 第*l* 层权重：*W*
> ^(*l*),\ 第*l*\ 层偏置**a**(*l*),\ 第^
>
> *l* 层偏置**b**(*l*);
>
> **1 for** *l* = 1 · · · *L* **do**
>
> **2** 初始化：*W*
> ^(*l*)\ ←\ 0*,*\ **a**(*l*)\ ←\ 0*,*\ **b**(*l*)\ ←\ 0;^
>
> **3** 从训练集中采样**h**ˆ(0);
>
> **4 for** *i* = 1 · · · *l* − 1 **do**
>
> **5** 根据分布*p*(**h**(*i*)\|**h**ˆ(*i*−1)) 采样**h**ˆ(*i*);
>
> **6 end**
>
> **7** 将 **h**ˆ(*l*−1) 作为训练样本， 充分训练第 *l* 层受限玻尔兹曼机
>
> *W* (*l*)*,* **a**(*l*)*,* **b**(*l*);
>
> **8 end**
>
> 输出**:** {*W* ^(*l*)^*,* **a**(*l*)*,* **b**(*l*)}*,* 1 ≤ *l* ≤ *L*
>
> 只需要向上的认知权重。
>
> *W*
> 。认知权重用来进行后验概率计算，而生成权重用来进行定义模型。认知权重的初始值*W*
> ^′(*l*)\ =\ *W*\ (*l*)^T。
>
> 深度信念网络一般采用contrastive wake-sleep算法进行精调，其算法过程是：

-   Wake
    > 阶段：认知过程，通过外界输入（可观测变量）和向上认知权重，计算每一层隐变量的后验概率并采样。然后，修改下行的生成权重使得下一
    > 层的变量的后验概率最大。也就是"如果现实跟我想象的不一样，改变我
    > 的权重使得我想象的东西就是这样的"；

-   Sleep
    > 阶段：生成过程，通过顶层的采样和向下的生成权重，逐层计算每一层的后验概率并采样。然后，修改向上的认知权重使得上一层变量的后
    > 验概率最大。也就是"如果梦中的景象不是我脑中的相应概念，改变我的
    > 认知权重使得这种景象在我看来就是这个概念"；

-   交替进行Wake 和Sleep 过程，直到收敛。

> 作为深度神经网络的精调
> 深度信念网络的一个应用是作为深度神经网络的预训练部分，提供神经网络的初始权重。
>
> 在深度信念网络的最顶层再增加一层输出层，然后再使用反向传播算法对
> 这些权重进行调优。特别是在训练数据比较少时，预训练的作用非常大。因为
> 不恰当的初始化权重会显著影响最终模型的性能，而预训练获得的权重在权值
> 空间中比随机权重更接近最优的权重，避免了反向传播算法因随机初始化权值
> 参数而容易陷入局部最优和训练时间长的缺点。这不仅提升了模型的性能，也
> 加快了调优阶段的收敛速度\[[Larochelle et al.](\l), [2007](\l)\]。

4.  总结和深入阅读 2019 年 4 月 6 日 311

> 图[12.7](\l)给出深度信念网络作为生成模型和判断模型的精调过程。
>
> 输出层
>
> *W* (4)

*W* (3)

> *W* ′(3)

*W* (2)

> *W* ′(2)

*W* (1)

> *W* ′(1)

可观测层 输入层

> 深度信念网络 深度神经网络
>
> 图 12.7 深度信念网络的精调过程
>
> **12.4** 总结和深入阅读
>
> 玻尔兹曼机是Hopﬁeld 网络的随机化版本，最早由 Geoﬀrey Hinton
> 等人提出\[[Hinton and Sejnowski](\l), [1986](\l), [Hinton et al.](\l),
> [1984](\l)\]。玻尔兹曼机能够学习数据的内部表示，并且其参数学习的方式和赫布型学习十分类似。没有任何约束的
> 玻尔兹曼机因为过于复杂，难以应用在实际问题上。通过引入一定的约束（即
> 变为二分图），受限玻尔兹曼机在特征抽取、协同过滤、分类等多个任务上得
> 到了广泛的应用。受限玻尔兹曼机最早由[Smolensky](\l) \[[1986](\l)\]
> 提出，并命名为簧风琴。[Carreira-Perpinan and Hinton](\l)
> \[[2005](\l)\] 提出了对比散度算法使得受限玻尔兹曼机的训练非常高效。
>
> 受限玻尔兹曼机一度变得非常流行，因为其作为深度信念网络的一部分，显
> 著提高了语音识别的精度\[[Dahl et al.](\l), [2012](\l), [Hinton et
> al.](\l), [2012](\l)\]，并开启了深度学习的浪潮。
>
> 深层神经网络的误差反向传播算法存在梯度消失问题，因此在2006 年以前，
> 我们还无法有效地训练深层神经网络。[Hinton et al.](\l) \[[2006](\l)\]
> 提出了深度信念网络，并通过逐层训练和精调可以有效地学习。[Salakhutdinov](\l)
> \[[2015](\l)\]
> 给出了深度信念网络可以逐层训练的理论依据。深度信念网络的一个重要贡献是可以为一个深层神经网络提供较好的初始参数，从而使得训练深层神经网络变得可行。深度信念网络也成为早期深度学习算法的主要框架之一。
>
> 优化算法参见第[7.2](\l)节。
>
> Metropolis 算 法 参 见第[11.3.4.2](\l)节。
>
> 和深度信念网络十分类似的一种深度概率模型是深度玻尔兹曼机（Deep
> Boltzmann Machines，DBM）\[[Salakhutdinov and Larochelle](\l),
> [2010](\l)\]。深度玻尔兹曼机是由多层的受限玻尔兹曼机堆叠而成，是真正的无向图模型，其联合概
> 率是通过能量函数来定义。和深度信念网络相比，深度玻尔兹曼机的学习和推
> 断要更加困难。
>
> 典型的深度信念网络的隐变量是二值的，其后验为伯努利分布，[Welling](\l)
> [et al.](\l) \[[2005](\l)\]
> 提出一个改进，允许隐变量为其它类型，其后验分布为指数族分布。
>
> [Lee et al.](\l) \[[2009](\l)\] 提出了卷积深度信念网络（Convolutional
> Deep Belief Networks，
> CDBN），采用和卷积神经网络类似的结构，以便处理高维的图像特征。通过基于卷积的受限玻尔兹曼机和概率最大汇聚操作，卷积深度信念网络也能够使用类似深度置信网络的训练方法进行训练。
>
> 除了深度信念网络之外，自编码器\[[Bengio et al.](\l), [2007](\l)\]
> 以及它的变体，比如稀疏自编码器\[[Ranzato et al.](\l), [2006](\l)\]
> 和去噪自编码器\[[Vincent et al.](\l),
> [2008](\l)\]，也可以用来作为深度神经网络的参数初始化，并可以得到和深度信念网络类似的
> 效果。并随着人们对深度学习认识的加深，出现了很多更加便捷的训练深层神
> 经网络的技术，比如 ReLU
> 激活函数、权重初始化、逐层归一化、各自优化算法以及快捷连接\[[He et
> al.](\l), [2016](\l)\]
> 等，使得我们可以不用预训练就可以训练一个非常深的神经网络。
>
> 尽管深度信念网络作为一种深度学习模型已经很少使用，但其在深度学习
> 发展进程中的贡献十分巨大，并且其理论基础为概率图模型，有非常好的解释
> 性，依然是一种值得深入研究的模型。

#### 习题

> 习题 **12-1** 如果使用Metropolis
> 算法对玻尔兹曼机进行采样，给出其提议分布的具体形式。
>
> 习题 **12-2** 在受限玻尔兹曼机中，证明公式([12.49](\l))。
>
> 习题**12-3** 在受限玻尔兹曼机中，证明公式([12.53](\l))、([12.54](\l))
> 和([12.55](\l)) 中参数的梯度。
>
> 习题**12-4**
> 计算"高斯-伯努利"受限玻尔兹曼机和"伯努利-高斯"受限玻尔兹曼机的条件概率*p*(**v**
> = **1**\|**h**) 和*p*(**h** = **1**\|**v**)。
>
> 参考文献 2019 年 4 月 6 日 313
>
> 习题 **12-5**
> 在受限玻尔兹曼机中，如果可观测变量服从多项分布，隐变量服务伯努利分布，若可观测变量的条件概率为
>
> exp(*a^k^* + Σ*~j~W^k^ h~j~*)
>
> *p*(*v^k^* = 1\|**h**) = Σ *i ij ,* (12.67)

*k*′=1

> *i j ij j*
>
> 其中*k* ∈ \[1*, K*\] 为可观测变量的取值，*v^k^* ∈ {1*,* 0} 表示第*i*
> 个可观测变量的值是否为*k*，请给出满足这个条件分布的能量函数。
>
> 习题 **12-6** 在深度信念网络中，试分析逐层训练背后的理论依据。
>
> 习题 **12-7** 分析深度信念网络和深度玻尔兹曼机之间的异同点。

#### 参考文献

> David H Ackley, Geoﬀrey E Hinton, and Terrence J Sejnowski. A learning
> algorithm for boltzmann machines. *Cognitive science*, 9(1):147--169,
> 1985.
>
> Yoshua Bengio, Pascal Lamblin, Dan Popovici, and Hugo Larochelle.
> Greedy layer-wise training of deep networks. In *Advances in neural
> information processing* *systems*, pages 153--160, 2007.
>
> Miguel A Carreira-Perpinan and Geoﬀrey E Hinton. On contrastive
> divergence learning. In *Aistats*, volume 10, pages 33--40. Cite-
> seer, 2005.
>
> George E Dahl, Dong Yu, Li Deng, and Alex Acero. Context-dependent
> pre-trained deep neural networks for large-vocabulary speech
> recognition. *IEEE Transactions on audio, speech, and language
> processing*, 20(1):30-- 42, 2012.
>
> Kaiming He, Xiangyu Zhang, Shaoqing Ren, and Jian Sun. Deep residual
> learning for image recognition. In *Proceedings of the IEEE conference
> on computer vision and* *pattern recognition*, pages 770--778, 2016.
> Geoﬀrey Hinton, Li Deng, Dong Yu, George E Dahl, Abdel-rahman Mohamed,
> Navdeep Jaitly, Andrew Senior, Vin- cent Vanhoucke, Patrick Nguyen,
> Tara N Sainath, et al. Deep neural networks for
>
> acoustic modeling in speech recognition: The shared views of four
> research groups. *IEEE Signal Processing Magazine*, 29(6): 82--97,
> 2012.
>
> Geoﬀrey E Hinton. Training products of experts by minimizing
> contrastive diver- gence. *Neural computation*, 14(8):1771-- 1800,
> 2002.
>
> Geoﬀrey E Hinton and Terrence J Se- jnowski. Learning and releaming in
> boltz- mann machines. *Parallel Distrilmted Pro-* *cessing*, 1, 1986.
>
> Geoﬀrey E Hinton, Terrence J Sejnowski, and David H Ackley. *Boltzmann
> machines: Constraint satisfaction networks that learn*.
> Carnegie-Mellon University, Department of Computer Science Pittsburgh,
> PA, 1984.
>
> Geoﬀrey E Hinton, Simon Osindero, and Yee-Whye Teh. A fast learning
> algorithm for deep belief nets. *Neural computation*,
> 18(7):1527--1554, 2006.
>
> Scott Kirkpatrick, C Daniel Gelatt, and Mario P Vecchi. Optimization
> by simu- lated annealing. *science*, 220(4598):671-- 680, 1983.
>
> Hugo Larochelle, Dumitru Erhan, Aaron Courville, James Bergstra, and
> Yoshua Ben- gio. An empirical evaluation of deep archi- tectures on
> problems with many factors of
>
> 314 2019 年 4 月 6 日 参考文献
>
> variation. In *Proceedings of the 24th inter- national conference on
> Machine learning*, pages 473--480. ACM, 2007.
>
> Honglak Lee, Roger Grosse, Rajesh Ran- ganath, and Andrew Y Ng.
> Convolutional deep belief networks for scalable unsuper- vised
> learning of hierarchical representa- tions. In *Proceedings of the
> 26th annual international conference on machine learn- ing*, pages
> 609--616. ACM, 2009.
>
> Marc'Aurelio Ranzato, Christopher Poult- ney, Sumit Chopra, and Yann
> LeCun. Eﬃ- cient learning of sparse representations with an
> energy-based model. In *Proceedings of the 19th International
> Conference on Neu- ral Information Processing Systems*, pages
> 1137--1144. MIT Press, 2006.
>
> Ruslan Salakhutdinov. Learning deep gen- erative models. *Annual
> Review of Statistics and Its Application*, 2:361--385, 2015.
>
> Ruslan Salakhutdinov and Hugo Larochelle. Eﬃcient learning of deep
> boltzmann ma- chines. In *Proceedings of the thirteenth in-
> ternational conference on artiﬁcial intelli-* *gence and statistics*,
> pages 693--700, 2010. Paul Smolensky. Information processing in
> dynamical systems: Foundations of har- mony theory. Technical report,
> Dept Of Computer Science, Colorado Univ At Boul- der, 1986.
>
> Pascal Vincent, Hugo Larochelle, Yoshua Bengio, and Pierre-Antoine
> Manzagol. Ex- tracting and composing robust features with denoising
> autoencoders. In *Proceedings of the International Conference on
> Machine* *Learning*, pages 1096--1103. ACM, 2008.
>
> Max Welling, Michal Rosen-Zvi, and Geof- frey E Hinton. Exponential
> family harmoni- ums with an application to information re- trieval. In
> *Advances in neural information processing systems*, pages 1481--1488,
> 2005.
>
> 第**13** 章 深度生成模型
>
> 我不能创造的东西，我就不了解。
>
> --- 理查德·菲利普·费曼
>
> 概率生成模型，简称生成模型（Generative
> Model），是概率统计和机器学习中的一类重要模型，指一系列用于随机生成可观测数据的模型。假设在一个
> 连续的或离散的高维空间X 中，存在一个随机向量**X**
> 服从一个未知的数据分布*p~r~*(**x**)*,* **x** ∈
> X。生成模型是根据一些可观测的样本**x**(1)*,* **x**(2)*,* · · · *,*
> **x**(*N* ) 来学习一个参数化的模型*p~θ~*(**x**)
> 来近似未知分布*p~r~*(**x**)，并可以用这个模型来生成一些样本，使得"生成"的样本和"真实"的样本尽可能地相似。
>
> 生成模型的应用十分广泛，可以用来不同的数据进行建模，比如图像、文
> 本、声音等。比如图像生成，我们将图像表示为一个随机向量**X**，其中每一维都表示一个像素值。假设自然场景的图像都服从一个未知的分布*p~r~*(**x**)，希望通过一些观测样本来估计其分布。高维随机向量一般比较难以直接建模，需要通
> 过一些条件独立性来简化模型。但是，自然图像中不同像素之间的存在复杂的
> 依赖关系（比如相邻像素的颜色一般是相似的），很难用一个明确的图模型来描
> 述其依赖关系，因此直接建模*p~r~*(**x**) 比较困难。
>
> 深度生成模型就是利用深层神经网络可以近似任意函数的能力来建模一个
> 复杂的分布 *p~r~*(**x**)。假设一个随机向量 **Z** 服从一个简单的分布
> *p*(**z**)*,* **z** ∈
> Z（比如标准正态分布），我们使用一个深层神经网络*g* : Z →
> X，并使得*g*(**z**) 服从*p~r~*(**x**)。
>
> 本章介绍两种深度生成模型：变分自动编码器\[[Kingma and Welling](\l),
> [2013](\l), [Rezende et al.](\l), [2014](\l)\]
> 和对抗生成式网络\[[Goodfellow et al.](\l), [2014](\l)\]。

#### 概率生成模型

> 生成模型一般具有两个基本功能：密度估计和生成样本。

a.  带隐变量的生成模型 (b) 带类别的生成模型

> 图 13.1 生成模型
>
> 密度估计参见第[9.2](\l)节。
>
> EM 算法参见第[11.4.2.1](\l)节。

######  密度估计

> 给定一组数据D = {**x**(*i*)}*,* 1 ≤ *i* ≤ *N*
> ，假设它们都是从独立地从相同的概率密度函数为*p~r~*(**x**)
> 的未知分布中产生的。密度估计（Density Estimation）是根据数据集D
> 来估计其概率密度函数*p~θ~*(**x**)。
>
> 在机器学习中，密度估计是一种非常典型的无监督学习问题。如果要建模
> 的分布包含隐变量（如图[13.1a](\l)），比如高斯混合模型，就需要利用EM
> 算法来进行密度估计。

1.  应用于监督学习

> 生成模型也可以应用于监督学习。监督学习的目标是建模输出标签的条件
> 概率密度函数*p*(*y*\|**x**)。根据贝叶斯公式，
>
> ( **x**) = [ *p*(**x***, y*)]{.underline} *.* (13.1)
>
> *p y*\| Σ
>
> *~y~ p*(**x***, y*)
>
> 采样方法参见第[11.3](\l)节。
>
> 我们可以将监督学习问题转换为联合概率密度函数*p*(**x***, y*)
> 的密度估计问题。
>
> 图[13.1a](\l)给出了生成模型用于监督学习的图模型表示。在监督学习中，比较典型的生成模型有朴素贝叶斯分类器、隐马尔可夫模型
>
> 判别模型
> 和生成模型相对应的另一类监督学习模型是判别模型（Discriminative
> Model）。判别式模型直接建模条件概率密度函数*p*(*y*\|**x**)，并不建模其联合概率密度函数
> *p*(**x***, y*)。常见的判别模型有logistic
> 回归、支持向量机、神经网络等。由生成模型可以得到判别模型，但由判别模型得不到生成模型。

###### 生成样本

> 生成样本就是给定一个概率密度函数为 *p~θ~*(**x**)
> 的分布，生成一些服从这个分布的样本，也称为采样。我们在第[11.3](\l)节中介绍了一些常用的采样方法。

*ϕ θ*

> 图 13.2 变分自编码器。实线表示生成模型，虚线表示变分近似。
>
> 对于图[13.1a](\l)中的图模型，在得到*p*(**z***, θ*)
> 和*p*(**x**\|**z***, θ*)
> 之后，我们就可以生成数据**x**，具体过程可以分为两步进行：

1.  根据隐变量的先验分布*p*(**z***, θ*) 进行采样，得到样本**z**；

2.  根据条件分布*p*(**x**\|**z***, θ*) 进行采样，得到**x**。

> 因此在生成模型中，重点是估计条件分布*p*(**x**\|**z***, θ*)。

2.  #### 变分自编码器

    1.  ###### 含隐变量的生成模型

> 假设一个生成模型（如图[13.2](\l)所示）中包含隐变量，即有部分变量是不可观
> 测的，其中观测变量**X** 是一个高维空间X 中的随机向量，隐变量**Z**
> 是一个相对
>
> 低维的空间Z 中的随机向量。这个生成模型的联合概率密度函数可以分解为
> 本章中，我们假设**X** 和**Z** 都

*p*(**x***,* **z**\|*θ*) = *p*(**x**\|**z***, θ*)*p*(**z**\|*θ*)*,*
(13.2)

> 其中*p*(**z**\|*θ*) 为隐变量**z**
> 先验分布的概率密度函数，*p*(**x**\|**z***, θ*) 为已知**z**
> 时观测变量**x** 的条件概率密度函数，*θ*
> 表示两个密度函数的参数。一般情况下，我们可以假设*p*(**z**\|*θ*)
> 和*p*(**x**\|**z***, θ*)
> 为某种参数化的分布族，比如正态分布。这些分布的形式已知，只是参数*θ*
> 未知，可以通过最大化似然来进行估计。
>
> 给定一个样本**x**，其对数边际似然log *p*(**x**\|*θ*) 可以分解为

log *p*(**x**\|*θ*) = *ELBO*(*q,* **x**\|*θ, ϕ*) +
*D*~KL~(*q*(**z**\|*ϕ*)∥*p*(**z**\|**x***, θ*))*,* (13.3)

> 是连续随机向量。
>
> 其中*q*(**z**\|*ϕ*) 是额外引入的变分密度函数，其参数为*ϕ*，*ELBO*(*q,*
> **x**\|*θ, ϕ*) 为证据 参见公式([11.96](\l))。

下界，

> *ELBO*(*q,* **x**\|*θ, ϕ*) = E**~z~**
>
> ~(**z**~ ~)~ log [*p*(**x***,* **z**\|*θ*)]{.underline} *.* (13.4)

∼*q* \|*ϕ*

> *q*(**z**\|*ϕ*)
>
> EM 算法
>
> 参见第[11.4.2.1](\l)节。
>
> 最大化对数边际似然log *p*(**x**\|*θ*) 可以用EM
> 算法来求解，具体可以分为两步：

-   E-step: 寻找一个密度函数*q*(**z**\|*ϕ*)
    > 使其等于或接近于后验密度函数*p*(**z**\|**x***, θ*)；

-   M-step: 保持*q*(**z**\|*ϕ*) 固定，寻找*θ* 来最大化*ELBO*(*q,*
    > **x**\|*θ, ϕ*)。

> 这样个步骤不断重复，直到收敛。
>
> 在EM 算法的每次迭代中，理论上最优的*q*(**z**\|*ϕ*)
> 为隐变量的后验概率密度函数*p*(**z**\|**x***, θ*)，
>
> *p*(**z x***, θ*) = [ *p*(**x**\|**z***,
> θ*)*p*(**z**\|*θ*)]{.underline} *.* (13.5)
>
> \| ∫*𝑥 p*(**x**\|**z***, θ*)*p*(**z**\|*θ*)*d***z**
>
> 后验密度函数*p*(**z**\|**x***, θ*)
> 的计算是一个统计推断问题，涉及到积分计算。当隐变量**z**
> 是有限的一维离散变量，则计算起来比较容易。在一般情况下，这个后验概率密度函数是很难计算的。此外，概率密度函数*p*(**x**\|**z***,
> θ*) 一般也比较复杂，很难直接用已知的分布族函数进行建模。
>
> 变分自编码器（Variational
> Autoencoder，VAE）是一种深度生成模型，其思想是利用神经网络来分别建模两个复杂的条件概率密度函数。

1.  用神经网络来产生变分分布*q*(**z**\|*ϕ*)，称为推断网络。理论上*q*(**z**\|*ϕ*)
    > 可以不依赖**x**。但由于*q*(**z**\|*ϕ*)
    > 的目标是近似后验分布*p*(**z**\|**x***, θ*)，其和**x**
    > 相关，因此变分密度函数一般写为*q*(**z**\|**x***,
    > ϕ*)。推断网络的输入为**x**，输出为变分分布*q*(**z**\|**x***, ϕ*)。

2.  用神经网络来产生概率分布*p*(**x**\|**z***,
    > θ*)，称为生成网络。生成网络的输入为

> **z**，输出为概率分布*p*(**x**\|**z***, θ*)。
>
> 将推断网络和生成网络合并就得到了变分自编码器的整个网络结构，如
> 图[13.3](\l)所示，其中实线表示网络计算操作，虚线表示采样操作。
>
> ![](/root/autodl-tmp/project_knowledge/Doc_QA/Knowledge_based/1828695663060254721/image_output/7.《神经网络与深度学习》/media/image203.png)
>
> 推断网络 *fI* (**x***, ϕ*)
>
> 图 13.3 变分自编码器的网络结构
>
> 生成网络 *fG*(**z***, θ*)
>
> 变分自编码器的名称来自于其整个网络结构和自编码器比较类似。推断网
> 络看作是"编码器"，将可观测变量映射为隐变量。生成网络可以看作是"解码
> 器"，将隐变量映射为可观测变量。但变分自编码器背后的原理和自编码器完全
> 不同。变分自编码器中的编码器和解码器的输出为分布（或分布的参数），而不
> 是确定的编码。

###### 推断网络

> 为了简单起见，假设*q*(**z**\|**x***, ϕ*)
> 是服从对角化协方差的高斯分布，
>
> *q*(**z**\|**x***, ϕ*) = N(**z**\|***µ**I, **σ***^2^*I*)*,* (13.6)
>
> 其中***µ**I* 和***σ***^2^
> 是高斯分布的均值和方差，可以通过推断网络*f~I~* (**x***, ϕ*) 来预测。
>
> 自编码器参见第[9.1.3](\l)节。
>
> ***µ**I*  = *f* (**x***, ϕ*)*,* (13.7)
>
> 其中推断网络 *f~I~* (**x***, ϕ*)
> 可以是一般的全连接网络或卷积网络，比如一个两层的神经网络，
>
> **h** = *σ*(*W* ^(1)^**x** + **b**(1))*,* (13.8)
>
> ***µ**I* = *W* ^(2)^**h** + **b**(2)*,* (13.9)
>
> ***σ**~I~* = softplus(*W* ^(3)^**h** + **b**(3))*,* (13.10)
>
> 其中*ϕ* 代表所有的网络参数{*W* ^(1)^*, W* ^(2)^*, W* ^(3)^*,*
> **b**(1)*,* **b**(2)*,* **b**(3)}，*σ* 和softplus为 softplus( ) =
> log(1 +

*e*^x^)*.*

> 激活函数。
>
> 相当于EM 算法中的E 步。
>
> **13.2.2.1** 推断网络的目标
>
> 推断网络的目标是使得*q*(**z**\|**x***, ϕ*)
> 来尽可能接近真实的后验*p*(**z**\|**x***,
> θ*)，需要找到变分参数*ϕ*^∗\ 来最小化两个分布的KL\ 散度。^

*ϕ*^∗^ = arg min *D*~KL~(*q*(**z**\|**x***, ϕ*)\|\|*p*(**z**\|**x***,
θ*))*.* (13.11)

> 然而直接计算上面的KL 散度是不可能的，因为*p*(**z**\|**x***, θ*)
> 一般无法计算。传统方法是利用采样或者变分方法来近似推断。基于采样的方法效率很低且估计也不
> 是很准确，所以一般使用的是变分推断方法，即用简单的分布*q*
> 去近似复杂的分布*p*(**z**\|**x***,
> θ*)。但是在深度生成模型中，*p*(**z**\|**x***, θ*)
> 是非常复杂的分布，很难用简单的分布去近似。因此，我们需要找到一种间接的计算方法。
>
> 根据公式([13.3](\l)) 可知，变分分布*q*(**z**\|**x***, ϕ*)
> 与真实后验*p*(**z**\|**x***, θ*)) 的KL 散度等于对数边际似然log
> *p*(**x**\|*θ*) 与其下界*ELBO*(*q,* **x**\|*θ, ϕ*) 的差。

*D*~KL~(*q*(**z**\|**x***, ϕ*)\|\|*p*(**z**\|**x***, θ*)) = log
*p*(**x**\|*θ*) − *ELBO*(*q,* **x**\|*θ, ϕ*)*,* (13.12)

> 因此，推断网络的目标函数为
>
> 第一项与*ϕ* 无关。
>
> *ϕ*^∗^ = arg min *D*~KL~(*q*(**z**\|**x***, ϕ*)\|\|*p*(**z**\|**x***,
> θ*))
>
> = arg min log *p*(**x**\|*θ*) − *ELBO*(*q,* **x**\|*θ, ϕ*)
>
> = arg max *ELBO*(*q,* **x** *θ, ϕ*)*.*

*ϕ*

> (13.13)
>
> (13.14)
>
> (13.15)

###### 生成网络

> 生成模型的联合分布*p*(**x***,* **z**\|*θ*)
> 可以分解为两部分：隐变量**z** 的先验分布*p*(**z**\|*θ*)
>
> 和条件概率分布*p*(**x**\|**z***, θ*)。
>
> 先验分布*p*(**z**\|*θ*) 一般假设隐变量**z**
> 的先验分布为各向同性的标准高斯分布N(**z**\|**0***,*
> **I**)。隐变量**z** 的每一维之间都是独立的。
>
> 条件概率分布 *p*(**x**\|**z***, θ*) 建模条件分布*p*(**x**\|**z***, θ*)
> 通过生成网络来建模。为了简单起见，我们同样用参数化的分布族来表示条件概率分布*p*(**x**\|**z***,
> θ*)，这些分布族的参数可以用生成网络来计算得到。
>
> 根据变量 **x** 的类型不同，可以假设 *p*(**x**\|**z***, θ*)
> 服从不同的分布族。如果 **x** ∈
>
> {0*,* 1}*d* 是 *d* 维的二值的向量，可以假设 log *p*(**x**\|**z***, θ*)
> 服从多变量的伯努利分布， 即
>
> *d*
>
> *p*(**x z***, θ*) = *p*(*x~i~* **z***, θ*) (13.16)
>
> *i*=1

*d*

> *xi* (1 *xi*)
>
> *i*
>
> *i*=1
>
> 其中*γ~i~* , *p*(*x~i~* = 1\|**z***, θ*) 为第*i* 维分布的参数。***γ***
> = \[*γ*~1~*,* · · · *, γ~d~*\]T 可以通过生成网络来预测。
>
> 如果**x** ∈ R*d* 是*d* 维的连续向量，可以假设*p*(**x**\|**z***, θ*)
> 服从对角化协方差的高斯分布，即
>
> *p*(**x**\|**z***, θ*) = N(**x**\|***µ**G, **σ***^2^ *I*)*,* (13.18)
>
> 其中***µ**G* 和***σ**~G~* 同样可以用生成网络*f~G~*(**z***, θ*)
> 来预测。
>
> **13.2.3.1** 生成网络的目标
>
> 生成网络的目标是找到一组*θ*^∗^ 最大化证据下界*ELBO*(*q,* **x**\|*θ,
> ϕ*)。 相当于EM 算法中的M 步。
>
> *θ*^∗^ = arg max *ELBO*(*q,* **x** *θ, ϕ*)*.* (13.19)

*θ*

###### 模型汇总

> 结合公式（[13.15](\l)）和（[13.19](\l)），推断网络和生成网络的目标都为最大化证据下界*ELBO*(*q,*
> **x**\|*θ, ϕ*)。因此，变分自编码器的总目标函数为
>
> max *ELBO*(*q,* **x**\|*θ, ϕ*) = max E**~z~**
>
> (**z** ) log [*p*(**x**\|**z***, θ*)*p*(**z**\|*θ*)]{.underline}
> (13.20)

*θ,ϕ*

*θ,ϕ*

> ∼*q* \|*ϕ*
>
> *q*(**z**\|*ϕ*)

= max E~**z**∼*q*(**z**\|**x***,ϕ*)~h log *p*(**x**\|**z***, θ*)i −
*D*~KL~ *q*(**z**\|**x***, ϕ*)\|\|*p*(**z**\|*θ*) *,* (13.21)

> 其中先验分布*p*(**z**\|*θ*) = N(**z**\|**0***,* **I**)，*θ* 和*ϕ*
> 分别表示生成网络和推断网络的参数。公式([13.21](\l))
> 中的期望E~**z**∼*q*(**z**\|**x***,ϕ*)\[log\ *p*(**x**\|**z***,\ θ*)\]\ 一般通过采样的方式进行计~
>
> 算。对于每个样本**x**，根据*q*(**z**\|**x***, ϕ*) 采集*M*
> 个**z**(*m*)*,* 1 ≤ *m* ≤ *M* ，

*M*

> E**~z~** *p* \| *, θ* ≈ *p* \|
>
> *m*)*, θ*)*.* (13.22)

∼*q*(**z**\|**x***,ϕ*)

> *M m*=1
>
> 从EM
> 算法角度来看，变分自编码器优化推断网络和生成网络的过程，可以分别看作是EM
> 算法中的E 步和M
> 步。但在变分自编码器中，这两步的目标合二为一，都是最大化证据下界。
>
> 此外，变分自编码器可以看作神经网络和贝叶斯网络的混合体。贝叶斯网
> 络中的节点可以看成是一个随机变量。在变分自编码器中，我们仅仅将隐藏编
> 码对应的节点看成是随机变量，其它节点还是作为普通神经元。这样，编码器
> 变成一个变分推断网络，而解码器可以看作是将隐变量映射到观测变量的生成
> 网络。

###### 训练

> 给定一个数据集D，包含 *N* 个从未知数据分布中抽取的独立同分布样本
>
> **x**(1)*,* **x**(2)*,* · · · *,* **x**(*N*
> )。变分自编码器的目标函数为

J (*ϕ, θ*\|D) =

> *n*Σ=1
>
> [ 1]{.underline} *^M^ m*=1

log *p*(**x**

(*n*)

> *n,m*)

*, θ*) − *D*~KL~

> *q*(**z**\|**x**

(*n*)

*, ϕ*)∥N (**z**\|**0***,* **I**) ! *,*

> (13.23)
>
> 其中**z**(*n,m*) 为第*n* 个样本的变分分布*q*(**z**\|**x**(*n*)*, ϕ*)
> 的第*m* 个采样。
>
> 如果采用随机梯度方法，每次从数据集中采一个样本**x**，然后根据*q*(**z**\|**x***,
> ϕ*)
>
> 采一个隐变量**z**，则目标函数变为
>
> J (*ϕ, θ*\|**x**) = log *p*(**x**\|**z***, θ*) − *D*~KL~
> *q*(**z**\|**x***, ϕ*)∥N (**z**\|**0***,* **I**) *.* (13.24)
>
> 假设 *q*(**z**\|**x***, ϕ*) 是正态分布，公式([13.24](\l)) 中的 KL
> 散度可以直接计算出解析解。
>
> 对于两个正态分布N(***µ***1*,* Σ~1~) 和N(***µ***2*,* Σ~2~)，其KL 散度为
>
> *D*~KL~(N(***µ***1*,* Σ~1~)∥N (***µ***2*,* Σ~2~))
>
> 矩阵的"迹"为主对角线（从左上方至右下方的对角线） 上各个元素的总和。
>
> 2
>
> 其中tr(·) 表示矩阵的迹；\| · \|
> 表示矩阵的行列式。这样当*q*(**z**\|**x**(*n*)*, ϕ*) 为N(***µ**I,
> **σ***^2^*I*) 时，
>
> *D*~KL~ *q*(**z**\|**x***, ϕ*)∥*p*(**z***, θ*)
>
> \|Σ~1~\|
>
> = [1]{.underline} tr(***σ***^2^*I*) + ***µ***^𝖳^***µ*** − *k* −
> log(\|***σ***^2^*I*\|) *,* (13.26)
>
> 其中***µ**I* 和***σ~I~*** 为推断网络*f~I~* (**x***, ϕ*) 的输出。
>
> 再参数化 在变分自编码器中，一个问题是如何求随机变量**z** 关于参数*ϕ*
> 的导数。因为随机变量**z** 采样自后验分布*q*(**z**\|**x***,
> ϕ*)，和参数*ϕ* 相关。但由于是采样的方式， 无法直接计算函数**z**
> 关于*ϕ* 的导数。
>
> 如果*q*(**z**\|**x***, ϕ*)
> 的随机性独立于参数*ϕ*，我们可以通过再参数化（Reparameterization）方法来计算导数。再参数化是实现通过随机变量实现反向传播的一种重要手段，
>
> 并用随机梯度下降训练整个网络，可以提高变分自编码器的训练效率。
>
> 假设*q*(**z**\|**x***, ϕ*) 为正态分布*N* (***µ**I,
> **σ***^2^*I*)，我们可以通过下面方式来采样**z**。
>
> **z** = ***µ**I* + ***σ**~I~* ⊙ ***ϵ**,* (13.27)
>
> 其中*ϵ* ∼ N(**0***,* **I**)，***µ**I* 和***σ~I~*** 是推断网络*f~I~*
> (**x***, ϕ*) 的输出。这样**z** 和***µ**I, **σ**~I~*
> 的关系从采样关系变为函数关系，就可以求**z** 关于*ϕ* 的导数。
>
> 如果进一步假设*p*(**x**\|**z***, θ*) 服从高斯分布N(**x**\|***µ**G,
> I*)，其中***µ**G* = *f~G~*(**z***, θ*)
> 是生成网络的输出，则目标函数可以简化为

J (*ϕ, θ*\|**x**) = −∥**x** − ***µ**G*∥2 + *D*~KL~ N(***µ**I, **σ**~I~*
)∥N (**0***,* **I**) *,* (13.28)

> 其中第一项可以近似看作是输入**x**
> 的重构正确性，第二项可以看作是正则化项。这和自编码器非常类似。变分自编码器的训练过程如图[13.4](\l)所示。
>
> ***µ**G*
>
> ( )
>
> [ *D*~KL~ N(***µ**I, **σ**~I~* )∥N(**0***,* **I**) ]{.underline}
>
> ***µ**~I~ **σ**~I~*

\+

×

> *ϵ* ∼ N (**0***,* **I**)
>
> 图 13.4 变分自编码器的训练过程，空心矩形表示目标函数
>
> 图[13.5](\l)给出了在MNIST
> 数据集上，变分自编码器学习到的隐变量流形的可视化示例。图[13.5a](\l)是将训练集上每个样本**x**
> 通过推断网络映射到2
> 维的隐变量空间，图中的每个点表示E\[**z**\|**x**\]，不同颜色表示不同的数字。图[13.5b](\l)是对2
> 维的标准高斯分布上进行均匀采样得到不同的隐变量**z**，然后通过生成网络产生
> 的E\[**x**\|**z**\]。
>
图片识别内容

图片识别内容

>
> \(a) 训练集上所有样本在隐空间上的投影。 (b) 隐变量**z**
> 在图像空间的投影。
>
> 图 13.5 在MNIST 数据集上，变分自编码器学习到的隐变量流形可视化示例

3.  #### 生成对抗网络

    1.  ###### 显式密度模型和隐式密度模型

> 在本书之前介绍的深度生成模型，比如变分自编码器、深度信念网络等，都
> 是显示地构建出样本的密度函数*p*(**x**\|*θ*)，并通过最大似然估计来求解参数，称
> 为显式密度模型（Explicit Density
> Model）。比如变分自编码器的密度函数为*p*(**x***,* **z**\|*θ*) =
> *p*(**x**\|**z***,
> θ*)*p*(**z**\|*θ*)。虽然使用了神经网络来估计*p*(**x**\|**z***,
> θ*)，但是我们依然假设*p*(**x**\|**z***, θ*)
> 为一个参数分布族，而神经网络只是用来预测这个参数分布族的参数。这在某种程度上限制了神经网络的能力。
>
> 如果只是希望有一个模型能生成符合数据分布 *p~r~*(**x**)
> 的样本，那么可以不显示地估计出数据分布的密度函数。假设在低维空间Z
> 中有一个简单容易采样的分布*p*(**z**)，*p*(**z**)
> 通常为标准多元正态分布N(**0***,*
> **I**)。我们用神经网络构建一个映射函数*G* : Z → X
> ，称为生成网络。利用神经网络强大的拟合能力，使得*G*(**z**)
> 服从数据分布*p~r~*(**x**)。这种模型就称为隐式密度模型（Implicit
> Density Model）
>
> 。所谓隐式模型就是指并不对显示地建模*p~r~*(**x**)，而是建模生成过程。图[13.6](\l)给出了隐式模型生成样本的过程。
>
> **z** ∼ N(**0***,* **I**) = **x**
>
> 图 13.6 隐式模型生成样本的过程

2.  ###### 网络分解

    1.  判别网络

> 隐式密度模型的一个关键是如何确保生成网络产生的样本一定是服从真实
> 的数据分布。既然我们不构建显示密度函数，就无法通过最大似然估计等方法
> 来训练。
>
> 生成对抗网络（Generative Adversarial
> Networks，GAN）是通过对抗训练的方式来使得生成网络产生的样本服从真实数据分布。在生成对抗网络中，有两个网络进行对抗训练。一个是判别网络，目标是尽量准确地判断一个样本是来自于真实数据还是生成网络产生的；另一个是生成网络，目标是尽量生成判别网络无法区分来源的样本。这两个目标相反的网络不断地进行交替训练。当最后收敛时，如果判别网络再也无法判断出一个样本的来源，那么也就等价于生成网络可以生成符合真实数据分布的样本。生成对抗网络的流程图如图[13.7](\l)所示。

**z** ∼ N(**0***,* **I**)

> 图 13.7 生成对抗网络的流程图
>
> 1/0
>
> 判别网络（Discriminator Network）*D*(**x***, ϕ*)
> 的目标是区分出一个样本**x** 时来自于真实分布*p~r~*(**x**)
> 还是来自于生成模型*p~θ~*(**x**)，因此判别网络实际上是一个两类分类器。用标签*y*
> = 1 来表示样本来自真实分布，*y* = 0 表示样本来自模型，
> 判别网络*D*(**x***, ϕ*) 的输出为**x** 属于真实数据分布的概率，即
>
> *p*(*y* = 1\|**x**) = *D*(**x***, ϕ*)*,* (13.29)
>
> 则样本来自模型生成的概率为*p*(*y* = 0\|**x**) = 1 − *D*(**x***, ϕ*)。
>
> 给定一个样本(**x***, y*)，*y* = {1*,* 0} 表示其自于*p~r~*(**x**)
> 还是*p~θ~*(**x**)，判别网络的目标函数为最小化交叉熵，即最大化对数似然。
>
> min − E**x**h*y* log *p*(*y* = 1\|**x**) + (1 − *y*) log *p*(*y* =
> 0\|**x**)i (13.30)
>
> = max E~**x**∼p*r*(**x**)~h log *D*(**x***, ϕ*)i + E**~x~**′∼p*θ*
> (**x**′)h log(1 − *D*(**x**^𝘫^*, ϕ*))i (13.31)
>
> = max E~**x**∼p*r*(**x**)~h log *D*(**x***, ϕ*)i + E~**z**∼p(**z**)~h
> log(1 − *D G*(**z***, θ*)*, ϕ*) i *,* (13.32)
>
> 其中*θ* 和*ϕ* 分布时生成网络和判别网络的参数。
>
> 交叉熵等于负的对数似然。

2.  生成网络

> 生成网络（Generator
> Network）的目标刚好和判别网络相反，即让判别网络将自己生成的样本判别为真实样本。
>
> max E~**z**∼*p*(**z**)~h log *D G*(**z***, θ*)*, ϕ*)i (13.33)
>
> = min E~**z**∼*p*(**z**)~h log 1 − *D G*(**z***, θ*)*, ϕ*) i *.*
> (13.34)
>
> 还有一种改进生成网络的梯度的方法是将真实样本和生成样本的标签互换，即生成样本的标签为1。
>
> 上面的这两个目标函数是等价的。但是在实际训练时，一般使用前者，因为其
> 梯度性质更好。我们知道，函数log(*x*)*, x* ∈ (0*,* 1) 在*x* 接近1
> 时的梯度要比接近0 时的梯度小很多，接近"饱和"区间。这样，当判别网络*D*
> 以很高的概率认为生成网络*G* 产生的样本是"假"样本，即 1 − *D G*(**z***,
> θ*)*, ϕ* → 1。这时目标函数关于*θ* 的梯度反而很小，从而不利于优化。

###### 训练

> 和单目标的优化任务相比，生成对抗网络的两个网络的优化目标刚好想反。
> 因此生成对抗网络的训练比较难，往往不太稳定。一般情况下，需要平衡两个网络的能力。对于判别网络来说，一开始的判别能力不能太强，否则难以提升生成网络的能力。然后也不能太弱，否则针对它训练的生成网络也不会太好。在训练时需要使用一些技巧，使得在每次迭代中，判别网络比生成网络的能力强一些，但又不能强太多。
>
> 生成对抗网络的训练流程如算法[13.1](\l)所示。每次迭代时，判别网络更新*K*
>
> 次而生成网络更新一次，即首先要保证判别网络足够强才能开始训练生成网络。
>
> 在实践中*K* 是一个超参数，其取值一般取决于具体任务。
>
> 算法 **13.1:** 生成对抗网络的训练过程
>
> 输入**:** 训练集D，对抗训练迭代次数*T*
> ，每次判别网络的训练迭代次数*K*，小批量样本数量*M*
>
> **1** 随机初始化*θ, ϕ*;
>
> **2 for** *t* ← 1 **to** *T* **do**
>
> // 训练判别网络*D*(**x***, ϕ*)
>
> **3 for** *k* ← 1 **to** *K* **do**
>
> // 采集小批量训练样本
>
> **4** 从训练集D 中采集*M* 个样本{**x**(*m*)}*,* 1 ≤ *m* ≤ *M* ;
>
> **5** 从分布N(**0***,* **I**) 中采集*M* 个样本{**z**(*m*)}*,* 1 ≤ *m*
> ≤ *M* ;
>
> **6** 使用随机梯度上升更新*ϕ*，梯度为

[* ∂ *]{.underline} h [ 1]{.underline} ΣM

> i

**7 end**

> *∂ϕ M*
>
> m=1
>
> log *D*(**x**(m)*, ϕ*) + log
>
> 1 − *D G*(**z**(m)*, θ*)*, ϕ* ;
>
> // 训练生成网络*G*(**z***, θ*)
>
> **8** 从分布N(**0***,* **I**) 中采集*M* 个样本{**z**(*m*)}*,* 1 ≤ *m*
> ≤ *M* ;
>
> **9** 使用随机梯度上升更新*θ*，梯度为

[* ∂ *]{.underline} h [ 1]{.underline} ΣM i

*∂θ*

> **10 end**
>
> 输出**:** 生成网络*G*(**z***, θ*)
>
> *M*
>
> m=1

*D G*(**z**(m)*, θ*)*, ϕ* ;

4.  一个生成对抗网络的具体实现：**DCGAN**

> 生成对抗网络是指一类采用对抗训练方式来进行学习的深度生成模型，其
> 包含的判别网络和生成网络都可以根据不同的生成任务使用不同的网络结构。
>
> 本节介绍一个生成对抗网络的具体例子深度卷积生成对抗网络（Deep Con-
> volutional Generative Adversarial Networks，DCGAN）\[[Radford et
> al.](\l), [2015](\l)\]。在DCGAN
> 中，判别网络是一个传统的深度卷积网络，但使用了带步长的卷积来实现下采样操作，不用最大汇聚（pooling）操作。生成网络使用一个特殊的深度卷积网络来实现，如图[13.8](\l)所示，使用微步卷积来生成64
> × 63 大小的图像。
>
> DCGAN
> 的主要优点是通过一些经验性的网络结构设计使得对抗训练更加稳定。比如，（1）使用代步长的卷积（在判别网络中）和微步卷积（在生成网
>
> 微步卷积参见第[5.5.1](\l)节。
>
图片识别内容
128
256
512
64
1024
16
Stride2
5
32
8
100z
Stride2
5
8
Stride2
16
Projectandreshape
32
Stride2
CONV1
CONV2
CONV3
64
CONV4
G(z)

>
> 图 13.8 DCGAN 中的生成网络。第一层是全连接层，输入是从均匀分布中随机
>
> 采样的100 维向量**z**，输出是4 × 4 × 1024 的向量，重塑为4 × 4 × 1024
> 的张量； 然后是四层的微步卷积，没有汇聚层。图片来源：\[[Radford et
> al.](\l), [2015](\l)\]
>
> 络中）来代替汇聚操作，以免损失信息；（2）使用批量归一化；（3）去除卷积层之后的全连接层；（4）在生成网络中，除了最后一层使用Tanh
> 激活函数外， 其余层都使用ReLU 函数；（5）在判别网络中，都使用LeakyReLU
> 激活函数。

###### 模型分析

> 将判别网络和生成网络合并，整个生成对抗网络的整个目标函数看作最小
> 化最大化游戏（Minimax Game），
>
> min max E~**x**∼p*r*(**x**)~h log *D*(**x***, ϕ*)i + E~**x**∼p~*θ*
> (**x**)h log(1 − *D* **x***, ϕ*) i (13.35)
>
> = min max E~**x**∼p*r*(**x**)~h log *D*(**x***, ϕ*)i +
> E~**z**∼p(**z**)~h log(1 − *D G*(**z***, θ*)*, ϕ*) i *,* (13.36)
>
> 参见习题[13-1](\l)。
>
> 因为之前提到的生成网络梯度问题，这个最小化最大化形式的目标函数一般用
> 来进行理论分析，并不是实际训练时的目标函数。
>
> 假设*p~r~*(**x**) 和*p~θ~*(**x**) 已知，则最优的判别器为

*D^⋆^*(**x**) =

> [ *p~r~*(**x**) ]{.underline}
>
> *p~r~*(**x**) + *p~θ~*(**x**)

*.* (13.37)

> 将最优的判别器*D^⋆^*(**x**) 代入公式([13.35](\l))，其目标函数变为

= E**~x~**

> *r*
>
> ~(**x**)~h log

*θ*

> ( *p*r(**x**) (**x**) i + E**x**
>
> ~(**x**)~h log
>
> ( *p*θ(**x**) (**x**) i (13.39)
>
> = *D*~KL~ *p*~r~∥*p*~a~ + *D*~KL~ *p*~θ~∥*p*~a~ − 2 log 2 (13.40)
>
> = 2*D*~JS~(*p*~r~∥*p*~θ~) − 2 log 2*,* (13.41)
>
> 其中*D*~JS~ 为JS 散度，*p~a~*(**x**) = 1 *p~r~*(**x**) + *p~θ~*(**x**)
> 为一个"平均"分布。
>
> 在生成对抗网络中，当判断网络为最优时，生成网络的优化目标是最小化
> 真实分布*p~r~* 和模型分布*p~θ~* 之间的JS 散度。当两个分布相同时，JS
> 散度为0，最优生成网络*G^⋆^* 对应的损失为*L*(*G^⋆^*\|*D^⋆^*) = −2 log
> 2。
>
> 然而，JS 散度的一个问题是：当两个分布没有重叠时，它们之间的JS
> 散度恒等于常数log 2。对生成网络来说，目标函数关于参数的梯度为0。

*∂*L(*G*\|*D^⋆^*) = 0

*∂θ*

> (13.42)
>
> 图[13.9](\l)给出了生成对抗网络中的梯度消失问题的示例。当真实分布*p~r~*
> 和模型分布*p~θ~*
> 没有重叠，最优的判断网络对所有生成数据的输出都为0，*D^⋆^*(*G*(**z***,
> θ*)) = 0*,* ∀**z**。因此，生成网络的梯度消失。
>
> 1
>
> 0
>
> 图 13.9 生成对抗网络中的梯度消失问题
>
> 因此，在实际训练生成对抗网络时，我们一般不会将判别网络训练到最优，
> 只进行一步或多步梯度下降，使得生成网络的梯度依然存在。然而，判别网络也不能太差，否则生成网络的梯度为错误的梯度。如何使得判别网络在梯度消失和梯度错误之间取得平衡并不是一件容易的事。

3.  模型坍塌

> 如果使用公式（[13.33](\l)）作为生成网络的目标函数，将最优判断网络*D^⋆^*
> 代入，得到

[ ]{.underline}

> 𝘫 ⋆ ⋆
>
> *θ*
>
> (13.43)
>
> = E**x**∼p*θ*
>
> = −E**~x~**
>
> *p*r(**x**)
>
> *p*~r~(**x**) + *p*~θ~(**x**)
>
> ~(**x**)~h log [*p*θ(**x**)]{.underline} i + E**~x~**
>
> *p*~θ~(**x**)
>
> *p*~θ~(**x**)
>
> ~(**x**)~h log [ *p*~θ~(**x**)]{.underline} i
>
> (13.44)
>
> (13.45)
>
> = −*D*~KL~ *p*~θ~∥*p*~r~ + E~**x**∼p~ ~(**x**)~h log 1 −
> *D*^⋆^(**x**))i
>
> = −*D*~KL~ *p*~θ~∥*p*~r~ + 2*D*~JS~(*p*~r~∥*p*~θ~) − 2 log 2 −
> E~**x**∼p~ ~(**x**)~h log *D*^⋆^(**x**)i*,*
>
> (13.46)
>
> (13.47)
>
> 根据公式([13.41](\l))
>
> 其中后两项和生成网络无关，因此
>
> max L′(*G*\|*D^⋆^*) = min *D*~KL~ *p~θ~*∥*p~r~* −
> 2*D*~JS~(*p~r~*∥*p~θ~*)*,* (13.48)
>
> 其中JS 散度*D*~JS~(*p~θ~*∥*p~r~*) ∈ \[0*,* log 2\]
> 为有界函数，因此生成网络的目标为更多的是受逆向KL
> 散度*D*~KL~(*p~θ~*∥*p~r~*) 影响，使得生成网络更倾向于生成一些更"安全"
> 的样本，从而造成模型坍塌（Model Collapse）问题。
>
> 前向和逆向**KL** 散度 因为KL
> 散度是一种非对称的散度，在计算真实分布*p~r~* 和模型分布*p~θ~* 之间的KL
> 散度时，按照顺序不同，有两种KL 散度：前向*KL* 散度
>
> （Forward KL divergence）*D*~KL~(*p~r~*∥*p~θ~*) 和逆向*KL*
> 散度（Reverse KL divergence）
>
> *D*~KL~(*p~θ~*∥*p~r~*)。前向和逆向KL 散度分别定义为
>
> *D*~KL~(*p* ∥*p* ) = ∫ *p* (**x**) log [*pr*(**x**)]{.underline}
> *d***x***,* (13.49)

*θ r*

> 在前向KL 散度中，
>
> *^θ^ p~r~*(**x**)

1.  当*p~r~*(**x**) → 0 而*p~θ~*(**x**) *\>* 0 时，*p~r~*(**x**) log
    > [*^p^r* (**x**)]{.underline} → 0。不管*p~θ~*(**x**) 如何取

> 值，都对前向KL 散度的计算没有贡献。

2.  当*p~r~*(**x**) *\>* 0 而*p~θ~*(**x**) → 0 时，*p~r~*(**x**) log
    > [*^p^r* (**x**)]{.underline} → ∞，前向KL 散度会变

> 得非常大。
>
> 因此，前向KL 散度会鼓励模型分布*p~θ~*(**x**)
> 尽可能覆盖所有真实分布*p~r~*(**x**) *\>*
>
> 0 的点，而不用回避*p~r~*(**x**) ≈ 0 的点。在逆向KL 散度中，

1.  当*p~r~*(**x**) → 0 而*p~θ~*(**x**) *\>* 0 时，*p~θ~*(**x**) log
    > [*^p^θ* (**x**)]{.underline} → ∞。即当*p~θ~*(**x**) 接近于

> 0，而*p~θ~*(**x**) 有一定的密度时，逆向KL 散度会变得非常大。

2.  当*p~θ~*(**x**) → 0 时，不管*p~r~*(**x**) 如何取值，*p~θ~*(**x**)
    > log [*^p^θ* (**x**)]{.underline} → 0。

> 因此，逆向KL 散度会鼓励模型分布*p~θ~*(**x**)
> 尽可能避开所有真实分布*p~r~*(**x**) ≈
>
> 0 的点，而不需要考虑是否覆盖所有布*p~r~*(**x**) *\>* 0 的点。
>
> 图[13.10](\l)给出数据真实分布为一个高斯混合分布，模型分布为一个单高斯分
> 布时，使用前向和逆向KL
> 散度来进行模型优化的示例。蓝色曲线为真实分布*p~r~*
> 的等高线，红色曲线为模型分布*p~θ~* 的等高线。

###### 改进模型

> 生成对抗网络的改进主要有以下几个方面：

真实分布 *pr* 前向 KL 散度 *D~KL~*(*p~r~*∥*p~θ~*) 逆向 KL 散度
*D~KL~*(*p~θ~*∥*p~r~*)

> 图 13.10 前向和逆向KL 散度
>
> GAN 中交叉熵（JS
> 散度）不适合衡量生成数据分布和真实数据分布的距离，如果通过优化JS
> 散度训练GAN 会导致找不到正确的优化目标，所以，
>
> **13.3.6.1 W-GAN**
>
> W-GAN 是一种通过用Wassertein 距离替代JS 散度来优化训练的生成对抗
>
> 网络\[[Arjovsky et al.](\l), [2017](\l)\]。 Wassertein 距 离 参 见
>
> 对于真实分布*p~r~* 和模型分布*p~θ~*，它们的1st-Wasserstein 距离为
>
> 第[E.3.4](\l)节。
>
> *W* ^1^(*p~r~, p~θ~*) = inf
>
> *γ*∼Π(*Pr,Pg* )

E~(**x***,***y**)∼*γ*~h\|\|**x** − **y**\|\|i*,* (13.51)

> 其中Γ(*p~r~, p~θ~*) 是边际分布为*p~r~* 和*p~θ~*
> 的所有可能的联合分布集合。
>
> 当两个分布没有重叠或者重叠非常少时，它们之间的KL 散度为+∞，JS
> 散度为log 2，并不随着两个分布之间的距离而变化。而1st-Wasserstein
> 距离可以依然衡量两个没有重叠分布之间的距离。
>
> 根据Kantorovich-Rubinstein 对偶定理，两个分布 *p~r~* 和*p~θ~* 之间的
> 1st-Wasserstein
>
> 距离的对偶形式为：
>
> *W* ^1^(*p~r~, p~θ~*) = sup E~**x**∼*p*~ \[*f* (**x**)\] −
> E~**x**∼*p*~ \[*f* (**x**)\]*,* (13.52)
>
> ∥*f* ∥*~L~*≤1
>
> 其中*f* : R*d* → R 为1-Lipschitz 函数，满足
>
> ∥*f* ∥ , sup [\|*f*(**x**) − *f*(**y**)\|]{.underline} ≤ 1*.* (13.53)

*L* **x y** \|**x** − **y**\|

> 我们可以将1-Lipschitz 连续的约束宽松为K-Lipschitz 连续，等于计算*p~r~*
> 和*p~θ~* 之间的*K* · *W* ^1^(*p~r~, p~θ~*)。
>
> 令*f* (**x***, ϕ*) 为一个神经网络，假设存在参数集合Φ，对于所有的*ϕ* ∈
> Φ，*f~ϕ~*(**x**)
>
> 为K-Lipschitz 连续函数。那么公式（[13.52](\l)）中的上界可以转换为
>
> max E~*x*∼*p*~*r* \[*f* (**x***, ϕ*)\] − E~*x*∼*p*~*θ* \[*f*~(~**x***,
> ϕ*)\]*,* (13.55)
>
> 参见习题[13-2](\l)。
>
> *l* 为参数数量。
>
> 其中*f* (**x***, ϕ*) 称为评价网络（Critic Network）。对于真实样本，*f*
> (**x***, ϕ*) 的打分要尽可能的高；对于模型生成的样本，*f* (**x***, ϕ*)
> 的打分要尽可能的低。和标准GAN 中的判别网络的值域为\[0*,* 1\]*l*
> 不同，评价网络*f* (**x***, ϕ*) 的值域没有限制。
>
> 因为神经网络为连续可导函数，为了使得*f* (**x***, ϕ*) 满足K-Lipschitz
> 连续，可以令导数∥ [*∂f* (**x***,ϕ*)]{.underline} ∥
> 有界。一种近似的方法是限制参数*ϕ* ∈ \[−*c, c*\]，*c*
> 为一个比较小的正数，比如0*.*01。
>
> 生成网络的目标是使得生成样本的*f* (**x***, ϕ*) 得分尽可能高。
>
> max E~**z**∼*p*(**z**)~h*f G*(**z***, θ*)*, ϕ*)i*.* (13.56)
>
> 因为*f* (**x***, ϕ*) 为不饱和函数，所以生成网络参数*θ*
> 的梯度不会消失，理论上解决了原始 GAN 训练不稳定的问题。并且 W-GAN
> 中生成网络的目标函数不再是两个分布的比率，在一定程度上缓解了模型坍塌问题，使得生成的样本具有多
> 样性。
>
> 算法[13.2](\l)给出W-GAN 的训练过程。和原始GAN 相比，W-GAN
> 的评价网络最后一层不使用sigmoid 函数，损失函数不取对数。

#### 总结和深入阅读

> 深度生成模型是一种有机地融合神经网络和概率图模型的生成模型，将神
> 经网络作为一个概率分布的逼近器，可以拟合非常复杂的数据分布。
>
> 变分自编码器\[[Kingma and Welling](\l), [2013](\l), [Rezende et
> al.](\l), [2014](\l)\]
> 是一个有意义的深度生成模型，可以有效地解决含隐变量的概率模型中后验分布难以估计的问题。变分自动编码器的一个详尽介绍可以参考文献\[[Doersch](\l),
> [2016](\l)\]。[Bowman et al.](\l) \[[2015](\l)\]
> 将进一步将变分自编码器应用于序列生成问题。
>
> 13.4 总结和深入阅读 2019 年 4 月 6 日 333
>
> 算法 **13.2:** W-GAN 的训练过程
>
> 输入**:** 训练集D，对抗训练迭代次数*T*
> ，每次评价网络的训练迭代次数*K*，小批量样本数量*M*
>
> **1** 随机初始化*θ, ϕ*;
>
> **2 for** *t* ← 1 **to** *T* **do**
>
> // 训练评价网络*f* (**x***, ϕ*)
>
> **3 for** *k* ← 1 **to** *K* **do**
>
> // 采集小批量训练样本
>
> **4** 从训练集D 中采集*M* 个样本{**x**(*m*)}*,* 1 ≤ *m* ≤ *M* ;
>
> **5** 从分布N(**0***,* **I**) 中采集*M* 个样本{**z**(*m*)}*,* 1 ≤ *m*
> ≤ *M* ;
>
> // 计算评价网络参数*ϕ* 的梯度

= [* ∂ *]{.underline} [ 1]{.underline} Σ*M*

> (**x**( ) )
>
> (**z**( ) )
>
> ;
>
> // 使用RMSProp 算法更新*ϕ*
>
> **7** *ϕ* ← *ϕ* + *α* · RMSProp(*ϕ, g~ϕ~*);
>
> // 梯度截断
>
> **8** *ϕ* ← clip(*ϕ,* −*c, c*);
>
> **9 end**
>
> // 训练生成网络*G*(**z***, θ*)
>
> **10** 从分布N(**0***,* **I**) 中采集*M* 个样本{**z**(*m*)}*,* 1 ≤ *m*
> ≤ *M* ;
>
> // 更新生成网络参数*θ*
>
> [* ∂ *]{.underline} [ 1]{.underline} Σ*M* ( )
>
> **12** *θ* ← *θ* + *α* · RMSProp(*θ, g~θ~*);
>
> **13 end**
>
> 输出**:** 生成网络*G*(**z***, θ*)
>
> 334 2019 年 4 月 6 日 参考文献
>
> 生成对抗网络\[[Goodfellow et al.](\l), [2014](\l)\]
> 是一个具有开创意义的深度生成模型，突破了以往的概率模型必须通过最大似然估计来学习参数的限制。DC-
> GAN\[[Radford et al.](\l), [2015](\l)\]
> 是一个生成对抗网络的成功实现，可以生成十分逼真的自然图像。[Yu et
> al.](\l) \[[2017](\l)\]
> 进一步在文本生成任务上结合对抗生成网络和强化学习来进行文本生成模型。对抗生成网络的训练不稳定问题的一种有效解
> 决方法是W-GAN\[[Arjovsky et al.](\l), [2017](\l)\]，通过用Wassertein
> 距离替代JS 散度来进行训练。
>
> 虽然深度生成模型取得巨大的成功，但是作为一种无监督模型，其主要的
> 缺点是缺乏有效的客观评价，因此不同模型之间的比较很难客观衡量。

#### 习题

> 参见公式([13.58](\l))。
>
> 习题 **13-1** 假设一个两类分类，类别为*c*~1~ 和*c*~2~，样本**x**
> 在两个类的条件分
>
> 布为*p*(**x**\|*c*~1~) 和*p*(**x**\|*c*~2~)，一个分类器*f* (**x**) =
> *p*(*c*~1~\|**x**) 用于预测一个样本**x** 来自类别*c*~1~
> 的后验概率。证明若采用交叉熵损失，
>
> L(*f* ) = E~**x**∼*p*(**x**\|*c*~1)h log *f* (**x**)i +
> E~**x**∼*p*(**x**\|*c*~2)h log 1 − *f* (**x**) i*,* (13.57)
>
> 则最优分类器*f^⋆^*(**x**) 为
>
> *f^⋆^*(**x**) = [ *p*(**x**\|*c*1)]{.underline} *.* (13.58)
>
> *p*(**x**\|*c*~1~) + *p*(**x**\|*c*~2~)
>
> 习题 **13-2** 分析下面函数是否满足Lipschitz 连续条件。
>
> （1）*f* : \[−1*,* 1\] → R，*f* (*x*) = *x*^2^；
>
> （2）*f* : R → R，*f* (*x*) = *x*^2^；
>
> （3）*f* : R → R，*f* (*x*) = √*x*2 + 1；
>
> （4）*f* : \[0*,* 1\] → \[0*,* 1\]，*f* (*x*) = √*x*。

#### 参考文献

> Martin Arjovsky, Soumith Chintala, and Léon Bottou. Wasserstein GAN.
> *arXiv* *preprint arXiv:1701.07875*, 2017.
>
> Samuel R Bowman, Luke Vilnis, Oriol Vinyals, Andrew M Dai, Rafal
> Jozefowicz, and Samy Bengio. Generating sentences
>
> from a continuous space. *arXiv preprint* *arXiv:1511.06349*, 2015.
>
> Carl Doersch. Tutorial on varia- tional autoencoders. *arXiv preprint*
> *arXiv:1606.05908*, 2016.
>
> Ian Goodfellow, Jean Pouget-Abadie,
>
> 参考文献 2019 年 4 月 6 日 335
>
> Mehdi Mirza, Bing Xu, David Warde- Farley, Sherjil Ozair, Aaron
> Courville, and Yoshua Bengio. Generative adversarial nets. In
> *Advances in Neural Information Processing Systems*, pages 2672--2680,
> 2014.
>
> Diederik P Kingma and Max Welling. Auto- encoding variational bayes.
> *arXiv preprint arXiv:1312.6114*, 2013.
>
> Alec Radford, Luke Metz, and Soumith Chintala. Unsupervised
> representation learning with deep convolutional genera-
>
> tive adversarial networks. *arXiv preprint* *arXiv:1511.06434*, 2015.
>
> Danilo Jimenez Rezende, Shakir Mohamed, and Daan Wierstra. Stochastic
> back- propagation and approximate inference in deep generative models.
> *arXiv preprint* *arXiv:1401.4082*, 2014.
>
> Lantao Yu, Weinan Zhang, Jun Wang, and Yong Yu. Seqgan: Sequence
> generative adversarial nets with policy gradient. In *Thirty-First
> AAAI Conference on Artiﬁcial Intelligence*, 2017.
>
> 第**14** 章 深度强化学习
>
> 除了试图直接去建立一个可以模拟成人大脑的程序之外，
> 为什么不试图建立一个可以模拟小孩大脑的程序呢？如果它接受适当的教育，就会获得成人的大脑。
>
> --- 阿兰· 图灵
>
> 在之前的章节中，我们主要关注于监督学习，而监督学习一般需要一定数
> 量的带标签的数据。在很多的应用场景中，通过人工标注的方式来给数据打标签的方式往往行不通。比如我们通过监督学习来训练一个模型可以来自动下围棋，就需要将当前棋盘的状态作为输入数据，其对应的最佳落子位置（动作）作为标签。训练一个好的模型就需要收集大量的不同棋盘状态以及对应动作。这种做法实践起来比较困难，一是对于每一种棋盘状态，即使是专家也很难给出"正确"的动作，二是获取大量数据的成本往往比较高。对于下棋这类任务，虽
> 然我们很难知道每一步的"正确"动作，但是其最后的结果（即赢输）却很容易判断。因此，如果可以通过大量的模拟数据，通过最后的结果（奖励）来倒推每一步棋的好坏，从而学习出"最佳"的下棋策略，这就是强化学习。
>
> 强化学习（Reinforcement
> Learning，RL），也叫增强学习，是指一类从（与环境）交互中不断学习的问题以及解决这类问题的方法。强化学习问题可以描
> 述为一个智能体从与环境的交互中不断学习以完成特定目标（比如取得最大奖
> 励值）。和深度学习类似，强化学习中的关键问题也是贡献度分配问题
> \[[Minsky](\l),
> [1963](\l)\]，每一个动作并不能直接得到监督信息，需要通过整个模型的最终监督信
> 息（奖励）得到，并且有一定的延时性。
>
> 强化学习也是机器学习中的一个重要分支。强化学习和监督学习的不同在
> 于，强化学习问题不需要给出"正确"策略作为监督信息，只需要给出策略的
>
> （延迟）回报，并通过调整策略来取得最大化的期望回报。
>
> 贡献度分配问题即一个系统 中不同的组件（components）
> 对最终系统输出结果的贡献 或影响。

#### 强化学习问题

> 也称为*K* 臂赌博机问题（K-
>
> 强化学习广泛应用在很多领域，比如电子游戏、棋类游戏、迷宫类游戏、控制系统、推荐等。这里我们介绍几个比较典型的强化学习例子。

###### 典型例子

> 多臂赌博机问题 给定*K*
> 个赌博机，拉动每个赌博机的拉杆（arm），赌博机会按照一个事先设定的概率掉出一块钱或不掉钱。每个赌博机掉钱的概率不一样。
> 多臂赌博机问题（multi-armed bandit
> problem）是指，给定有限的机会次数*T* ，
> 如何玩这些赌博机才能使得期望累积收益最大化。多臂赌博机问题在广告推荐、
>
> armed bandit problem）。 投资组合等领域有着非常重要的应用。
>
> 悬崖行走问题 在一个网格世界（grid
> world）中，每个格子表示一个状态。如[14.1](\l)所示的一个网格世界，每个状态为(*i,
> j*)*,* 1 ≤ *i* ≤ 7*,* 1 ≤ *j* ≤ 3，其中格子(2*,* 1) 到(6*,* 1)
> 是悬崖（cliff）。有一个醉汉，从左下角的开始位置*S*，走到右下角的目标位置*E*。如果走到悬崖，醉汉会跌落悬崖并死去。醉汉可以选择行走的路线，即在每个状态时，选择行走的方向：上下左右。动作空间A
> = {↑*,* ↓*,* ←*,*
> →}。但每走一步，都有一定的概率滑落到周围其他的格子。醉汉的目标是如何安全地到达目标位置。
>
> 3
>
> 2

1 S

1 2 3

E

> 4 5 6 7
>
> 图 14.1 醉汉悬崖问题

###### 强化学习定义

> 现在我们描述下强化学习的任务定义。在强化学习中，有两个可以进行交
> 互的对象：智能体和环境。

-   智能体（agent）可以感知外界环境的状态（state）和反馈的奖励（reward），并进行学习和决策。

> 智能体的决策功能是指根据外界环境的状态来做出不同的动作（action），而学习功能是指根据外界环境的奖励来调整策略。

-   环境（environment）是智能体外部的所有事物，并受智能体动作的影响
    > 而改变其状态，并反馈给智能体相应的奖励。

> 在强化学习中的基本要素包括：

-   状态*s* 是对环境的描述，可以是离散的或连续的，其状态空间为S；

-   动作*a* 是对智能体行为的描述，可以是离散的或连续的，其动作空间为A；

-   策略*π*(*a*\|*s*) 是智能体根据环境状态*s* 来决定下一步的动作*a*
    > 的函数；

-   状态转移概率 *p*(*s*^′^\|*s, a*) 是在智能体根据当前状态 *s*
    > 做出一个动作 *a* 之后， 环境在下一个时刻转变为状态*s*^′\ 的概率；^

-   即时奖励*r*(*s, a,
    > s*^′)\ 是一个标量函数，即智能体根据当前状态*s*\ 做出动作*a*\ 之后，环境会反馈给智能体一个奖励，这个奖励也经常和下一个时刻的状^态*s*^′\ 有关。^

> 策略 智能体的策略（policy）就是智能体如何根据环境状态*s*
> 来决定下一步的动作*a*，通常可以分为确定性策略（Deterministic
> Policy）和随机性策略（Stochastic Policy）两组。
>
> 确定性策略是从状态空间到动作空间的映射函数*π* : S → A。随机性策略
>
> 表示在给定环境状态时，智能体选择某个动作的概率分布。
>
> *π*(*a*\|*s*) , *p*(*a*\|*s*)*,* (14.1)
>
> *π*(*a*\|*s*) = 1*.* (14.2)
>
> *a*∈A
>
> 通常情况下，强化学习一般使用随机性的策略。随机性的策略可以有很多
> 优点。比如在学习时可以通过引入一定随机性更好地探索环境。二是使得策略
> 更加地多样性。比如在围棋中，确定性策略总是会在同一个位置上下棋，会导
> 致你的策略很容易被对手预测。

###### 马尔可夫决策过程

> 为了简单起见，我们将智能体与环境的交互看作是离散的时间序列。图[14.2](\l)给
> 出了智能体与环境的交互。
>
> 参考利用*-*探索策略。
>
> 状态 *s~t~* 动作 *a~t~*
>
> 图 14.2 智能体与环境的交互
>
> 智能体从感知到的初始环境*s*~0~
> 开始，然后决定做一个相应的动作*a*~0~，环境相应地发生改变到新的状态*s*~1~，并反馈给智能体一个即时奖励*r*~1~，然后智能体又根据状态*s*~1~
> 做一个动作*a*~1~，环境相应改变为*s*~2~，并反馈奖励*r*~2~。这样的交互可以一直进行下去。
>
> *s*~0~*, a*~0~*, s*~1~*, r*~1~*, a*~1~*,* · · · *, s~t~*~−1~*,
> r~t~*~−1~*, a~t~*~−1~*, s~t~, r~t~,* · · · *,* (14.3)
>
> 其中*r~t~* = *r*(*s~t~*~−1~*, a~t~*~−1~*, s~t~*) 是第*t*
> 时刻的即时奖励。
>
> 智能体与环境的交互的过程可以看作是一个马尔可夫决策过程。
>
> 马尔可夫过程（Markov Process）是具有马尔可夫性的随机变量序列*s*~0~*,
> s*~1~*,* · · · ， *s~t~* ∈ S，其下一个时刻的状态*s~t~*~+1~
> 只取决于当前状态*s~t~*，
>
> *p*(*s~t~*~+1~\|*s~t~,* · · · *, s*~0~) = *p*(*s~t~*~+1~\|*s~t~*)*,*
> (14.4)
>
> 马 尔 可 夫 过 程 参 见第[D.3.1](\l)节。
>
> 其中*p*(*s~t~*~+1~\|*s~t~*) 称为状态转移概率，

*st*+1∈S

> *p*(*s~t~*~+1~\|*s~t~*) = 1。
>
> 马尔可夫决策过程（Markov Decision Process，MDP）在马尔可夫过程中
>
> 加入一个额外的变量：动作*a*，即下一个时刻的状态*s~t~*~+1~
> 和当前时刻的状态*s~t~*
>
> 以及动作*a~t~* 相关，
>
> *p*(*s~t~*~+1~\|*s~t~, a~t~,* · · · *, s*~0~*, a*~0~) =
> *p*(*s~t~*~+1~\|*s~t~, a~t~*)*,* (14.5)
>
> 其中*p*(*s~t~*~+1~\|*s~t~, a~t~*) 为状态转移概率。
>
> 给定策略*π*(*a*\|*s*)，马尔可夫决策过程的一个轨迹（trajectory） *τ* =
> *s*~0~*, a*~0~*, s*~1~*, r*~1~*, a*~1~*,* · · · *, s~T~* ~−1~*, a~T~*
> ~−1~*, s~T~ , r~T~*

的概率为

> *p*(*τ* ) = *p*(*s*~0~*, a*~0~*, s*~1~*, a*~1~*,* · · · )*,* (14.6)
>
> *T* −1
>
> = *p*(*s*~0~) *π*(*a~t~ s~t~*)*p*(*s~t~*~+1~ *s~t~, a~t~*)*.* (14.7)
>
> *t*=0
>
> 图[14.3](\l)给出了马尔可夫决策过程的图模型表示。
>
> · · ·
>
> · · ·
>
> 图 14.3 马尔可夫决策过程的图模型表示

4.  ###### 强化学习的目标函数

    1.  总回报

> 给定策略 *π*(*a*\|*s*)，智能体和环境一次交互过程的轨迹 *τ*
> 所收到的累积奖励为总回报（return）。
>
> *T* −1

*G*(*τ* ) = *r~t~*~+1~ (14.8)

> *t*=0 *T* −1
>
> = *r*(*s~t~, a~t~, s~t~*~+1~)*.* (14.9)
>
> *t*=0
>
> 假设环境中有一个或多个特殊的终止状态（terminal
> state），当到达终止状态时，一个智能体和环境的交互过程就结束了。这一轮交互的过程称为一个
> 回合（episode）或试验（trial）。一般的强化学习任务（比如下棋、游戏）都
> 属于这种回合式的任务。
>
> 如果环境中没有终止状态（比如终身学习的机器人），即*T* =
> ∞，称为持续性强化学习任务，其总回报也可能是无穷大。为了解决这个问题，我们可以引
> 入一个折扣率来降低远期回报的权重。折扣回报（discounted return）定义为
>
> *T* −1

*G*(*τ* ) = *γ r~t~*~+1~*,* (14.10)

> *t*=0
>
> 其中*γ* ∈ \[0*,* 1\] 是折扣率。当*γ* 接近于0
> 时，智能体更在意短期回报；而当*γ* 接近于1 时，长期回报变得更重要。

2.  目标函数

> 因为策略和状态转移都有一定的随机性，每次试验得到的轨迹是一个随机
> 序列，其收获的总回报也不一样。强化学习的目标是学习到一个策略*π~θ~*(*a*\|*s*)
> 来
>
> 持续性强化学习的优化目标也可以定义为 MDP 到达平稳分布时"即时奖励"的期
>
> 最大化期望回报（expected
> return），即希望智能体执行一系列的动作来获得尽可能多的平均回报。
>
> *T* −1
>
> J (*θ*) = E~*τ*∼*p*~ ~(*τ*)~\[*G*(*τ* )\] = E~*τ*∼*p*~ ~(*τ*)~\[ *γ
> r~t~*~+1~\]*.* (14.11)

*θ*

> 望。
>
> 其中*θ* 为策略函数的参数。

###### 值函数

> *θ*
>
> *t*=0
>
> 为了评估一个策略*π*
> 的期望回报，我们定义两个值函数：状态值函数和状态-动作值函数。

1.  状态值函数

> 一个策略*π* 期望回报可以分解为

\[ ( )\] =

> \" h *T*Σ−1
>
> = i\# (14.12)
>
> = E~*s*∼*p*(*s*~0 ) \[*V ^π^*(*s*)\] *,* (14.13)
>
> 其中*V ^π^*(*s*) 称为状态值函数（state value function），表示从状态*s*
> 开始，执行策略*π* 得到的期望总回报

*V ^π^*(*s*) =

> E*τ* ∼*p*(*τ* )
>
> *T* −1
>
> *t*=0

*γtrt*+1\|*τs*0

> = *s*i*,*
>
> (14.14)
>
> 其中*τ~s~*0 表示轨迹*τ* 的起始状态。
>
> 为了方便起见，我们用*τ*~0:*T*~ 来表示从轨迹*s*~0~*, a*~0~*, s*~1~*,* ·
> · · *, s~T~* ，用*τ*~1:*T*~ 表示轨迹*s*~1~*, a*~1~*,* · · · *, s~T~*
> ，因此有*τ*~0:*T*~ = *s*~0~*, a*~0~*, τ*~1:*T*~ 。
>
> 根据马尔可夫性，*V ^π^*(*s*) 可展开得到

*V* ^π^(*s*) = E~τ~0:

∼p(τ)

\"*r*1 + *γ*

T −1

> t=1

*γ*t−1*r*t+1\|*τ*s0 = *s*\#

> (14.15)
>
> = Ea∼π(a\|s)Es′∼p(s′\|s,a)Eτ1:*T*

∼p(τ)

\"*r*(*s, a, s*^𝘫^) + *γ*

T −1

> t=1

*γ*t−1*r*t+1\|*τ*s1 = *s*𝘫\#

> (14.16)
>
> 贝 尔 曼 方 程 因 提 出 者Richard Bellman而得名，也叫做"动态规划方程"
> 。
>
> = Ea∼π(a\|s)Es′∼p(s′\|s,a)

\"*r*(*s, a, s*^𝘫^) + *γ*E~τ~1:*T*

∼p(τ)

> T −1
>
> t=1

*γ*t−1*r*t+1\|*τ*s1 = *s*𝘫i\#

> (14.17)
>
> Richard Bellman（1920 －
> 1984），美国应用数学家，美国国家科学院院士，和动态规划的创始人。
>
> = E~a∼π(a\|s)~E~s~′∼p(s′\|s,a) *r*(*s, a, s*^𝘫^) + *γV* ^π^(*s*^𝘫^)
> *.* (14.18)
>
> 公式([14.18](\l)) 也称为贝尔曼方程（Bellman
> equation），表示当前状态的值函数可以通过下个状态的值函数来计算。
>
> 如果给定策略*π*(*a*\|*s*)，状态转移概率*p*(*s*^′^\|*s, a*)
> 和奖励*r*(*s, a, s*^′^)，我们就可以通过迭代的方式来计算*V
> ^π^*(*s*)。由于存在折扣率，迭代一定步数后，每个状态的值函数就会固定不变。

2.  状态**-**动作值函数

> 公式([14.18](\l)) 中的第二个期望是指初始状态为*s*
> 并进行动作*a*，然后执行策略*π*
> 得到的期望总回报，称为状态*-*动作值函数（state-action value
> function），
>
> *Q^π^*(*s, a*) = E*~s~*′∼*p*(*s*′\|*s,a*) \[*r*(*s, a, s*^′^) + *γV
> ^π^*(*s*^′^)\] *,* (14.19)
>
> 状态-动作值函数也经常称为*Q* 函数（Q-function）。
>
> 状态值函数*V ^π^*(*s*) 是Q 函数*Q^π^*(*s, a*) 关于动作*a* 的期望，
>
> *V ^π^*(*s*) = E~*a*∼*π*(*a*\|*s*)~\[*Q^π^*(*s, a*)\]*.* (14.20)
>
> 结合公式（[14.19](\l)）和（[14.20](\l)），Q 函数可以写为
>
> *Q^π^*(*s, a*) = E*~s~*′∼*p*(*s*′\|*s,a*) *r*(*s, a, s*^′^) +
> *γ*E*~a~*′∼*π*(*a*′\|*s*′)\[*Q^π^*(*s*^′^*, a*^′^)\] *,* (14.21)
>
> 这是关于Q 函数的贝尔曼方程。

3.  值函数的作用

> 值函数可以看作是对策略*π* 的评估。如果在状态*s*，有一个动作*a*
> 使得*Q^π^*(*s, a*) *\>*
>
> *V ^π^*(*s*)，说明执行动作*a* 比当前的策略*π*(*a*\|*s*)
> 要好，我们就可以调整参数使得策略*π*(*a*\|*s*) 的概率增加。

###### 深度强化学习

> 在强化学习中，一般需要建模策略 *π*(*a*\|*s*) 和值函数 *V ^π^*(*s*)*,
> Q^π^*(*s,
> a*)。早期的强化学习算法主要关注于状态和动作都是离散且有限的问题，可以使用表格来记录这些概率。但在很多实际问题中，有些任务的状态和动作的数量非常多。
> 比如围棋的棋局有3361 ≈ 10170
> 种状态，动作（即落子位置）数量为361。还有些任务的状态和动作是连续的。比如在自动驾驶中，智能体感知到的环境状态是各种传统器数据，一般都是连续的。动作是操作方向盘的方向（−90
> ∼ 90 度） 和速度控制（0 ∼ 300 公里/小时），也是连续的。
>
> 为了有效地解决这些问题，可以一个复杂的函数（比如深度神经网络）来
> 使得智能体可以感知更复杂的环境状态以及建立更复杂的策略，提高强化学习
> 算法的能力，并提高泛化能力。
>
> 深度强化学习（deep reinforcement
> learning）是将强化学习和深度学习结合在一起，用强化学习来定义问题和优化目标，用深度学习来解决策略和值函数
>
> 的建模问题，然后使用误差反向传播算法来优化目标函数。深度强化学习在一定程度上具备解决复杂问题的通用智能，并在很多任务上都取得了很大的成功。

#### 基于值函数的学习方法

> 值函数是对策略*π* 的评估，如果策略*π*
> 有限（即状态数和动作数都有限）时，
> 可以对所有的策略进行评估并选出最优策略*π*^∗^。
>
> *s, π*^∗^ = arg max *V ^π^*(*s*)*.* (14.22)
>
> *π*
>
> 但这种方式在实践中很难实现。假设状态空间S 和动作空间A
> 都是离散且有限的，策略空间为\|A\|\|S\|，往往也非常大。
>
> 一种可行的方式是通过迭代的方法不断优化策略，直到选出最优策略。对于一个策略*π*(*a*\|*s*)，其Q
> 函数为*Q^π^*(*s, a*)，我们可以设置一个新的策略*π*^′^(*a*\|*s*)，

*π*^′^(*a*\|*s*) =

> 1 if *a* = arg max~*a*ˆ~ *Q^π^*(*s, a*ˆ)
>
> *,* (14.23)
>
> 0 otherwise
>
> 即*π*^′^(*a*\|*s*) 为一个确定性的策略，也可以直接写为
>
> *π*^′^(*s*) = arg max *Q^π^*(*s, a*)*.* (14.24)
>
> *a*
>
> 参见习题[14-1](\l)。
>
> 如果执行*π*^′^，会有
>
> ∀*s, V ^π^*′ (*s*) ≥ *V ^π^*(*s*)*.* (14.25)
>
> 基于模型的强化学习，也叫做模型相关的强化学习，或有模型的强化学习。
>
> 根据公式([14.25](\l))，我们可以通过下面方式来学习最优策略：先随机初始化
> 一个策略，计算该策略的值函数，并根据值函数来设置新的策略，然后一直反
> 复迭代直到收敛。
>
> 基于值函数的策略学习方法中最关键的是如何计算策略*π*
> 的值函数，一般有动态规划或蒙特卡罗两种计算方式。

###### 动态规划算法

> 从贝尔曼方程可知，如果知道马尔可夫决策过程的状态转移概率*p*(*s*^′^\|*s,
> a*) 和奖励*r*(*s, a,
> s*^′^)，我们直接可以通过贝尔曼方程来迭代计算其值函数。这种模型已知的强化学习算法也称为基于模型的强化学习（Model-Based
> Reinforcement Learning）算法，这里的模型就是指马尔可夫决策过程。
>
> 在已知模型时，可以通过动态规划的方法来计算。常用的方法主要有策略
> 迭代算法和值迭代算法。

1.  策略迭代

> 策略迭代（Policy Iteration）算法中，每次迭代可以分为两步：

1.  策略评估（policy
    > evaluation）：计算当前策略下，每个状态的值函数，即算法[14.1](\l)中的3-6
    > 步。策略评估可以通过贝尔曼方程（公式([14.18](\l))）进行迭代计算*V
    > ^π^*(*s*)。

> 如果状态数有限时，也可以通过直接求解Bellman 方程来得到得到*V
> ^π^*(*s*)。

2.  策略改进（policy
    > improvement）：根据值函数来更新策略，即算法[14.1](\l)中的7-8 步。

> 策略迭代如算法[14.1](\l)所示。
>
> 算法 **14.1:** 策略迭代算法
>
> 输入**:** MDP 五元组：S*,* A*, P, r, γ*;
>
> **1** 初始化： *s, a, π*(*a s*) = [ 1]{.underline} ;
>
> \|A\|
>
> **2 repeat**
>
> // 策略评估
>
> **3 repeat**
>
> **4** 根据贝尔曼方程（公式([14.18](\l))），计算*V ^π^*(*s*)*,* ∀*s*;
>
> **5 until** ∀*s*，*V ^π^*(*s*) 收敛;
>
> // 策略改进
>
> **6** 根据公式([14.19](\l))，计算*Q*(*s, a*);
>
> **7** ∀*s, π*(*s*) = arg max*~a~ Q*(*s, a*);
>
> **8 until** ∀*s*，*π*(*s*) 收敛;
>
> [ ]{.underline} [输出**:** 策略*π *]{.underline}

2.  值迭代

> 策略迭代中的策略评估和策略改进是交替轮流进行，其中策略评估也是通
> 过一个内部迭代来进行计算，其计算量比较大。事实上，我们不需要每次计算
> 出每次策略对应的精确的值函数，也就是说内部迭代不需要执行到完全收敛。
>
> 值迭代（Value
> Iteration）方法将策略评估和策略改进两个过程合并，来直接计算出最优策略。
>
> 假设最优策略*π*^∗\ 对应的值函数称为最优值函数，那么最优状态值函数*V*\ ∗^(*s*)
>
> 和最优状态*-*动作值函数*Q*^∗^(*s, a*) 的关系为
>
> *V* ^∗^(*s*) = max *Q*^∗^(*s, a*)*.* (14.26)

*a*

> 参见习题[14-2](\l)。
>
> 根据贝尔曼方程可知，最优状态值函数*V* ^∗^(*s*)
> 和最优状态-动作值函数*Q*^∗^(*s, a*)
>
> 也可以进行迭代计算。
>
> *V* ^∗^(*s*) = max E*~s~*′∼*p*(*s*′\|*s,a*) *r*(*s, a, s*^′^) + *γV*
> ^∗^(*s*^′^) *,* (14.27)
>
> *Q*^∗^(*s, a*) = E*~s~*′∼*p*(*s*′\|*s,a*) *r*(*s, a, s*^′^) + *γ* max
> *Q*^∗^(*s*^′^*, a*^′^) *,* (14.28)
>
> 这两个公式称为贝尔曼最优方程（Bellman Optimality Equation）。
>
> 值迭代方法通过直接优化贝尔曼最优方程（公式([14.27](\l))），迭代计算最优
> 值函数。值迭代方法如算法[14.2](\l)所示。
>
> 算法 **14.2:** 值迭代算法
>
> 输入**:** MDP 五元组：S*,* A*, P, r, γ*;
>
> **1** 初始化：∀*s* ∈ S*, V* (*s*) = 0 ;
>
> **2 repeat**
>
> **3** ∀*s*, *V* (*s*) ← max E*~s~*′∼*p*(*s*′\|*s,a*) *r*(*s, a, s*^′^)
> + *γV* (*s*^′^) ;
>
> **4 until** ∀*s*，*V* (*s*) 收敛;
>
> **5** 根据公式([14.19](\l)) 计算*Q*(*s, a*);
>
> **6** ∀*s, π*(*s*) = arg max*~a~ Q*(*s, a*);
>
> [ ]{.underline} [输出**:** 策略*π *]{.underline}
>
> 策略迭代 **VS** 值迭代
> 在策略迭代中，每次迭代的时间复杂度最大为*O*(\|S\|3\|A\|3)，
> 最大迭代次数为\|A\|\|S\|。而在值迭代中，每次迭代的时间复杂度最大为*O*(\|S\|2\|A\|)，
> 但迭代次数要比策略迭代算法更多。
>
> 策略迭代是根据贝尔曼方程来更新值函数，并根据当前的值函数来改进策
> 略。而值迭代算法是直接使用贝尔曼最优方程来更新值函数，收敛时的值函数
> 就是最优的值函数，其对应的策略也就是最优的策略。
>
> 值迭代和策略迭代都需要经过非常多的迭代次数才能完全收敛。在实际应
> 用中，可以不必等到完全收敛。这样，当状态和动作数量有限时，经过有限次
> 迭代就可以能收敛到近似最优策略。
>
> 基于模型的强化学习算法实际上是一种动态规划方法。在实际应用中有以
> 下两点限制。
>
> 一是要求模型已知，即要给出马尔可夫决策过程的状态转移概率*p*(*s*^′^\|*s,
> a*) 和奖励函数*r*(*s, a,
> s*^′^)，这个要求很难满足。如果是事先不知道模型，但仍然希望通过基于模型的学习算法，也可以通过与环境交互来学习出状态转移概率和
> 奖励函数。一个简单的计算模型的方法为R-max \[[Brafman and
> Tennenholtz](\l),
> [2002](\l)\]，通过随机游走的方法来探索环境。每次随机一个策略并执行，然后收集
>
> 状态转移和奖励的样本。在收集一定的样本后，就可以通过统计或监督学习来重构出马尔可夫决策过程。但是，这种基于采样的重构过程的复杂度也非常高，
> 只能应用于状态数非常少的场合。
>
> 二是效率问题，当状态数量较大的时候，算法的效率比较低。但在实际应
> 用中，很多问题的状态数量和动作数量非常多。比如，围棋有19 × 19 = 361
> 个位置，每个位置有黑子、白子或无子三种状态，整个棋局有3361 ≈ 10170
> 种状态。动作（即落子位置）数量为361。不管是值迭代还是策略迭代，以当前计算
> 机的计算能力，根本无法计算。一个有效的方法是通过一个函数（比如神经网
> 络）来近似计算值函数，以减少复杂度，并提高泛化能力。

###### 蒙特卡罗方法

> 在很多应用场景中，马尔可夫决策过程的状态转移概率*p*(*s*^′^\|*s, a*)
> 和奖励函数 *r*(*s, a, s*^′^)
> 都是未知的。在这种情况下，我们一般需要智能体和环境进行交互，并收集一些样本。然后再根据这些样本来求解马尔可夫决策过程最优策略。
> 这种模型未知，基于采样的学习算法也称为模型无关的强化学习（Model-Free
> Reinforcement Learning）算法。
>
> Q 函数*Q^π^*(*s, a*) 为初始状态为*s*，并执行动作*a*
> 后的所能得到的期望总回报， 可以写为
>
> 参见第[14.2.4](\l)节。
>
> 模型无关的强化学习，也叫做无模型的强化学习。
>
> 参见公式([14.19](\l))。
>
> *Q^π^*(*s, a*) = E~*τ*∼*p*(*τ*)~\[*G*(*τ~s~*0 =*s,a*0 =*a*)\]*,*
> (14.29)
>
> 其中*τ~s~*0 =*s,a*0 =*a* 表示轨迹*τ* 的起始状态和动作为*s, a*。
>
> 如果模型未知，Q
> 函数可以通过采样来进行计算，这就是蒙特卡罗方法。对于一个策略
> *π*，智能体从状态 *s*，执行动作 *a*
> 开始，然后通过随机游走的方法来探索环境，并计算其得到的总回报。假设我们进行*N*
> 次试验，得到*N* 个轨迹*τ* ^(1)^*, τ* ^(2)^*,* · · · *, τ*
> ^(*N*)^，其总回报分别为*G*(*τ*
> ^(1))*,\ G*(*τ*\ (2))*,*\ ·\ ·\ ·\ *,\ G*(*τ*\ (*N*))。Q\ 函数可以近似为^

( ) ˆ (

> ) = [ 1]{.underline} Σ ( )
>
> (14.30)

*Q^π^ s, a*

> ≈ *Q s, a*
>
> *N n*=1
>
> (*n*)
>
> *s*0 =*s,a*0 =*a*
>
> 当*N* → ∞ 时，*Q*ˆ*π* (*s, a*) → *Q^π^*(*s, a*)。
>
> 在似估计出Q 函数*Q*ˆ*π* (*s, a*)
> 之后，就可以进行策略改进。然后在新的策略下重新通过采样来估计Q
> 函数，并不断重复，直至收敛。
>
> 利用和探索
> 但在蒙特卡罗方法中，如果采用确定性策略*π*，每次试验得到的轨迹是一样的，只能计算出*Q^π^*(*s,
> π*(*s*))，而无法计算其它动作*a*^′\ 的Q\ 函数，因此也无法进一步改进策略。这样情况仅仅是对当前策略的利用（exploitation），而^
>
> 这也可以看做是一个多臂赌
>
> 缺失了对环境的探索（exploration），即试验的轨迹尽可能覆盖所有的状态和动作，以找到更好的策略。
>
> 博机问题。 为了平衡利用和探索，我们可以采用*ϵ-*贪心法（*ϵ*-greedy
> method）。对于
>
> 一个目标策略*π*，其对应的*ϵ*-贪心法策略为

*π^ϵ^*(*s*) = 

> *π*(*s*)*,* 按概率1 − *ϵ,*
>
> (14.31)
>
> 随机选择A中的动作*,* 按概率*ϵ.*
>
> 这样，*ϵ*-贪心法将一个仅利用的策略转为带探索的策略。每次选择动作*π*(*s*)
> 的概率为1 − *ϵ* + [ 1]{.underline} ，其它动作的概率为
> [^\ 1^]{.underline} 。
>
> \|A\| \|A\|
>
> 重要性采样参见第[11.3](\l)节。
>
> 同策略
> 在蒙特卡罗方法中，如果采样策略是*π^ϵ^*(*s*)，不断改进策略也是*π^ϵ^*(*s*)
> 而不是目标策略*π*(*s*)。这种采样与改进策略相同（即都是*π^ϵ^*(*s*)）的强化学习方法叫做同策略（on
> policy）方法。
>
> 异策略
> 如果采样策略是*π^ϵ^*(*s*)，而优化目标是策略*π*，可以通过重要性采样，引入重要性权重来实现对目标策略*π*
> 的优化。这种采样与改进分别使用不同策略的强化学习方法叫做异策略（oﬀ
> policy）方法。

###### 时序差分学习方法

> 蒙特卡罗采样方法一般需要拿到完整的轨迹，才能对策略进行评估并更新
> 模型，因此效率也比较低。
>
> 时序差分学习（temporal-diﬀerence
> learning）结合了动态规划和蒙特卡罗方法，比仅仅使用蒙特卡罗采样方法的效率要高很多\[[Sutton
> and Barto](\l),
> [2018](\l)\]。时序差分学习是模拟一段轨迹，每行动一步(或者几步)，就利用贝尔曼方程来评估行动前状态的价值。当时序差分学习中每次更新的动作数为最大步数时，就等价于蒙特卡罗方法。
>
> 首先，将蒙特卡罗方法中Q 函数*Q*ˆ*π* (*s, a*)
> 的估计改为增量计算的方式，假设第*N* 次试验后值函数*Q*ˆ*π* (*s, a*)
> 的平均为

*Q*ˆ*π* (*s, a*) = [ 1]{.underline}

> Σ *G*(*τ* (*n*)
>
> ) (14.32)

*N*

*n*=1

> *s*0 =*s,a*0 =*a*
>
> *N* −1
>
> = [ 1]{.underline} (*G*(*τ* ^(*N*)^ ) + Σ *G*(*τ* ^(*n*)^ )) (14.33)
>
> = [ 1]{.underline} *G*(*τ* ^(*N*)^ [ ]{.underline} ) + (*N* −
> 1)*Q*ˆ*π* (*s, a*) (14.34)

*N*

= *Q*ˆ*π*

> *s*0 =*s,a*0 =*a*
>
> (*s, a*) + 1 *G*(*τ* ^(*N*)^
>
> *N* −1
>
> ) − *Q*ˆ*π*
>
> (*s, a*) *,* (14.35)
>
> 其中*τ~s~*0 =*s,a*0 =*a* 表示轨迹*τ* 的起始状态和动作为*s, a*。
>
> 值函数*Q*ˆ*π* (*s, a*) 在第*N* 试验后的平均等于第*N* − 1
> 试验后的平均加上一个增量。更一般性地，我们将权重系数
> [^\ 1^]{.underline} 改为一个比较小的正数 。这样每次采

*N*

> 用一个新的轨迹*τ~s~*0 =*s,a*0 =*a*，就可以更新*Q*ˆ*π* (*s, a*)。

*Q*ˆ*π* (*s, a*) ← *Q*ˆ*π* (*s, a*) + *α* *G*(*τ~s~*0 =*s,a*0 =*a*) −
*Q*ˆ*π* (*s, a*) *,* (14.36)

> 其中增量*δ* , *G*(*τ~s~*0 =*s,a*0 =*a*) − *Q*ˆ*π* (*s, a*)
> 称为蒙特卡罗误差，表示当前轨迹的真实回报 *G*(*τ~s~*0 =*s,a*0 =*a*)
> 与期望回报*Q*ˆ*π* (*s, a*) 之间的差距。
>
> 在公式（[14.36](\l)）中，*G*(*τ~s~*0 =*s,a*0 =*a*)
> 为一次试验的完整轨迹所得到的总回报。为了提高效率，可以借助动态规划的方法来计算*G*(*τ~s~*0
> =*s,a*0 =*a*)，而不需要得到完整的轨迹。从*s, a*
> 开始，采样下一步的状态和动作(*s*^′^*, a*^′^)，并得到奖励*r*(*s, a,
> s*^′^)， 然后利用贝尔曼方程来近似估计*G*(*τ~s~*0 =*s,a*0 =*a*)，

*G*(*τ~s~*0 =*s,a*0 =*a,s*1=*s*′*,a*1=*a*′ ) = *r*(*s, a, s*^′^) +
*γG*(*τ~s~*0 =*s*′*,a*0 =*a*′ ) (14.37)

÷ *r*(*s, a, s*^′^) + *γQ*ˆ*π* (*s*^′^*, a*^′^)*,* (14.38)

> 其中*Q*ˆ*π* (*s*^′^*, a*^′^) 是当前的Q 函数的近似估计。
>
> 贝 尔 曼 方 程 参 见 公 式
>
> ([14.21](\l))。
>
> 参见习题[14-3](\l)。
>
> 结合公式([14.36](\l)) 和([14.38](\l))，有
>
> *Q*ˆ*π* (*s, a*) ← *Q*ˆ*π* (*s, a*) + *α* *r*(*s, a, s*^′^) + *γQ*ˆ*π*
> (*s*^′^*, a*^′^) − *Q*ˆ*π* (*s, a*) *,* (14.39)
>
> 因此，更新*Q*ˆ*π* (*s, a*) 只需要知道当前状态*s*
> 和动作*a*、奖励*r*(*s, a,
> s*^′^)、下一步的状态*s*^′\ 和动作*a*′^。这种策略学习方法称为*SARSA*
> 算法（State Action Reward State Action，SARSA）\[[Rummery and
> Niranjan](\l), [1994](\l)\]。
>
> SARSA
> 算法[14.3](\l)所示，其采样和优化的策略都是*π^ϵ^*，因此是一种同策略算法。为了提高计算效率，我们不需要对环境中所有的*s,
> a* 组合进行穷举，并计算值函数。只需要将当前的探索(*s, a, r, s*^′^*,
> a*^′^) 中*s*^′^*, a*^′\ 作为下一次估计的起始状态^
>
> 和动作。
>
> 算法 **14.3:** SARSA：一种同策略的时序差分学习算法
>
> 输入**:** 状态空间S，动作空间A，折扣率*γ*，学习率*α*
>
> **1** 随机初始化*Q*(*s, a*);

**2** *s, a, π*(*a s*) = [ 1]{.underline} ;

> \|A\|
>
> **3 repeat**
>
> **4** 初始化起始状态*s*;
>
> **5** 选择动作*a* = *π^ϵ^*(*s*);
>
> **6 repeat**
>
> **7** 执行动作*a*，得到即时奖励*r* 和新状态*s*^′^;
>
> **8** 在状态*s*^′^，选择动作*a*^′\ =\ *πϵ*^(*s*^′^);
>
> **9** *Q*(*s, a*) ← *Q*(*s, a*) + *α r* + *γQ*(*s*^𝘫^*, a*^𝘫^) −
> *Q*(*s, a*) ;
>
> **10** 更新策略：*π*(*s*) = arg max~*a*∈\|A\|~ *Q*(*s, a*);
>
> **11** *s* ← *s*^′^*, a* ← *a*^′^;
>
> **12 until** *s* 为终止状态;
>
> **13 until** ∀*s, a*，*Q*(*s, a*) 收敛;
>
> 输出**:** 策略*π*(*s*)
>
> 多巴胺是一种神经传导物质，
>
> 时序差分学习是强化学习的主要学习方法，其关键步骤就是在每次迭代中优化Q
> 函数来减少现实 *r* + *γQ*(*s*^′^*, a*^′^) 和预期 *Q*(*s, a*)
> 的差距。这和动物学习的机制十分相像。在大脑神经元中，多巴胺的释放机制和时序差分学习十分吻合。[Schultz](\l)
> \[[1998](\l)\]
> 的一个实验中，通过监测猴子大脑释放的多巴胺浓度，发现如果猴子获得比预期更多的果汁，或者在没有预想到的时间喝到果汁,
> 多巴胺释放大增。如果本来预期的果汁没有喝到，多巴胺的释放就会大减。多巴胺的释放,
> 来自对于实际奖励和预期奖励的差异，而不是奖励本身。
>
> 传递开心、兴奋有关的信息。
> 时序差分学习和蒙特卡罗方法的主要不同为：蒙特卡罗需要完整一个路径完成才能知道其总回报，也不依赖马尔可夫性质；而时序差分学习只需要一步，
> 其总回报需要依赖马尔可夫性质来进行近似估计。

1.  **Q** 学习

> *Q* 学习（Q-Learning）算法\[[Watkins and Dayan](\l), [1992](\l)\]
> 是一种异策略的时序差分学习算法。在Q 学习中，Q 函数的估计方法为
>
> 事实上，Q 学习算法被提出
>
> 的时间更早，SARSA 算法是
>
> Q 学习算法的改进。
>
> *Q*(*s, a*) ← *Q*(*s, a*) + *α r* + *γ* max *Q*(*s*^′^*, a*^′^) −
> *Q*(*s, a*) *,* (14.40)
>
> 相当于让*Q*(*s, a*) 直接去估计最优状态值函数*Q*^∗^(*s, a*)。
>
> 与SARSA 算法的不同，Q 学习算法不通过*π^ϵ^*
> 来选下一步的动作*a*^′^，而是直接选最优的Q 函数，因此更新后的Q
> 函数是关于策略*π* 的，而不是策略*π^ϵ^* 的。
>
> Q 学习算法[14.4](\l)所示。
>
> 算法 **14.4:** Q 学习：一种异策略的时序差分学习算法
>
> 输入**:** 状态空间S，动作空间A，折扣率*γ*，学习率*α*
>
> **1** 随机初始化*Q*(*s, a*);
>
> **2** *s, a, π*(*a s*) = [ 1]{.underline} ;
>
> \|A\|
>
> **3 repeat**
>
> **4** 初始化起始状态*s*;
>
> **5 repeat**
>
> **6** 在状态*s*，选择动作*a* = *π^ϵ^*(*s*);
>
> **7** 执行动作*a*，得到即时奖励*r* 和新状态*s*^′^;
>
> **8** *Q*(*s, a*) ← *Q*(*s, a*) + *α r* + *γ* max~a~′ *Q*(*s*^𝘫^*,
> a*^𝘫^) − *Q*(*s, a*) ;
>
> **9** *s* ← *s*^′^;
>
> **10 until** *s* 为终止状态;
>
> **11 until** ∀*s, a*，*Q*(*s, a*) 收敛;
>
> [ 输出**:** 策略*π*(*s*) = arg max*~a~*]{.underline}[~∈\|A\|~ *Q*(*s,
> a*) ]{.underline}

4.  深度**Q** 网络

> 为了在连续的状态和动作空间中计算值函数 *Q^π^*(*s,
> a*)，我们可以用一个函 数*Q~ϕ~*(**s***,* **a**)
> 来表示近似计算，称为值函数近似（value function approximation）
>
> 。
>
> *Q~ϕ~*(**s***,* **a**) ≈ *Q^π^*(*s, a*)*,* (14.41)
>
> 其中**s***,* **a** 分别是状态*s* 和动作*a*
> 的向量表示；函数*Q~ϕ~*(**s***,* **a**) 通常是一个参数为*ϕ*
>
> 的函数，比如神经网络，输出为一个实数，称为*Q* 网络（Q-network）。
>
> 如果动作为有限离散的*m* 个动作*a*~1~*,* · · · *, a~m~*，我们可以让Q
> 网络输出一个
>
> *m* 维向量，其中每一维用*Q~ϕ~*(**s***, a~i~*)
> 来表示，对应值函数*Q*(*s, a~i~*) 的近似值。

*Q~ϕ~*(**s***, a*~1~)  *Q^π^*(*s, a*~1~) 

*Q~ϕ~*(**s***, a~m~*) *Q^π^*(*s, a~m~*)

> 我们需要学习一个参数*ϕ* 来使得函数*Q~ϕ~*(**s***,* **a**)
> 可以逼近值函数*Q^π^*(*s,
> a*)。如果采用蒙特卡罗方法，就直接让*Q~ϕ~*(**s***,* **a**)
> 去逼近平均的总回报*Q*ˆ*π* (*s,
> a*)；如果采样时序差分方法，就让*Q~ϕ~*(**s***,* **a**)
> 去逼近E**~s~**′*,***a**′ \[*r* + *γQ~ϕ~*(**s**′*,* **a**′)\]。
>
> 以*Q* 学习为例，采用随机梯度下降，目标函数为

( ) = +

> max
>
> (**s a** )
>
> (**s a**) 2
>
> (14.43)
>
> 经验回放可以形象地理解为
>
> 其中**s**′*,* **a**′ 是下一时刻的状态*s*^′\ 和动作*a*′\ 的向量表示。^
>
> 然而，这个目标函数存在两个问题：一是目标不稳定，参数学习的目标依赖
> 于参数本身；二是样本之间有很强的相关性。为了解决这两个问题，[Mnih et
> al.](\l) \[[2015](\l)\] 提出了一种深度*Q* 网络（deep
> Q-networks，DQN）。深度Q 网络采取两个措施：一是目标网络冻结（freezing
> target
> networks），即在一个时间段内固定目标中的参数，来稳定学习目标；二是经验回放（experience
> replay），构建
>
> 在回忆中学习。
> 一个经验池来去除数据相关性。经验池是由智能体最近的经历组成的数据集。
>
> 训练时，随机从经验池中抽取样本来来代替当前的样本用来进行训练。这样，也可以就打破了和相邻训练样本的相似性，避免模型陷入局部最优。经验回放在一定程度上类似于监督学习。先收集样本，然后在这些样本上进行训练。
> 深度Q 网络的学习过程如算法[14.5](\l)所示。
>
> 算法 **14.5:** 带经验回放的深度Q 网络
>
> 输入**:** 状态空间S，动作空间A，折扣率*γ*，学习率*α*
>
> **1** 初始化经验池D，容量为*N* ;
>
> **2** 随机初始化*Q* 网络的参数*ϕ*;
>
> **3** 随机初始化目标*Q* 网络的参数*ϕ*ˆ = *ϕ*;
>
> **4 repeat**
>
> **5** 初始化起始状态*s*;
>
> **6 repeat**
>
> **7** 在状态*s*，选择动作*a* = *π^ϵ^*;
>
> **8** 执行动作*a*，观测环境，得到即时奖励*r* 和新的状态*s*^′^;
>
> **9** 将*s, a, r, s*^′\ 放入D\ 中;^
>
> **10** 从D 中采样*ss, aa, rr, ss*^′^;

**11** *y* = 

> *rr, ss*^𝘫^为终止状态*,* ;
>
> **12** 以 *y* − *Q~ϕ~*
>
> **13** *s* ← *s*^′^;

(**ss***,* **aa**) 2 为损失函数来训练*Q* 网络;

> ˆ
>
> **14** 每隔*C* 步，*ϕ* ← *ϕ*;
>
> **15 until** *s* 为终止状态;
>
> **16 until** ∀*s, a*，*Q~ϕ~*(**s***,* **a**) 收敛;
>
> 输出**:** *Q* 网络*Q~ϕ~*(**s***,* **a**)
>
> 整体上，在基于值函数的学习方法中，策略一般为确定性的策略。策略优
>
> 化通常都依赖于值函数，比如贪心策略 *π*(*s*) = arg max*~a~ Q*(*s,
> a*)。最优策略一般需要遍历当前状态s 下的所有动作，并找出最优的*Q*(*s,
> a*)。如果动作空间离散但是很大时，那么遍历求最大需要很高的时间复杂度；如果动作空间是连续
> 的并且*Q*(*s, a*) 非凸时，也很难求解出最佳的策略。

#### 基于策略函数的学习方法

> 强化学习的目标是学习到一个策略*π~θ~*(*a*\|*s*)
> 来最大化期望回报。一种直接的方法是在策略空间直接搜索来得到最佳策略，称为策略搜索（policy
> search）。策略搜索本质是一个优化问题，可以分为基于梯度的优化和无梯度优化。策略搜索和基于值函数的方法相比，策略搜索可以不需要值函数，直接优化策略。参数化的策略能够处理连续状态和动作，可以直接学出随机性策略。
>
> 策略梯度（policy
> gradient）是一种基于梯度的强化学习方法。假设*π~θ~*(*a*\|*s*)
>
> 是一个关于 *θ* 的连续可微函数，我们可以用梯度上升的方法来优化参数 *θ*
> 使得
>
> 目标函数J (*θ*) 最大。 目 标 函 数 J (*θ*) 参 见 公 式
>
> 目标函数J (*θ*) 关于策略参数*θ* 的导数为
>
> [*∂*J]{.underline} [(*θ*)]{.underline} = [* ∂ *]{.underline} ∫ *p*
> (*τ* )*G*(*τ* )*dτ* (14.44)
>
> ([14.11](\l))。
>
> = ∫ [* ∂ *]{.underline}*p* (*τ* ) *G*(*τ* )*dτ* (14.45)
>
> = ∫ *p* (*τ* ) [ 1 *∂ *]{.underline}*p* (*τ* ) *G*(*τ* )*dτ* (14.46)
>
> = ∫ *p* (*τ* ) [* ∂ *]{.underline} log *p* (*τ* ) *G*(*τ* )*dτ*
> (14.47)
>
> = E *[∂]{.underline}* log *p* (*τ* )*G*(*τ* ) *,* (14.48)
>
> 其中 [*^\ ∂^*]{.underline} ^log\ *p*^*~θ~*(*τ* ) 为函数log *p~θ~*(*τ*
> ) 关于*θ* 的偏导数。从公式([14.48](\l)) 中可以看出， 参数*θ*
> 优化的方向是使得总回报*G*(*τ* ) 越大的轨迹*τ* 的概率*p~θ~*(*τ* )
> 也越大。
>
> [* ∂*]{.underline} log *p~θ~*(*τ* ) 可以进一步分解为

[* ∂*]{.underline} log

> ( ) = [* ∂ *]{.underline} log (
>
> *T* −1
>
> ) ( ) (
>
> )! (14.49)

= [* ∂*]{.underline} log

> *∂θ*
>
> *T* −1

*p*(*s*~0~

> *T* −1

) + log

> *t*=0

*π~θ~*(*a~t~*\|*s~t~*

) + log

*p*(*s~t~*~+1~\|*s~t~, a~t~*

)! (14.50)

> = Σ [* ∂*]{.underline} log *π* (*a* \|*s* )*.* (14.51)
>
> 可以看出， [*^\ ∂^*]{.underline} ^log\ *p*^*~θ~*(*τ* )
> 是和状态转移概率无关，只和策略函数相关。
>
> 因此，策略梯度 *^[∂]{.underline}^* ^[(*θ*)]{.underline}^ 可写为
>
> *∂θ*
>
> T −1
>
> *G*(*τ* ) = *γ*^t^*r*~t+1~
>
> [*∂*J]{.underline} [(*θ*)]{.underline} =
>
> *∂θ*
>
> E*τ* ∼*p~θ~*(*τ* )
>
> *T* −1 [* ∂ *]{.underline} log
>
> *t*=0

*π~θ~*(*a~t~*\|*s~t~*)!

*G*(*τ* )\#

> (14.52)

t=0

> = \" *T*Σ−1 [ ]{.underline}

log *π* (*a* \|*s* )!

*G*(*τ*

> ) + *γ^t^G*(*τ*
>
> ) \#
>
> (14.53)

*τ* ∼*p~θ~*(*τ* )

> *t*=0 *∂θ*
>
> *θ t t*
>
> 0:*t*−1
>
> *t*:*T*
>
> = \"*T*Σ−1 [* ∂ *]{.underline} log (
>
> ) ( ) \#
>
> (14.54)
>
> 其中*G*(*τ~t~*~:*T*~ ) 为从时刻*t* 作为起始时刻收到总回报
>
> *T* −1
>
> *G*(*τ~t~*~:*T*~ ) = *γ* ^−^ *r~t~*′+1*.* (14.55)
>
> *t*′=*t*

##### REINFORCE 算法

> 公式([14.54](\l))
> 中，期望可以通过采样的方法来近似。对当前策略*π~θ~*，可以随机
>
> 游走采集多个轨迹*τ* ^(1)^*, τ* ^(2)^*,* · · · *, τ*
> ^(*N*)^，每一条轨迹*τ* ^(*n*)^ =
>
> (*n*)*, a*(*n*)*, s*(*n*)*, a*(*n*)*,* · · · *,*，

其梯度定义为

[*∂*J]{.underline} [(*θ*)]{.underline}

> [1]{.underline} Σ
>
> *T*Σ−1 [ *∂ *]{.underline}
>
> ( ) ( )
>
> *s*0 0 1 1
>
> !
>
> 结合随机梯度上升算法，我们可以每次采集一条轨迹，计算每个时刻的梯
> 度并更新参数，称为*REINFORCE* 算法\[[Williams](\l),
> [1992](\l)\]，如算法[14.6](\l)所示。
>
> 算法 **14.6:** REINFORCE 算法
>
> 输入**:**
> 状态空间S，动作空间A，可微分的策略函数*π~θ~*(*a*\|*s*)，折扣率

*γ*，学习率*α*;

**1** 随机初始化参数*θ*;

> **2 repeat**
>
> **3** 根据策略*π~θ~*(*a*\|*s*) 生成一条轨迹
>
> *τ* = *s*~0~*, a*~0~*, s*~1~*, a*~1~*,* · · · *, s~T~* ~−1~*, a~T~*
> ~−1~*, s~T~* ;
>
> **4 for** *t=0* **to** *T* **do**
>
> **5** 计算*G*(*τ~t~*~:*T*~ );
>
> // 更新策略函数参数
>
> **6** *θ* ← *θ* + *αγ^t^G*(*τ~t~*~:*T*~ ) [* ∂ *]{.underline} log
> *π~θ~*(*a~t~*\|*s~t~*);
>
> **7 end**
>
> **8 until** *θ* 收敛;
>
> [ 输出]{.underline}[**:** 策略*π~θ~ *]{.underline}

2.  带基准线的**REINFORCE** 算法

> REINFORCE
> 算法的一个主要缺点是不同路径之间的方差很大，导致训练不稳定，这是在高维空间中使用蒙特卡罗方法的的通病。一种减少方差的通用
> 方法是引入一个控制变量。假设要估计函数*f* 的期望，为了减少*f*
> 的方差，我们引入一个已知期望的函数*g*，令

*f*ˆ = *f* − *α*(*g* − E\[*g*\])*.* (14.57)

> 因为E\[*f*ˆ\] = E\[*f* \]，我们可以用*f*ˆ的期望来估计函数*f*
> 的期望，同时利用函数*g*
>
> 来减小*f*ˆ的方差。函数*f*ˆ的方差为

var(*f*ˆ) = var(*f* ) − 2*α* cov(*f, g*) + *α*^2^ var(*g*)*,* (14.58)

> 其中var(·)*,* cov(·*,* ·) 分别表示方差和协方差。
>
> 如果要使得var(*f*ˆ) 最小，令 [^*∂*\ var(*f*^ˆ)]{.underline} = 0，得到
>
> cov(*f, g*)

因此，

> *α* = var(*g*) *.* (14.59)

var(*f*ˆ) = 1

> cov(*f, g*)2
>
> − var(*g*) var(*f* )

var(*f*

) (14.60)

> = 1 − corr(*f, g*)2 var(*f* )*,* (14.61)
>
> 其中corr(*f, g*) 为函数*f* 和*g* 的相关性。如果相关性越高，则*f*
> 的方差越小。
>
> 带基准线的 **REINFORCE** 算法 在每个时刻*t*，其策略梯度为

[*∂*J*~t~*(*θ*)]{.underline} = E E

> *γ^t^G*(*τ*
>
> ) [* ∂*]{.underline} log *π* (*a* \|*s* ) *.* (14.62)
>
> 为了减小策略梯度的方差，我们引入一个和*a~t~*
> 无关的基准函数*b*(*s~t~*)，
>
> *∂*Jˆ*t*(*θ*) = E E
>
> *γ^t^ G*(*τ*
>
> ) − *b*(*s* ) [* ∂*]{.underline} log *π* (*a* \|*s* ) *.* (14.63)
>
> 因为*b*(*s~t~*) 和*a~t~* 无关，有

E *b*(*s* ) [* ∂*]{.underline} log *π* (*a* \|*s* ) = ∫

= ∫

> *b*(*s* ) [* ∂*]{.underline} log *π* (*a* \|*s* ) *π* (*a* \|*s* )*da
> b*(*s* ) *π* (*a* \|*s* ))*da*
>
> (14.64)
>
> (14.65)
>
> = [* ∂ *]{.underline}*b*(*s* ) ∫ *π* (*a* \|*s* ))*da*
>
> = [* ∂*]{.underline} *b*(*s* ) · 1 = 0*.*

(14.66)

(14.67)

> ∫ *π*~θ~(*a*~t~\|*s*~t~)*da*~t~ = 1
>
> 因此， *∂*Jˆ*t*(*θ*) = [*∂*J*~t~*(*θ*)]{.underline}。

*∂θ ∂θ*

> 为了可以有效地减小方差，*b*(*s~t~*) 和*G*(*τ~t~*~:*T*~ )
> 越相关越好，一个很自然的选择是令*b*(*s~t~*) 为值函数*V ^π^θ*
> (*s~t~*)。但是由于值函数未知，我们可以用一个可学习的函数*V~ϕ~*(*s~t~*)
> 来近似值函数，目标函数为
>
> L(*ϕ*\|*s , π* ) = *V ^π^θ* (*s* ) − *V* (*s* ) *,* (14.68)

2

> *t θ t ϕ t*
>
> 其中*V ^π^θ* (*s~t~*) = E\[*G*(*τ~t~*~:*T*~ )\]
> 也用蒙特卡罗方法进行估计。采用随机梯度下降法，参数*ϕ* 的梯度为

[*∂*L(*ϕ*\|*s~t~, π~θ~*)]{.underline} = − *G*(*τ*

> ) − *V*
>
> (*s* ) [*∂Vϕ*(*st*)]{.underline} *.* (14.69)
>
> 策略函数参数*θ* 的梯度为

*∂*Jˆ*t*(*θ*) = E E

> *γ^t^ G*(*τ*
>
> ) − *V*
>
> (*s* ) [* ∂*]{.underline} log *π* (*a* \|*s* ) *.* (14.70)
>
> 算法[14.7](\l)给出了带基准线的REINFORCE 算法的训练过程。
>
> 算法 **14.7:** 带基准线的REINFORCE 算法
>
> 输入**:**
> 状态空间S，动作空间A，可微分的策略函数*π~θ~*(*a*\|*s*)，可微分的状态值函数*V~ϕ~*(*s*)，折扣率*γ*，学习率*α*，*β*;
>
> **1** 随机初始化参数*θ*,*ϕ*;
>
> **2 repeat**
>
> **3** 根据策略*π~θ~*(*a*\|*s*) 生成一条轨迹
>
> *τ* = *s*~0~*, a*~0~*, s*~1~*, a*~1~*,* · · · *, s~T~* ~−1~*, a~T~*
> ~−1~*, s~T~* ;
>
> **4 for** *t=0* **to** *T* **do**
>
> **5** 计算*G*(*τ~t~*~:*T*~ );
>
> **6** *δ* ← *G*(*τ~t~*~:*T*~ ) − *V~ϕ~*(*s~t~*);
>
> // 更新值函数参数
>
> **7** *ϕ* ← *ϕ* + *βδ [^\ ∂^]{.underline} V~ϕ~*(*s~t~*);
>
> // 更新策略函数参数
>
> **8** *θ* ← *θ* + *αγ^t^δ [^\ ∂^]{.underline}* log
> *π~θ~*(*a~t~*\|*s~t~*);
>
> **9 end**
>
> **10 until** *θ* 收敛;
>
> [ 输出]{.underline}[**:** 策略*π~θ~ *]{.underline}

4.  **Actor-Critic** 算法

> 在REINFORCE
> 算法中，每次需要根据一个策略采集一条完整的轨迹，并计算这条轨迹上的回报。这种采样方式的方差比较大，学习效率也比较低。我

4.  Actor-Critic 算法 2019 年 4 月 6 日 357

> 们可以借鉴时序差分学习的思想，使用动态规划方法来提高采样的效率，即从
> 状态开始*s* 的总回报可以通过当前动作的即时奖励*r*(*s, a, s*^′^)
> 和下一个状态*s*^′\ 的值函数来近似估计。^
>
> 演员*-*评论员算法（Actor-Critic
> Algorithm）是一种结合策略梯度和时序差分学习的强化学习方法。其中演员（actor）是指策略函数*π~θ~*(*s,
> a*)，即学习一个策略来得到尽量高的回报，评论员（critic）是指值函数*V~ϕ~*(*s*)，对当前策略的值函数进行估计，即评估actor
> 的好坏。借助于值函数，Actor-Critic
> 算法可以进行单步更新参数，不需要等到回合结束才进行更新。
>
> 在Actor-Critic 算法中的策略函数*π~θ~*(*s, a*) 和值函数*V~ϕ~*(*s*)
> 都是待学习的函数，需要在训练过程中同时学习。
>
> 假设从时刻*t* 开始的回报*G*(*τ~t~*~:*T*~ )，我们用下面公式近似计算。
>
> 参见第[14.2.3](\l)节。
>
> *G*ˆ(*τ~t~*~:*T*~ ) = *r~t~*~+1~ + *γV~ϕ~*(*s~t~*~+1~)*,* (14.71)
>
> 其中*s~t~*~+1~ 是*t* + 1 时刻的状态，*r~t~*~+1~ 是即时奖励。
>
> 在每步更新中，分别进行策略函数*π~θ~*(*s, a*) 和值函数*V~ϕ~*(*s*)
> 的学习。一方面， 更新参数*ϕ* 使得值函数*V~ϕ~*(*s~t~*)
> 接近于估计的真实回报*G*ˆ(*τ~t~*~:*T*~ )，

min ˆ( )

> ( ) 2
>
> (14.72)
>
> 另一方面，将值函数*V~ϕ~*(*s~t~*)
> 作为基函数来更新参数*θ*，减少策略梯度的方差。
>
> *θ* ← *θ* + *αγ^t^* *G*ˆ(*τ*
>
> ) − *V*
>
> (*s* ) [* ∂*]{.underline} log *π* (*a* \|*s* )*.* (14.73)
>
> 在每步更新中，演员根据当前的环境状态*s* 和策略*π~θ~*(*a*\|*s*)
> 去执行动作*a*，环境状态变为*s*^′^，并得到即时奖励*r*。评论员（值函数*V~ϕ~*(*s*)）根据环境给出的真
> 实奖励和之前标准下的打分(*r* +
> *γV~ϕ~*(*s*^′^))，来调整自己的打分标准，使得自己的评分更接近环境的真实回报。演员则跟据评论员的打分，调整自己的策略*π~θ~*，
> 争取下次做得更好。开始训练时，演员随机表演，评论员随机打分。通过不断的学习，评论员的评分越来越准，演员的动作越来越好。
>
> 算法[14.8](\l)给出了actor-critic 算法的训练过程。
>
> 算法 **14.8:** actor-critic 算法
>
> 输入**:** 状态空间S，动作空间A; 可微分的策略函数*π~θ~*(*a*\|*s*);
>
> 可微分的状态值函数*V~ϕ~*(*s*);
>
> 折扣率*γ*，学习率*α \>* 0,*β \>* 0;
>
> **1** 随机初始化参数*θ*,*ϕ*;
>
> **2 repeat**
>
> **3** 初始化起始状态*s*;
>
> **4** *λ* = 1;
>
> **5 repeat**
>
> **6** 在状态*s*，选择动作*a* = *π~θ~*(*a*\|*s*);
>
> **7** 执行动作*a*，得到即时奖励*r* 和新状态*s*^′^;
>
> **8** *δ* ← *r* + *γV~ϕ~*(*s*^′^) − *V~ϕ~*(*s*);
>
> **9** *ϕ* ← *ϕ* + *βδ [^\ ∂^]{.underline} V~ϕ~*(*s*);
>
> **10** *θ* ← *θ* + *αλδ [^\ ∂^]{.underline}* log *π~θ~*(*a*\|*s*);
>
> **11** *λ* ← *γλ*;
>
> **12** *s* ← *s*^′^;
>
> **13 until** *s* 为终止状态;
>
> **14 until** *θ* 收敛;
>
> [ 输出]{.underline}[**:** 策略*π~θ~ *]{.underline}
>
> 虽然在带基准线的REINFORCE
> 算法也同时学习策略函数和值函数，但是它并不是一种Actor-Critic
> 算法。因为其中值函数只是用作基线函数以减少方差，并不用来估计回报（即评论员的角色）。

#### 总结和深入阅读

> 强化学习是一种十分吸引人的机器学习方法，通过智能体不断与环境进行
> 交互，并根据经验调整其策略来最大化其长远的所有奖励的累积值。强化学习
> 更接近生物学习的本质，可以应对多种复杂的场景，而从更接近通用人工智能
> 系统的目标。
>
> 强化学习和监督学习的区别在于：（1）强化学习的样本通过不同与环境进行交互产生，即试错学习，而监督学习的样本由人工收集并标注；（2）强化学习的反馈信息只有奖励，并且是延迟的；而监督学习需要明确的指导信息（每
> 一个状态对应的动作）。
>
> 现代强化学习可以追溯到两个来源：一个是心理学中的行为主义理论，即
>
> 有机体如何在环境给予的奖励或惩罚的刺激下，逐步形成对刺激的预期，产生
> 能获得最大利益的习惯性行为；另一个是控制论领域的最优控制问题，即在满
> 足一定约束条件下，寻求最优控制策略，使得性能指标取极大值或极小值。
>
> 强化学习的算法非常多，大体上可以分为基于值函数的方法（包括动态规
> 划、时序差分学习等）、基于策略函数的方法（包括策略梯度等）以及融合两者
> 的方法。不同算法之间的关系如图[14.4](\l)所示。
>
> 图 14.4 不同强化学习算法之间的关系
>
> 一般而言，基于值函数的方法策略更新时可能会导致值函数的改变比较大，
> 对收敛性有一定影响，而基于策略函数的方法在策略更新时更加更平稳些。但后者因为策略函数的解空间比较大，难以进行充分的采样，导致方差较大，并容易收敛到局部最优解。Actor-Critic
> 算法通过融合两种方法，取长补短，有着更好的收敛性。
>
> 这些不同的强化学习算法的优化步骤都可以分为三步：（1）执行策略，生成样本；（2）估计回报；（3）更新策略。表[14.1](\l)给出了四种典型的强化学习算法
>
> （SARSA、Q 学习、REINFORCE、Actor-Critic 算法）的比较。
>
> 强化学习的主要参考文献为[Sutton and Barto](\l) \[[2018](\l)\]
> 的《Reinforcement Learning: An Antroduction》。
>
> 和深度强化学习方面，DeepMind 的\[[Mnih et al.](\l), [2015](\l)\]
> 在2013 年提出了第一个强化学习和深度学习结合的模型，深度 *Q*
> 网络（DQN）。虽然DQN
> 模型相对比较简单，只是面向有限的动作空间，但依然在Atari
> 游戏上取了很大的成功，取得了超越人类水平的成绩。之后，深度强化学习开始快速发展。一些基于DQN
> 的改进包括双Q 网络\[[Van Hasselt et al.](\l),
> [2016](\l)\]、优先级经验回放\[[Schaul](\l)
>
> 算法 步骤
>
> （1）执行策略，生成样本：*s, a, r, s*^𝘫^*, a*^𝘫^
>
> SARSA
>
> Q 学习
>
> （2）估计回报：*Q*(*s, a*) ← *Q*(*s, a*) + *α r* + *γQ*(*s*^𝘫^*,
> a*^𝘫^) − *Q*(*s, a*)
>
> （3）更新策略：*π*(*s*) = arg max~a∈\|𝖰\|~ *Q*(*s, a*)

1.  执行策略，生成样本：*s, a, r, s*^𝘫^

2.  估计回报：*Q*(*s, a*) ← *Q*(*s, a*) + *α r* + *γ* max~a~′
    > *Q*(*s*^𝘫^*, a*^𝘫^) − *Q*(*s, a*)

> （3）更新策略：*π*(*s*) = arg max~a∈\|𝖰\|~ *Q*(*s, a*)
>
> （1）执行策略，生成样本：*τ* = *s*0*, a*0*, s*1*, a*1*,* · · ·
>
> T −1
>
> REINFORCE（2）估计回报：*G*(*τ* ) = Σ *r*t+1 [ ]{.underline}

3.  更新策略：*θ* ← *θ* + ΣT −1 ∂ log
    > *π*~θ~(*a*~t~\|*s*~t~)*γ*^t^*G*(*τ*~t:T~ )

Actor-Critic

> （1）执行策略，生成样本：*s, a, s*^𝘫^*, r*
>
> （2）估计回报：*G*(*s*) = *r* + *γV*~ϕ~(*s*^𝘫^)
>
> *ϕ* ← *ϕ* + *β G*(*s*) − *V*~ϕ~(*s*) [ ∂]{.underline} *V*~ϕ~(*s*)
>
> （3）更新策略：*λ* ← *γλ*
>
> *θ* ← *θ* + *αλ G*(*s*) − *V*~ϕ~(*s*) [ ∂]{.underline} log
> *π*~θ~(*a*\|*s*)
>
> 表 14.1 四种强化学习算法的比较
>
> et al., [2015](\l)\]、决斗网络\[[Wang et al.](\l), [2015](\l)\] 等。
>
> 目前，深度强化学习更多是同时使用策略网络和值网络来近似策略函数和值函数。在actor-critic
> 算法的基础上，[Silver et al.](\l) \[[2014](\l)\]
> 将策略梯度的思想推广到确定性的策略上，提出了确定性策略梯度（Deterministic
> Policy Gradient， DPG）算法。策略函数为状态到动作的映射 *a* =
> *π~θ~*(*s*)。采用确定性策略的一个好处是方差会变得很小，提高收敛性。确定性策略的缺点是对环境的探索不足，可以通过异策略的方法解决。[Lillicrap
> et al.](\l) \[[2015](\l)\] 进一步在DPG 算法的基础上，利用DQN
> 来估计值函数，提出深度确定性策略梯度（Deep Determin- istic Policy
> Gradient，DDPG）算法。DDPG 算法可以适合连续的状态和动作空间。[Mnih et
> al.](\l) \[[2016](\l)\]
> 利用分布式计算的思想提出了异步优势的演员*-*评论员
>
> （Asynchronous Advantage Actor-Critic，A3C）算法。在A3C
> 算法中，有多个并行的环境，每个环境中都有一个智能体执行各自的动作和并计算累计的参数
> 梯度。在一定步数后进行累计，利用累计的参数梯度去更新所有智能体共享的
> 全局参数。因为不同环境中的智能体可以使用不同的探索策略，会导致经验样
>
> 本之间的相关性较小，可以提高学习效率。
>
> 除了本章中介绍的标准强化学习之外，还存在一些更加泛化的强化学习 问题。
>
> 部分可观测马尔可夫决策过程 部分可观测马尔可夫决策过程（Partially Ob-
> servable Markov Decision
> Processes，POMDP）是一个马尔可夫决策过程的泛化。POMDP
> 依然具有马尔可夫性，但是假设智能体无法感知环境的状态*s*，只能知道部分观测值*o*。比如在自动驾驶中，智能体只能感知传感器采集的有限的
> 环境信息。
>
> POMDP 可以用一个7 元组描述：(S*,* A*, T,* 𝑌*,* Ω*,* O*, γ*)，其中S
> 表示状态空间，为隐变量，A 为动作空间，*T* (*s*^′^\|*s, a*)
> 为状态转移概率，𝑌 为奖励函数，Ω(*o*\|*s, a*)为观测概率，O
> 为观测空间，*γ* 为折扣系数。
>
> 逆向强化学习
> 强化学习的基础是智能体可以和环境进行交互，得到奖励。但在某些情况下，智能体无法从环境得到奖励，只有一组轨迹示例（demonstration）。比如在自动驾驶中，我们可以得到司机的一组轨迹数据，但并不知道司机在每个时刻得到的即时奖励。虽然我们可以用监督学习来解决，称为行为克隆。但行为克隆只是学习司机的行为，并没有深究司机行为的动机。
>
> 逆向强化学习（Inverse Reinforcement
> Learning，IRL）就是指一个不带奖励的马尔可夫决策过程，通过给定的一组专家（或教师）的行为轨迹示例来逆
> 向估计出奖励函数*r*(*s, a, s*^′^)
> 来解释专家的行为，然后再进行强化学习。
>
> 分层强化学习 分层强化学习（Hierarchical Reinforcement
> Learning，HRL）是指将一个复杂的强化学习问题分解成多个小的、简单的子问题\[[Barto
> and Ma-](\l) [hadevan](\l),
> [2003](\l)\]，每个子问题都可以单独用马尔可夫决策过程来建模。这样，我们可以将智能体的策略分为高层次策略和低层次策略，高层次策略根据当前状
> 态决定如何执行低层次策略。这样，智能体就可以解决一些非常复杂的任务。

#### 习题

> 习题 **14-1** 证明公式([14.25](\l))。
>
> 习题 **14-2** 证明公式([14.27](\l)) 和([14.28](\l)) 会收敛到最优解。
>
> 习题 **14-3** 比较证明公式([14.21](\l)) 和([14.38](\l)) 的不同之处。
>
> 362 2019 年 4 月 6 日 参考文献
>
> 习题 **14-4** 分析SARSA 算法和Q 学习算法的不同。
>
> 习题 **14-5** 证明公式([14.54](\l))。

#### 参考文献

> Andrew G Barto and Sridhar Mahadevan. Recent advances in hierarchical
> reinforce- ment learning. *Discrete Event Dynamic* *Systems*,
> 13(4):341--379, 2003.
>
> Ronen I Brafman and Moshe Tennenholtz. R-max -- a general polynomial
> time algo- rithm for near-optimal reinforcement learn- ing. *Journal
> of Machine Learning Research*, 3(Oct):213--231, 2002.
>
> Timothy P Lillicrap, Jonathan J Hunt, Alexander Pritzel, Nicolas
> Heess, Tom Erez, Yuval Tassa, David Silver, and Daan Wierstra.
> Continuous control with deep reinforcement learning. *arXiv preprint*
> *arXiv:1509.02971*, 2015.
>
> Marvin Minsky. Steps toward artiﬁcial in- telligence. *Computers and
> thought*, 406:450, 1963.
>
> Volodymyr Mnih, Koray Kavukcuoglu, David Silver, Andrei A Rusu, Joel
> Veness, Marc G Bellemare, Alex Graves, Martin Riedmiller, Andreas K
> Fidjeland, Georg Os- trovski, et al. Human-level control through deep
> reinforcement learning. *Nature*, 518 (7540):529--533, 2015.
>
> Volodymyr Mnih, Adria Puigdomenech Ba- dia, Mehdi Mirza, Alex Graves,
> Timothy Lillicrap, Tim Harley, David Silver, and Ko- ray Kavukcuoglu.
> Asynchronous methods for deep reinforcement learning. In *Proceed-
> ings of International Conference on Ma-* *chine Learning*, pages
> 1928--1937, 2016.
>
> Gavin A Rummery and Mahesan Niranjan.
>
> *On-line Q-learning using connectionist sys-*
>
> *tems*, volume 37. University of Cambridge, Department of Engineering,
> 1994.
>
> Tom Schaul, John Quan, Ioannis Antonoglou, and David Silver. Priori-
> tized experience replay. *arXiv preprint* *arXiv:1511.05952*, 2015.
>
> Wolfram Schultz. Predictive reward signal of dopamine neurons.
> *Journal of neurophys-* *iology*, 80(1):1--27, 1998.
>
> David Silver, Guy Lever, Nicolas Heess, Thomas Degris, Daan Wierstra,
> and Mar- tin Riedmiller. Deterministic policy gra- dient algorithms.
> In *Proceedings of Inter- national Conference on Machine Learning*,
> pages 387--395, 2014.
>
> Richard S Sutton and Andrew G Barto. *Reinforcement learning: An
> introduction*. MIT press, 2018.
>
> Hado Van Hasselt, Arthur Guez, and David Silver. Deep reinforcement
> learning with double q-learning. In *AAAI*, pages 2094-- 2100, 2016.
>
> Ziyu Wang, Tom Schaul, Matteo Hessel, Hado Van Hasselt, Marc Lanctot,
> and Nando De Freitas. Dueling network ar- chitectures for deep
> reinforcement learning. *arXiv preprint arXiv:1511.06581*, 2015.
>
> Christopher JCH Watkins and Peter Dayan. Q-learning. *Machine
> learning*, 8(3):279-- 292, 1992.
>
> Ronald J Williams. Simple statistical gradient-following algorithms
> for connec- tionist reinforcement learning. *Machine learning*,
> 8(3-4):229--256, 1992.
>
> 第**15** 章 序列生成模型
>
> 人类语言似乎是一种独特的现象，在动物世界中没有显著 类似的存在。
>
> --- 诺姆·乔姆斯基
>
> 在深度学习的应用中，有很多数据是以序列的形式存在，比如声音、语言、
> 视频、DNA
> 序列或者其它的时序数据等。以自然语言为例，一个句子可以看做是符合一定自然语言规则的词（word）的序列。这些语言规则包含非常复杂的语法和语义的组合关系，很难显式地建模这些规则。在认知心理学上有一个经典的实验，当一个人看到下面两个句子：
>
> 面包上涂黄油面包上涂袜子
>
> 后一个句子在人脑的语义整合时需要更多的处理时间，更不符合自然语言规则。
> 从统计的角度来看，这些语言规则可以看成是一种概率分布。一个长度为*T*
> 的文本序列看作一个随机事件*X*~1:*T*~ = ⟨*X*~1~*,* · · · *, X~T~*
> ⟩，其中每个位置上的变量*X~t\ ~*的样本空间为一个给定的词表（vocabulary）V，整个序列
> **x**~1:*T*~ 的样本空间为
>
> \|V\|*T*
> 。在某种程度上，自然语言也确实有很多随机因素。比如当我们称赞一个人漂亮时，可以说"美丽"，"帅"或者"好看"等。当不指定使用场合时，这几个词可以交替使用，具体使用哪个词可以看作一个随机事件。
>
> 给定一个序列样本**x**~1:*T*~ = *x*~1~*, x*~2~*,* · · · *, x~T~*
> ，其概率可以看出是*T* 个词的联合概率。
>
> *P* (**X**~1:*T*~ = **x**~1:*T*~ ) = *P* (*X*~1~ = *x*~1~*, X*~2~ =
> *x*~2~*,* · · · *, X~T~* = *x~T~* ) (15.1)
>
> = *p*(**x**~1:*T*~ )*.* (15.2)
>
> 和一般的概率模型类似，序列概率模型有两个基本问题：（1）学习问题：给
>
> 这里假定语言的最基本单位为词（word），当然也可以为字或字母（character）。
>
> 在本章中，我们用*X*t 表示位置 *t* 上的随机变量，**x**~1:T~
> 表示一个序列样本，*x*t 来表示一个序列样本在位置 *t* 上的值。
>
> 不失一般性，本章以自然语言为例来介绍序列概率模型。
>
> 定一组序列数据，估计这些数据背后的概率分布；（2）生成问题：从已知的序列分布中生成新的序列样本。
>
> 序列数据一般可以通过概率图模型来建模序列中不同变量之间的依赖关
>
> 系，本章主要介绍在序列数据上经常使用的一种模型：自回归生成模型（Autoregressive
> Generative Model）。

#### 序列概率模型

> 序列数据有两个特点：（1）样本是变长的；（2）样本空间为非常大。对于一个长度为*T*
> 的序列，其样本空间为\|V\|*T*
> 。因此，我们很难用已知的概率模型来直接建模整个序列的概率。
>
> 根据概率的乘法公式，序列**x**~1:*T*~ 的概率可以写为

*p*(**x**~1:*T*~ ) =
*p*(*x*~1~)*p*(*x*~2~\|*x*~1~)*p*(*x*~3~\|**x**~1:2~) · · · *p*(*x~T~*
\|**x**~1:(*T*~ ~−1)~) (15.3)

> *T*

= *p*(*x~t~* **x**~1:(*t*−1)~)*,* (15.4)

> *t*=1
>
> 其中*x~t~* ∈ V*, t* ∈ \[1*, T* \] 为词表V
> 中的一个词，*p*(*x*~1~\|*x*~0~) = *p*(*x*~1~)。
>
> 因此，序列数据的概率密度估计问题可以转换为单变量的条件概率估计问
> 题，即给定**x**~1:(*t*−1)~ 时*x~t~*
> 的条件概率*p*(*x~t~*\|**x**~1:(*t*−1))。~
>
> 给定*N* 个序列数据{**x**^(*n*)^
>
> *n*=1

，序列概率模型需要学习一个模型*p~θ~*(*x*\|**x**~1:(*t*−1))~

> 来最大化整个数据集的对数似然函数。
>
> *N N Tn*
>
> max Σ log *p~θ~* **x**^(*n*)^ = max Σ Σ log
>
> (*n*) (*n*)
>
> *.* (15.5)
>
> 自回归模型参见第[6.1.2](\l)节。
>
> 多项分布参见第[D.2.2.2](\l)节。
>
> N 元统计模型参见第[15.2](\l)节。
>
> 在这种序列模型方式中，每一步都需要将前面的输出作为当前步的输入，是
> 一种自回归（autoregressive）的方式。因此这一类模型也称为自回归生成模型
>
> （Autoregressive Generative Model）。
>
> 由于*X~t~* ∈ V
> 为离散变量，我们可以假设条件概率*p~θ~*(*x~t~*\|**x**~1:(*t*−1))\ 服从多项分布，然后通过不同的模型来估计。本章主要介绍两种比较主流的模型：*N*\ 元~~统计模型和深度序列模型。~
>
> 深度序列模型参见第[15.3](\l)节。 **15.1.1** 序列生成
>
> 一旦通过最大似然估计训练了模型*p~θ~*(*x*\|**x**~1:(*t*−1))，就可以通过时间顺序来\ 生成一个完整的序列样本。令*x*ˆ*t*~
> 为在第*t* 时根据分布*p~θ~*(*x*\|**x**ˆ~1:(*t*−1)~) 生成的词，
>
> *x*ˆ*~t~* ∼ *p~θ~*(*x*\|**x**ˆ~1:(*t*−1)~)*,* (15.6)
>
> 15.1 序列概率模型 2019 年 4 月 6 日 365
>
> 其中**x**ˆ~1:(*t*−1)~ = *x*ˆ~1~*,* *, x*ˆ~*t*−1~ 为前面*t* − 1
> 步中生成的前缀序列。
>
> 自回归的方式可以生成一个无限长度的序列。为了避免这种情况，通常会
> 设置一个特殊的符号"\<eos\>"来表示序列的结束。在训练时，每个序列样本的结尾都加上符号"\<eos\>"。在测试时，一旦生成了符号"\<eos\>"，就中止生成过程。
>
> 束搜索
> 当使用自回归模型生成一个最可能的序列时，生成过程是一种从左到右的贪婪式搜索过程。在每一步都生成最可能的词，
>
> *x*ˆ*~t~* = arg max *p~θ~*(*x* **x**ˆ~1:(*t*−1)~)*,* (15.7)
>
> *x*∈V
>
> 其中**x**ˆ~1:(*t*−1)~ = *x*ˆ~1~*,* *, x*ˆ~*t*−1~ 为前面*t* − 1
> 步中生成的前缀序列。
>
> 这种贪婪式的搜索方式是次优的，生成的序列**x**ˆ~1:*T*~
> 并不保证是全局最优的。
>
> *T T*
>
> Y max *p~θ~*(*x~t~*\|**x**ˆ~1:(*t*−1)~) ≤ max *T* Y
> *p~θ~*(*x*\|**x**~1:(*t*−1)~)*.* (15.8)
>
> 一种常用的减少搜索错误的启发式方法是束搜索（Beam
> Search）。在每一步的生成中，生成*K* 个最可能的前缀序列，其中*K*
> 为束的大小（Beam Size）， 是一个超参数。
>
> 束搜索的过程如下：在第1 步时，生成*K* 个最可能的词。在后面每一步中，
> 从*K*\|V\| 个候选输出中选择*K*
> 个最可能的序列。图[15.1](\l)给出了一个束搜索过程的
>
> 示例，其中词表V = {*A, B, C*}，束大小为2。 参见习题[15-5](\l)。

t=1 t=2 t=3

> ![](/root/autodl-tmp/project_knowledge/Doc_QA/Knowledge_based/1828695663060254721/image_output/7.《神经网络与深度学习》/media/image215.png)*AAB*
>
> *ϕ*
>
> *CBA*
>
> 图 15.1 束搜索过程示例
>
> 束搜索可以通过调整束大小*K* 来平衡计算复杂度和搜索质量之间的优先级。
>
> 马尔可夫性质参见第[D.3](\l)节。
>
> 多项分布参见第[D.2.2.2](\l)节。

2.  **\
    > N** 元统计模型

> 由于数据稀疏问题，当*t*
> 比较大时，依然很难估计条件概率*p*(*x~t~*\|**x**~1:(*t*−1))。一个简化的方法是*N*\ 元模型（N-Gram\ Model），假设每个词*xt*~
> 只依赖于其前面的*n* − 1 个词（*n* 阶马尔可夫性质），即
>
> *p*(*xt*\|**x**1:(*t*−1)) = *p*(*xt*\|**x**(*t*−*n*+1):(*t*−1))*.*
> (15.9)
>
> 当*n* = 1 时，称为一元（unigram）模型；当*n* = 2
> 时，称为二元（bigram） 模型，以此类推。
>
> 一元模型 当*n* = 1 时，序列**x**~1:*T*~
> 中每个词都和其它词独立，和它的上下文无关。每个位置上的词都是从多项分布独立生成的。在多项分布中，*θ*
> = \[*θ*~1~*,* · · · *, θ*~\|V\|~\] 为词表中每个词被抽取的概率。
>
> 在一元模型中，序列**x**~1:*T*~ 的概率可以写为
>
> *T* \|V\|
>
> *p*(**x**~1:*T*~ \|*θ*) = Y *p*(*x~t~*) = Y *θ^m^k ,* (15.10)
>
> *t*=1 *k*=1
>
> 其中*m~k~* 为词表中第*k* 个词*v~k~*
> 在序列中出现的次数。公式([15.10](\l))和标准多项分布的区别是没有多项式系数，因为这里词的顺序是给定的。
>
> 给定一组训练集{**x**(*n*)1:*Tn* }*N* ′ ，其对数似然函数为：
>
> *N* ^′^ \|V\|
>
> (*n*) 1:*Tn*
>
> *n*=1
>
> *m~k~ k*
>
> *k*=1
>
> \|V\|
>
> (15.11)
>
> = *m~k~* log *θ~k~,* (15.12)
>
> *k*=1
>
> 其中*m~k~* 为第*k* 个词在整个训练集中出现的次数。
>
> 这样一元模型的最大似然估计可以转化为约束优化问题：
>
> \|V\|
>
> max
>
> *θ*

subjuct to

> *m~k~* log *θ~k~* (15.13)
>
> *k*=1
>
> \|V\|
>
> *θ~k~* = 1*.* (15.14)
>
> *k*=1
>
> 拉格朗日乘子参见第[C.3](\l)节。
> 引入拉格朗日乘子*λ*，定义拉格朗日函数Λ(*θ, λ*) 为
>
> \|V\|

Λ(*θ, λ*) = *m~k~*

> *k*=1
>
> log *θ~k~*
>
> \+ *λ* \|V\| *θ*
>
> *k*=1
>
> − 1 *.* (15.15)
>
> 15.2 N 元统计模型 2019 年 4 月 6 日 367
>
> 令
>
> [*∂*Λ(*θ, λ*)]{.underline} = *[mk]{.underline}* + *λ* = 0*,* (15.16)

*∂θ~k~*

> *θ~k~*
>
> \|V\|

[*∂*Λ(*θ, λ*)]{.underline} = *θ*

*k*=1

> − 1 = 0*.* (15.17)
>
> 求解上述方程得到*λ* = − Σ*V m~v~*，进一步得到
>
> *θ^ML^* = [* mk *]{.underline} = *[mk]{.underline} ,* (15.18)

Σ\|*k*V=\|1 *mk m*¯

> 其中*m*¯估计。
>
> = Σ\|*k*V=\|1 *m~k~*
> 为文档集合的长度。由此可见，最大似然估计等价于频率
>
> **N** 元模型 同理，N
> 元模型中的条件概率*p*(*x~t~*\|**x**~(*t*−*n*+1):(*t*−1))\ 也可以通过最大似然函数来得到。~
>
> 参见习题[15-1](\l)。

(*x* \|**x**

> ) = **m x**(*t*−*n*+1):*t*
>
> *,* (15.19)

*p t* (*t*−*n*+1):(*t*−1)

> **m x**~(~

*t*−*n*

+1):(

*t*−1)

> 其中**m**(**x**~(*t*−*n*+1):*t*~) 为**x**~(*t*−*n*+1):*t*~
> 在数据集中出现的次数。
>
> N
> 元模型广泛应用于各种自然语言处理问题，如语音识别、机器翻译、拼音输入法，字符识别等。通过N
> 元模型，我们可以计算一个序列的概率，从而判断该序列是否符合自然语言的语法和语义规则。
>
> 平滑技术 N
> 元模型的一个主要问题是数据稀疏问题。数据稀疏问题在基于统计的机器学习中是一个常见的问题，主要是由于训练样本不足而导致密度估计不
> 准确。在一元模型中，如果一个词*v*
> 在训练数据集里不存在，就会导致任何包含*v* 的句子的概率都为0。同样在N
> 元模型中，当一个N
> 元组合在训练数据集中不存在时，包含这个组合的句子的概率为0。
>
> 数据稀疏问题最直接的解决方法就是增加训练数据集的规模，但其边际效
> 益会随着数据集规模的增加而递减。以自然语言为例，由于大多数自然语言都
>
> 服从Zipf 定律。在一个给定自然语言数据集里，一个单词出现的频率与它在频
> Zipf 定律是美国语言学家
>
> 率表里的排名成反比。出现频率最高的单词的出现频率大约是出现频率第二位
>
> 的单词的2 倍，大约是出现频率第三位的单词的3
> 倍。因此，在自然语言中大部分的词都是低频词，很难通过增加数据集来避免数据稀疏问题。
>
> 数据稀疏问题的一种解决方法是平滑技术（Smoothing），即给一些没有出现的词组合赋予一定先验概率。平滑技术是N
> 元模型中的一项必不可少的技术， 比如加法平滑的计算公式为：
>
> George K. Zipf 提出的实验定律。

*p x* \|**x**

> = m **x**(*t*−*n*+1):*t* + *δ*
>
> *,* (15.20)
>
> 参见习题[15-2](\l)。
>
> 其中*δ* ∈ (0*,* 1\] 为常数。*δ* = 1 时，称为加*1* 平滑。
>
> 除了加法平滑，还有很多平滑技术，比如Good-Turing 平滑，Kneser-Ney
>
> 平滑等，其基本思想都是增加低频词的频率，而降低高频词的频率。

#### 深度序列模型

> 深度序列模型（Deep Sequence
> Model）是指利用神经网络模型来估计条件概率*pθ* (*xt*\|**x**1:(*t*−1))，
>
> 假设一个神经网络*f* (·*, θ*)，其输入为历史信息*h~t~* =
> **x**~1:(*t*−1)~，输出为词表V
>
> 中的每个词*v~k~*(1 ≤ *k* ≤ \|V\| 出现的概率，并满足
>
> \|V\|

*f~k~* **x**~1:(*t*−1)~*, θ* = 1*,* (15.21)

> *k*=1
>
> 其中*θ*
> 表示网络参数。条件概率*p~θ~*(*x~t~*\|**x**~1:(*t*−1))\ 可以从神经网络的输出中得到，~

*p~θ~*(*x~t~*\|**x**~1:(*t*−1)~) = *f~k~xt* (**x**~1:(*t*−1)~; *θ*)*,*
(15.22)

> 其中*k~x~t* 为*x~t~* 在词表V 中索引。
>
> 深度序列模型一般可以分为三个部分：嵌入层、特征层、输出层。
>
> 嵌入层 令*h~t~* = **x**~1:(*t*−1)~
> 表示输入的历史信息，一般为符号序列。由于神经网络模型一般要求输入形式为实数向量，因此为了能够使得神经网络模型能处理符
> 号数据，需要将这些符号转换为向量形式。一种简单的转换方法是通过一个嵌
> 入表（Embedding Lookup
> Table）来将每个符号直接映射成向量表示。嵌入表也称为嵌入矩阵或查询表。令*M*
> ∈ R*d*1×\|V\| 为嵌入矩阵，其中第*k* 列向量**m***~k~* ∈ R*d*1
> 表示词表中第*k* 个词对应的向量表示。
>
> **m**~1~ **m**~2~ **m**~3~ **m**~k~

图 15.2 嵌入矩阵

> **m**\|V\|−2 **m**\|V\|−1 **m**\|V\|
>
> 假设词 *x~t~* 对应词表中的索引为 *k*，则其one-hot 向量表示为 *δ~t~* ∈
> {0*,* 1}\|V\|， 即第*k* 维为1，其余为0 的\|V\| 维向量。词*x~t~*
> 对应的向量表示为
>
> **e***~t~* = *Mδ~t~* = **m***~k~.* (15.23)
>
> 15.3 深度序列模型 2019 年 4 月 6 日 369

通过上面的映射可以得到序列*x*~1:(*t*−1)~ 对应的向量序列**e**~1~*, ,*
**e**~*t*−1~。

特征层 特征层用于从输入向量序列**e**~1~*, ,* **e**~*t*−1~
中提取特征，输出为一个可以

> 表示历史信息的向量**h***~t~*。
>
> 特征层可以通过不同类型的神经网络来实现，比如前馈神经网络和循环神
> 经网络。常见的网络类型有以下三种：

1.  简单平均

> **h** *t*−1
>
> *~t~* = *α~i~***e***~i~,* (15.24)
>
> *i*=1
>
> 其中*α~i~* 为每个词的权重。
>
> 权重*α~i~* 可以和位置*i* 及其表示**e***~i~*
> 相关，也可以无关。简单起见，可以设置 *α~i~* = [ 1]{.underline}
> 。权重*α~i~* 也可以通过注意力机制来动态计算。
>
> −

2.  前馈神经网络

> 前馈神经网络要求输入的大小是固定的。因此和N
> 元模型类似，假设历史信息只包含前面*n* − 1 个词。
>
> 首先将这*n* − 1 个的词向量的**e**~*t*−*n*+1~*,* · · · *,* **e**~*t*−1~
> 拼接成一个*d*~1~ × (*n* − 1) 维的向量**h**′。
>
> 注意力机制参见第[8.1.2](\l)节。参见习题[15-3](\l)。

**h**′ = **e**~*t*−*n*+1~ ⊕ · · · ⊕ **e**~*t*−1~*,* (15.25)

> 其中⊕ 表示向量拼接操作。
>
> 然后将**h**′
> 输入到由前馈神经网络构成的隐藏层，最后一层隐藏层的输出**h***~t~*。
>
> **h***~t~* = *g*(**h**′*, θ~g~*)*,* (15.26)
>
> 其中*g*(·*, θ~g~*) 可以为全连接的前馈神经网络或卷积神经网络，*θ~g~*
> 为网络参数。为了增加特征的多样性，前馈网络中也可以包含跳层连接（Skip-Layer
> Con-
>
> nections）\[[Bengio et al.](\l), [2003](\l)\]，比如

**h***~t~* = **e***~t~* ⊕ *g*(**h**′*, θ~g~*)*.* (15.27)

3.  循环神经网络

> 和前馈神经网络不同，循环神经网络可以接受变长的输入序列，依次接受
> 输入**e**~1~*,* · · · *,* **e**~*t*−1~，得到时刻*t* 的隐藏状态*h~t~*
>
> **h***~t~* = *g*(**h**~*t*−1~*,* **e***~t~, θ~g~*)*,* (15.28)
>
> 其中*g*(·) 为一个非线性函数，*θ~g~* 为循环网络的参数，**h**~0~ = 0。
>
> 前馈网络模型和循环网络模型的不同之处在于循环神经网络利用隐藏状态来记录以前所有时刻的信息，而前馈神经网络只能接受前*n*
> − 1 个时刻的信息。
>
> ![](/root/autodl-tmp/project_knowledge/Doc_QA/Knowledge_based/1828695663060254721/image_output/7.《神经网络与深度学习》/media/image232.png)**y**~t~

*xt*−*n*+1

> *xt*−*n*+2
>
> *. . .*
>
> *xt*−1

a.  前馈神经网络模型

> **y**~t~

b.  循环神经网络模型

> *xt*−1
>
> 图 15.3 深度序列模型
>
> 输出层 输出层为一般使用softmax
> 分类器，接受历史信息的向量表示**h***~t~* ∈ R*d*2 ，
> 输出为词表中每个词的后验概率，输出大小为\|V\|。

**o***~t~* = softmax(**o**ˆ*~t~*) (15.29)

= softmax(*W* **h***~t~* + **b**)*,* (15.30)

> 其中输出向量**o***~t~* ∈ (0*,* 1)\|V\| 为预测的概率分布，第*k*
> 维是词表中第*k* 个词出现的条件概率；**o**ˆ*~t~*
> 是为归一化的得分向量；*W* ∈ R\|V\|×*d*2
> 是最后一层隐藏层到输出层直接的权重矩阵，**b** ∈ R\|V\| 为偏置。
>
> 图[15.3](\l)给出了两种不同的深度序列模型，图[15.3a](\l)为前馈网络模型（虚线边
> 为可选的跳层连接），图[15.3b](\l)为循环神经网络模型。
>
> **15.3.1** 参数学习
>
> 给定一个训练序列**x**~1:*T*~
> ，深度序列模型的训练目标为找到一组参数*θ*，使得对数似然函数最大。
>
> *T*
>
> log *p~θ~*(**x**~1:*T*~ ) = log *p~θ~*(*x~t~* **x**~1:(*t*−1)~)*,*
> (15.31)
>
> *t*=1
>
> 其中*θ* 表示网络中的所有参数，包括嵌入矩阵*M*
> 以及神经网络的权重和偏置。网络参数一般通过梯度上升法来学习，
>
> [*∂* log *p~θ~*(**x**~1:*T*~ )]{.underline}
>
> 简要起见，这里忽略了正则化项。
>
> 其中*α* 为学习率。
>
> *θ* ← *θ* + *α*
>
> *,* (15.32)
>
> *∂θ*

#### 评价方法

> 构造一个序列生成模型后，需要有一个度量来评价其好坏。

###### 困惑度

> 给定一个测试文本集合，一个好的序列生成模型应该使得测试集合中的句
> 子的联合概率尽可能高。
>
> 困惑度（Perplexity）是信息论的一个概念，可以用来衡量一个分布的不确定性。对于离散随机变量*X*
> ∈ X，其概率分布为*p*(*x*)，困惑度为
>
> 2*H*(*p*) = 2− Σ*x*∈X *p*(*x*) log~2~ *p*(*x*)*,* (15.33)
>
> 其中*H*(*p*) 为分布*p* 的熵。
>
> 困惑度也可以用来衡量两个分布之间差异。对于一个未知的数据分布*p~r~*(*x*)
> 和一个模型分布*p~θ~*(*x*)，我们从*p~r~*(*x*)
> 中采样出一组测试样本*x*^(1)^*,* · · · *,
> x*^(*N*)^，模型分布*p~θ~*(*x*) 的困惑度为

2*H*(*p*˜ *,p* ) = 2− [ 1]{.underline} Σ*N*

> log
>
> *p* (*x*^(*n*)^)
>
> (15.34)
>
> 其中*H*(*p*˜*~r~, p~θ~*) 为样本的经验分布*p*˜*~r~* 与模型分布*p~θ~*
> 之间的交叉熵，也是所有样本上的负对数似然函数。
>
> 困惑度可以衡量模型分布与样本经验分布之间的契合程度。困惑度越低则
> 两个分布越接近。因此模型分布*p~θ~*(*x*) 的好坏可以用困惑度来评价。
>
> 假设测试集合共有独立同分布的 *N* 个序列{**x**^(*n*)^
>
> *n*=1

。我们可以用模型

> *p~θ~*(**x**) 对每个序列计算其概率*p~θ~*(**x**^(*n*)^
>
> )，整个测试集的联合概率为
>
> *N N Tn*

Y *pθ* **x**(*n*)

> = Y Y
>
> (*n*) (*n*)
>
> *.* (15.35)
>
> 模型*p~θ~*(**x**) 的困惑度定义为

PPL( ) = 2^−^ [ 1]{.underline} Σ*N*

> log *p* **x**^(*n*)^
>
> (15.36)

= 2− [ 1]{.underline} Σ*N*

> Σ*Tn* log *p* (*n*)\|**x**(*n*)
>
> (15.37)

*T*

= Y*N*

> *n*=1
>
> *Tn*
>
> *t*=1
>
> (*n*)
>
> *~θ~ xt*
>
> (*n*)
>
> 1:(*t*−1)
>
> !−1*/T*

*p~θ~*

*n*=1 *t*=1

> *xt* \|**x**1:(*t*−1)
>
> *,* (15.38)
>
> 其中 *T* = Σ*N T~n~*
> 为测试数据集中序列的总长度。可以看出，困惑度为每个
>
> 词条件概率*p~θ~ x*^(*n*)^\|**x**^(*n*)^
> 的几何平均数的倒数。测试集中所有序列的概率越
>
> 几何平均数是一种求数值平 均数的[方法，]{.underline}
> [计]{.underline}算公式为：
>
> 大，困惑度越小，模型越好。
>
> 假设一个序列模型赋予每个词出现的概率均等，即*p~θ~
> x*^(*n*)^\|**x**^(*n*)^
>
> = [ 1]{.underline} ，
>
> *x*¯ = *n* Qn *x .*
>
> *t* 1:(*t*−1) \|V\|

t=1 t

> 则该模型的困惑度为\|V\|。以英语为例，N 元模型的困惑度范围一般为50 ∼
> 1000
>
> 之间。

2.  **BLEU**

> *BLEU*（Bilingual Evaluation
> Understudy）是衡量模型生成序列和参考序列之间的N
> 元词组（N-Gram）的重合度，最早用来评价机器翻译模型的质量，
> 目前也广泛应用在各种序列生成任务中。
>
> 假设从模型分布*p~θ~*
> 中生成一个候选（Candidate）序列**x**，从真实数据分布中采样出的一组参考（Reference）序列**s**(1)*,*
> · · · *,* **s**(*K*)，我们首先从生成序列中
>
> 提取N 元组合的集合𝑌，并计算N 元组合的精度（Precision），

Σ min *c~w~*

(**x**)*,* m*^K^*ax *c*

> (**s**(*k*))
>
> (**x**) = [^*w*∈𝑌^ *k*=1]{.underline} *,* (15.39)
>
> *P~n~*

*w*∈𝑌

> *c~w~*(**x**)
>
> 其中*c~w~*(**x**) 是N 元组合*w* 在生成序列**x**
> 中出现的次数，*c~w~*(**s**(*k*)) 是N 元组合*w* 在参考序列**s**(*k*)
> 中出现的次数。N 元组合的精度*P~n~*(**x**) 是计算生成序列中的N
> 元组合有多少比例在参考序列中出现。
>
> 由于精度只衡量生成序列中的N
> 元组合是否在参考序列中出现，生成序列越短，其精度会越高，因此可以引入长度惩罚因子(Brevity
> Penalty)。如果生成序列的长度短于参考序列，就对其进行惩罚。

*b*(**x**) = 

> 1 if *l~x~ \> l~s~*
>
> exp 1 − *l~s~/l~x~* if *l~x~* ≤ *l~s~*
>
> (15.40)
>
> 其中*l~x~* 为生成序列**x** 的长度，*l~s~* 为参考序列的最短长度。
>
> BLEU 是通过计算不同长度的N 元组合的精度，并进行几何加权平均而得到。
>
> *N*
>
> BLEU-N(**x**) = *b*(**x**) exp *w~n~* log *P~n~ ,* (15.41)
>
> *n*=1
>
> 其中*w~n~* 为不同N 元组合的权重，一般设为 [^\ 1^]{.underline} 。BLEU
> 取值范围是\[0*,* 1\]，越大表明生成的质量越好。但是BLEU
> 只计算精度，而不关心召回率（即参考序列里的N
> 元组合是否在生成序列中出现）。

##### ROUGE

> *ROUGE*（Recall-Oriented Understudy for Gisting
> Evaluation）最早应用于文本摘要领域。和 BLEU 类似，但ROUGE
> 计算的是召回率（Recall）。
>
> 假设从模型分布*p~θ~*
> 中生成一个候选（Candidate）序列**x**，从真实数据分布中采样出的一组参考（Reference）序列**s**(1)*,*
> · · · *,* **s**(*K*)，令𝑌 为从参考序列中提取N 元组合的集合，ROUGE-N
> 的定义为
>
> 参见习题[15-4](\l)。

Σ*K* Σ

> min *c~w~*

(**x**)*, c~w~*

**s**(*k*)

> ROUGE-N(**x**) = [^*k*=1^ ^*w*∈𝑌^]{.underline} *,* (15.42)
>
> Σ*K* Σ
>
> *cw* **s**(*k*)
>
> *k*=1 *w*∈𝑌
>
> 其中*c~w~*(**x**) 是N 元组合*w* 在生成序列**x**
> 中出现的次数，*c~w~*(**s**(*k*)) 是N 元组合*w* 在参考序列**s**(*k*)
> 中出现的次数。

#### 序列生成模型中的学习问题

> 协 变 量 偏 移 问 题 参 见
>
> 使用最大似然估计来学习自回归序列生成模型时，会存在以下三个主要问
> 题：曝光偏差、训练目标不一致和计算效率。下面我们分别介绍这三个问题以
> 及解决方面。

###### 曝光偏差问题

> 在自回归生成模型中，第*t*
> 步的输入为模型生成的前缀序列**x**ˆ~1:(*t*−1)~。而在训练时，我们使用的前缀序列是训练集中的真实数据**x**~1:(*t*−1))，而不是模型预测的**x**ˆ1:(*t*−1)~)。这种学习方式也称为教师强制（Teacher
> Forcing）\[[Williams and](\l) [Zipser](\l), [1989](\l)\]。
>
> 模型生成的分布*p~θ~* **x**~1:(~ ~1))\ 和真实数据分布*pr*~ **x**~1:(~
> ~1))\ 并不严格一致，\ 因此条件概率\ *pθ*~
> *x*\|**x**~1:(*t*−1))\ 在训练和测试会存在协变量偏移问题。一旦在预~
>
> 第[10.4.0.2](\l)节。 测前缀**x**ˆ~1:(*t*−1)~)
> 的过程中存在错误，会导致错误传播，使得后续生成的序列也会偏离真实分布。这个问题称为曝光偏差（Exposure
> Bias）。
>
> 计划采样
> 为了缓解曝光偏差的问题，我们可以在训练时混合使用真实数据和模型生成数据。在第*t*
> 步时，模型随机使用真实数据*x~t~*~−1~
> 或前一步生成的词*x*ˆ~*t*−1~作为输入。
>
> 令*ϵ* ∈ \[0*,* 1\] 为一个控制替换率的超参数，在每一步时，以*ϵ*
> 的概率使用真实数据*x~t~*~−1~，以1 − *ϵ*
> 的概率来使用生成数据*x*ˆ~*t*−1~。当令*ϵ* = 1
> 时，训练和最大似然估计一样，使用真实数据；当令*ϵ* = 0
> 时，训练时全部使用模型生成数据。
>
> 直觉上，如果一开始训练时的*ϵ*
> 过小，模型相当于在噪声很大的数据上训练，会导致模型性能变差，并且难以收敛。因此，一个较好的策略是在训练初
> 期赋予*ϵ* 较大的值，随着训练次数的增加逐步减少*ϵ*
> 的取值。这种策略称为计划采样（Scheduled Sampling）\[[Bengio et
> al.](\l), [2015](\l)\]。
>
> 令*ϵ~i~* 为在第*i*
> 次迭代时的替换率，在计划采样中可以通过下面几种方法来逐步降低*ϵ*
> 的取值。

1.  线性衰减：*ϵ~i~* = max(*ϵ, k* − *ci*)，其中*ϵ* 为最小的替换率，*k*
    > 和*c* 分别为初始值和衰减率。

2.  指数衰减：*ϵ~i~* = *k^i^*，其中*k \<* 1 为初始替换率。

3.  逆Sigmoid 衰减：*ϵ~i~* = *k/*(*k* + exp(*i/k*))，其中*k* ≥ 1
    > 来控制衰减速度。

> 计划采样的一个缺点是在每一步中不管输入如何选择，目标输出依然是来
> 自于真实数据。这可能使得模型预测一些不正确的序列。比如一个真实的序列
>
> 是"吃饭"，如果在第一步生成时使用模型预测的词"喝"，模型就会强制记住
> "喝饭"这个不正确的序列。

###### 训练目标不一致问题

> 序列生成模型一般是采用和任务相关的指标来进行评价，比如BLEU、ROUGE
> 等，而训练时是使用最大似然估计，这导致训练目标和评价方法不一致。并且
> 这些评价指标一般都是不可微的，无法直接使用基于梯度的方法来进行优化。
>
> 基于强化学习的序列生成
> 为了可以直接优化评价目标，我们可以将自回归的序列生成可以看作是一种马尔可夫决策过程，并使用强化学习的方法来进行训练。

参见第[14.1.3](\l)节。

> 在第*t* 步，动作*a~t~*
> 可以看作是从词表中选择一个词，策略为*π~θ~*(*a*\|*s~t~*)，其中状态
> *s~t~* 为之前步骤中生成的前缀序列 **x**~1:(*t*−1)~。一个序列
> **x**~1:*T*~ 可以看作是马尔克夫决策过程的一个轨迹（trajectory）
>
> *τ* = {*s*~1~*, a*~1~*, s*~2~*, a*~2~*\..., s~T~ , a~T~* }*.* (15.43)
>
> 轨迹*τ* 的概率为

*T*

*p~θ~*(*τ* ) = *π~θ~ a~t~* = *x~t~ s~t~* = *x*~1:(*t*−1)~ *,* (15.44)

> *t*=1
>
> 其中状态转移概率 *p s~t~* = **x**~1:*t*~\|*s~t~*~−1~ =
> **x**~1:(*t*−1)~*, a~t~*~−1~ = *x~t~*~−1~ = 1 是确定性的，
> 可以被忽略。
>
> 强化学习的目标是学习一个策略*π~θ~*(*a*\|*s~t~*) 使得期望回报最大，

J (*θ*) = E~*τ*∼*p*~*θ* (*τ* )\[*G*(*τ* )\] (15.45)

= E**~x~**1:*T* ∼*pθ* (**x**1:*T* )\[*G*(**x**~1:*T*~ )\]*,* (15.46)

> 其中*G*(**x**~1:*T*~ ) 为序列**x**~1:*T*~ 的总回报，可以为BLEU、ROUGE
> 或其它评价指标。这样序列生成问题就转换为强化学习问题，其策略函数*π~θ~*(*a*\|*s~t~*)
> 可以通过
>
> REINFORCE 算法或Actor-Critic 算法来进行学习。为了改进强化学习的效率，
> 策略函数*π~θ~*(*a*\|*s~t~*) 一般会通过最大似然估计来进行预训练。
>
> 基于强化学习的序列生成模型不但可以解决训练和评价目标不一致问题，
> 也可以有效地解决曝光偏差问题。

###### 计算效率问题

> 序列生成模型的输出层为词表中所有词的条件概率，需要softmax
> 归一化。当词表比较大时，计算效率比较低。
>
> 在第*t* 步时，前缀序列为*h~t~* = **x**~1:(*t*−1)~，词*x~t~*
> 的条件概率为
>
> *p~θ~*(*x~t~*\|*h~t~*) = softmax *s*(*x~t~, h~t~*; *θ*) (15.47)
>
> exp *s*(*x , h* ; *θ*)
>
> Σ*v*∈ V exp *s*(*v, h~t~*; *θ*)

*,* (15.48)

> *s*(*x , h* ; *θ*) = \[**o**ˆ \] ，**o**ˆ 为
>
> 其中*s*(*x~t~, h~t~*; *θ*)
> 为未经过softmax归一化的得分函数，*Z*(*h~t~*; *θ*)
> 为配分函数（Partition
>
> t t t k*xt* t
>
> Function）。
>
> 未归一化的网络输出参见公
>
> 式([15.29](\l))。
>
> 参见第[11.1.4](\l)节。 *Z*(*h~t~*; *θ*) = exp *s*(*v, h~t~*; *θ*) *.*
> (15.50)
>
> *v*∈V
>
> 配分函数的计算需要对词表中所有的词*v* 计算*s*(*v, h~t~*; *θ*)
> 并求和。当词表比较大时，计算开销非常大。比如在自然语言中，词表V
> 的规模一般在1 万到10
> 万之间。在训练时，每个样本都要计算一次配分函数，这样每一轮迭代需要计
> 算*T* 次配分函数（*T*
> 为训练文本长度），导致整个训练过程变得十分耗时。因此在实践中，我们通常采用一些近似估计的方法来加快训练速度。常用的方法可
> 以分为两类：（1）层次化的softmax 计算，将标准softmax
> 函数的扁平结构转换为层次化结构；（2）基于采样的方法，通过采样来近似计算更新梯度。
>
> 本节介绍三种方法加速训练的方法：层次化softmax
> 方法、重要性采样和噪声对比估计。

1.  层次化 **Softmax**

> 我们先来考虑两层的来组织词表，即将词表中词分成*k*
> 组，并每一个词只能属于一个分组，每组大小为 ^[\|V]{.underline}\|^
> 。假设词*w* 所属的组为*c*(*w*)，则

*p*(*w*\|*h*) = *p*(*w, c*(*w*)\|*h*) (15.51)

= *p*(*w*\|*c*(*w*)*, h*)*p*(*c*(*w*)\|*h*)*,* (15.52)

> 其中*p*(*c*(*w*)\|*h*) 是给定历史信息*h* 条件下，类*c*(*w*)
> 的后验概率，*p*(*w*\|*c*(*w*)*, h*) 是给定历史信息*h* 和类*c*(*w*)
> 条件下，词*w*
> 的后验概率。因此，一个词的概率可以分解为两个概率*p*(*w*\|*c*(*w*)*,
> h*) 和*p*(*c*(*w*)\|*h*)
> 的乘积，它们可以分别利用神经网络来估计，这样计算softmax
> 函数时分别只需要做 ^[\|V]{.underline}\|^ 和*k* 次求和，从而就大大提
>
> 高了softmax 函数的计算速度。
>
> 一般对于词表大小 ，我们将词平均分到 个分组中，每组
> 个词。这样通过一层的分组，我们可以将softmax 计算加速 ^1^ √\|V\|
> 倍。比如当词
>
> 表大小为40*,* 000 时，将词表中所有词分到200 组，每组200
> 个词。这样只需要计算两次200 类的softmax，比直接计算40*,* 000
> 类的softmax 加快100 倍。
>
> 为了进一步降低softmax
> 的计算复杂度，我们可以更深层的树结构来组织词汇表。假设用二叉树来组织词表中的所有词，二叉树的叶子节点代表词表中
> 的词，非叶子节点表示不同层次上的类别。图[15.4](\l)给出了平衡二叉树和Huﬀman
> 二叉树的示例。

![](/root/autodl-tmp/project_knowledge/Doc_QA/Knowledge_based/1828695663060254721/image_output/7.《神经网络与深度学习》/media/image236.png)

(a) 平衡树

> 图 15.4 层次化树结构

(b) Huﬀman 树

> 如果我们将二叉树上所有左链接标记为0，右链接标记为1。每一个词可以
> 用根节点到它所在的叶子之间路径上的标记来进行编码。图[15.4a](\l)中所示的四个
> 词的编码分别为：
>
> *v*~1~ = 00*, v*~2~ = 01*, v*~3~ = 10*, v*~4~ = 10*.* (15.53)
>
> 假设词*v*
> 在二叉树上从根节点到其所在叶子节点的路径长度为*m*，其编码可以表示一个位向量（bit
> vector）：\[*b*~1~*,* · · · *, b~m~*\]T。词*v* 的条件概率为
>
> *P* (*v*\|*h*) = *p b*~1~*,* · · · *, b~m~*\|*h* (15.54)
>
> = *p b~j~ b*~1~*, , b~j~*~−1~*, h ,* (15.55)
>
> *j*=1

*m*

> = *p b~j~ b~j~*~−1~*, h ,* (15.56)
>
> *j*=1
>
> 由于*b~j~* ∈ {0*,* 1} 为二值变量，*p*(*b~j~*\|*b~j~*~−1~*, h*)
> 可以看作是两类分类问题，可以使用logistic 回归来进行预测。
>
> *p*(*b~j~* = 1\|*b~j~*~−1~*, h*) = *σ* **w**T
>
> **h** + **b**~*n*(*b*~

*j*−1

~)~ *,* (15.57)

> 其中*n*(*b~j~*~−1~) 为词*v* 在树*T* 上的路径上的第*j* − 1 个节点。
>
> 若使用平衡二叉树来进行分组，则条件概率估计可以转换为log~2~ \|V\|
> 个两类分类问题。这时softmax 函数可以用logistic 函数代替,
> 计算效率可以加速 ^\|V\|^

~2~ \|V\|

> 倍。
>
> WordNet 是按照词义来组织的英语词汇知识库， 由Princeton 大学研发。
>
> Huﬀman 编 码 是 David Huﬀman 于 1952
> 年发明的一种用于无损数据压缩的熵编码（权编码）算法。
>
> 将词表中的词按照树结构进行组织，有以下几种转换方式：

-   利用人工整理的词汇层次结构，比如利用WordNet\[[Miller](\l),
    > [1995](\l)\]
    > 系统中的"IS-A"关系（即上下位关系）。例如，"狗"是"动物"的下位词。因为
    > WordNet
    > 的层次化结构不是二叉树，因此需要通过进一步聚类来转换为二叉树。

-   使用Huﬀman 编码。Huﬀman
    > 编码对出现概率高的词使用较短的编码，出现概率低的词则使用较长的编码。因此训练速度会更快。Huﬀman
    > 编码的算法如算法[15.1](\l)所示。

> 算法 **15.1:** Huﬀman 树构建算法
>
> 输入**:** 词表: V
>
> **1** 初始化：为每个词*v* 建立一个叶子节点，其概率为词的出现频率;
>
> **2** 将所有的叶子节点放入集合S 中;
>
> **3 while** \|S\| *\>* 1 **do**
>
> **4** 从集合S 选择两棵概率最低的节点*n*~1~ 和*n*~2~;
>
> **5** 构建一个新节点*n*^′^，并将*n*~1~ 和*n*~2~
> 作为*n*^′\ 的左右子节点;^
>
> **6** 新节点*n*^′\ 的概率*n*^~1~ 和*n*~2~ 的概率之和，;
>
> **7** 将新二叉树加入集合S 中，并把*n*~1~ 和*n*~2~ 从集合S 中移除;
>
> **8 end**
>
> **9** 集合S 中最后一个节点为*n*;
>
> [ ]{.underline} [输出**:** 以*n* 为根节点的二叉树*T *]{.underline}

2.  重要性采样

> 参见第[11.3](\l)节。
>
> 另一种加速训练速度的方法是基于采样的方法，即通过采样来近似计算训
> 练时的梯度。
>
> 用随机梯度上升来更新参数 *θ* 时，第 *t* 个样本(*h~t~, x~t~*)
> 的目标函数关于 *θ* 的梯度为
>
> *∂* log *p* (*x* \|*h* ) = *∂s*(*x , h* ; *θ*)
>
> *∂* log Σ exp *s*(*v, h~t~*; *θ*)
>
> (15.58)
>
> *∂θ ∂θ* − *∂θ*
>
> = [*∂s*(*x , h* ; *θ*)]{.underline}
>
> [ 1]{.underline} *∂* Σ exp *s*(*v, h~t~*; *θ*)
>
> (15.59)
>
> *∂θ* − Σ exp *s*(*v, h~t~*; *θ*) · *∂θ*

exp *s*(*v, h~t~*; *θ*)

> = [*∂s*(*x~t~, h~t~*; *θ*)]{.underline} − Σ Σ 1 · *∂*
>
> (15.60)
>
> *∂θ*
>
> = [*∂s*(*x~t~, h~t~*; *θ*)]{.underline}
>
> *∂θ*
>
> exp
>
> *v w*
>
> exp
>
> *s*(*w, h~t~*; *θ*)
>
> *s*(*v, h~t~*; *θ*)

*∂θ*

> *∂s*(*v, h~t~*; *θ*)
>
> (15.61)
>
> = [*∂s*(*x~t~, h~t~*; *θ*)]{.underline} − Σ *p* (*v*\|*h* ) [*∂s*(*v,
> h~t~*; *θ*)]{.underline}
>
> (15.62)
>
> = [*∂s*(*x~t~, h~t~*; *θ*)]{.underline} E

*∂θ*

*p~θ~*(*v*\|*h~t~*)

> [*∂s*(*v, h~t~*; *θ*)]{.underline} *.* (15.63)
>
> *∂θ*
>
> 公式（[15.63](\l)）中最后一项是计算 [*^\ ∂^*]{.underline}
> ^*s*(*v,\ h*^*~t~*; *θ*) 在分布*p~θ~*(*v*\|*h~t~*)
> 下的期望。从公式（[15.61](\l)）中可以看出，在计算每个样本的梯度时需要在整个词表上计算两次求和。一次是求配分函数
> *w* exp *s*(*w, h~t~*; *θ*) ，另一次是计算所有词的梯度的期望E\[ [*
> ∂*]{.underline} *s*(*v, h~t~*;
> *θ*)\]。由于自然语言中的词表都比较大，训练速度会非常慢。
>
> 为了提高训练效率，可以用采样方法来进行近似地估计公式([15.63](\l))
> 中的期望。但是我们不能使用直接根据分布*p~θ~*(*v*\|*h~t~*)
> 进行采样，因为直接采样需要在
>
> 需要先计算分布*p~θ~*(*v*\|*h~t~*)，而这正是我们希望避免的。
> 重要性采样参见第[11.3.3](\l)节。
>
> 重要性采样是用一个容易采样的提议分布*q*，来近似估计分布*p*。
>
> 公式([15.63](\l)) 中最后一项可以写为：
>
> E [*∂s*(*v, h~t~*; *θ*)]{.underline} = Σ *p* (*v*\|*h* ) [*∂s*(*v,
> h~t~*; *θ*)]{.underline}
>
> (15.64)
>
> = Σ *q*(*v*\|*h* ) [*p~θ~*(*v*\|*h~t~*)]{.underline} · [*∂s*(*v,
> h~t~*; *θ*)]{.underline}
>
> (15.65)
>
> = E [*p~θ~*(*v*\|*h~t~*)]{.underline} · [*∂s*(*v, h~t~*;
> *θ*)]{.underline} *.* (15.66)

*q*(*v*\|*ht*)

> *q*(*v*\|*h~t~*) *∂θ*
>
> 这样原始分布 *p~θ~*(*v*\|*h~t~*) 上的期望转换为提议分布
> *q*(*v*\|*h~t~*) 上的期望。提议分布 *q*
> 需要尽可能和*p~θ~*(*v*\|*h~t~*) 接近，并且从*q*(*v*\|*h~t~*)
> 采样的代价要比较小。在实践中，提议分布*q*(*v*\|*h~t~*) 可以采用N
> 元模型的分布函数。
>
> 根据分布*Q*(*v*\|*h~t~*) 独立采样*K* 个样本*v*~1~*,* · · · *, v~K~*
> 来近似求解公式（[15.66](\l)）。

[*∂s*(*v, h* ; *θ*)]{.underline} [1]{.underline} Σ [*p* (*v* \|*h* )
*∂s*(*v , h* ; *θ*)]{.underline}

> 在公式([15.67](\l))
> 中，依然需要每一个计算抽取样本的概率*p~θ~*(*v~k~*\|*h*)。
>
> [*s*(*v~k~, h~t~*; *θ*)]{.underline}

*p~θ~*(*v~k~*\|*h~t~*) =

> *,* (15.68)
>
> *Z h~t~*
>
> 其中 *Z*(*h~t~*) = *w* exp *s*(*w, h~t~*; *θ*)
> 为配分函数，需要在所有样本上进行计算*s*(*w, h~t~*; *θ*)
> 并求和。为了避免这种情况，我们可以进一步把配分函数*Z*(*h~t~*)
> 的计算也使用重要性采样来计算。
>
> *Z*(*h~t~*) = Σ exp *s*(*w, h~t~*; *θ*)
>
> (15.69)

= Σ *q*(*w*\|*h~t~*)

> 1

*q*(*w*\|*h~t~*

) exp *s*(*w, h~t~*; *θ*)

> (15.70)

*w*

= E*q*(*w*\|*ht*)

> 1
>
> *q*(*w*\|*h~t~*

) exp *s*(*w, h~t~*; *θ*)

> (15.71)
>
> 通过采样近似估计
>
> [1]{.underline} *^K^*
>
> ≈ *s v , h θ*
>
> (15.72)

*K*

= [ 1]{.underline}

> *k*=1
>
> Σ
>
> *q*(*v~k~*\|*h~t~*) *^k^ ^t^*
>
> exp *s*(*v~k~, h~t~*; *θ*)
>
> (15.73)

= [ 1]{.underline}

> Σ *r*(*v* )*,*

(15.74)

> *k*
>
> *k*=1
>
> 其中*r*(*v* ) = ^exp^ *s*(*vk,ht*;*θ*) ，*q*(*v* \|*h* )
> 为提议分布。为了提高效率，可以和公式
>
> （[15.67](\l)）中的提议分布设为一致，并复用在上一步中抽取的样本。
>
> 在近似估计了配分函数以及梯度期望之后，公式（[15.67](\l)）可写为

[*∂s*(*v, h* ; *θ*)]{.underline} [1]{.underline} Σ

> [*p* (*v* \|*h* ) *∂s*(*v , h* ; *θ*)]{.underline}
>
> (15.75)

= [ 1]{.underline} Σ

> exp *s*(*v~k~, h~t~*; *θ*)
>
> 1 *∂s*(*v , h* ; *θ*)
>
> (15.76)

= [ 1]{.underline}

> *K*
>
> *r v [k]{.underline} [t]{.underline}*
>
> (15.77)

*K Z*(*h~t~*) *^k^ ∂θ*

*k*

*∂s*(*v~k~, h~t~*; *θ*)

> ≈ Σ
>
> (15.78)

*k*=1

> *K*
>
> *k*=1
>
> *r*(*v~k~*) *∂θ*
>
> *K*
>
> *r v ^[k]{.underline}^ ^[t]{.underline}^ .*
>
> *K*
>
> *k*=1
>
> *r*(*v~k~*)
>
> *k*=1 *∂θ*
>
> 将公式（[15.79](\l)）代入公式（[15.63](\l)），得到每个样本目标函数关于*θ*
> 的梯度
>
> 可以近似为
>
> [*∂* log *p* (*x* \|*h* )]{.underline} = [*∂s*(*x , h* ;
> *θ*)]{.underline} − Σ 1
>
> *K*
>
> *r*(*v* ) *,* (15.80)
>
> *θ t t*
>
> *∂θ*

*t t*

> *K*
>
> *k*=1
>
> *r*(*v~k~*)
>
> *k t*
>
> *k*=1 *∂θ*
>
> 其中*v*~1~*,* · · · *, v~k~* 为从提议分布*q*(*v*\|*h~t~*) 中从词表V
> 独立抽取的词。和公式（[15.63](\l)）
> 相比，重要性采样相当于采样了一个词表的子集V′ = {*v*~1~*,* · · · *,
> v~k~*}，然后在这个子集上求梯度 [^*∂s*(*v*^*k,h*;*θ*)]{.underline}
> 的期望；公式（[15.63](\l)）中分布 *p~θ~*(*v*\|*h~t~*) 被 *r*(*v~k~*)
> 所替代。这样目标函数关于*θ*
> 的梯度就避免了在词表上对所有词进行计算，只需要
> 计算较少的抽取的样本。采样的样本数量*K*
> 越大，近似越接近正确值。在实际应用中，*K* 取100
> 左右就能够以足够高的精度对期望做出估计。通过重要性采样的方法，训练速度可以加速
> ^[\|V]{.underline}\|^ 倍。
>
> 重要性采样的思想和算法都比较简单，但其效果依赖于建议分布*q*(*v*\|*h~t~*)
> 的选取。如果*q*(*v*\|*h~t~*)
> 选取不合适时，会造成梯度估计非常不稳定。在实践中，提议分布
> *q*(*v*\|*h~t~*) 经常使用一元模型的分布函数。虽然直观上
> *q*(*v*\|*h~t~*) 采用N 元模型更加准确，但使用复杂的N
> 元模型分布并不能改进性能，原因是N
> 元模型的分布和神经网络模型估计的分布之间有很大的差异\[[Bengio and
> Senécal](\l), [2008](\l)\]。

3.  噪声对比估计

> 除重要性采样外，噪声对比估计（Noise-Contrastive
> Estimation，NCE）也是一种常用的近似估计梯度的方法。
>
> 噪声对比估计是将密度估计问题转换为两类分类问题，从而降低计算复杂
> 度\[[Gutmann and Hyvärinen](\l),
> [2010](\l)\]。噪声对比估计的思想在我们日常生活中十分常见。比如我们教小孩认识"苹果"，往往会让小孩从一堆各式各样的水果中
> 找出哪个是"苹果"。通过不断的对比和纠错，最终小孩会知道了解"苹果"的
> 特征，并很容易识别出"苹果"。
>
> 噪声对比估计的数学描述如下：假设有三个分布，一个是需要建模真实数据分布*p~r~*(*x*)；第二是模型分布*p~θ~*(*x*)，并期望调整模型参数*θ*
> 来使得*p~θ~*(*x*)
> 来拟合真实数据分布*p~r~*(*x*)；第三个是噪声分布*q*(*x*)，用来对比学习。给定一个样本*x*，如果*x*
> 是从*p~r~*(*x*) 中抽取的，称为真实样本，如果*x* 是从*q*(*x*)
> 中抽取的，则称为噪声样本。为了判断样本*x*
> 是真实样本还是噪声样本，引入一个辨别函数*D*。
>
> 噪声对比估计是通过调整模型*p~θ~*(*x*) 使得辨别函数*D*
> 很容易能分别出样本*x* 来自哪个分布。令*y* ∈ {1*,* 0} 表示一个样本*x*
> 是真实样本或噪声样本，其条件概率为
>
> *p*(*x*\|*y* = 1) = *p~θ~*(*x*)*,* (15.81)
>
> *p*(*x*\|*y* = 0) = *q*(*x*)*.* (15.82)
>
> 一般噪声样本的数量要比真实样本大很多。为了提高近似效率，我们近似
> 假设噪声样本的数量是真实样本的*K* 倍，即*y* 的先验分布满足
>
> *P* (*y* = 0) = *KP* (*y* = 1)*.* (15.83)
>
> 根据贝叶斯公式，样本*x* 来自于真实数据分布的后验概率为
>
> [ *p*(*x*\|*y* = 1)*p*(*y* = 1) ]{.underline}
>
> *p*(*x*\|*y* = 1)*p*(*y* = 1) + *p*(*x*\|*y* = 0)*p*(*y* = 0)

= [ *p~θ~*(*x*)*p*(*y* = 1) ]{.underline}

*p~θ~*(*x*)*p*(*y* = 1) + *q*(*x*) · *kp*(*y* = 1)

> (15.84)
>
> (15.85)
>
> = [ *pθ* (*x*)]{.underline} *.* (15.86)
>
> *p~θ~ x Kq x*
>
> 相反，样本*x* 来自于噪声分布的后验概率为 *p*(*y* = 0\|*x*) = 1 −
> *p*(*y* = 1\|*x*)。
>
> 从真实分布*p~r~*(*x*) 中抽取*N* 个样本*x*~1~*,* · · · *, x~N~*
> ，将其类别设为*y* = 1，然后从噪声分布中抽取*KN* 个样本*x*^′^1*,* · · ·
> *, x*^′^*kn*，将其类别设为*y* =
> 0。噪声对比估计的目标是将真实样本和噪声样本区别开来，可以看作是一个两类分类问题。噪
> 声对比估计的损失函数为

L(*θ*) =

> [ 1]{.underline} *^N^*
>
> − *N* (*K* + 1)

*n*

> log

*p*(*y*

> = 1\|*x~n~*
>
> *KN*

) + log

> *n*=1

*p*(*y*

> = 0\|*x*^′^*n*
>
> )! *.*
>
> (15.87)
>
> 生成对抗网络参见第[13.3](\l)节。
>
> *p*~θ~(*v*\|*h*) 参见公式([15.48](\l))。
>
> 通过不断采样真实样本和噪声样本，并用梯度下降法可以学习参数*θ*
> 使得*p~θ~*(*x*)
>
> 逼近于真实分布*p~r~*(*x*)。
>
> 噪声对比估计相当于用判别式的准则L(*θ*)
> 来训练一个生成式模型*p~θ~*(*x*)，使得判别函数*D* 很容易能分别出样本*x*
> 来自哪个分布，其思想与生成式对抗网络类似。不同之处在于，在噪声对比估计中的判别函数*D*
> 是通过贝叶斯公式计算得到，而生成对抗网络的判别函数*D*
> 是一个需要学习的神经网络。
>
> 基于噪声对比估计的序列模型
> 在计算序列模型的条件概率时，我们也可以利用噪声对比估计的思想来提高计算效率\[[Mnih
> and Kavukcuoglu](\l), [2013](\l), [Mnih and](\l) [Teh](\l),
> [2012](\l)\]。在序列模型中需要建模的分布是*p~θ~*(*v*\|*h*)，原则上噪声分布*q*(*v*\|*h*)
> 应该是依赖于历史信息*h*
> 的条件分布，但实践中一般使用和历史信息无关的分布*q*(*v*)，比如一元模型的分布。
>
> 给定历史信息*h*，我们需要判断词表中每一个词*v*
> 是来自于真实分布还是噪声分布。
>
> *P* (*y* = 1\|*v, h*) = [ *pθ* (*v*\|*h*)]{.underline} *.* (15.88)
>
> 对于一个训练序列**x**~1:*T*~ ，将{(*x~t~, h~t~*)}*T*
> 作为真实样本，从噪声分布中抽取
>
> *K* 个样本(*x*^′^*t,*1*,* · · · *,
> x*^′^*t,k*)。噪声对比估计的目标函数是
>
> 为了简洁起见，这里省略了
>
> [ 1 ]{.underline}
>
> T (K+1)
>
> L(*θ*) =
>
> − Σ*t*=1
>
> log

*P* (*y*

> = 1\|*x~t~, h~t~*
>
> *K*

) +

> *k*=1

log(1

> − *P* (*y*
>
> = 1\|*x*^′^*t,k, h~t~*

))! *.*

> (15.89)
>
> 虽然通过噪声对比估计，将一个\|V\| 类的分类问题转为一个两类分类问题，
> 但是依然需要计算*p~θ~*(*v*\|*h*)，其中仍然涉及到配分函数的计算。为了避免计算配分函数，我们将负对数配分函数−
> log *Z*(*h, θ*) 作为一个可学习的参数*𝑥~h~*（即每一个*h*
> 对应一个参数），这样条件概率*p~θ~*(*v*\|*h*) 重新定义为
>
> *p~θ~*(*v*\|*h*) = exp *s*(*v, h*; *θ*) exp(*𝑥~h~*)*.* (15.90)
>
> 噪声对比估计方法的一个特点是会促使未归一化分布exp *s*(*v, h*; *θ*)
> 可以自己学习到一个近似归一化的分布，并接近真实的数据分布*p~r~*(*v*\|*h*)
> \[[Gutmann](\l) [and Hyvärinen](\l),
> [2010](\l)\]。也就是说，学习出来的exp(*𝑥~h~*) ≈ 1。这样可以直接令
>
> exp(*𝑥~h~*) = 1*,* ∀*h*，并用未归一化的分布exp *s*(*v, h*; *θ*)
> 来代替*p~θ~*(*v*\|*h*)。 [Mnih and Teh](\l) \[[2012](\l)\] 也在实
>
> 公式（[15.88](\l)）可以写为
>
> (*y* = 1\|*v, h*) =
>
> exp *s*(*v, h*; *θ*)

(15.91)

> 验中证实，直接令exp(*𝑥*~h~) = 1 不会影响模型的性能。因为
>
> *p* exp *s*(*v, h*; *θ*) ) + *Kq*(*v*)
>
> = 1
>
> 1 + [ *Kq*(*v*) ]{.underline}
>
> exp *s*(*v,h*;*θ*)
>
> 1
>
> 1 + exp − *s*(*v, h*; *θ*) − log *Kq*(*v*)
>
> (15.92)
>
> (15.93)
>
> 神经网络有大量的参数，这
>
> 些参数足以让模型学习到一个近似归一化的分布。

= 1 + exp( 1

> (15.94)
>
> −(∆*s*(*v, h*; *θ*)))
>
> = *σ*(∆*s*(*v, h*; *θ*))*,* (15.95)
>
> 其中*σ* 为logistic 函数，∆*s*(*v, h*; *θ*) = *s*(*v, h*; *θ*) −
> log(*Kq*(*v*)) 为模型打分（未归一化分布）与放大的噪声分布之间的差。
>
> 在噪声对比估计中，噪声分布*q*(*v*) 的选取也十分关键。首先是从*q*(*v*)
> 中采样要十分容易。另外*q*(*v*) 要和真实数据分布*p~r~*(*v*\|*h*)
> 比较接近，否则分类问题就变得十分容易，不需要学习到一个接近真实分布的*p~θ~*(*v*\|*h*)
> 就可以分出数据来源了。对自然语言的序列模型，*q*(*v*)
> 取一元模型的分布是一个很好的选择。每次迭代噪声样本的个数*K* 取值在25 ∼
> 100 左右。
>
> 总结
> 基于采样的方法并不改变模型的结构，只是近似计算参数梯度。在训练时可以显著提高模型的训练速度，但是在测试阶段依然需要计算配分函数。而基
> 于层次化softmax
> 的方法改变了模型的结构，在训练和测试时都可以加快计算速度。

#### 序列到序列模型

> 在序列生成任务中，有一类任务是输入一个序列，生成另一个序列，比如
> 机器翻译、语音识别、文本摘要、对话系统、图像标题生成等。
>
> 序列到序列（Sequence-to-Sequence，Seq2Seq）是一种条件的序列生成问题，给定一个序列**x**~1:*S*~，生成另一个序列**y**~1:*T*~
> 。输入序列的长度*S* 和输出序列的长度*T*
> 可以不同。比如在机器翻译中，输入源语言，输入为目标语言。图[15.5](\l)给出了基于循环神经网络的序列到序列机器翻译示例。
>
> 图 15.5 基于循环神经网络的序列到序列机器翻译
>
> 序列到序列模型的目标是估计条件概率
>
> *T*
>
> *p~θ~*(**y**~1:*T*~ **x**~1:*S*~) = *p~θ~*(*y~t~* **y**~1:(*t*−1)~*,*
> **x**~1:*S*~)*,* (15.96)
>
> *t*=1
>
> 其中**y***~t~* ∈ V 为词表V 中的某个词。
>
> 给定一组训练数据{(**x***~S~n*

*,* **y***~T~*

> *n*=1

，我们可以使用最大似然估计来训练模

> 型参数。
>
> *N*
>
> max log *p~θ~*(**y**~1:*T*~*n* **x**~1:*S*~*n* )*.* (15.97)
>
> *θ*
>
> *n*=1
>
> 一旦训练完成，模型就可以根据一个输入序列**x** 来生成最可能的目标序列，
>
> **y**ˆ = arg max *p~θ~*(**y x**)*,* (15.98)
>
> **y**
>
> 具体的生成过程可以通过贪婪方法或束搜索来完成。
>
> 和一般的序列生成模型类似，条件概率 *p~θ~*(*y~t~*\|**y**~1:(*t*−1)~*,*
> **x**~1:*S*~)
> 可以使用各种不同的神经网络来实现。这里我们介绍三种主要的序列到序列模型。

###### 基于循环神经网络的序列到序列模型

> 实现序列到序列的最直接方法是使用两个循环神经网络来分别进行编码和
> 解码，也称为编码器*-*解码器（Encoder-Decoder）模型。
>
> 编码器 首先使用一个循环神经网络*R*~enc~ 来编码输入序列**x**~1:*S*~
> 得到一个固定维数的向量**u**，**u**
> 一般为编码循环神经网络最后时刻的隐状态。

**h***e* = *f*enc(**h***e*

> *,* **e***~x~*
>
> *, θ*~enc~)*,* ∀*t* ∈ \[1 : *S*\]*,* (15.99)

**u** = **h***e ,* (15.100)

> 其中*f*~enc~(·) 为编码循环神经网络，可以为LSTM
> 或GRU，其参数为*θ*~enc~，**e***~x~* 为词*x* 的词向量。
>
> 解码器 在生成目标序列时，使用另外一个循环神经网络 *R*~dec~
> 来进行解码。在解码过程的第*t*
> 步时，已生成前缀序列为**y**~1:(*t*−1)~。令**h***~t~*
> 表示在网络*R*~dec~ 的隐状态，**o***~t~* ∈ (0*,* 1)\|V\|
> 为词表中所有词的后验概率，则

**h***d* = **u***,* (15.101)

**h***d* = *f*dec(**h***d*

> *,* **e***~y~*
>
> *, θ*~dec~)*,* (15.102)

*t t*−1 *t*−1

> **o***~t~* = *g*(**h***d, θ~o~*)*,* (15.103)
>
> 其中*f*~dec~(·) 为解码循环神经网络，*g*(·) 为最后一层为softmax
> 函数的前馈神经网络，*θ*~dec~ 和*θ~o~* 为网络参数，**e***~y~* 为*y*
> 的词向量，*y*~0~ 为可以为特殊的符号，比如"\$".
>
> 基于循环神经网络的序列到序列模型的缺点是：（1）向量**c**
> 的容量问题，输入序列的信息很难全部保存在一个固定维度的向量中；（2）当序列很长时，由于循环神经网络的长期依赖问题，容易丢失输入序列的信息。

###### 基于注意力的序列到序列模型

> 为了获取更丰富的输入序列信息，我们可以在每一步中通过注意力机制来
> 从输入序列中选取有用的信息。
>
> 长期依赖问题参见第[6.5](\l)节。
>
图片识别内容

> 见https://nndl. github.io/v/sgm-seq2seq
>
> 在解码过程的第*t* 步时，先用上一步的隐状态**h***d*

−

> 作为查询向量，利用注
>
> 意力机制从所有输入序列的隐状态*H^e^* = \[**h**~1~*e,* · · · *,*
> **h***e* \] 中选择相关信息。

**c***~t~* = **att**(*H^e^,* **h***d*

*S*

> *S*
>
> *e i*
>
> *i*=1

(15.104)

> 注意力机制参见第[8.1.2](\l)节。
>
> = Σ softmax *s*(**h***e,* **h***d*
>
> ) **h***e*
>
> (15.105)
>
> 其中*s*(·) 为注意力打分函数。 注 意 力 打 分 函 数 参 见
>
> 解码器第*t* 步的隐状态为

**h***d* = *f*dec(**h***d*

> *,* \[**e***~y~*
>
> ; **c***~t~*\]*, θ*~dec~)*,* (15.106)
>
> 第[8.1.2](\l)节。

*t t*−1

> *t*−1

###### 基于自注意力的序列到序列模型

> 除长期依赖问题外，基于循环神经网络的序列到序列模型的另一个不足是
> 无法并行计算。为了提高并行计算效率以及捕捉长距离的依赖关系，我们可以
> 使用自注意模型来建立一个全连接的网络结构。
>
> 邱锡鹏：《神经网络与深度学习》
>
> 自 注 意 力 模 型 参
> 见第h[8](\l)t[.](\l)t[2](\l)p[.2](\l)s节:/。/nndl.github.io/
>
> 本节介绍一个典型的基于自注意力的序列到序列模型：Transformer\[[Vaswani](\l)
> [et al.](\l), [2017](\l)\]。

1.  自注意力

> subsection 多头自注意力
>
> 对于一个向量序列*H* = \[**h**~1~*,* · · · *,* **h***~T~* \] ∈
> R*dh*×*T* ，首先用自注意力模型来对其进行编码。

**self** -**att**(*Q, K, V* ) = softmax

> *K*T*Q*
>
> *V*
>
> *d~h~*
>
> *,* (15.107)
>
> *Q* = *W~Q~H, K* = *W~K~X, V* = *W~V~ X,* (15.108)
>
> 其中*d~h~* 是输入向量**h***~t~* 的维度，*W~Q~* ∈ R*dk* ×*dh , W~K~* ∈
> R*dk* ×*dh , W~V~* ∈ R*dv* ×*dh* 为三个投影矩阵。

2.  多头自注意力

> 自注意力模型可以看作是在一个线性投影空间中建立向量 *H*
> 之间交互关系。为了提取更多的交互信息，我们可以使用多头注意力，在多个不同的投影
> 空间中捕捉不同的交互信息。
>
> **MultiHead**(*H*) = *W~O~*\[**head**~1~; · · · ; **head***~M~* \]*,*
> (15.109)
>
> **head***~m~* = **self** -**att**(*Q~m~, K~m~, V~m~*)*,* (15.110)
>
> ∀*m* ∈ \[1 : *M* \]*, Q~m~* = *W^m^H, K* = *W^m^X, V* = *W^m^X,*
> (15.111)
>
> 其中*W~O~* ∈ R*dh*×*Mdv* 为输出投影矩阵，*W^m^* ∈ R*dk* ×*dh , W^m^* ∈
> R*dk* ×*dh , W^m^* ∈
>
> *Q K V*
>
> R*dv* ×*dh* 为投影矩阵，*m* ∈ \[1*, M* \]。

3.  基于自注意力模型的序列编码

> 对于一个序列**x**~1:*T*~
> ，我们可以构建一个多层的多头自注意力来对其进行编码。由于自注意力模型忽略了输入信息的位置信息，因此初始的输入序列中加
> 入位置编码信息来进行修正。对于一个输入序列**x**~1:*T*~ ，
>
> *H*^(0)^ = \[**e***~x~*1 ⊕ **p**~1~*,* · · · *,* **e***~x~T* ⊕
> **p***~T~* \]*,* (15.112)
>
> 其中**e***~x~t* 为词*x~t~* 的嵌入向量表示，**p***~t~* 为位置*t*
> 的向量表示。第*l* 层的隐状态**H**(*l*) 为
>
> *Z*^(*l*)^ =norm *H*^(*l*−1)^ + MultiHead *H*^(*l*−1)^ *,* (15.113)
>
> *H*^(*l*)^ =norm **Z**(*l*) + FFN(*Z*^(*l*)^) *,* (15.114)
>
> 其中norm(·) 表示层归一化，FFN(·)
> 表示逐位置的前馈神经网络（Position-wise Feed-Forward
> Network），为一个简单的两层网络。对于输入序列中每个位置上向量**z**，
>
> 层归一化参见第[7.5.2](\l)节。
>
> FFN(**z**) = *W*~2~ReLu(*W*~1~**z** + **b**~1~) + **b**~2~*,* (15.115)
>
> 其中*W*~1~*, W*~2~*,* **b**~1~*,* **b**~2~ 为网络参数。
>
> 基于自注意力模型的序列编码可以看作是一个全连接的前馈神经网络，第 *l*
> 层的每个位置都接受第*l* − 1
> 层的所有位置的输出。不同的是，其连接权重是通过注意力机制动态计算得到。

4.  基于自注意力模型的序列到序列模型

> 将自注意力模型应用在序列到序列任务中，其整个网络结构可以分为两 部分：
>
> 编码器
> 编码器只包含多层的自注意力模块，每一层都接受前一层的输出作为输入。编码器的输入为序列**x**~1:*S*~，输出为一个向量序列*H^e^*
> = \[**h**~1~*e,* · · · *,* **h***e* \]。
>
> 解码器
> 解码器依是通过自回归的方式来生成目标序列。和编码器不同，解码器可以由以下三个模块构成：

1.  自注意力模块：第*t*
    > 步时，先使用自注意力模型对已生成的前缀序列**y**~1:(*t*−1)~

> 基 于 Transformer 的序 列 到 序 列 生 成 过
> 程见https://nndl.github.io/ v/sgm-seq2seq
>
图片识别内容


进行编码得到*H^d^* = \[**h**~1~*d,* · · · *,* **h***d*
\]。在训练时，解码器的输入为整个目

> 标序列，这时可以通过一个掩码（mask）来阻止每个位置选择其后面的输
> 入信息。

2.  解码器到编码器注意力模块：使用**h***d*

−

> 来从输入序列*H^e^* 中选取有用的信息。
>
> 作为查询向量，通过注意力机制

3.  逐位置的前馈神经网络：使用一个前馈神经网络来综合得到所有信息。

> 将上述三个步骤重复多次，最后通过一个全连接前馈神经网络来计算输出
> 概率。
>
> 图[15.6](\l)给出了Transformer 的网络结构示例。
>
图片识别内容
Output
Probabilities
Softmax
↑
Linear
个
Add&Norm
Feed
Forward
Add&Norm
Add&Norm
Multi-Head
Feed
Attention
Forward
Nx
Add&Norm
Nx
Add&Norm
Masked
Multi-Head
Multi-Head
Attention
Attention
Positional
Positional
Encoding
+
Encoding
Input
Output
Embedding
Embedding
Inputs
Outputs
(shiftedright)

>
> 图 15.6 Transformer 网络结构

#### 总结和深入阅读

> 序列生成模型主要解决序列数据的密度估计和生成问题，是一种在实际应
> 用中十分重要的一类模型。目前主流的序列生成模型都是通过自回归模型。最
> 早的深度序列模型是神经网络语言模型。[Bengio et al.](\l) \[[2003](\l)\]
> 最早提出了基于前馈神经网络的语言模型，随后[Mikolov et al.](\l)
> \[[2010](\l)\] 利用循环神经网络来实现语言模型。[Oord et al.](\l)
> \[[2016](\l)\]
> 针对语音合成任务提出了WaveNet，可以生成接近自然人声的语音。
>
> 为了解决曝光偏差问题，[Venkatraman et al.](\l) \[[2014](\l)\]
> 提出了DAD（Data as
> Demonstrator）算法，即在训练时混合使用真实数据和模型生成的数据，[Bengio](\l)
> [et al.](\l) \[[2015](\l)\] 进一步使用课程学习（Curriculum
> Learning）控制使用两种数据的比例。[Ranzato et al.](\l) \[[2015](\l)\]
> 将序列生成看作是强化学习问题，并使用最大似然估
>
> 15.7 总结和深入阅读 2019 年 4 月 6 日 389
>
> 计来预训练模型，并逐步将训练目标由最大似然估计切换为最大期望回报。[Yu](\l)
> [et al.](\l) \[[2017](\l)\]
> 进一步利用对抗生成网络的思想来进行文本生成。
>
> 由于深度序列模型在输出层使用softmax进行归一化，计算代价很高。[Ben-](\l)
> [gio and Senécal](\l) \[[2008](\l)\]
> 提出了利用重要性采样来加速softmax的计算，[Mnih and](\l)
> [Kavukcuoglu](\l) \[[2013](\l)\]
> 提出了噪声对比估计来计算非归一化的条件概率，[Morin](\l) [and
> Bengio](\l) \[[2005](\l)\] 最早使用了层次化softmax
> 函数来近似扁平的softmax 函数。
>
> 在序列生成任务，序列到序列生成是一类十分重要的任务类型。[Sutskever](\l)
> [et al.](\l) \[[2014](\l)\]
> 最早使用循环神经网络来进行机器翻译，[Bahdanau et al.](\l)
> \[[2014](\l)\]
> 使用注意力模型来改进循环神经网络的长期依赖问题，[Gehring et al.](\l)
> \[[2017](\l)\]
> 提出了基于卷积神经网络的序列到序列模型。目前最成功的序列到序列模型是全连
> 接的自注意力模型，比如Transformer\[[Vaswani et al.](\l),
> [2017](\l)\]。
>
> Texar[1](\l)提供了一个非常好的序列生成工具，提供了很多主流的序列生成模型。

#### 习题

> 习题 **15-1** 证明公式([15.19](\l))。
>
> 习题 **15-2** 通过文献了解N 元模型中Good-Turing 平滑，Kneser-Ney
> 平滑的原理。
>
> 习题 **15-3** 试通过注意力机制来动态计算公式([15.24](\l))中的权重。
>
> 习题 **15-4** 给定一个生成序列"The cat sat on the mat"和两个参考序列
>
> "The cat is on the mat"、"The bird sat on the bush"，分别计算BLEU-2 和
> ROUGE-2 得分。
>
> 习题 **15-5** 描述束搜索的实现算法。
>
> 习题 **15-6**
> 根据公式([15.89](\l))和([15.95](\l))，计算噪声对比估计的参数梯度，并分析其和重要性采样中参数梯度（公式（[15.80](\l)））的异同点。
>
> 1 https://github.com/asyml/texar
>
> 390 2019 年 4 月 6 日 参考文献

#### 参考文献

> Dzmitry Bahdanau, Kyunghyun Cho, and Yoshua Bengio. Neural machine
> translation by jointly learning to align and translate. *ArXiv
> e-prints*, September 2014.
>
> Samy Bengio, Oriol Vinyals, Navdeep Jaitly, and Noam Shazeer.
> Scheduled sam- pling for sequence prediction with recurrent neural
> networks. In *Advances in Neural In- formation Processing Systems*,
> pages 1171-- 1179, 2015.
>
> Yoshua Bengio and Jean-Sébastien Senécal. Adaptive importance sampling
> to accelerate training of a neural probabilistic language model. *IEEE
> Transactions on Neural Net- works*, 19(4):713--722, 2008.
>
> Yoshua Bengio, Rejean Ducharme, and Pas- cal Vincent. A neural
> probabilistic language model. *Journal of Machine Learning Re-
> search*, 3:1137--1155, 2003.
>
> Jonas Gehring, Michael Auli, David Grang- ier, Denis Yarats, and Yann
> N Dauphin. Convolutional sequence to sequence learn- ing. In
> *Proceedings of the 34th Interna- tional Conference on Machine
> Learning*, pages 1243--1252, 2017.
>
> Michael Gutmann and Aapo Hyvärinen. Noise-contrastive estimation: A
> new esti- mation principle for unnormalized statisti- cal models. In
> *AISTATS*, 2010.
>
> Tomas Mikolov, Martin Karaﬁát, Lukas Burget, Jan Cernocky\`, and
> Sanjeev Khu- danpur. Recurrent neural network based language model. In
> *Interspeech*, volume 2, page 3, 2010.
>
> George A Miller. Wordnet: a lexical database for english.
> *Communications of the ACM*, 38(11):39--41, 1995.
>
> Andriy Mnih and Koray Kavukcuoglu. Learning word embeddings eﬃciently
> with noise-contrastive estimation. In *Advances in Neural Information
> Processing Systems*, pages 2265--2273, 2013.
>
> Andriy Mnih and Yee Whye Teh. A fast and simple algorithm for training
> neural prob- abilistic language models. *arXiv preprint*
> *arXiv:1206.6426*, 2012.
>
> Frederic Morin and Yoshua Bengio. Hierar- chical probabilistic neural
> network language model. In *Aistats*, volume 5, pages 246--252, 2005.
>
> Aaron van den Oord, Sander Dieleman, Heiga Zen, Karen Simonyan, Oriol
> Vinyals, Alex Graves, Nal Kalchbrenner, Andrew Se- nior, and Koray
> Kavukcuoglu. Wavenet: A generative model for raw audio. *arXiv*
> *preprint arXiv:1609.03499*, 2016.
>
> Marc'Aurelio Ranzato, Sumit Chopra, Michael Auli, and Wojciech
> Zaremba. Sequence level training with recur- rent neural networks.
> *arXiv preprint* *arXiv:1511.06732*, 2015.
>
> Ilya Sutskever, Oriol Vinyals, and Quoc VV Le. Sequence to sequence
> learning with neu- ral networks. In *Advances in Neural In- formation
> Processing Systems*, pages 3104-- 3112, 2014.
>
> Ashish Vaswani, Noam Shazeer, Niki Parmar, Jakob Uszkoreit, Llion
> Jones, Aidan N. Gomez, Lukasz Kaiser, and Illia Polosukhin. Attention
> is all you need. In *Advances in Neural Information Processing*
> *Systems*, pages 6000--6010, 2017.
>
> Arun Venkatraman, Byron Boots, Martial Hebert, and J Andrew Bagnell.
> Data as demonstrator with applications to system identiﬁcation. In
> *ALR Workshop, NIPS*, 2014.
>
> Ronald J Williams and David Zipser. A learning algorithm for
> continually running fully recurrent neural networks. *Neural*
> *computation*, 1(2):270--280, 1989.
>
> Lantao Yu, Weinan Zhang, Jun Wang, and Yong Yu. Seqgan: Sequence
> generative adversarial nets with policy gradient. In *Thirty-First
> AAAI Conference on Artiﬁcial Intelligence*, 2017.
>
> 数学基础
>
> 本附录介绍一些深度学习涉及的数学基础知识，包括线性代数、微积分、数值
> 优化、概率论和信息论等。

A.  线性代数

> 线性代数主要包含向量、向量空间（或称线性空间）以及向量的线性变换和有
> 限维的线性方程组。

###### 向量

> **A.1** 向量和向量空间
>
> 标量（Scalar）是一个实数，只有大小，没有方向。而向量（Vector）是由
> 一组实数组成的有序数组，同时具有大小和方向。一个*n* 维向量**a**
> 是由*n* 个有序实数组成，表示为
>
> **a** = \[*a*~1~*, a*~2~*,* · · · *, a~n~*\]*,* (A.1)
>
> 其中*a~i~* 称为向量**a** 的第*i* 个分量，或第*i*
> 维。向量符号一般用黑体小写字母**a***,* **b***,* **c**，
> 或小写希腊字母*α, β, γ* 等来表示。

###### 向量空间

> 向量空间（Vector Space），也称线性空间（Linear
> Space），是指由向量组成的集合，并满足以下两个条件：

1.  向量加法+：向量空间V 中的两个向量**a** 和**b**，它们的和**a** +
    > **b** 也属于空间V；

2.  标量乘法·：向量空间V 中的任一向量**a** 和任一标量*c*，它们的乘积*c*
    > · **a** 也属于空间V。

> 欧氏空间 一个常用的线性空间是欧氏空间（Euclidean
> Space）。一个欧氏空间表示通常为R*n*，其中*n*
> 为空间维度（Dimension）。欧氏空间中向量的加法和标量乘法定义为：

\[*a*~1~*, a*~2~*,* · · · *, a~n~*\] + \[*b*~1~*, b*~2~*,* · · · *,
b~n~*\] = \[*a*~1~ + *b*~1~*, a*~2~ + *b*~2~*,* · · · *, a~n~* +
*b~n~*\]*,* (A.2)

*c*\[*a*~1~*, a*~2~*,* · · · *, a~n~*\] = \[*ca*~1~*, ca*~2~*,* · · · *,
ca~n~*\]*,* (A.3)

> 其中*a, b, c* ∈ R 为一个标量。
>
> 线性子空间 向量空间V 的线性子空间𝐶 是V
> 的一个子集，并且满足向量空间的条件（向量加法和标量乘法）。
>
> 线性无关 线性空间V 中的一组向量{**v**~1~*,* **v**~2~*,* · · · *,*
> **v***~n~*}，如果对任意的一组标量*λ*~1~*, λ*~2~*,* · · · *,
> λ~n~*，满足*λ*~1~**v**~1~ + *λ*~2~**v**~2~ + · · · + *λ~n~***v***~n~*
> = 0，则必然 *λ*~1~ = *λ*~2~ = · · · = *λ~n~* = 0，那么{**v**~1~*,*
> **v**~2~*,* · · · *,* **v***~n~*} 是线性无关的，也称为线性独立的。
>
> 基向量 向量空间V 的基（Base）B = {**e**~1~*,* **e**~2~*,* · · · *,*
> **e***~n~*} 是V 的有限子集，其元素之间线性无关。向量空间V
> 所有的向量都可以按唯一的方式表达为 B 中向量的线性组合。对任意*v* ∈
> V，存在一组标量(*λ*~1~*, λ*~2~*,* · · · *, λ~n~*) 使得

**v** = *λ*~1~**e**~1~ + *λ*~2~**e**~2~ + · · · + *λ~n~***e***~n~,*
(A.4)

> 其中基B 中的向量称为基向量（Base Vector）。如果基向量是有序的，则标量
>
> (*λ*~1~*, λ*~2~*,* · · · *, λ~n~*) 称为向量**v** 关于基B
> 的坐标（Coordinates）。*n* 维空间V 的一组标准基（Standard Basis）为
>
> **e**~1~ = \[1*,* 0*,* 0*,* · · · *,* 0\]*,* (A.5)
>
> **e**~2~ = \[0*,* 1*,* 0*,* · · · *,* 0\]*,* (A.6)

· · · (A.7)

> **e***~n~* = \[0*,* 0*,* 0*,* · · · *,* 1\]*,* (A.8)
>
> V 中的任一向量**v** = \[*v*~1~*, v*~2~*,* · · · *, v~n~*\]
> 可以唯一的表示为

\[*v*~1~*, v*~2~*,* · · · *, v~n~*\] = *v*~1~**e**~1~ + *v*~2~**e**~2~ +
· · · + *v~n~***e***~n~,* (A.9)

> *v*~1~*, v*~2~*,* · · · *, v~n~* 也称为向量**v**
> 的笛卡尔坐标（Cartesian
> Coordinate）。向量空间中的每个向量可以看作是一个线性空间中的笛卡儿坐标。
>
> 内积 一个*n* 维线性空间中的两个向量**a** 和**b**，其内积为
>
> *n*
>
> **a***,* **b** = *a~i~b~i~,* (A.10)
>
> *i*=1

1.  向量和向量空间 2019 年 4 月 6 日 393

图片识别内容


> *p* = 1 *p* = 2 *p* = ∞ *p* = ^1^
>
> 图 A.1 常见的范数。红线表示不同范数的*ℓ~p~* = 1 的点。
>
> 正交
> 如果向量空间中两个向量的内积为0，则它们正交（Orthogonal）。如果向量空间中一个向量**v**
> 与子空间𝐶 中的每个向量都正交，那么向量**v** 和子空间
>
> 𝐶 正交。

###### 范数

> 范数（Norm）是一个表示向量"长度"的函数，为向量空间内的所有向量赋予非零的正长度或大小。对于一个*n*
> 维向量**v**，一个常见的范数函数为*ℓ~p~* 范数，

*ℓ~p~*(**v**)

> ≡ ∥**v**∥*~p~*
>
> = *n*
>
> *i*=1
>
> \|*v~i~*\|

1*/p*

*,*

> (A.11)
>
> 其中*p* ≥ 0 为一个标量的参数。常用的*p* 的取值有1，2，∞ 等。
>
> *ℓ*~1~ 范数 *ℓ*~1~ 范数为向量的各个元素的绝对值之和。

*n*

> **v** ~1~ = *v~i~ .* (A.12)
>
> *i*=1
>
> *ℓ*~2~ 范数 *ℓ*~2~ 范数为向量的各个元素的
>
> *n*

**v** ~2~ =

> *i*=1
>
> *v*^2^ =
>
> [ ]{.underline}
>
> **v**T**v***.* (A.13)
>
> *ℓ*~2~ 范数又称为*Euclidean* 范数或者*Frobenius*
> 范数。从几何角度，向量也可以表示为从原点出发的一个带箭头的有向线段，其*ℓ*~2~
> 范数为线段的长度，也常称为向量的模。
>
> *ℓ*~∞\ 范数\ *ℓ*∞\ 范数为向量的各个元素的最大绝对值，~
>
> ∥**v**∥~∞~ = max{*v*~1~*, v*~2~*,* · · · *, v~n~*}*.* (A.14)
>
> 图[A.1](\l)给出了常见范数的示例。

###### 常见的向量

> 全*0* 向量指所有元素都为0 的向量，用**0** 表示。全0
> 向量为笛卡尔坐标系中的原点。
>
> 全*1* 向量指所有值为1 的向量，用**1** 表示。
>
> *one-hot* 向量为有且只有一个元素为1，其余元素都为0 的向量。one-hot
> 向量是在数字电路中的一种状态编码，指对任意给定的状态，状态寄存器中只有
> l 位为1，其余位都为0。

1.  线性映射

<!-- -->

2.  矩阵

> 线性映射（Linear Mapping）是指从线性空间V 到线性空间𝑌
> 的一个映射函数*f* : V → 𝑌，并满足：对于V 中任何两个向量**u** 和**v**
> 以及任何标量*c*，有

*f* (**u** + **v**) = *f* (**u**) + *f* (**v**)*,* (A.15)

*f* (*c***v**) = *cf* (**v**)*.* (A.16)

> 两个有限维欧氏空间的映射函数*f* : R*n* → R*m* 可以表示为
>
>  *a*~11~*x*~1~ + *a*~12~*x*~2~ + · · · + *a*~1*n*~*x~n~* 
>
> **y** = *A***x** , *a*~21~*x*~1~ + *a*~22~*x*~2~ + · · · +
> *a*~2*n*~*x~n~*
>
>  . 
>
>  
>
> *a~m~*~1~*x*~1~ + *a~m~*~2~*x*~2~ + · · · + *a~mn~x~n~*
>
> 其中*A* 定义为*m* × *n* 的矩阵（Matrix），是一个由*m* 行*n*
> 列元素排列成的矩形阵列。一个矩阵*A* 从左上角数起的第*i* 行第*j*
> 列上的元素称为第*i, j* 项，通常记为\[*A*\]*~ij~* 或*a~ij~*。矩阵*A*
> 定义了一个从R*n* 到R*m* 的线性映射；向量**x** ∈ R*n* 和**y** ∈
> R*m*分别为两个空间中的列向量，即大小为*n* × 1 的矩阵。
>
>  *x*1   *y*1 
>
> **x** =   *,* **y** =   *.* (A.18)
>
> 如果没有特别说明，本书默
>
>  *xn*  *ym*

认向量为列向量。
为简化书写、方便排版起见，本书约定逗号隔离的向量表示\[*x*~1~*, x*~2~*,*
· · · *, x~n~*\]

为行向量，列向量通常用分号隔开的表示**x** = \[*x*~1~; *x*~2~; · · · ;
*x~n~*\]，或行向量的转

> 置\[*x*~1~*, x*~2~*,* · · · *, x~n~*\]T。

###### 矩阵操作

> 加 如果*A* 和*B* 都为*m* × *n* 的矩阵，则*A* 和*B* 的加也是*m* × *n*
> 的矩阵，其每个元素是A 和B 相应元素相加。
>
> \[*A* + *B*\]*~ij~* = *a~ij~* + *b~ij~.* (A.19)
>
> 乘积 假设有两个*A* 和*B* 分别表示两个线性映射*g* : R*m* → R*k* 和*f* :
> R*n* → R*m*， 则其复合线性映射
>
> (*g* ◦ *f* )(**x**) = *g*(*f* (**x**)) = *g*(*B***x**) = *A*(*B***x**)
> = (*AB*)**x***,* (A.20)
>
> 其中*AB* 表示矩阵*A* 和*B* 的乘积，定义为

*m*

> \[*AB*\]*~ij~* = *a~ik~b~kj~.* (A.21)
>
> *k*=1
>
> 两个矩阵的乘积仅当第一个矩阵的列数和第二个矩阵的行数相等时才能定义。
> 如*A* 是*k* × *m* 矩阵和*B* 是*m* × *n* 矩阵，则乘积*AB* 是一个*k* ×
> *n* 的矩阵。
>
> 矩阵的乘法满足结合律和分配律：

-   结合律：(*AB*)*C* = *A*(*BC*),

-   分配律：(*A* + *B*)*C* = *AC* + *BC*，*C*(*A* + *B*) = *CA* + *CB*.

> **Hadamard** 积 *A* 和*B* 的*Hadamard* 积，也称为逐点乘积，为*A* 和*B*
> 中对应的元素相乘。
>
> \[*A* ⊙ *B*\]*~ij~* = *a~ij~b~ij~.* (A.22)
>
> 一个标量*c* 与矩阵*A* 乘积为*A* 的每个元素是*A* 的相应元素与*c* 的乘积
>
> \[*cA*\]*~ij~* = *ca~ij~.* (A.23)
>
> 转置 *m* × *n* 矩阵*A* 的转置（Transposition）是一个*n* × *m*
> 的矩阵，记为*A*T，*A*T
>
> 的第i 行第j 列的元素是原矩阵*A* 的第j 行第i 列的元素，
>
> \[*A*T\]*~ij~* = \[*A*\]*~ji~.* (A.24)
>
> 向量化 矩阵的向量化是将矩阵表示为一个列向量。这里，**vec**
> 是向量化算子。设*A* = \[*a~ij~*\]~*m*×*n*~，则
>
> **vec**(*A*) = \[*a*~11~*, a*~21~*,* · · · *, a~m~*~1~*, a*~12~*,
> a*~22~*,* · · · *, a~m~*~2~*,* · · · *, a*~1*n*~*, a*~2*n*~*,* · · ·
> *, a~mn~*\]T*.*
>
> 迹 方块矩阵*A*
> 的对角线元素之和称为它的迹（Trace），记为*tr*(*A*)。尽管矩阵的乘法不满足交换律，但它们的迹相同，即*tr*(*AB*)
> = *tr*(*BA*)。
>
> 行列式 方块矩阵*A* 的行列式是一个将其映射到标量的函数，记作det(*A*)
> 或\|*A*\|。行列式可以看做是有向面积或体积的概念在欧氏空间中的推广。在*n*
> 维欧氏空间中，行列式描述的是一个线性变换对"体积"所造成的影响。
>
> 一个*n* × *n* 的方块矩阵*A* 的行列式定义为：
>
> det(*A*) = Σ sgn(*σ*) Y *a~i,σ~*~(*i*)~ (A.25)
>
> 其中*S~n~* 是{1*,* 2*, \..., n*} 的所有排列的集合，*σ*
> 是其中一个排列，*σ*(*i*) 是元素*i* 在排列*σ* 中的位置，sgn(*σ*)
> 表示排列*σ* 的符号差，定义为

(*σ*) = 

> 1 *σ*中的逆序对有偶数个
>
> (A.26)
>
> −1 *σ*中的逆序对有奇数个
>
> 其中逆序对的定义为：在排列*σ* 中，如果有序数对(*i, j*) 满足1 ≤ *i \<
> j* ≤ *n* 但*σ*(*i*) *\> σ*(*j*)，则其为*σ* 的一个逆序对。
>
> 秩 一个矩阵 *A* 的列秩是 *A* 的线性无关的列向量数量，行秩是 *A*
> 的线性无关的行向量数量。一个矩阵的列秩和行秩总是相等的，简称为秩（Rank）。
>
> 一个*m*×*n* 的矩阵的秩最大为min(*m, n*)。两个矩阵的乘积*AB*
> 的秩rank(*AB*) ≤
>
> min rank(*A*)*,* rank(*B*) 。
>
> 范数 矩阵的范数有很多种形式，其中常用的*ℓ~p~* 范数定义为

∥*A*∥*~p~* =

> Σ*m* Σ
>
> \|*a~ij~*\|
>
> 1*/p*

*.* (A.27)

###### 矩阵类型

> *i*=1 *j*=1
>
> 对称矩阵 对称矩阵（Symmetric Matrix）指其转置等于自己的矩阵，即满足
>
> *A* = *A*T。
>
> 对角矩阵 对角矩阵（Diagonal Matrix）是一个主对角线之外的元素皆为0
> 的矩阵。对角线上的元素可以为0 或其他值。一个*n* × *n* 的对角矩阵*A*
> 满足：

\[*A*\]*~ij~* = 0 if *i*

> *j* ∀*i, j* ∈ {1*,* · · · *, n*} (A.28)
>
> 对角矩阵*A* 也可以记为diag(**a**)，**a** 为一个*n* 维向量，并满足
>
> \[*A*\]*~ii~* = *a~i~.* (A.29)
>
> *n* × *n* 的对角矩阵*A* = diag(**a**) 和*n* 维向量**b**
> 的乘积为一个*n* 维向量
>
> *A***b** = diag(**a**)**b** = **a** ⊙ **b***,* (A.30)
>
> 其中⊙ 表示点乘，即(**a** ⊙ **b**)*~i~* = *a~i~b~i~*。
>
> 单位矩阵 单位矩阵（Identity
> Matrix）是一种特殊的的对角矩阵，其主对角线元素为1，其余元素为0。*n*
> 阶单位矩阵**I***~n~*，是一个*n* × *n* 的方块矩阵。可以记为 **I***~n~*
> = diag(1*,* 1*, \...,* 1)。
>
> 一个*m* × *n* 的矩阵A 和单位矩阵的乘积等于其本身。
>
> *A***I***~n~* = **I***~m~A* = *A.* (A.31)
>
> 逆矩阵 对于一个*n* × *n* 的方块矩阵*A*，如果存在另一个方块矩阵*B* 使得
>
> *AB* = *BA* = **I***~n~* (A.32)
>
> 为单位阵，则称*A* 是可逆的。矩阵*B* 称为矩阵*A* 的逆矩阵（Inverse
> Matrix）， 记为*A*^−1^。
>
> 一个方阵的行列式等于0 当且仅当该方阵不可逆。
>
> 正定矩阵 对于一个 *n* × *n* 的对称矩阵 *A*，如果对于所有的非零向量
> **x** ∈ R*n*
>
> 都满足
>
> **x**T*Ax \>* 0*,* (A.33)
>
> 则*A* 为正定矩阵（Positive-Deﬁnite Matrix）。如果**x**T*Ax* ≥ 0，则*A*
> 是半正定矩阵（Positive-Semideﬁnite Matrix）。
>
> 正交矩阵 正交矩阵（Orthogonal Matrix ）*A*
> 为一个方块矩阵，其逆矩阵等于其转置矩阵。
>
> *A*T = *A*^−1^*,* (A.34)
>
> 等价于*A*T*A* = *AA*T = **I***~n~*。
>
> **Gram** 矩阵 向量空间中一组向量 **v**~1~*,* **v**~2~ · · · *,*
> **v***~n~* 的 *Gram* 矩阵（Gram Matrix）
>
> *G* 是内积的对称矩阵，其元素*G**~ij~* 为 **v**T**v***~j~*。

###### 特征值与特征矢量

> 如果一个标量*λ* 和一个非零向量**v** 满足

*A***v** = *λ***v***,* (A.35)

则*λ* 和**v** 分别称为矩阵*A*
的特征值（Eigenvalue）和特征向量（Eigenvector）。

###### 矩阵分解

> 一个矩阵通常可以用一些比较"简单"的矩阵来表示，称为矩阵分解（Matrix
> Decomposition, Matrix Factorization）。
>
> 奇异值分解 一个*m*×*n* 的矩阵*A* 的奇异值分解（Singular Value
> Decomposition， SVD）定义为
>
> *A* = *U* Σ*V* T*,* (A.36)
>
> 其中*U* 和*V* 分别为*m* × *m* 和*n* × *n* 的正交矩阵，Σ 为*m* × *n*
> 的对角矩阵，其对角线上的元素称为奇异值（Singular Value）。
>
> 特征分解 一个*n* × *n* 的方块矩阵*A*
> 的特征分解（Eigendecomposition）定义为
>
> *A* = *Q*Λ*Q*^−1^*,* (A.37)
>
> 其中*Q* 为*n* × *n* 的方块矩阵，其每一列都为*A* 的特征向量，
> 为对角阵，其每一个对角元素为*A* 的特征值。
>
> 如果*A* 为对称矩阵，则*A* 可以被分解为
>
> *A* = *Q*Λ*Q*T*,* (A.38)
>
> 其中*Q* 为正交阵。

微积分
------

> 2019 年 4 月 6 日 399

#### 导数

> 导数（Derivative）是微积分学中重要的基础概念。
>
> 对于定义域和值域都是实数域的函数*f* : R → R，若*f* (*x*) 在点*x*~0~
> 的某个邻域∆*x* 内，极限

*f* ^′^(*x*~0~) = lim

∆*x*→0

> [*f*(*x*~0~ + ∆*x*)]{.underline} [*f*(*x*~0~)]{.underline}
>
> ∆*x*
>
> (B.1)
>
> 存在，则称函数*f* (*x*) 在点*x*~0~ 处可导，*f* ^′^(*x*~0~)
> 称为其导数，或导函数，也可以记为 [d*f* (*x*0)]{.underline} 。
>
> *x*
>
> 在几何上，导数可以看做函数曲线上的切线斜率。图[B.1](\l)给出了一个函数导数的可视化示例，其中函数*g*(*x*)
> 的斜率为函数*f* (*x*) 在点*x* 的导数，∆*y* = *f* (*x* +
>
> ∆*x*) − *f* (*x*)。
>
> *y*
>
> 3
>
> 2
>
> 1
>
> 0 *x*
>
> 0 1 2 3
>
> 图 B.1 函数*f* (*x*) = log(*x*) + 1 的导数
>
> 给定一个连续函数，计算其导数的过程称为微分（Diﬀerentiation）。微分
> 的逆过程为积分（Integration）。函数*f* (*x*) 的积分可以写为
>
> *F* (*x*) = ∫ *f* (*x*)d*x,* (B.2)
>
> 其中*F* (*x*) 称为*f* (*x*) 的原函数。
>
> 若函数*f* (*x*)
> 在其定义域包含的某区间内每一个点都可导，那么也可以说函数 *f* (*x*)
> 在这个区间内可导。如果一个函数 *f* (*x*)
> 在定义域中的所有点都存在导数，则*f* (*x*) 为可微函数（Diﬀerentiable
> Function）。可微函数一定连续，但连续函数不一定可微。例如函数\|*x*\|
> 为连续函数，但在点*x* = 0 处不可导。
>
> 表[B.1](\l)给出了几个常见函数的导数。

+-----------------------+-----------------------+-----------------------+
| 函数                  | > 函数形式            | > 导数                |
+-----------------------+-----------------------+-----------------------+
| 常函数                | > *f* (*x*) =         | > *f* ^′^(*x*) = 0    |
|                       | > *C*，其中*C* 为常数 |                       |
+-----------------------+-----------------------+-----------------------+
| 幂函数                | > *f* (*x*) =         | > *f* ^′^(*x*) =      |
|                       | > *x^r^*，其中*r*     | > *rx^r^*^−1^         |
|                       | > 是非零实数          |                       |
+-----------------------+-----------------------+-----------------------+
| 指数函数              | > *f* (*x*) =         | > *f* ^′^(*x*) =      |
|                       | > exp(*x*)            | > exp(*x*)            |
+-----------------------+-----------------------+-----------------------+

> 对数函数 *f* (*x*) = log(*x*) *f* ^′^(*x*) = [1]{.underline}
>
> 表 B.1 几个常见函数的导数
>
> 高阶导数 对一个函数的导数继续求导，可以得到高阶导数。函数 *f* (*x*)
> 的导数
>
> *f* ^′^(*x*) 称为一阶导数，*f* ^′^(*x*) 的导数称为二阶导数，记为*f*
> ^′′^(*x*) 或 ^d^2*f* (*x*) 。
>
> 偏导数 对于一个多变量函数*f* : R*d* → R，它的偏导数（Partial
> Derivative ）是关于其中一个变量*x~i~*
> 的导数，而保持其他变量固定，可以记为*fx*′ *i* (**x**)，𝖮*~x~i f*
> (**x**)，
>
> [*∂f* (**x**)]{.underline} 或 [* ∂ *]{.underline} *f* (**x**)。
>
> *∂xi ∂xi*
>
> 对于一个*d* 维向量**x** ∈ R*d*，函数*f* (**x**) = *f* (*x*~1~*,* · · ·
> *, x~d~*) ∈ R，则*f* (**x**) 关于**x**

的偏导数为

>  [*∂f* (**x**)]{.underline} 

*∂f* (**x**) = 

> *∂x*1
>
> .
>
>  ∈ R*^d^.* (B.3)
>
> *∂***x** [ ]{.underline}
>
> *∂f* (**x**)
>
> *∂x~d~*
>
> 若函数*f* (**x**) ∈ R*k* 的值也为一个向量，则*f* (**x**) 关于**x**
> 的偏导数为

 [*∂f*1(**x**)]{.underline}

> [(**x**)]{.underline}
>
> · · ·

*∂f* (**x**)

*∂x ∂x*

 . 

> 称为*Jacobian* 矩阵。
>
> [*∂f*1(**x**)]{.underline}
>
> *∂x~d~*
>
> [(**x**)]{.underline}
>
> · · · *~∂x~d*
>
> B.1 导数 2019 年 4 月 6 日 401

###### 导数法则

> 一个复杂函数的导数的计算可以通过以下法则来简化。

1.  加（减）法则

> **y** = *f* (**x**),**z** = *g*(**x**) 则
>
> [*∂*(**y** + **z**)]{.underline} = [*∂***y**]{.underline} +
> [*∂***z**]{.underline} *.* (B.5)

*∂***x** *∂***x** *∂***x**

2.  乘法法则

    1.  若**x** ∈ R*p*，**y** = *f* (**x**) ∈ R*q* ，**z** = *g*(**x**)
        > ∈ R*q* ，则

> *∂***y**T**z** = [*∂***y**]{.underline}**z** + [*∂***z**]{.underline}
> **y**
>
> (B.6)

*∂***x** *∂***x** *∂***x**

2.  若**x** ∈ R*p*，**y** = *f* (**x**) ∈ R*s*，**z** = *g*(**x**) ∈
    R*t*，*A* ∈ R*s*×*t* 和**x** 无关，则

*∂***y**T*A***z** = [*∂***y**]{.underline}

*A***z** +

> [*∂***z**]{.underline} T
>
> *A*

**y***.* (B.7)

*∂***x** *∂***x** *∂***x**

3.  若**x** ∈ R*p*，*y* = *f* (**x**) ∈ R，**z** = *g*(**x**) ∈ R*p*，则

> [*∂y***z**]{.underline} = *y [∂]{.underline}***[z]{.underline}** +
> *∂y* **z**T*.* (B.8)

*∂***x** *∂***x** *∂***x**

3.  链式法则

> 链式法则（Chain
> Rule），是求复合函数导数的一个法则，是在微积分中计算导数的一种常用方法[^1^](\l)。

1.  若**x** ∈ R*p*，**y** = *g*(**x**) ∈ R*s*，**z** = *f* (**y**) ∈
    > R*t*，则

> [*∂***z**]{.underline} = [*∂***y** *∂***z**]{.underline} *.* (B.9)

*∂***x** *∂***x** *∂***y**

2.  若*X* ∈ R*p*×*q* 为矩阵，*Y* = *g*(*X*) ∈ R*s*×*t*，*𝑥* = *f* (*Y* )
    > ∈ R，则

> [* ∂𝑥 *]{.underline} = tr ( [* ∂𝑥*]{.underline} )T [* ∂Y
> *]{.underline} *.* (B.10)

3.  若*X* ∈ R*p*×*q* 为矩阵，**y** = *g*(*X*) ∈ R*s*，*𝑥* = *f* (**y**)
    > ∈ R，则

*∂𝑥*

> = ( *∂𝑥* )T *∂***y**
>
> *.* (B.11)

*∂X~ij~*

> *∂***y** *∂X~ij~*

4.  若*x* ∈ R，**u** = *u*(*x*) ∈ R*p*，**g** = *g*(**u**) ∈ R*q* ，则

**g** *∂***g** T *∂***u**

> *[∂]{.underline}* = *.* (B.12)

#### 常见函数的导数

> 这里我们介绍本书中常用的几个函数。

###### 向量函数及其导数

> [*∂***x**]{.underline} = *I,* (B.13)
>
> *∂*
>
> [*∂A***x**]{.underline} = *A*T*,* (B.14)
>
> *∂*
>
> *∂***x**T*A*
>
> *∂***x** *A*
>
> (B.15)

###### 按位计算的向量函数及其导数

> 假设一个函数*f* (*x*) 的输入是标量*x*。对于一组*K* 个标量*x*~1~*,* · ·
> · *, x~K~*，我们可以通过*f* (*x*) 得到另外一组*K* 个标量*𝑥*~1~*,* · ·
> · *, 𝑥~K~*，
>
> *𝑥~k~* = *f* (*x~k~*)*,* ∀*k* = 1*,* · · · *, K* (B.16)
>
> 为了简便起见，我们定义**x** = \[*x*~1~*,* · · · *, x~K~*\]T，**z** =
> \[*𝑥*~1~*,* · · · *, 𝑥~K~*\]T，
>
> **z** = *f* (**x**)*,* (B.17)
>
> 其中，*f* (**x**) 是按位运算的，即\[*f* (**x**)\]*~i~* = *f*
> (*x~i~*)。
>
> 当*x* 为标量时，*f* (*x*) 的导数记为*f* ^′^(*x*)。当输入为*K*
> 维向量**x** = \[*x*~1~*,* · · · *, x~K~*\]T
>
> 时，其导数为一个对角矩阵。

[*∂f*(**x**)]{.underline} = h [*∂f*(*x~j~*)]{.underline} i

(B.18)

>  *f* ^′^(*x*~1~) 0 · · · 0 
>
> 0 *f* ^′^(*x*~2~) · · · 0
>
>  
>
> (B.19)
>
>  
>
> 0 0 · · · *f* ^′^(*x~K~*)
>
> = diag(*f* ^′^(**x**))*.* (B.20)

3.  **Logistic** 函数

> Logistic 函数是一种常用的S 形函数，是比利时数学家 Pierre François Ver-
> hulst 在1844-1845
> 年研究种群数量的增长模型时提出命名的，最初作为一种生态学模型。
>
> B.2 常见函数的导数 2019 年 4 月 6 日 403
>
> −10 −5 0 5 10
>
> 图 B.2 Logistic 函数
>
> Logistic 函数定义为：
>
> logistic(*x*) = 1 + exp( *L*
>
> *,* (B.21)
>
> 这里exp(·) 函数表示自然对数，*x*~0~ 是中心点，*L* 是最大值，*k*
> 是曲线的倾斜度。图[B.2](\l)给出了几种不同参数的logistic
> 函数曲线。当*x* 趋向于−∞ 时，logistic(*x*) 接近于0；当*x* 趋向于+∞
> 时，logistic(*x*) 接近于*L*.
>
> 当参数为(*k* = 1*, x*~0~ = 0*, L* = 1) 时，logistic
> 函数称为标准logistic 函数，记为*σ*(*x*)。
>
> *σ*(*x*) = 1 + exp(−*x*) *.* (B.22)
>
> 标准logistic
> 函数在机器学习中使用得非常广泛，经常用来将一个实数空间的数映射到(0*,*
> 1) 区间。
>
> 标准logistic 函数的导数为
>
> *σ*^′^(*x*) = *σ*(*x*)(1 − *σ*(*x*)) (B.23)
>
> 当输入为*K* 维向量**x** = \[*x*~1~*,* · · · *, x~K~*\]T 时，其导数为
>
> *σ*^′^(**x**) = diag *σ*(**x**) ⊙ (1 − *σ*(**x**)) *.* (B.24)

##### softmax 函数

> softmax 函数是将多个标量映射为一个概率分布。对于*K* 个标量*x*~1~*,* ·
> · · *, x~K~*，softmax 函数定义为
>
> [ exp(*x~k~*) ]{.underline}

*𝑥~k~*

> = softmax(*x~k~*) =
>
> *K*
>
> *i*=1
>
> exp(*x~i~*)

*,* (B.25)

> 这样，我们可以将*K* 个变量*x*~1~*,* · · · *, x~K~*
> 转换为一个分布：*𝑥*~1~*,* · · · *, 𝑥~K~*，满足
>
> *K*

*𝑥~k~* ∈ \[0*,* 1\]*,* ∀*k,*

> *𝑥~k~* = 1*.* (B.26)
>
> *i*=1
>
> 当softmax 函数的输入为*K* 维向量**x** 时，
>
> **z**ˆ = softmax(**x**) (B.27)

[ 1]{.underline} 

> exp(*x*~1~) 

*k*=1

> *k*
>
> exp(*x~K~*)

= [ exp(**x**) ]{.underline}

> (B.29)
>
> *K*
>
> *k*=1
>
> exp(*x~k~*)
>
> exp(**x**)
>
> T exp(**x**)

*,* (B.30)

> 其中，**1***~K~* = \[1*,* · · · *,* 1\]~*K*×1~ 是*K* 维的全1
> 向量。其导数为
>
> *∂* softmax(**x**)
>
> *∂***x**
>
> T exp(**x**
>
> *∂***x**

(B.31)

[ 1 *∂* exp(**x**)]{.underline}

> *∂* **1**T 1
>
> **x**)

= **1**T exp(**x**) *∂***x** +

> exp(
>
> *∂***x**
>
> (exp(**x**))^T^
>
> (B.32)

= [diag (exp(**x**))]{.underline}

> [ 1]{.underline} *∂* **1**T exp(**x**) (exp(**x**))T
>
> (B.33)
>
> **1**T exp(**x**) − (**1**T exp(**x**))2 *∂***x**
>
> diag (exp(**x**)) **1**~K~ = exp(**x**)
>
> = [diag (exp(**x**))]{.underline} − [ 1]{.underline} diag (exp(**x**))
> **1** (exp(**x**))^T^
>
> = [diag (exp(**x**))]{.underline} − [ 1]{.underline} exp(**x**)
> (exp(**x**))^T^
>
> = diag [ exp(**x**)]{.underline} [exp(**x**)]{.underline}
> (exp(**x**))^T^
>
> = diag (softmax(**x**)) − softmax(**x**) softmax(**x**)^T^*.*
>
> (B.34)
>
> (B.35)
>
> (B.36)
>
> (B.37)

数学优化
--------

> 2019 年 4 月 6 日 405
>
> 数学优化（Mathematical
> Optimization）问题，也叫最优化问题，是指在一定约束条件下，求解一个目标函数的最大值（或最小值）问题。
>
> 数学优化问题的定义为：给定一个目标函数（也叫代价函数）*f* : A → R，
> 寻找一个变量（也叫参数）**x**∗ ∈ D，使得对于所有 D 中的 **x**，*f*
> (**x**∗) ≤ *f* (**x**)（最小化）；或者*f* (**x**∗) ≥ *f*
> (**x**)（最大化），其中D 为变量**x** 的约束集，也叫可行域； D
> 中的变量被称为是可行解。

1.  #### 数学优化的类型

    1.  ###### 离散优化和连续优化

> 根据输入变量**x**
> 的值域是否为实数域，数学优化问题可以分为离散优化问题和连续优化问题。

1.  离散优化问题

> 离散优化（Discrete
> Optimization）问题是目标函数的输入变量为离散变量，比如为整数或有限集合中的元素。离散优化问题主要有两个分支：

1.  组合优化（Combinatorial
    > Optimization）：其目标是从一个有限集合中找出使得目标函数最优的元素。在一般的组合优化问题中，集合中的元
    > 素之间存在一定的关联，可以表示为图结构。典型的组合优化问题有旅
    > 行商问题、最小生成树问题、图着色问题等。很多机器学习问题都是组
    > 合优化问题，比如特征选择、聚类问题、超参数优化问题以及结构化学习

> （Structured Learning）中标签预测问题等。

2.  整数规划（Integer Programming）：输入变量**x** ∈ Z*d*
    > 为整数。一般常见的整数规划问题为整数线性规划（Integer Linear
    > Programming，ILP）。整数线性规划的一种最直接的求解方法是：（1）去掉输入必须为整数的限制，将原问题转换为一般的线性规划问题，这个线性规划问题为原问题的松弛问题；（2）求得相应松弛问题的解；（3）把松弛问题的解四舍五入到最接近的整数。但是这种方法得到的解一般都不是最优的，因此原问题的最优解不一定在松弛问题最优解的附近。另外，这种方法得到的解也不一定满足约束条件。

> 离散优化问题的求解一般都比较困难，优化算法的复杂度都比较高。

2.  连续优化问题

> 连续优化（Continuous
> Optimization）问题是目标函数的输入变量为连续变量**x** ∈
> R*d*，即目标函数为实函数。本节后面的内容主要以连续优化为主。

###### 无约束优化和约束优化

> 最优化问题一般可以表示
>
> 在连续优化问题中，根据是否有变量的约束条件，可以将优化问题分为无
> 约束优化问题和约束优化问题。
>
> 无约束优化问题（Unconstrained Optimization）的可行域为整个实数域
>
> D = R*d*，可以写为
>
> 为求最小值问题。求*f* (**x**) 最大值等价于求−*f* (**x**) 的最小值。
>
> min
>
> **x**
>
> *f* (**x**) (C.1)
>
> 拉 格 朗 日 乘 数 法 参 见
>
> 其中**x** ∈ R*d* 为输入变量，*f* : R*d* → R 为目标函数。
>
> 约束优化问题（Constrained Optimization）中变量**x**
> 需要满足一些等式或不等式的约束。约束优化问题通常使用拉格朗日乘数法来进行求解。
>
> ^第[C.3](\l)节。^ **C.1.3** 线性优化和非线性优化
>
> 如果在公式([C.1](\l))
> 中，目标函数和所有的约束函数都为线性函数，则该问题为线性规划问题（Linear
> Programming）。相反，如果目标函数或任何一个约束函数为非线性函数，则该问题为非线性规划问题（Nonlinear
> Programming）
>
> 。
>
> 在非线性优化问题中，有一类比较特殊的问题是凸优化问题（Convex Pro-
> gramming）。在凸优化问题中，变量**x**
> 的可行域为凸集，即对于集合中任意两点，它们的连线全部位于在集合内部。目标函数*f*
> 也必须为凸函数，即满足
>
> *f* (*α***x** + (1 − *α*)**y**) ≤ *αf* (**x**) + (1 − *α*)*f*
> (**y**)*,* ∀*α* ∈ \[0*,* 1\]*.* (C.2)
>
> 凸优化问题是一种特殊的约束优化问题，需满足目标函数为凸函数，并且
> 等式约束函数为线性函数，不等式约束函数为凹函数。

#### 优化算法

> 优化问题一般都是通过迭代的方式来求解：通过猜测一个初始的估计
> **x**~0~， 然后不断迭代产生新的估计**x**~1~*,* **x**~2~*,* · · ·
> **x***~t~*，希望**x***~t~*
> 最终收敛到期望的最优解**x**∗。一个好的优化算法应该是在一定的时间或空间复杂度下能够快速准确地找到最优解。同时，好的优化算法受初始猜测点的影响较小，通过迭代能稳定地找到最优解**x**∗
> 的邻域，然后迅速收敛于**x**∗。
>
> C.2 优化算法 2019 年 4 月 6 日 407
>
> 优化算法中常用的迭代方法有线性搜索和置信域方法等。线性搜索的策略
> 是寻找方向和步长，具体算法有梯度下降法、牛顿法、共轭梯度法等。

1.  全局最优和局部最优

> 对于很多非线性优化问题，会存在若干个局部的极小值。局部最小值，或
> 局部最优解**x**∗ 定义为：存在一个 *δ \>* 0，对于所有的满足∥**x** −
> **x**∗∥ ≤ *δ* 的**x**，公式*f* (**x**∗) ≤ *f* (**x**)
> 成立。也就是说，在**x**∗ 的附近区域内，所有的函数值都大于或者等于*f*
> (**x**∗)。
>
> 对于所有的**x** ∈ *A*，都有*f* (**x**∗) ≤ *f* (**x**) 成立，则**x**∗
> 为全局最小值，或全局最优解。
>
> 一般的，求局部最优解是容易的，但很难保证其为全局最优解。对于线性
> 规划或凸优化问题，局部最优解就是全局最优解。
>
> 要确认一个点**x**∗
> 是否为局部最优解，通过比较它的邻域内有没有更小的函数值是不现实的。如果函数*f*
> (**x**) 是二次连续可微的，我们可以通过检查目标函数在点**x**∗
> 的梯度𝖮*f* (**x**∗) 和Hessian 矩阵𝖮2*f* (**x**∗) 来判断。
>
> 本书中只介绍梯度下降法。
>
> 证明*.* 如果函数*f* (**x**) 是连续可微的，根据泰勒展开公式（Taylor's
> Formula），函数*f* (**x**) 的一阶展开可以近似为
>
> *f* (**x**∗ + △**x**) = *f* (**x**∗) + △**x**T𝖮*f* (**x**∗)*,* (C.3)
>
> 假设𝖮*f* (**x**∗) ̸= 0，则可以找到一个△**x**（比如△**x** = −*α*𝖮*f*
> (**x**∗)，*α* 为很小的正数），使得
>
> *f* (**x**∗ + △**x**) − *f* (**x**∗) = △**x**T𝖮*f* (**x**∗) ≤ 0*.*
> (C.4)
>
> 这和局部最优的定义矛盾。
>
> 证明*.* 如果函数*f* (**x**) 是二次连续可微的，函数*f* (**x**)
> 的二阶展开可以近似为

*f* (**x**∗ + △**x**) = *f* (**x**∗) + △**x**T𝖮*f* (**x**∗) +
[1]{.underline} △**x**T(𝖮2*f* (**x**∗))△**x***.* (C.5)

> 由一阶必要性定理可知𝖮*f* (**x**∗) = 0，则
>
> *f* (**x**∗ + △**x**) − *f* (**x**∗) = [1]{.underline} △**x**T(𝖮2*f*
> (**x**∗))△**x** ≥ 0*.* (C.6)
>
> 即𝖮2*f* (**x**∗) 为半正定矩阵。

2.  梯度下降法

> 梯度下降法（Gradient Descent Method），也叫最速下降法（Steepest De-
> scend Method），经常用来求解无约束优化的极小值问题。
>
> 对于函数*f* (**x**)，如果*f* (**x**) 在点**x***~t~*
> 附近是连续可微的，那么*f* (**x**) 下降最快的方向是 *f* (**x**)
> 在**x***~t~* 点的梯度方法的反方向。
>
> 根据泰勒一阶展开公式，

*f* (**x**~*t*+1~) = *f* (**x***~t~* + △**x**) ≈ *f* (**x***~t~*) +
△**x**T𝖮*f* (**x***~t~*)*.* (C.7)

> 要使得*f* (**x**~*t*+1~) *\< f* (**x***~t~*)，就得使△**x**T𝖮*f*
> (**x***~t~*) *\<* 0。我们取△**x** = −*α*𝖮*f* (**x***~t~*)。如果*α \>*
> 0 为一个够小数值时，那么 *f* (**x**~*t*+1~) *\< f* (**x***~t~*) 成立。
>
> 这样我们就可以从一个初始值**x**~0~ 出发，通过迭代公式

**x**~*t*+1~ = **x***~t~* − *α~t~*𝖮*f* (**x***~t~*)*, t* ≥ 0*.* (C.8)

> 生成序列 **x**~0~*,* **x**~1~*,* **x**~2~*, . . .* 使得

*f* (**x**~0~) ≥ *f* (**x**~1~) ≥ *f* (**x**~2~) ≥ · · · (C.9)

> 如果顺利的话，序列 (**x***~n~*)
> 收敛到局部最优解**x**∗。注意每次迭代步长 *α*
> 可以改变，但其取值必须合适，如果过大就不会收敛，如果过小则收敛速度太慢。
>
> 梯度下降法的过程如图[C.1](\l)所示。曲线是等高线（水平集），即函数*f*
> 为不同常数的集合构成的曲线。红色的箭头指向该点梯度的反方向（梯度方向与通过该点的等高线垂直）。沿着梯度下降方向，将最终到达函数*f*
> 值的局部最优解。
>
> x0
>
> ![](/root/autodl-tmp/project_knowledge/Doc_QA/Knowledge_based/1828695663060254721/image_output/7.《神经网络与深度学习》/media/image241.png)
>
> 图 C.1 梯度下降法
>
> 梯度下降法为一阶收敛算法，当靠近极小值时梯度变小，收敛速度会变慢，
> 并且可能以"之字形"的方式下降。如果目标函数为二阶连续可微，我们可以采用牛顿法。牛顿法为二阶收敛算法，收敛速度更快，但是每次迭代需要计算Hessian
> 矩阵的逆矩阵，复杂较高。
>
> 相反，如果我们要求解一个最大值问题，就需要向梯度正方向迭代进行搜
> 索，逐渐接近函数的局部极大值点，这个过程则被称为梯度上升法（Gradient
> Ascent）。

3.  拉格朗日乘数法与**KKT** 条件

> 拉格朗日乘数法（Lagrange
> Multiplier）是约束优化问题的一种有效求解方法。约束优化问题可以表示为
>
> 以数学家约瑟夫·拉格朗日命名。
>
> min
>
> **x**
>
> *f* (**x**)
>
> subject to *h~i~*(**x**) = 0*, i* = 1*, . . . , m*
>
> *g~j~*(**x**) ≤ 0*, j* = 1*, . . . , n*
>
> 其中*h~i~*(**x**) 为等式约束函数，*g~j~*(**x**)
> 为不等式约束函数。**x** 的可行域为
>
> (C.10)

*m n*

> D = **dom***f* ∩ \\ **dom***h~i~* ∩ \\ **dom***g~j~* ⊆ R*^d^,* (C.11)

*i*=1

> 其中**dom***f* 是函数*f* 的定义域。
>
> *j*=1

###### 等式约束优化问题

> 如果公式([C.10](\l))
> 中只有等式约束，我们可以构造一个拉格朗日函数Λ(**x***, λ*)
>
> *m*
>
> Λ(**x***, λ*) = *f* (**x**) + *λ~i~h~i~*(**x**)*,* (C.12)
>
> *i*=1
>
> 其中 *λ* 为拉格朗日乘数，可以是正数或负数。如果 *f* (**x**∗)
> 是原始约束优化问题的局部最优值，那么存在一个*λ*^∗\ 使得(**x**∗*,\ λ*∗^)
> 为拉格朗日函数Λ(**x***, λ*) 的平稳点
>
> （stationary point）。因此，只需要令 ^[*∂*Λ(**x***,λ*)]{.underline}^ =
> 0 和 ^[*∂*Λ(**x***,λ*)]{.underline}^ = 0，得到
>
> 平稳点是指一阶偏导数为 0
>
> 的点。平稳点不一定为极值
>
> *∂***x** *∂λ*
>
> *m*
>
> 点。 𝖮*f* (**x**) + Σ *λ~i~*𝖮*h~i~*(**x**) = 0*,* (C.13)
>
> *h~i~*(**x**) = 0*, i* = 0*,* · · · *, m* (C.14)
>
> 上面方程组的解即为原始问题的可能解。在实际应用中，需根据问题来验证是
> 否为极值点。
>
> 拉格朗日乘数法是将一个有*d* 个变量和*m*
> 个等式约束条件的最优化问题转换为一个有*d* + *m*
> 个变量的函数求平稳点的问题。拉格朗日乘数法所得的平稳点会包含原问题的所有极值点，但并不保证每个平稳点都是原问题的极值点。

###### 不等式约束优化问题

> 对于公式([C.10](\l)) 中定义的一般约束优化问题，其拉格朗日函数为
>
> *m n*
>
> Λ(**x***,* **a***,* **b**) = *f* (**x**) + Σ *a~i~h~i~*(**x**) + Σ
> *b~j~g~j~*(**x**)*,* (C.15)
>
> 不等式约束优化问题中的拉格朗日乘数也称为KKT 乘数。
>
> 其中**a** = \[*a*~1~*,* · · · *, a~m~*\]T
> 为等式约束的拉格朗日乘数，**b** = \[*b*~1~*,* · · · *, b~n~*\]T
> 为不等式约束的拉格朗日乘数。
>
> 当约束条件不满足时，有max~**a***,***b**~ Λ(**x***,* **a***,* **b**) =
> ∞；当约束条件满足时并且
>
> **b** ≥ 0 时，max~**a***,***b**~ Λ(**x***,* **a***,* **b**) = *f*
> (**x**)。因此原始约束优化问题等价于
>
> min max Λ(**x***,* **a***,* **b**)*,* (C.16)
>
> **x a***,***b**
>
> subject to **b** ≥ 0*,* (C.17)
>
> 这个min-max 优化问题称为主问题（Primal Problem）。
>
> 对偶问题 主问题的优化一般比较困难，我们可以通过交换min-max
> 的顺序来简化。定义拉格朗日对偶函数为
>
> Γ(**a***,* **b**) = inf Λ(**x***,* **a***,* **b**)*.* (C.18)
>
> **x**∈D
>
> Γ(**a***,* **b**) 是一个凹函数，即使*f* (**x**) 是非凸的。当**b** ≥ 0
> 时，对于任意的**x**˜ ∈ D，有
>
> Γ(**a***,* **b**) = inf Λ(**x***,* **a***,* **b**) Λ(**x**˜*,*
> **a***,* **b**) *f* (**x**˜)*,* (C.19)
>
> **x**∈D
>
> 令*p*^∗\ 是原问题的最优值，则有^
>
> Γ(**a***,* **b**) ≤ *p*^∗^*,* (C.20)
>
> 即拉格朗日对偶函数Γ(**a***,* **b**) 为原问题最优值的下界。
>
> 优化拉格朗日对偶函数Γ(**a***,* **b**)
> 并得到原问题的最优下界，称为拉格朗日对偶问题（Lagrange Dual
> Problem）。
>
> max
>
> **a***,***b**
>
> Γ(**a***,* **b**)*,* (C.21)
>
> subject to **b** ≥ 0*.* (C.22)
>
> 拉格朗日对偶函数为凹函数，因此拉格朗日对偶问题为凸优化问题。
>
> 令*d*^∗\ 是拉格朗日对偶问题的最优值，则有*d*∗\ ≤\ *p*∗^，这个性质称为弱对偶性（Weak
> Duality）。如果*d*^∗\ =\ *p*∗^，这个性质称为强对偶性（Strong Duality）
>
> 。
>
> 当强对偶性成立时，令**x**∗ 和**a**∗*,* **b**∗
> 分别是原问题问题和对偶问题的最优解， 那么它们满足以下条件：

*m n*

> 𝖮*f* (**x**∗) + Σ *ai*∗𝖮*h~i~*(**x**∗) + Σ *b*^∗^*j* 𝖮*g~j~*(**x**∗) =
> 0*,* (C.23)

*h~i~*(**x**∗) = 0*, i* = 0*,* · · · *, m* (C.24)

*g~j~*(**x**∗) ≤ 0*, j* = 0*,* · · · *, n* (C.25)

*b*^∗^*j g~j~*(**x**∗) = 0*, j* = 0*,* · · · *, n* (C.26)

*b*^∗^*j* ≥ 0*, j* = 0*,* · · · *, n* (C.27)

> 称为不等式约束优化问题的*KKT*条件（Karush-Kuhn-Tucker
> Conditions）。KKT条件是拉格朗日乘数法在不等式约束优化问题上的泛化。当原问题是凸优化问题时，满足KKT
> 条件的解也是原问题和对偶问题的最优解。
>
> KKT条件中需要关注的是公式([C.26](\l))，称为互补松弛条件（Complementary
> Slackness）。如果最优解**x**∗ 出现在不等式约束的边界上*g~j~*(**x**) =
> 0，则*b*^∗^*j \>* 0；如果**x**∗ 出现在不等式约束的内部*g~j~*(**x**)
> *\<* 0，则*b*^∗^*j* =
> 0。互补松弛条件说明当最优解出现在不等式约束的内部，则约束失效。
>
> 关于数学优化的内容，可以阅读《Numerical Optimization》\[[Nocedal
> and](\l) [Wright](\l), [2006](\l)\] 和《Convex Optimization》\[[Boyd
> and Vandenberghe](\l), [2004](\l)\]。

概率论
------

> 概率论主要研究大量随机现象中的数量规律，其应用十分广泛，几乎遍及各个
> 领域。

#### 样本空间

> 样本空间是一个随机试验所有可能结果的集合。例如，如果抛掷一枚硬币，
> 那么样本空间就是集合{正面，反面}。如果投掷一个骰子，那么样本空间就是
>
> {1*,* 2*,* 3*,* 4*,* 5*,* 6}。随机试验中的每个可能结果称为样本点。
>
> 有些试验有两个或多个可能的样本空间。例如，从52
> 张扑克牌中随机抽出一张，样本空间可以是数字（A
> 到K），也可以是花色（黑桃，红桃，梅花，方块）。如果要完整地描述一张牌，就需要同时给出数字和花色，这时样本空间可
> 以通过构建上述两个样本空间的笛卡儿乘积来得到。

#### 事件和概率

> 随机事件（或简称事件）指的是一个被赋予概率的事物集合，也就是样本空间中的一个子集。概率（Probability）表示一个随机事件发生的可能性大小，
> 为0 到1 之间的一个非负实数。比如，一个0.5 的概率表示一个事件有50%
> 的可能性发生。
>
> 对于一个机会均等的抛硬币动作来说，其样本空间为"正面"或"反面"。
> 我们可以定义各个随机事件，并计算其概率。比如，

-   {正面}，其概率为0.5；

-   {反面}，其概率为0.5；

-   空集∅，不是正面也不是反面，其概率为0；

-   {正面\| 反面}，不是正面就是反面，其概率为1。

    1.  ###### 随机变量

> 在随机试验中，试验的结果可以用一个数 *X* 来表示，这个数 *X*
> 是随着试验结果的不同而变化的，是样本点的一个函数。我们把这种数称为随机变量
>
> （Random
> Variable）。例如，随机掷一个骰子，得到的点数就可以看成一个随机变量*X*，*X*
> 的取值为{1*,* 2*,* 3*,* 4*,* 5*,* 6}。
>
> 如果随机掷两个骰子，整个事件空间Ω 可以由36 个元素组成：
>
> Ω = {(*i, j*)\|*i* = 1*, . . . ,* 6; *j* = 1*, . . . ,* 6} (D.1)
>
> 一个随机事件也可以定义多个随机变量。比如在掷两个骰子的随机事件中，
> 可以定义随机变量*X* 为获得的两个骰子的点数和，也可以定义随机变量*Y*
> 为获得的两个骰子的点数差。随机变量*X* 可以有11 个整数值，而随机变量*Y*
> 只有6 个。
>
> *X*(*i, j*) := *i* + *j, x* = 2*,* 3*, . . . ,* 12 (D.2)
>
> *Y* (*i, j*) := \| *i* − *j* \|*, y* = 0*,* 1*,* 2*,* 3*,* 4*,* 5*.*
> (D.3)
>
> 其中*i, j* 分别为两个骰子的点数。

1.  离散随机变量

> 如果随机变量*X* 所可能取的值为有限可列举的，有*n* 个有限取值
>
> {*x*~1~*,* · · · *, x~n~*}*,*
>
> 则称*X* 为离散随机变量。
>
> 要了解*X* 的统计规律，就必须知道它取每种可能值*x~i~* 的概率，即
>
> *P* (*X* = *x~i~*) = *p*(*x~i~*)*,* ∀*i* ∈ \[1*, n*\]*.* (D.4)
>
> *p*(*x*~1~)*,* · · · *, p*(*x~n~*) 称为离散型随机变量*X*
> 的概率分布（Probability Distribution） 或分布，并且满足
>
> 一般用大写的字母表示一个随机变量，用小字字母表示
> 该变量的某一个具体的取值。

*n*

> *p*(*x~i~*) = 1 (D.5)
>
> *i*=1
>
> *p*(*x~i~*) ≥ 0*,* ∀*i* ∈ \[1*, n*\]*,* (D.6)
>
> 常见的离散随机变量的概率分布有：
>
> 伯努利分布 在一次试验中，事件A 出现的概率为*µ*，不出现的概率为1 −
> *µ*。若用变量*X* 表示事件*A* 出现的次数，则*X* 的取值为0
> 和1，其相应的分布为
>
> *p*(*x*) = *µ^x^*(1 − *µ*)(1−*x*)*,* (D.7)
>
> 这个分布称为伯努利分布（Bernoulli Distribution）, 又名两点分布或者0-1
> 分布。
>
> 二项分布 在n 次伯努利分布中，若以变量*X* 表示事件A 出现的次数，则*X*
> 的取值为{0*,* · · · *, n*}，其相应的分布为二项分布（Binomial
> Distribution）。
>
> *P* (*X* = *k*) = *n µ^k^*(1 − *µ*)*n*−*k, k* = 1 · · · *, n* (D.8)
>
> 其中 *^n^* 为二项式系数（这就是二项分布的名称的由来），表示从
> 个元素中取

*k*

> 出*k* 个元素而不考虑其顺序的组合的总数。

2.  连续随机变量

> 与离散随机变量不同，一些随机变量*X*
> 的取值是不可列举的，由全部实数或者由一部分区间组成，比如
>
> *X* = {*x*\|*a* ≤ *x* ≤ *b*}*,* −∞ *\< a \< b \<* ∞
>
> 则称*X* 为连续随机变量。连续随机变量的值是不可数及无穷尽的。
>
> 对于连续随机变量*X*，它取一个具体值*x~i~*
> 的概率为0，这个离散随机变量截然不同。因此用列举连续随机变量取某个值的概率来描述这种随机变量不但
> 做不到，也毫无意义。
>
> 连续随机变量*X* 的概率分布一般用概率密度函数（Probability Density
> Func- tion，PDF）*p*(*x*) 来描述。*p*(*x*) 为可积函数，并满足
>
> *p*(*x*)*dx* = 1 (D.9)
>
> −∞
>
> *p*(*x*) ≥ 0*.* (D.10)
>
> 给定概率密度函数*p*(*x*)，便可以计算出随机变量落入某一个区间的概率，而
> *p*(*x*) 本身反映了随机变量取落入*x* 的非常小的邻近区间中的概率大小。
>
> 常见的连续随机变量的概率分布有：
>
> 均匀分布 若*a, b* 为有限数，\[*a, b*\] 上的均匀分布（Uniform
> Distribution）的概率密度函数定义为

( ) =  [ 1 ]{.underline}

> *, a* ≤ *x* ≤ *b*
>
> (D.11)
>
> *p x b*−*a*

 0 *, x \< a*或*x \> b*

> 正态分布 正态分布（Normal Distribution），又名高斯分布（Gaussian
> Distri-
> bution），是自然界最常见的一种分布，并且具有很多良好的性质，在很多领域都有非常重要的影响力，其概率密度函数为

*p*(*x*) = √2*πσ* exp

> (*x µ*)2
>
> − 2*σ*2
>
> *,* (D.12)
>
> 其中，*σ \>* 0，*µ* 和*σ* 均为常数。若随机变量*X* 服从一个参数为*µ*
> 和*σ* 的概率分布，简记为
>
> *X* ∼ N(*µ, σ*^2^)*.* (D.13)
>
> 当*µ* = 0，*σ* = 1 时，称为标准正态分布（Standard Normal
> Distribution）。
>
> 图[D.1a](\l)和[D.1b](\l)分别显示了均匀分布和正态分布的概率密度函数。

1

0*.*8

0*.*6

0*.*4

0*.*2

1

> 0*.*8
>
> 0*.*6
>
> 0*.*4
>
> 0*.*2
>
> 0 −3 −2 −1 0 1 2 3

(a) 均匀分布

> −3 −2 −1 0 1 2 3

(b) 正态分布

> 图 D.1 连续随机变量的密度函数

3.  累积分布函数

> 对于一个随机变量*X*，其累积分布函数（Cumulative Distribution
> Function， CDF）是随机变量*X* 的取值小于等于*x* 的概率。
>
> cdf(*x*) = *P* (*X* ≤ *x*)*.* (D.14)
>
> 以连续随机变量*X* 为例，累积分布函数定义为

cdf(

> ) = ∫ *x* ( )
>
> (D.15)
>
> 其中*p*(*x*)
> 为概率密度函数。图[D.2](\l)给出了标准正态分布的累计分布函数。

1

> 0*.*8
>
> 0*.*6
>
> 0*.*4
>
> 0*.*2
>
> −3 −2 −1 0 1 2 3
>
> 图 D.2 标准正态分布的概率密度函数和累计概率分布

###### 随机向量

> 随机向量是指一组随机变量构成的向量。如果*X*~1~*, X*~2~*,* · · · *,
> X~n~* 为*n* 个随机变量, 那么称\[*X*~1~*, X*~2~*,* · · · *, X~n~*\]
> 为一个 *n* 维随机向量。一维随机向量称为随机变量。
>
> 随机向量也分为离散随机向量和连续随机向量。

4.  离散随机向量

> 离散随机向量的联合概率分布（Joint Probability Distribution）为
>
> *P* (*X*~1~ = *x*~1~*, X*~2~ = *x*~2~*,* · · · *, X~n~* = *x~n~*) =
> *p*(*x*~1~*, x*~2~*,* · · · *, x~n~*)*,*
>
> 其中*x~i~* ∈ *ω~i~* 为变量*X~i~* 的取值，*ω~i~* 为变量*X~i~*
> 的样本空间。和离散随机变量类似，离散随机向量的概率分布满足

*p*(*x*~1~*, x*~2~*,* · · · *, x~n~*) ≥ 0*,* ∀*x*~1~ ∈ *ω*~1~*, x*~2~ ∈
*ω*~2~*,* · · · *, x~n~* ∈ *ω~n~* (D.16)

> Σ Σ · · · Σ
>
> *p*(*x*~1~*, x*~2~*,* · · · *, x~n~*) = 1*.* (D.17)
>
> 多项分布 一个常见的离散向量概率分布为多项分布（Multinomial Distribu-
> tion）。多项分布是二项分布在随机向量的推广。假设一个袋子中装了很多球，
> 总共有*K* 个不同的颜色。我们从袋子中取出*n*
> 个球。每次取出一个球时，就在袋子中放入一个同样颜色的球。这样保证同一颜色的球在不同试验中被取出的概率是相等的。令**X**
> 为一个*K* 维随机向量，每个元素*X~k~*(*k* = 1*,* · · · *, K*)
> 为取出的*n* 个球中颜色为*k* 的球的数量，则*X*
> 服从多项分布，其概率分布为

*p*(*x*~1~*, . . . , x*

> \|***µ***) = ! *n*! *µ^x^*1 · · · *µ^x^K ,* (D.18)

*K x*~1~ · · · *x~K~*! 1 *K*

> 其中***µ*** = \[*µ*~1~*,* · · · *, µ~K~*\]T
> 分别为每次抽取的球的颜色为1*,* · · · *, K* 的概率；*x*~1~*,* · · · *,
> x~K~*
>
> 为非负整数，并且满足Σ*K x~k~* = *n*。
>
> 多项分布的概率分布也可以用gamma 函数表示：
>
> ( ) = Γ(Σ *x*
>
> \+ 1) Y*K*
>
> (D.19)

其中Γ(*𝑥*) = ∫0∞ *t dt* 为gamma 函数。这种表示形式和 Dirichlet
分布类似，

> *𝑥*−1
>
> 而Dirichlet 分布可以作为多项分布的共轭先验。

5.  连续随机向量

> 连续随机向量的其联合概率密度函数（Joint Probability Density Function）
> 满足
>
> +∞
>
> −∞ · · ·
>
> *p*(**x**) = *p*(*x*~1~*,* · · · *, x~n~*) ≥ 0*,* (D.20)
>
> +∞
>
> *p*(*x*~1~*,* · · · *, x~n~*)*dx*~1~ · · · *dx~n~* = 1*.* (D.21)
>
> −∞
>
> 多元正态分布 一个常见的连续随机向量分布为多元正态分布（Multivariate
> Nor- mal Distribution），也称为多元高斯分布（Multivariate Gaussian
> Distribution）
>
> 。若*n* 维随机向量**X** = \[*X*~1~*, . . . , X~n~*\]T 服从*n*
> 元正态分布，其密度函数为
>
> (2*π*)*n/*2\|Σ\|1*/*2 2
>
> 其中***µ***
> 为多元正态分布的均值向量，Σ为多元正态分布的协方差矩阵，\|Σ\| 表示
>
> Σ 的行列式。
>
> 各项同性高斯分布 如果一个多元高斯分布的协方差矩阵简化为Σ =
> *σ*^2^*I*，即每一个维随机变量都独立并且方差相同，那么这个多元高斯分布称为各项同性高
> 斯分布（Isotropic Gaussian Distribution）。
>
> **Dirichlet** 分布 一个*n* 维随机向量**X** 的Dirichlet 分布为
>
> *p*(**x**\|***α***) = [ Γ(*α*0)]{.underline} Y *x^α^i*−1*,* (D.23)
>
> 不失一般性，下面以二维随机向量进行讨论，这些结论在多维时依然成立。

Γ(*α*~1~) · · · Γ(*α~n~*) *i*=1

> 其中***α*** = \[*α*~1~*, . . . , α~K~*\]T 为Dirichlet 分布的参数。

###### 边际分布

> 对于二维离散随机向量(*X, Y* )，假设*X* 取值空间为Ω*~x~*，*Y*
> 取值空间为Ω*~y~*。其联合概率分布满足
>
> *p*(*x, y*) ≥ 0*,* Σ Σ *p*(*x~i~, y~j~*) = 1*.* (D.24)
>
> *x*∈Ω*x y*∈Ω*y*
>
> 对于联合概率分布*p*(*x, y*)，我们可以分别对*x* 和*y* 进行求和。
>
> （1）对于固定的*x*，
>
> *p*(*x, y*) = *P* (*X* = *x*) = *p*(*x*)*.* (D.25)
>
> *y*∈Ω*y*
>
> （2）对于固定的*y*，
>
> *p*(*x, y*) = *P* (*Y* = *y*) = *p*(*y*)*.* (D.26)
>
> *x*∈Ω*x*
>
> 由离散随机向量(*X, Y* ) 的联合概率分布，对*Y*
> 的所有取值进行求和得到*X* 的概率分布；而对*X*
> 的所有取值进行求和得到*Y* 的概率分布。这里*p*(*x*) 和*p*(*y*)
> 就称为*p*(*x, y*) 的边际分布（Marginal Distribution）。
>
> 对于二维连续随机向量(*X, Y* )，其边际分布为：

*p*(*x*) =

*p*(*y*) =

> *p*(*x, y*)*dy* (D.27)
>
> −∞
>
> ∞ *p*(*x, y*)*dx* (D.28)
>
> −∞
>
> 一个二元正态分布的边际分布仍为正态分布。

###### 条件概率分布

> 对于离散随机向量(*X, Y* )，已知*X* = *x* 的条件下，随机变量*Y* = *y*
> 的条件概率（Conditional Probability）为：
>
> *p*(*y*\|*x*) = *P* (*Y* = *y*\|*X* = *x*) =
>
> *p*(*x, y*) *p*(*x*)
>
> 这个公式定义了随机变量*Y* 关于随机变量*X* 的条件概率分布（Conditional
> Prob- ability Distribution），简称条件分布。
>
> 对于二维连续随机向量(*X, Y* )，已知*X* = *x* 的条件下，随机变量*Y* =
> *y* 的
>
> 条件概率密度函数（Conditional Probability Density Function）为
>
> *p*(*x, y*)

*p*(*y*\|*x*) =

> *.* (D.30)
>
> *p x*
>
> 同理，已知*Y* = *y* 的条件下，随机变量*X* = *x* 的条件概率密度函数为
>
> *p*(*x, y*)

*p*(*x*\|*y*) =

> *.* (D.31)
>
> *p y*
>
> 通过公式([D.30](\l))
> 和([D.31](\l))，我们可以得到两个条件概率*p*(*y*\|*x*) 和*p*(*x*\|*y*)
> 之间的关系。
>
> *p*(*y*\|*x*) = [*p*(*x*\|*y*)*p*(*y*)]{.underline} *.* (D.32)
>
> 这个公式称为贝叶斯定理（Bayes' Theorem），或贝叶斯公式。

###### 独立与条件独立

> 对于两个离散（或连续）随机变量*X* 和*Y*
> ，如果其联合概率（或联合概率密度函数）*p*(*x, y*) 满足
>
> *p*(*x, y*) = *p*(*x*)*p*(*y*)*,* (D.33)
>
> 则称*X* 和*Y* 相互独立（independence），记为*X* ⊥ *Y* 。
>
> 对于三个离散（或连续）随机变量*X*、*Y*
> 和*Z*，如果条件概率（或联合概率密度函数）*p*(*x, y*\|*𝑥*) 满足
>
> *p*(*x, y*\|*𝑥*) = *P* (*X* = *x, Y* = *y*\|*Z* = *𝑥*) =
> *p*(*x*\|*𝑥*)*p*(*y*\|*𝑥*)*,* (D.34)
>
> 则称在给定变量*Z* 时，*X* 和*Y* 条件独立（conditional
> independence），记为*X* ⊥
>
> ⊥ *Y* \|*Z*。

###### 期望和方差

> 期望 对于离散变量*X*，其概率分布为*p*(*x*~1~)*,* · · · *,
> p*(*x~n~*)，*X* 的期望（Expectation）或均值定义为
>
> 这里的线性相关和线性代数

*n*

> E\[*X*\] = *x~i~p*(*x~i~*)*.* (D.35)

*i*=1

> 对于连续随机变量*X*，概率密度函数为*p*(*x*)，其期望定义为
>
> E\[*X*\] = ∫R *xp*(*x*) *dx.* (D.36)
>
> 方差 随机变量*X*
> 的方差（Variance）用来定义它的概率分布的离散程度，定义为

var(*X*) = E *X* − E\[*X*\] 2 *.* (D.37)

> 随机变量 *X* 的方差也称为它的二阶矩。 var(*X*) 则称为 *X*
> 的根方差或标准差。
>
> 协方差 两个连续随机变量*X* 和*Y*
> 的协方差（Covariance）用来衡量两个随机变量的分布之间的总体变化性，定义为

cov(*X, Y* ) = E *X* − E\[*X*\] *Y* − E\[*Y* \] *,* (D.38)

> 协方差经常也用来衡量两个随机变量之间的线性相关性。如果两个随机变
> 量的协方差为0，那么称这两个随机变量是线性不相关。两个随机变量之间没有
>
> 中的线性相关含义不同。
> 线性相关性，并非表示它们之间独立的，可能存在某种非线性的函数关系。反
>
> 之，如果*X* 与*Y* 是统计独立的，那么它们之间的协方差一定为0。
>
> 协方差矩阵 两个*m* 和*n* 维的连续随机向量**X**
> 和**Y**，它们的协方差（Covariance） 为*m* × *n* 的矩阵，定义为
>
> cov(**X Y**) = E **X** − E\[**X**\] **Y** − E\[**Y**\] T (D.39)
>
> 协方差矩阵cov(**X***,* **Y**) 的第(*i, j*) 个元素等于随机变量*X~i~*
> 和*Y~j~* 的协方差。两个向量变量的协方差cov(**X***,* **Y**)
> 与cov(**Y***,* **X**) 互为转置关系。
>
> 如果两个随机向量的协方差矩阵为对角阵，那么称这两个随机向量是无 关的。
>
> 单个随机向量**X** 的协方差矩阵定义为
>
> cov(**X**) = cov(**X***,* **X**)*.* (D.40)

1.  **Jensen** 不等式

> 如果*X* 是随机变量，*g* 是凸函数，则
>
> *g* (E\[*X*\]) ≤ E \[*g*(*X*)\] *.* (D.41)
>
> 等式当且仅当 *X* 是一个常数或*g* 是线性时成立。

2.  大数定律

> 大数定律（Law Of Large Numbers）是指*n* 个样本*X*~1~*,* · · · *, X~n~*
> 是独立同分布的，即E\[*X*~1~\] = · · · = E\[*X~n~*\] = *µ*，那么其均值
>
> 收敛于期望值*µ*。

*X*¯*n*

> = [1]{.underline} (*X*~1~

*n*

> \+ · · · + *X~n~*

)*,* (D.42)

> *X*¯*n* → *µ* for *n* → ∞ (D.43)

#### 随机过程

> 随机过程（Stochastic Process）是一组随机变量*X~t~* 的集合，其中*t*
> 属于一个索引（index）集合𝘧 。索引集合𝘧
> 可以定义在时间域或者空间域，但一般为时间域，以实数或正数表示。当*t*
> 为实数时，随机过程为连续随机过程；当*t*
> 为整数时，为离散随机过程。日常生活中的很多例子包括股票的波动、语音信号、
> 身高的变化等都可以看作是随机过程。常见的和时间相关的随机过程模型包括贝努力过程、随机游走、马尔可夫过程等。和空间相关的随机过程通常称为随机场（Random
> Field）。比如一张二维的图片，每个像素点（变量）通过空间的位置进行索引，这些像素就组成了一个随机过程。

###### 马尔可夫过程

> 马尔可夫性质 在随机过程中，马尔可夫性质（Markov
> Property）是指一个随机过程在给定现在状态及所有过去状态情况下，其未来状态的条件概率分布仅依赖于当前状态。以离散随机过程为例，假设随机变量*X*~0~*,
> X*~1~*,* · · · *, X~T~*
> 构成一个随机过程。这些随机变量的所有可能取值的集合被称为状态空间（State
> Space）
>
> 。如果*X~t~*~+1~ 对于过去状态的条件概率分布仅是*X~t~* 的一个函数，则

*P* (*X~t~*~+1~ = *x~t~*~+1~\|*X*~0:*t*~ = *x*~0:*t*~) = *P* (*X~t~*~+1~
= *x~t~*~+1~\|*X~t~* = *x~t~*)*,* (D.44)

> 其中*X*~0:*t*~ 表示变量集合*X*~0~*, X*~1~*,* · · · *,
> X~t~*，*x*~0:*t*~ 为在状态空间中的状态序列。
>
> 马尔可夫性质也可以描述为给定当前状态时，将来的状态与过去状态是条
> 件独立的。

1.  马尔可夫链

> 离散时间的马尔可夫过程也称为马尔可夫链（Markov
> Chain）。如果一个马尔可夫链的条件概率

*P* (*X~t~*~+1~ = *s~i~*\|*X~t~* = *s~j~*) = **T**(*s~i~, s~j~*)*,*
(D.45)

> 在不同时间都是不变的，即和时间*t*
> 无关，则称为时间同质的马尔可夫链（Time- Homogeneous Markov
> Chains）。如果状态空间是有限的，*T* (*s~i~, s~j~*) 也可以用一个矩阵*T*
> 表示，称为状态转移矩阵（Transition Matrix），其中元素*t~ij~*
> 表示状态*s~i~* 转移到状态*s~j~* 的概率。
>
> 平稳分布 假设状态空间大小为*M* ，向量*π* = \[*π*~1~*,* · · · *, π~M~*
> \]T 为状态空间中的一
>
> 个分布，满足0 ≤ *π~i~* ≤ 1 和Σ*M π~i~* = 1。
>
> 对于状态转移矩阵为**T** 的时间同质的马尔可夫链，如果存在一个分布*π* 满
>
> 足
>
> *π* = **T***π,* (D.46)
>
> 即分布*π* 就称为该马尔可夫链的平稳分布（Stationary
> Distribution）。根据特征向量的定义可知，*π* 为矩阵**T**
> 的（归一化）的对应特征值为1 的特征向量。
>
> 如果一个马尔可夫链的状态转移矩阵**T**
> 满足所有状态可遍历性以及非周期性，那么对于任意一个初始状态分布*π*^(0)^，将经过一定时间的状态转移之后，都会收敛到平稳分布，即

*π* = lim

*N* →∞

**T***N π*^(0)^*.* (D.47)

###### 高斯过程

> 高斯过程（Gaussian
> Process）也是一种应用广泛的随机过程模型。假设有一组连续随机变量*X*~0~*,
> X*~1~*,* · · · *, X~T~* ，如果由这组随机变量构成的任一有限集合
>
> *X~t~*1*,*··· *,t* = \[*X~t~*1 *,* · · · *, X~t~* \]T
>
> 都服从一个多元正态分布，那么这组随机变量为一个随机过程。高斯过程也可
> 以定义为：如果*X~t~*1*,*··· *,tn*
> 的任一线性组合都服从一元正态分布，那么这组随机变量为一个随机过程。
>
> 高斯过程回归 高斯过程回归（Gaussian Process
> Regression）是利用高斯过程来对一个函数分布进行建模。和机器学习中参数化建模（比如贝叶斯线性回归）
> 相比，高斯过程是一种非参数模型，可以拟合一个黑盒函数，并给出拟合结果的置信度\[[Rasmussen](\l),
> [2004](\l)\]。
>
> 假设一个未知函数*f* (**x**)
> 服从高斯过程，且为平滑函数。如果两个样本**x**~1~*,* **x**~2~
> 比较接近，那么对应的*f* (**x**~1~)*, f* (**x**~2~)
> 也比较接近。假设从函数*f* (**x**) 中采样有限个样本*X* = \[**x**~1~*,*
> **x**~2~*,* · · · *,* **x***~N~* \]，这*N* 个点服从一个多元正态分布，
>
> \[*f* (**x**~1~)*, f* (**x**~2~)*,* · · · *, f* (**x***~N~* )\]T ∼ N
> *µ*(*X*)*, K*(*X, X*) *,* (D.49)
>
> 其中*µ*(*X*) = \[*µ*(**x**~1~)*, µ*(**x**~2~)*,* · · · *,
> µ*(**x***~N~* )\]T 是均值向量，*K*(*X, X*) = \[*k*(**x***~i~,*
> **x***~j~*)\]~*N*×*N*~
>
> 是协方差矩阵，*k*(**x***~i~,* **x***~j~*)
> 为核函数，可以衡量两个样本的相似度。
>
> 在高斯过程回归，一个常用的核函数是平方指数（Squared Exponential）函
>
> 数
>
> −∥**x***~i~* − **x***~j~*∥2
>
> 在支持向量机中，平方指数核函数也叫高斯核函数或径[向基函数]{.underline}。这里为了避免混

*k*(**x***~i~,* **x***~j~*) = exp

2*l*2

> *,* (D.50)
>
> 淆，我们称为平方指数核函
>
> 数。
>
> 其中*l* 为超参数。当**x***~i~* 和**x***~j~*
> 越接近，其核函数的值越大，表明*f* (**x***~i~*) 和*f* (**x***~j~*)
> 越相关。
>
> 假设*f* (**x**) 的一组带噪声的观测值为{(**x***~n~, y~n~*)}*N*
> ，其中*y~n~* ∼ N(*f* (**x***~n~*)*, σ*^2^)
>
> 为正态分布，*σ* 为噪声方差。
>
> 对于一个新的样本点**x**∗，我们希望预测函数*y*^∗^ = *f*
> (**x**∗)。令**y** = \[*y*~1~*, y*~2~*,* · · · *, y~n~*\]
>
> 为已有的观测值，根据高斯过程的假设，\[**y**; *y*^∗^\] 满足

 **y** 

> *µ*(*X*)
>
> *K*(*X, X*) + *σ*^2^**I** *K*(**x**∗*, X*)T
>
>   ∼ *N*   
>
> *,* (D.51)
>
> 其中*K*(**x**∗*, X*) = \[*k*(**x**∗*,* **x**~1~)*,* · · · *,
> k*(**x**∗*,* **x***~n~*)\]。根据上面的联合分布，*y*^∗\ 的后验分布为^
>
> *p*(*y*^∗^\|*X,* **y**) = N(*µ*ˆ*, σ*ˆ2)*,* (D.52)
>
> 其中均值*µ*ˆ 和方差*σ*ˆ 为
>
> *µ*ˆ = *K*(**x**∗*, X*)(*K*(*X, X*) + *σ*^2^**I**)−1(**y** − *µ*(*X*))
> + *µ*(**x**∗)*,* (D.53)
>
> *σ*ˆ2 = *k*(**x**∗*,* **x**∗) − *K*(**x**∗*, X*)(*K*(*X, X*) +
> *σ*^2^**I**)−1*K*(**x**∗*, X*)T*.* (D.54)
>
> 从公式([D.53](\l)) 可以看出，均值函数*µ*(*x*)
> 可以近似地互相抵消。在实际应用中，一般假设*µ*(*x*) = 0，均值*µ*ˆ
> 可以将简化为
>
> *µ*ˆ = *K*(**x**∗*, X*)(*K*(*X, X*) + *σ*^2^**I**)−1**y***.* (D.55)
>
> 高斯过程回归可以认为是一种有效的贝叶斯优化方法，广泛地应用于机器
> 学习中。

信息论
------

> 2019 年 4 月 6 日 425
>
> 信息论（Information
> Theory）是数学、物理、统计、计算机科学等多个学科的交叉领域。信息论是由
> Claude Shannon 最早提出的，主要研究信息的量化、存
>
> 储和通信等方法。这里，"信息"是指一组消息的集合。假设在一个噪声通道上
> Claude Shannon，1916 年4
>
> 发送消息，我们需要考虑如何对每一个信息进行编码、传输以及解码，使得接
>
> 收者可以尽可能准确地重构出消息。
>
> 在机器学习相关领域，信息论也有着大量的应用。比如特征抽取、统计推
> 断、自然语言处理等。
>
> 月30 日－ 2001 年2 月26 日），美国数学家、电子工程师和
> 密码学家，被誉为信息论的 创始人。

1.  自信息和熵

<!-- -->

1.  熵

> 熵（Entropy）最早是物理学的概念，用于表示一个热力学系统的无序程度。
> 在信息论中，熵用来衡量一个随机事件的不确定性。假设对一个随机变量*X*（取值集合为X，概率分布为*p*(*x*)*,
> x* ∈ X）进行编码，自信息*I*(*x*) 是变量*X* = *x*
> 时的信息量或编码长度，定义为
>
> *I*(*x*) = − log(*p*(*x*))*,* (E.1)
>
> 那么随机变量*X* 的平均编码长度，即熵定义为
>
> *H*(*X*) = E*~X~* \[I(*x*)\] (E.2)
>
> = E*~X~* \[− log(*p*(*x*))\] (E.3)
>
> = − *p*(*x*) log *p*(*x*)*,* (E.4)
>
> *x*∈X
>
> 其中当*p*(*x~i~*) = 0 时，我们定义0 log 0 =
> 0，这与极限一致，lim~*p*→0+~ *p* log *p* = 0。
>
> 熵是一个随机变量的平均编码长度，即自信息的数学期望。熵越高，则随机变量的信息越多；熵越低，则信息越少。如果变量*X*
> 当且仅当在*x* 时*p*(*x*) = 1，
> 则熵为0。也就是说，对于一个确定的信息，其熵为0，信息量也为0。如果其概率分布为一个均匀分布，则熵最大。假设一个随机变量*X*
> 有三种可能值*x*~1~*, x*~2~*, x*~3~， 不同概率分布对应的熵如下：
>
> 在熵的定义中，对数的底可以使用2、自然常数*e*，或是10。

###### 联合熵和条件熵

> 对于两个离散随机变量*X* 和*Y* ，假设*X* 取值集合为X ；*Y*
> 取值集合为Y，其联合概率分布满足为*p*(*x, y*)，则
>
> *X* 和*Y* 的联合熵（Joint Entropy）为
>
> *H*(*X, Y* ) = − *p*(*x, y*) log *p*(*x, y*)*.* (E.5)
>
> *x*∈X *y*∈Y
>
> *X* 和*Y* 的条件熵（Conditional Entropy）为
>
> *H*(*X*\|*Y* ) = − *p*(*x, y*) log *p*(*x*\|*y*) (E.6)
>
> *x*∈X *y*∈Y
>
> = − Σ Σ *p*(*x, y*) log [*p*(*x, y*)]{.underline} *.* (E.7)
>
> *x*∈X *y*∈Y
>
> 根据其定义，条件熵也可以写为
>
> *H*(*X*\|*Y* ) = *H*(*X, Y* ) − *H*(*Y* )*.* (E.8)

#### 互信息

> 互信息（Mutual
> Information）是衡量已知一个变量时，另一个变量不确定性的减少程度。两个离散随机变量*X*
> 和*Y* 的互信息定义为
>
> *I*(*X*; *Y* ) = Σ Σ *p*(*x, y*) log [ *p*(*x, y*)]{.underline} *.*
> (E.9)
>
> *x*∈X *y*∈Y
>
> 互信息的一个性质为

*I*(*X*; *Y* ) = *H*(*X*) − *H*(*X*\|*Y* ) (E.10)

= *H*(*Y* ) − *H*(*Y* \|*X*)*.* (E.11)

> 如果*X* 和*Y* 相互独立，即*X* 不对*Y*
> 提供任何信息，反之亦然，因此它们的互信息为零。

3.  交叉熵和散度 2019 年 4 月 6 日 427

> **E.3** 交叉熵和散度

###### 交叉熵

> 对应分布为*p*(*x*) 的随机变量，熵*H*(*p*)
> 表示其最优编码长度。交叉熵（Cross Entropy）是按照概率分布*q*
> 的最优编码对真实分布为*p* 的信息进行编码的长度， 定义为

*H*(*p, q*) = E*~p~*\[− log *q*(*x*)\] (E.12)

= − *p*(*x*) log *q*(*x*)*.* (E.13)

*x*

> 在给定*p* 的情况下，如果*q* 和*p* 越接近，交叉熵越小；如果*q* 和*p*
> 越远，交叉熵就越大。

2.  **KL** 散度

> *KL* 散度（Kullback-Leibler Divergence），也叫*KL*
> 距离或相对熵(Relative Entropy)，是用概率分布*q* 来近似*p*
> 时所造成的信息损失量。KL 散度是按照概率分布*q*
> 的最优编码对真实分布为*p* 的信息进行编码，其平均编码长度*H*(*p, q*)
> 和*p* 的最优平均编码长度*H*(*p*) 之间的差异。对于离散概率分布*p*
> 和*q*，从*q* 到*p* 的KL 散度定义为
>
> *D*~KL~(*p*∥*q*) = *H*(*p, q*) − *H*(*p*) (E.14)
>
> = Σ *p*(*x*) log [*p*(*x*)]{.underline} *,* (E.15)

*x*

> 其中为了保证连续性，定义0 log 0 = 0*,* 0 log 0 = 0。
>
> 0 *q*
>
> KL 散度可以是衡量两个概率分布之间的距离。KL
> 散度总是非负的，*D*~KL~(*p*∥*q*) ≥
>
> 0。只有当*p* = *q* 时，*D*~KL~(*p*∥*q*) = 0。如果两个分布越接近，KL
> 散度越小；如果两个分布越远，KL 散度就越大。但KL
> 散度并不是一个真正的度量或距离，一是KL 散度不满足距离的对称性，二是KL
> 散度不满足距离的三角不等式性质。

3.  **JS** 散度

> *JS* 散度（Jensen--Shannon
> Divergence）是一种对称的衡量两个分布相似度的度量方式，定义为

1 1

> *D*~JS~(*p*∥*q*) = 2 *D*~KL~(*p*∥*m*) + 2 *D~KL~*(*q*∥*m*)*,* (E.16)
>
> 其中*m* = 1 (*p* + *q*)。
>
> JS 散度是KL 散度一种改进。但两种散度有存在一个问题，即如果两个分布 *p,
> q* 个分布没有重叠或者重叠非常少时，KL 散度和JS
> 散度都很难衡量两个分布的距离。

4.  **Wasserstein** 距离

> *Wasserstein* 距离（Wasserstein
> Distance）也是用于衡量两个分布之间的距离。对于两个分布*q*~1~*,
> q*~2~，*p*^th^-Wasserstein 距离定义为

*W~p~*(*q*~1~*, q*~2~) =

> inf
>
> *γ*(*x,y*)∈Γ(*q*1*,q*2)

1

E(*x,y*)∼*γ*(*x,y*)\[*d*(*x, y*)*p*\]

*,* (E.17)

> 其中Γ(*q*~1~*, q*~2~) 是边际分布为*q*~1~ 和*q*~2~
> 的所有可能的联合分布集合，*d*(*x, y*) 为*x* 和*y* 的距离，比如*ℓ~p~*
> 距离等。
>
> 如果将两个分布看作是两个土堆，联合分布*γ*(*x, y*) 看作是从土堆*q*~1~
> 的位置*x* 到土堆*q*~2~ 的位置*y* 的搬运土的数量，并有
>
> *γ*(*x, y*) = *q*~2~(*y*)*,* (E.18)
>
> *x*
>
> *γ*(*x, y*) = *q*~1~(*x*)*.* (E.19)
>
> *y*
>
> *q*~1~ 和*q*~2~ 为*γ*(*x, y*) 的两个边际分布。
>
> E~(*x,y*)∼*γ*(*x,y*)~\[*d*(*x, y*)*p*\] 可以理解为在联合分布 *γ*(*x,
> y*) 下把形状为 *q*~1~ 的土堆搬运到形状为*q*~2~ 的土堆所需的工作量，
>
> E~(*x,y*)∼*γ*(*x,y*)~\[*d*(*x, y*)*p*\] = *γ*(*x, y*)*d*(*x, y*)*p,*
> (E.20)
>
> (*x,y*)
>
> 其中从土堆*q*~1~ 中的点*x* 到土堆*q*~2~ 中的点*y*
> 的移动土的数量和距离分别为*γ*(*x, y*) 和*d*(*x,
> y*)*p*。因此，Wasserstein
> 距离可以理解为搬运土堆的最小工作量，也称为推土机距离（Earth-Mover's
> Distance，EMD）。图[E.1](\l)给出了两个离散变量分布的Wasserstein
> 距离示例。图[E.1c](\l)中同颜色方块表示在分布*q*~1~ 中为相同位置。

![](/root/autodl-tmp/project_knowledge/Doc_QA/Knowledge_based/1828695663060254721/image_output/7.《神经网络与深度学习》/media/image242.png)

a.  *q*~1~(*x*) (b) *q*~2~(*x*) (c) *q*~1~ 到*q*~2~ 最优的运输方案

> 图 E.1 Wasserstein 距离示例
>
> 参考文献 2019 年 4 月 6 日 429
>
> Wasserstein 距离相比KL 散度和JS
> 散度的优势在于：即使两个分布没有重叠或者重叠非常少，Wasserstein
> 距离仍然能反映两个分布的远近。
>
> 对于R*n* 空间中的两个高斯分布*p* = N(*µ*~1~*,* Σ~1~) 和*q* =
> N(*µ*~2~*,* Σ~2~)，它们的2nd-Wasserstein 距离为

*D* (*p*∥*q*) = ∥*µ* − *µ* ∥2 + tr Σ + Σ − 2 Σ1 Σ Σ1 1*/*2 *.* (E.21)

> 当两个分布的的方差为0 时，2nd-Wasserstein 距离等价与欧氏距离。

#### 参考文献

> Stephen Boyd and Lieven Vandenberghe. *Convex optimization*. Cambridge
> university press, 2004.
>
> Jorge Nocedal and Stephen Wright. *Numer- ical optimization*. Springer
> Science & Busi-
>
> ness Media, 2006.
>
> Carl Edward Rasmussen. Gaussian pro- cesses in machine learning. In
> *Advanced lectures on machine learning*, pages 63--71. Springer, 2004.

