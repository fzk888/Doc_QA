 《神经网络与深度学习》Neural Networks and Deep Learning邱锡鹏xpqiu@fudan.edu.cn2019 年 4 月 6 日
 22019 年 4 月 6 日2019 年 4 月 6 日第 1 章 绪论21.1.1 人工智能的流派目前我们对人类智能机理依然知之甚少，还没有一个通用的理论来指导如何构建一个人工智能系统。不同的研究者都有各自的理解，因此在人工智能的研究过程中产生了很多不同的流派。比如一些研究者认为人工智能应该通过研究人类智能的机理来构建一个仿生的模拟系统，而另外一些研究者则认为可以使用其它方法来实现人类的某种智能行为。一个著名的例子是让机器具有飞行能力不需要模拟鸟的飞行方式，而是应该研究空气动力学。尽管人工智能的流派非常多，但主流的方法大体上可以归结为以下两种：符号主义 符号主义（symbolism），又称逻辑主义、心理学派或计算机学派，是通过分析人类智能的功能，然后通过计算机来实现这些功能。符号主义有两个 基本假设：（1）信息可以用符号来表示；（2）符号可以通过显式的规则（比如逻辑运算）来操作。人类的认知过程可以看作是符号操作过程。在人工智能的 推理期和知识期，符号主义的方法比较盛行，并取得了大量的成果。连接主义 连接主义（connectionism），又称仿生学派或生理学派，是认知科学领域中的一类信息处理的方法和理论。在认知科学领域，人类的认知过程可以看做是一种信息处理过程。连接主义认为人类的认知过程是由大量简单神经元构成的神经网络中的信息处理过程，而不是符号运算。因此，联结主义模型的主要结构是由大量的简单的信息处理单元组成的互联网络，具有非线性、分布式、并行化、局部性计算以及适应性等特性。符号主义方法的一个优点是可解释性，而这也正是连接主义方法的弊端。深 度学习的主要模型神经网络就是一种连接主义模型。随着深度学习的发展，越来越多的研究者开始关注如何融合符号主义和连接主义，建立一种高效并且具 有可解释性的模型。1.1 神经网络随着神经科学、认知科学的发展，我们逐渐知道人类的智能行为都和大脑活动有关。人类大脑是一个可以产生意识、思想和情感的器官。受到人脑神经系统的启发，早期的神经科学家构造了一种模仿人脑神经系统的数学模型，称邱锡鹏：《神经网络与深度学习》https://nndl.github.io/
 1.2 神经网络2019 年 4 月 6 日3为人工神经网络，简称神经网络。在机器学习领域，神经网络是指由很多人工神经元构成的网络结构模型，这些人工神经元之间的连接强度是可学习的参数。1.2.1 大脑神经网络人类大脑是人体最复杂的器官，由神经元、神经胶质细胞、神经干细胞和 血管组成。其中，神经元（Neuron），也叫神经细胞（Nerve Cell），是携带和邱锡鹏：《神经网络与深度学习》https://nndl.github.io/
 42019 年 4 月 6 日第 1 章 绪论传输信息的细胞，是人脑神经系统中最基本的单元。人脑神经系统是一个非常复杂的组织，包含近860 亿个神经元 [Azevedo et al., 2009]，每个神经元有上千个突触和其它神经元相连接。这些神经元和它们之间的连接形成巨大的复杂网络，其中神经连接的总长度可达数千公里。我们人造的复杂网络，比如全球的计算机网络，和大脑神经网络相比要“简单”得多。早在1904 年，生物学家就已经发现了神经元的结构。典型的神经元结构大致可分为细胞体和细胞突起。• 细胞体（Soma）中的神经细胞膜上有各种受体和离子通道，胞膜的受体 可与相应的化学物质神经递质结合，引起离子通透性及膜内外电位差发生 改变，产生相应的生理活动：兴奋或抑制。• 细胞突起是由细胞体延伸出来的细长部分，又可分为树突和轴突。– 树突（Dendrite）可以接受刺激并将兴奋传入细胞体。每个神经元可以有一或多个树突。– 轴突 (Axons) 可以把自身的兴奋状态从胞体传送到另一个神经元或其他组织。每个神经元只有一个轴突。神经元可以接受其它神经元的信息，也可以发送信息给其它神经元。神经元之间没有物理连接，中间留有20 纳米左右的缝隙。神经元之间靠突触（Synapse） 进行互联来传递信息，形成一个神经网络，即神经系统。突触可以理解为神经元之间的链接“接口”，将一个神经元的兴奋状态传到另一个神经元。一个神经元可被视为一种只有两种状态的细胞：兴奋和抑制。神经元的状态取决于从其它的神经细胞收到的输入信号量，及突触的强度（抑制或加强）。当信号量总和超过了某个阈值时，细胞体就会兴奋，产生电脉冲。电脉冲沿着轴突并通过突触传递到其它神经元。图1.2给出了一种典型的神经元结构。树突突触兰氏结细胞体轴突髓鞘细胞核图 1.2 典型神经元结构11图片来源：https://commons.wikimedia.org/wiki/File:Neuron_Hand-tuned.svg邱锡鹏：《神经网络与深度学习》https://nndl.github.io/
 1.2 神经网络2019 年 4 月 6 日5我们知道，一个人的智力不完全由遗传决定，大部分来自于生活经验。也就 是说人脑神经网络是一个具有学习能力的系统。那么人脑神经网络是如何学习 的呢？在人脑神经网络中，每个神经元本身并不重要，重要的是神经元如何组 成联接。不同神经元之间的突触有强有弱，其强度是可以通过学习（训练）来不断改变的，具有一定的可塑性。不同的连接形成了不同的记忆印痕。1949年，加拿大心理学家Donald Hebb 在《行为的组织》（The Organization of Behavior）一书中提出突触可塑性的基本原理，“当神经元 A 的一个轴突和神经元B 很近，Donald Hebb，1904–1985），加拿大神经心理学家，认知心理生理学的开创者。足以对它产生影响，并且持续地、重复地参与了对神经元B个神经元或其中之一会发生某种生长过程或新陈代谢变化，以致于神经元A 作为能使神经元B 兴奋的细胞之一，它的效能加强了。”这个机制称为赫布理论（的兴奋，那么在这两Hebbian Theory）或赫布法则（Hebb’s Rule）。如果两个神经元总是相关联地受到刺激，它们之间的突触强度增加。这样的学习方法被称为赫布型学习（Hebbian learning）。Hebb 认为人脑有两种记忆：长期记忆和短期记忆。短期记忆持续时间不超过一分钟。如果一个经验重复足够的次数，此经验就可储存在长期记忆中。短期记忆转化为长期记忆的过程就称为凝固作用。人脑中的海马区为大脑结构凝固作用的核心区域。1.2.2 人工神经网络人工神经网络是一种模拟人脑神经网络而设计的数据模型或计算模型，它从结构、实现机理和功能上模拟人脑神经网络。人工神经网络与生物神经元类似，由多个节点（人工神经元）相互连接而成，可以用来对数据之间的复杂关系进行建模。不同节点之间的连接被赋予了不同的权重，每个权重代表了一个节点对另一个节点的影响大小。每个节点代表一种特定函数，来自其他节点的信息经过其相应的权重综合计算，输入到一个激励函数中并得到一个新的活性值（兴奋或抑制）。从系统观点看，人工神经元网络是由大量神经元通过极其丰富和完善的连接而构成的自适应非线性动态系统。虽然我们可以比较容易地构造一个人工神经网络，但是如何让人工神经网络具有学习能力并不是一件容易的事情。早期的神经网络模型并不具备学习能力。首个可学习的人工神经网络是赫布网络，采用一种基于赫布规则的无监督学习方法。感知器是最早的具有机器学习思想的神经网络，但其学习方法无法扩展到多层的神经网络上。直到1980 年左右，反向传播算法才有效地解决了多层神经网络的学习问题，并成为最为流行的神经网络学习算法。感知器参见第3.4节。人工神经网络诞生之初并不是用来解决机器学习问题。由于人工神经网络可以看作是一个通用的函数逼近器，一个两层的神经网络可以逼近任意的函数，因此人工神经网络可以看作一个可学习的函数，并应用到机器学习中。理论上，只要有足够的训练数据和神经元数量，人工神经网络就可以学到很多复杂的函邱锡鹏：《神经网络与深度学习》https://nndl.github.io/
 62019 年 4 月 6 日第 1 章 绪论数。人工神经网络模型的塑造任何函数的能力大小可以称为网络容量（NetworkCapacity），与可以被储存在网络中的信息的复杂度以及数量相关。本书中描述的人工神经网络主要是一种作为机器学习的1.2.3 神经网络的发展历史模型。神经网络的发展大致经过五个阶段。第一阶段：模型提出 第一个阶段为1943～1969 年，是神经网络发展的第一个高潮期。在此期间，科学家们提出了许多神经元模型和学习规则。在 1943 年，心理学家Warren McCulloch 和数学家Walter Pitts 最早描述了一种理想化的人工神经网络，并构建了一种基于简单逻辑运算的计算机制。他们提出的神经网络模型称为MP 模型。至此，开启了神经网络研究的序幕。阿兰·图灵在1948 年的论文中描述了一种“B 型图灵机”。之后，研究人员将基于赫布型学习的思想应用到“B 型图灵机”上。1951 年，McCulloch 和 Pitts 的学生Marvin Minsky 建造了第一台神经网络机SNARC。MarvinMinsky，1927～2016 年，人工智能领域最重要的领导者和创新者之一， 麻省理工学院人工智能实验 室的创始人之一。因其在人 工智能领域的贡献，1969 年获得图灵奖。Rosenblatt [1958] 最早提出可以模拟人类感知能力的神经网络模型，并称之为感知器（Perceptron），并提出了一种接近于人类学习过程（迭代、试错） 的学习算法。但感知器因其结构过于简单，不能解决简单的异或（XOR）等线性不可分问题。在这一时期，神经网络以其独特的结构和处理信息的方法，在许多实际应用领域（自动控制领域、模式识别等）中取得了显著的成效。第二阶段：冰河期 第二阶段为1969 年～1983 年，为神经网络发展的第一个低谷期。在此期间，神经网络的研究处于长年停滞及低潮状态。1969 年，Marvin Minsky 出版《感知机》一书，指出了神经网络的两个关键缺陷：第一个是感知机无法处理异或回路问题；第二个是当时的计算机无法支持处理大型神经网络所需要计算能力。这些论断直接将以感知器为代表的神 经网络打入冷宫，导致神经网络的研究进入了十多年的“冰河期”。1974 年，哈佛大学的Paul Webos 发明反向传播算法（Backpropagation，BP），但当时未受到应有的重视。1980 年，Fukushima [1980]（福岛邦彦）提出了一种带卷积和子采样操作的多层神经网络：新知机（Neocognitron）。新知机的提出是受到了动物初级视皮层简单细胞和复杂细胞的感受野的启发。但新知机并没有采用反向传播算法， 而是采用了无监督学习的方式来训练，因此没有引起足够的重视。邱锡鹏：《神经网络与深度学习》https://nndl.github.io/
 1.2 神经网络2019 年 4 月 6 日7第三阶段：反向传播算法引起的复兴 第三阶段为1983 年～1995 年，为神经网络发展的第二个高潮期。这个时期中，反向传播算法重新激发了人们对神经网 络的兴趣。1983 年，加州理工学院的物理学家John Hopﬁeld 提出了一种用于联想记忆和优化计算的神经网络，称为Hopﬁeld 网络。Hopﬁeld 网络在旅行商问题上获得当时最好结果，并引起了轰动。参见第8.3.4.1节。1984 年，Geoﬀrey Hinton 提出一种随机化版本的Hopﬁeld 网络，即玻尔兹曼机。玻尔兹曼机参见第12.1节。真正引起神经网络第二次研究高潮的是反向传播算法。1986年，David Rumel-hart 和James McClelland 对于连接主义在计算机模拟神经活动中的应用提供了全面的论述，并重新发明了反向传播算法。Geoﬀrey Hinton 等人将引入到多层 感知器[Williams and Hinton, 1986]，人工神经网络才又重新引起人们的注意， 并开始成为新的研究热点。随后，LeCun et al. [1989] 将反向传播算法引入了卷积神经网络，并在手写体数字识别上取得了很大的成功[LeCun et al., 1998]。反向传播算法是迄今最为成功的神经网络学习算法，不仅用于多层前馈神经网络， 还用于其他类型神经网络的训练。第四阶段：流行度降低 第四个阶段为1995～2006 年，在此期间，支持向量机和其他更简单的方法（例如线性分类器）在机器学习领域的流行度逐渐超过了神经网络。虽然神经网络可以很容易地增加层数、神经元数量，而从构建复杂的网络，但其计算复杂性也会指数级增长。当时的计算机性能和数据规模不足以支持训练大规模的神经网络。在20 世纪90 年代中期，统计学习理论和以支持向量机为代表的机器学习模型开始兴起。相比之下，神经网络的理论基础不清晰、优化困难、可解释性差等缺点更加凸显，神经网络的研究又一次陷入低潮。第五阶段：深度学习的崛起 2006 年，Hinton and Salakhutdinov [2006] 发现多层前馈神经网络可以先通过逐层预训练，再用反向传播算法进行精调的方式进行有效学习。随着深度的人工神经网络在语音识别[Hinton et al., 2012] 和图像分类[Krizhevsky et al., 2012] 等任务上的巨大成功，以神经网络为基础的“深度学习”迅速崛起。近年来，随着大规模并行计算以及GPU设备的普及，计算机的计算能力得以大幅提高。此外，可供机器学习的数据规模也越来越大。在计 算能力和数据规模的支持下，计算机已经可以训练大规模的人工神经网络。各 大科技公司都投入巨资研究深度学习，神经网络迎来第三次高潮。邱锡鹏：《神经网络与深度学习》https://nndl.github.io/
 82019 年 4 月 6 日第 1 章 绪论1.2 机器学习机器学习（Machine Learning，ML）是指从有限的观测数据中学习（或“猜测”）出具有一般性的规律，并将这些规律应用到未观测样本上的方法。机器学习的详细介绍参见第2章。传统的机器学习主要关注于如何学习一个预测模型。一般需要首先将数据表示为一组特征（Feature），特征的表示形式可以是连续的数值、离散的符号或其它形式。然后将这些特征输入到预测模型，并输出预测结果。这类机器学习可以看作是浅层学习（Shallow Learning）。浅层学习的一个重要特点是不涉及特征学习，其特征主要靠人工经验或特征转换方法来抽取。当我们用机器学习来解决实际任务时，会面对多种多样的数据形式，比如声音、图像、文本等。像图像这类数据很自然地可以表示为一个连续的向量。而文本数据一般由离散符号组成。特别是计算机内部，每个符号都是表示为无意义的编码，很难找到合适的表示方式。因此，在实际任务中使用机器学习模型 一般会包含以下几个步骤（如图1.3所示）：比如图像直接将像素的颜色值（灰度值或RGB 值）组成一个连续向量。原始数据数据预处理特征提取特征处理特征转换预测结果浅层学习图 1.3 传统机器学习的数据处理流程• 数据预处理：经过数据的预处理，如去除噪声等。比如在文本分类中，去除停用词等。• 特征提取：从原始数据中提取一些有效的特征。比如在图像分类中，提取边缘、尺度不变特征变换（Scale Invariant Feature Transform，SIFT）特征等。• 特征转换：对特征进行一定的加工，比如降维和升维。降维包括特征抽取（Feature Extraction）和特征选择（Feature Selection）两种途径。常用的特征转换方法有主成分分析（Principal components analysis，PCA）、线性判别分析（Linear Discriminant Analysis）等。很多特征转换方法也都是机器学习方法。• 预测：机器学习的核心部分，学习一个函数进行预测。上述流程中，每步特征处理以及预测一般都是分开进行处理的。传统的机器学习模型主要关注于最后一步，即构建预测函数。但是实际操作过程中，不同预测模型的性能相差不多，而前三步中的特征处理对最终系统的准确性有着十分关键的作用。由于特征处理一般都需要人工干预完成，利用人类的经验来选取好的特征，并最终提高机器学习系统的性能。因此，很多的模式识别问题变成了特征工程（Feature Engineering）问题。开发一个机器学习系统的主要工作量都消耗在了预处理、特征提取以及特征转换上。邱锡鹏：《神经网络与深度学习》https://nndl.github.io/
 1.4 表示学习2019 年 4 月 6 日151.3 表示学习为了提高机器学习系统的准确率，我们就需要将输入信息转换为有效的特征，或者更一般性称为表示（representation）。如果有一种算法可以自动地学习出有效的特征，并提高最终机器学习模型的性能，那么这种学习就是可以叫做表示学习（Representation Learning）。语义鸿沟 表示学习的关键是解决语义鸿沟（Semantic Gap）问题。语义鸿沟问题是指输入数据的底层特征和高层语义信息之间的不一致性和差异性。比如给定一些关于“车”的图片，由于图片中每辆车的颜色和形状等属性都不尽相同， 不同图片在像素级别上的表示（即底层特征）差异性也会非常大。但是我们人理解这些图片是建立在比较抽象的高层语义概念上的。如果一个预测模型直接建立在底层特征之上，会导致对预测模型的能力要求过高。如果可以有一个好的表示在某种程度上可以反映出数据的高层语义特征，那么我们就可以相对容易地构建后续的机器学习模型。在表示学习中，有两个核心问题：一是“什么是一个好的表示？”；二是“如何学习到好的表示？”1.4.1 局部表示和分布式表示“好的表示”是一个非常主观的概念，没有一个明确的标准。但一般而言，一个好的表示具有以下几个优点：• 一个好的表示应该具有很强的表示能力，即同样大小的向量可以表示更多 信息。• 一个好的表示应该使后续的学习任务变得简单，即需要包含更高层的语义 信息。• 一个好的表示应该具有一般性，是任务或领域独立的。虽然目前的大部分表示学习方法还是基于某个任务来学习，但我们期望其学到的表示可以比 较容易的迁移到其它任务上。在传统机器学习中，我们经常使用两种方式来表示特征：局部表示（LocalRepresentation）和分布式表示（Distributed Representation）。以颜色表示为例，我们一般有两种表示方法。以颜色表示为例，我们有很多词来形容颜色的词1，除了基本的“红”、“蓝”、“绿”、“白”、“黑”等之外，有很多以地区或物品命名的，比如“中国红”、“天蓝色”、“咖啡色”、“琥珀色”等等。11300 多种。https://en.wikipedia.org/wiki/Lists_of_据不完全统计，现有的颜色命名已经有colors邱锡鹏：《神经网络与深度学习》https://nndl.github.io/
 162019 年 4 月 6 日第 1 章 绪论一种表示颜色的方式是以不同名字来命名不同的颜色，这种表示方式叫做局部表示，也称为离散表示或符号表示。局部表示通常可以表示为one-hot 向量的形式。假设所有颜色的名字构成一个词表V，词表大小为|V|。我们可以用一 个|V| 维的one-hot 向量来表示每一种颜色。第i 种颜色的one-hot 向量中，第i 维的值为1，其它都为0。one-hot 向量参见第A.1.4节。局部表示有两个不足之处：（1）one-hot 向量的维数很高，且不能扩展。如果有一种新的颜色，我们就需要增加一维来表示；（2）不同颜色之间的相似度都为0，即我们无法知道“红色”和“中国红”的相似度要比“红色”和“黑色” 的相似度要高。另一种表示颜色的方式是用RGB 值来表示颜色，不同颜色对应到R、G、B三维空间中一个点，这种表示方式叫做分布式表示。分布式表示通常可以表示为低维的稠密向量。分布式表示叫做分散式表示可能更容易理解。即一种颜色的语义分散到语义空间中的不同基向量上。相比与局部表示，分布式表示的表示能力要比局部表示强很多，分布式表示的向量维度一般都比较低。我们只需要用一个三维的稠密向量就可以表示所有颜色。并且分布式表示也很容易表示新的颜色名。此外，不同颜色之间的相似度也很容易计算。表1.1列出了4 种颜色的局部表示和分布式表示。颜色局部表示分布式表示琥珀色天蓝色中国红咖啡色[1, 0, 0, 0]T[0, 1, 0, 0]T[0, 0, 1, 0]T[0, 0, 0, 1]T[1.00, 0.75, 0.00]T[0.00, 0.5, 1.00]T[0.67, 0.22, 0.12]T[0.44, 0.31 0.22]T表 1.1 局部表示和分布式表示示例我们可以使用神经网络来将高维的局部表示空间R|V| 映射到一个非常低维的分布式表示空间Rd, d ≪ |V|。在这个低维空间中，每个特征不在是坐标轴上的点，而是分散在整个低维空间中。在机器学习中，这个过程也称为嵌入（embedding）。嵌入通常指将一个度量空间中的一些对象映射到另一个低维的度量空间中，并尽可能保持不同对象之间的拓扑关系。比如自然语言中词的分布式表示，也经常叫做词嵌入。图1.4展示了一个3 维 one-hot 向量空间和一个2 维嵌入空间的对比。在one-hot 向量空间中，每个特征都位于坐标轴上，每个坐标轴上一个特征。而在低维的嵌入空间中，每个特征都不在坐标轴上，特征之间可以计算相似度。邱锡鹏：《神经网络与深度学习》https://nndl.github.io/
 1.5 深度学习2019 年 4 月 6 日17邱锡鹏：《神经网络与深度学习》https://nndl.github.io/
 182019 年 4 月 6 日第 1 章 绪论w2嵌入空间w1w3邱锡鹏：《神经网络与深度学习》https://nndl.github.io/
 1.5 深度学习2019 年 4 月 6 日19图 1.4 One-hot 向量空间与嵌入空间1.4.2 表示学习要学习到一种好的高层语义表示（一般为分布式表示），通常需要从底层特 征开始，经过多步非线性转换才能得到。一个深层结构的优点是可以增加特征的连续多次的线性转换等价于重用性，从而指数级地增加表示能力。因此，表示学习的关键是构建具有一 定一次线性转换。深度的多层次特征表示[Bengio et al., 2013]。在传统的机器学习中，也有很多有关特征学习的方法，比如主成分分析、线 性判别分析、独立成分分析等。但是传统的特征学习一般是通过人为地设计一 些准则，然后根据这些准则来选取有效的特征。特征的学习是和最终预测模型 的学习分开进行的，因此学习到的特征不一定可以提升最终模型的性能。参见第2.6.1节。1.4 深度学习为了学习一种好的表示，需要构建具有一定“深度”的模型，并通过学习算法来让模型来自动学习出好的特征表示（从底层特征，到中层特征，再到高层特征），从而最终提升预测模型的准确率。所谓“深度”是指原始数据进行非 线性特征转换的次数。如果把一个表示学习系统看作是一个有向图结构，深度 也可以看作是从输入节点到输出节点所经过的最长路径的长度。这样我们就需要一种学习方法可以从数据中学习一个“深度模型”，这就是 深度学习（Deep Learning，DL）。深度学习是机器学习的一个子问题，其主要目的是从数据中自动学习到有效的特征表示。深度学习虽然早期主要用来进行表示学习，但越来越多地用来进行处理更加复杂的推理、决策等问题。邱锡鹏：《神经网络与深度学习》https://nndl.github.io/
 202019 年 4 月 6 日第 1 章 绪论图1.5给出了深度学习的数据处理流程。通过多层的特征转换，把原始数据变成为更高层次、更抽象的表示。这些学习到的表示可以替代人工设计的特征， 从而避免“特征工程”。原始数据底层特征中层特征表示学习高层特征预测结果深度学习图 1.5 深度学习的数据处理流程深度学习是将原始的数据特征通过多步的特征转换得到一种特征表示，并进一步输入到预测函数得到最终结果。和“浅层学习”不同，深度学习需要解决的关键问题是贡献度分配问题（Credit Assignment Problem，CAP）[Minsky,1963]，即一个系统中不同的组件（Components）或其参数对最终系统输出结果的贡献或影响。以下围棋为例，每当下完一盘棋，最后的结果要么赢要么输。我们会思考哪几步棋导致了最后的胜利，而又是哪几步棋导致了最后的败局。如何判断每一步棋的贡献就是贡献度分配问题，这也是一个非常困难的问题。从某种意义上讲，深度学习也可以看作是一种强化学习（Reinforcement Learning，RL），每个内部组件并不能直接得到监督信息，需要通过整个模型的最终监督信息（奖励）得到，并且有一定的延时性。强化学习参见第14章。目前，深度学习采用的模型主要是神经网络模型，其主要原因是神经网络模型可以使用误差反向传播算法，从而可以比较好地解决贡献度分配问题。只要是超过一层神经网络都会存在贡献度分配问题，因此超过一层的神经网络都可以看作是深度学习模型。随着深度学习的快速发展，模型深度也从早期的5 ∼ 10 层到目前的数百层。随着模型深度的不断增加，其特征表示的能力也越来越强， 从而使后续的预测更加容易。1.5.1 端到端学习在一些复杂任务中，传统机器学习方法需要将一个任务的输入和输出之间人为地切割成很多子模块（或多个阶段），每个子模块分开学习。比如一个自然 语言理解任务，一般需要分词、词性标注、句法分析、语义分析、语义推理等骤。这种学习方式有两个问题：一是每一个模块都需要单独优化，并且其优目标和任务总体目标并不能保证一致。二是错误传播，即前一步的错误会对续的模型造成很大的影响。这样就增加了机器学习方法在实际应用的难度。步化后端到端学习（End-to-End Learning），也称端到端训练，是指在学习过程中不进行分模块或分阶段进行训练，直接优化任务的总体目标。在端到端学习中，一般不需要明确地给出不同模块或阶段的功能，中间过程不需要人为干预。邱锡鹏：《神经网络与深度学习》https://nndl.github.io/
 1.5 深度学习2019 年 4 月 6 日21端到端学习的训练数据为“输入-输出”对的形式，无需提供其它额外信息。因此，端到端学习和深度学习一样，都是要解决“贡献度分配”问题。目前，大部分采用神经网络模型的深度学习也可以看作是一种端到端的学习。1.5.2 常用的深度学习框架在深度学习中，一般通过误差反向传播算法来进行参数学习。采用手工方式来计算梯度再写代码实现的方式会非常低效，并且容易出错。此外，深度学习模型需要的计算机资源比较多，一般需要在CPU和GPU之间不断进行切换，开发难度也比较大。因此，一些支持自动梯度计算、无缝CPU 和 GPU 切换等功能的深度学习框架就应运而生。比较有代表性的框架包括：Theano、Caﬀe、TensorFlow、Pytorch、Keras等。Theano1：蒙特利尔大学的Python 工具包，用来高效地定义、优化和执行Theano 项目目前已停止维护。多维数组数据对应数学表达式。Theano 可以透明的使用 GPUs 和高效的符号微分。Caﬀe2： 全 称 为 Convolutional Architecture for Fast Feature Embedding，是一个卷积网络模型的计算框架，所要实现的网络结构可以在配置文件中指定，不需要编码。Caﬀe 是用C++ 和Python 实现，主要用于计算机视觉。TensorFlow3：Google 公司开发的Python 工具包，可以在任意具备CPU 或者 GPU 的设备上运行。TensorFlow 的计算过程使用数据流图来表示。Tensor-Flow的名字来源于其计算过程中的操作对象为多维数组，即张量（tensor）。Chainer4：一个最早采用动态计算图的神经网络框架，其核心开发团队为来自日本的一家机器学习创业公司Preferred Networks。和 Tensorﬂow、Theano、Caﬀe 等框架使用的静态计算图相比，动态计算图可以在运行时动态地构建计算图，因此非常很适合进行一些复杂的决策或推理任务。PyTorch5：由Facebook、NVIDIA、Twitter等公司开发维护的深度学习框架，其前身为Lua 语言的Torch6。PyTorch 也是基于动态计算图的框架，在需要动态改变神经网络结构的任务中有着明显的优势。此外，还有一些深度学习框架，包括微软的CNTK7，由亚马逊、华盛顿大1 http://www.deeplearning.net/software/theano2 http://caﬀe.berkeleyvision.org3 https://www.tensorﬂow.org4 https://chainer.org5 http://pytorch.org6 http://torch.ch7全称为Microsoft Cognitive Toolkit。https://github.com/Microsoft/CNTK邱锡鹏：《神经网络与深度学习》https://nndl.github.io/
 222019 年 4 月 6 日第 1 章 绪论学和卡内基梅隆大学等开发维护的MXNet1和百度开发的PaddlePaddle2等。在这些基础框架之上，还有一些建立在这些框架之上的高度模块化的神经网络库，使得构建一个神经网络模型就像搭积木一样容易。其中比较有名的模块化神经网络框架有：（1）基于TensorFlow 和 Theano 的 Keras3和（2）基于Theano的Lasagne4。更多的深度学习框架可以参考https://en.wikipedia.org/wiki/Comparison_of_deep_learning_software。1.5 本书的组织结构本书主要对神经网络和深度学习所涉及的知识提出一个较全面的基础性介绍。本书的组织结构如图1.6所示，可以分为三大块：机器学习、神经网络和概率图模型。邱锡鹏：《神经网络与深度学习》https://nndl.github.io/
 玻尔兹曼机无向图有向图近似推断精确推断深度信念网络生成对抗网络变分自编码器EM 算法9 年 4 月 6 日23模型推断学习卷积网络密度估计自编码器聚类全连接网络概率图模型无监督学习前馈网络图网络模型神经网络机器学习类型强化学习记忆网络分类回归结构化学习监督学习循环网络模型要素学习准则记忆增强网络线性模型结构风险最小化最大对数似然最大后验估计非线性模型优化算法随机梯度下降邱锡鹏：《神经网络与深度学习》https://nndl.github.io/
 242019 年 4 月 6 日图 1.6 本书的组织结构第 1 章 绪论机器学习 机器学习可以分为监督学习、无监督学习和强化学习。第2章对机器学习进行概述，使读者能够了解机器学习的基本概念，并以线性回归为例来讲述不同学习算法之间的关联。第3章主要介绍一些基本的线性模型。这两章都以监督学习为主进行介绍。第9章介绍了一些无监督学习方法。第10章中介绍一些1 https://mxnet.apache.org2全称为Parallel Distributed Deep Learning。http://paddlepaddle.org/3 http://keras.io/4 https://github.com/Lasagne/Lasagne邱锡鹏：《神经网络与深度学习》https://nndl.github.io/
 1.6 总结和深入阅读2019 年 4 月 6 日21和模型无关的机器学习方法。第14章介绍了深度强化学习的知识。神经网络 第4章到第6章分别讲述三种主要的神经网络模型：前馈神经网络、卷积神经网络和循环神经网络。并在第6章中介绍一种更一般性的网络：图网络。 第7章介绍神经网络的优化与正则化方法。第8章介绍神经网络中的注意力机制和外部记忆。概率图模型概率图模型为机器学习提供了一个更加便捷的描述框架。目前深度学习和概率图模型的融合已经十分流行。第11章介绍了概率图模型的基本概念，并在第12章介绍两种概率图模型：玻尔兹曼机和深度信念网络。第13章和第15章分布介绍两种概率生成模型：深度生成模型和序列生成模型。由于深度学习涉及到非常多的研究领域，因此很多知识无法进行追根溯源并深入介绍。每章最后一节都提供了一些参考文献，读者度需要通过深入阅读来了解这些知识。此外，本书的附录中介绍了一些深度学习涉及到的数学知识，包括线性代数、微积分、概率论、信息论和优化等。1.7 总结和深入阅读要理解深度学习的意义或重要性，就得从机器学习或者是人工智能的更广的视角来分析。在传统机器学习中，除了模型和学习算法外，特征或表示也是影响最终学习效果的重要因素，甚至在很多的任务上比算法更重要。因此，要开发一个实际的机器学习系统，人们往往需要花费大量的精力去尝试设计不同的特征以及特征组合，来提高最终的系统能力，这就是所谓的特征工程问题。如何自动学习有效的数据表示是成为机器学习中的关键问题。早期的表示学习方法，比如特征抽取和特征选择，都是人工引入一些主观假设来进行学习的。这种表示学习不是端到端的学习方式，得到的表示不一定对后续的机器学习任务有效。而深度学习是将表示学习和预测模型的学习进行端到端的学习，中间不需要人工干预。深度学习所要解决的问题是贡献度分配问题，而神经网络恰好是解决这个问题的有效模型。套用马克思的一句名言“金银天然不是货币， 但货币天然是金银”，我们可以说，深度学习天然不是神经网络，但神经网络天然是深度学习。目前，深度学习主要以神经网络模型为基础，研究如何设计模型结构，如何有效地学习模型的参数，如何优化模型性能以及在不同任务上的应用等。Bengio et al. [2013] 给出了一个很好的表示学习综述。若希望全面了解人工神经网络和深度学习的知识，可以参考《Deep Learning》[Goodfellow et al.,2015] 以及文献 [Bengio, 2009]。关于神经网络的历史可以参考文献[Anderson邱锡鹏：《神经网络与深度学习》https://nndl.github.io/
 222019 年 4 月 6 日参考文献and Rosenfeld, 2000]。斯坦福大学的CS231n1 和 CS224n2是两门非常好的深度学习入门课程，分别从计算机视觉和自然语言处理两个角度来讲授了深度学习的基础知识和最新进展。深度学习的研究进展非常迅速。因此，最新的文献一般会发表在学术会议上。和深度学习相关的学术会议主要有：• 国际表示学习会议3（International Conference on Learning Representa-tions，ICLR）：主要聚焦于深度学习。• 神经信息处理系统年会4（Annual Conference on Neural Information Pro-cessing Systems，NeurIPS）：交叉学科会议，但偏重于机器学习。主要包括神经信息处理，统计方法，学习理论以及应用等。• 国际机器学习会议5（International Conference on Machine Learning，ICML）：机器学习顶级会议，深度学习作为近年来的热点，也占据了ICML 的很大比例。• 国际人工智能联合会议6（International Joint Conference on Artiﬁcial In-telligence，IJCAI）：人工智能领域最顶尖的综合性会议。历史悠久，从1969年开始举办。• 美国人工智能协会年会7（AAAI Conference on Artiﬁcial Intelligence，AAAI）：人工智能领域的顶级会议，每年二月份左右召开, 地点一般在北美。另外，人工智能的很多子领域也都有非常好的专业学术会议。在计算机视觉领域，有计算机视觉与模式识别大会（IEEE Conference on Computer Visionand Pattern Recognition，CVPR）和国际计算机视觉会议（International Com-ference on Computer Vision，ICCV）。在自然语言处理领域，有计算语言学年会（Annual Meeting of the Association for Computational Linguistics，ACL）和自然语言处理实证方法大会（Conference on Empirical Methods in NaturalLanguage Processing，EMNLP）等。参考文献周志华. 机器学习. 清华大学出版社, 北京,2016. ISBN 978-7-302-206853-6.1 http://cs231n.stanford.edu2http://web.stanford.edu/class/cs224n/3 http://www.iclr.cc4 https://nips.cc5 https://icml.cc6 https://www.ijcai.org7 http://www.aaai.org邱锡鹏：《神经网络与深度学习》https://nndl.github.io/
 参考文献2019 年 4 月 6 日23James A Anderson and Edward Rosenfeld.Talking nets: An oral history of neural net-works. MiT Press, 2000.The shared views of four research groups.IEEE Signal Processing Magazine, 29(6):82–97, 2012.Frederico AC Azevedo, Ludmila RB Car-valho, Lea T Grinberg, José Marcelo Far-fel, Renata EL Ferretti, Renata EP Leite,Roberto Lent, Suzana Herculano-Houzel,et al. Equal numbers of neuronal and non-neuronal cells make the human brain an iso-metrically scaled-up primate brain. Journalof Comparative Neurology, 513(5):532–541,2009.Geoﬀrey E Hinton and Ruslan R Salakhut-dinov. Reducing the dimensionality of datawith neural networks. Science, 313(5786):504–507, 2006.Alex Krizhevsky, Ilya Sutskever, and Ge-oﬀrey E Hinton. Imagenet classiﬁcationwith deep convolutional neural networks. InAdvances in neural information processingsystems, pages 1097–1105, 2012.Yoshua Bengio. Learning deep architecturesYann LeCun, Bernhard Boser, JohnSfor AI. Foundations and trendsRchine Learning, 2(1):1–127, 2009.in Ma-Denker, Donnie Henderson, Richard EHoward, Wayne Hubbard, and Lawrence DYoshua Bengio, Aaron Courville, and Pas-cal Vincent. Representation learning: A re-view and new perspectives. IEEE transac-tions on pattern analysis and machine in-telligence, 35(8):1798–1828, 2013.Jackel. Backpropagation applied to hand-written zip code recognition. Neural com-putation, 1(4):541–551, 1989.Yann LeCun, Léon Bottou, Yoshua Ben-gio, and Patrick Haﬀner. Gradient-basedlearning applied to document recognition.Proceedings of the IEEE, 86(11):2278–2324,1998.Kunihiko Fukushima. Neocognitron:Aself-organizing neural network model fora mechanism of pattern recognition unaf-fected by shift in position. Biological cyber-netics, 36(4):193–202, 1980.Marvin Minsky. Steps toward artiﬁcial in-telligence. Computers and thought, 406:450,1963.Ian Goodfellow, Aaron Courville, andYoshua Bengio. Deep learning. Book inpreparation for MIT Press, 2015. URLhttp://goodfeli.github.io/dlbook/.Frank Rosenblatt. The perceptron: a prob-abilistic model for information storage andorganization in the brain. Psychological re-view, 65(6):386, 1958.Geoﬀrey Hinton, Li Deng, Dong Yu,George E Dahl, Abdel-rahman Mohamed,Navdeep Jaitly, Andrew Senior, Vin-cent Vanhoucke, Patrick Nguyen, Tara NSainath, et al. Deep neural networks foracoustic modeling in speech recognition:DE Rumelhart GE Hinton RJ Williamsand GE Hinton. Learning representationsby back-propagating errors. Nature, pages323–533, 1986.邱锡鹏：《神经网络与深度学习》https://nndl.github.io/
 

 第 2 章 机器学习概述机器学习是对能通过经验自动改进的计算机算法的研究。— Mitchell [1997]通俗地讲，机器学习（Machine Learning，ML）就是让计算机从数据中进行自动学习，得到某种知识（或规律）。作为一门学科，机器学习通常指一类问题以及解决这类问题的方法，即如何从观测数据（样本）中寻找规律，并利用学习到的规律（模型）对未知或无法观测的数据进行预测。机器学习问题在早期的工程领域也经常称为模式识别（Pattern Recogni-tion，PR），但模式识别更偏向于具体的应用任务，比如光学字符识别、语音识别，人脸识别等。这些任务的特点是对于我们人类而言，这些任务很容易完成，但我们不知道自己是如何做到的，因此也很难人工设计一个计算机程序来解决这些任务。一个可行的方法是设计一个算法可以让计算机自己从有标注的样本上学习其中的规律，并用来完成各种识别任务。随着机器学习技术的应用越来越广，现在机器学习的概念逐渐替代模式识别，成为这一类问题及其解决方法的统称。以手写体数字识别为例，我们需要让计算机能自动识别手写的数字。比如图2.1中的例子，将 识别为数字 5，将 识别为数字 6。手写数字识别是一个经典的机器学习任务，对人来说很简单，但对计算机来说却十分困难。我们很难总结每个数字的手写体特征，或者区分不同数字的规则，因此设计一套识别算法几乎是一项几乎不可能的任务。在现实生活中，很多问题都类似于手写体数字识别这类问题，比如物体识别、语音识别等。对于这类问题，我们不知道如何设计一个计算机程序来解决，即使可以通过一些启发式规则来实现，其过程也是极其复杂的。因此，人们开始尝试采用另一种思路，即让计算机“看”大量的样本，并从中学习到一些经验，然后用这些经验来识别新的样本。要识别手写体数字，首先通过人工标注大量的手写体数字图像（即每张图像都通过人工标记了它是什么数字），这些图像作为训练数据，然后通过学习算法自动生成一
 262019 年 4 月 6 日第2 章 机器学习概述套模型，并依靠它来识别新的手写体数字。这和人类学习过程也比较类似，我们教小孩子识别数字也是这样的过程。这种通过数据来学习的方法就称为机器学习的方法。图 2.1 手写体数字识别示例（图片来源[LeCun et al., 1998]）本章先介绍机器学习的基本概念和要素，并较详细地描述一个简单的机器学习例子，线性回归。2.1 基本概念首先介绍下机器学习中的一些基本概念：包括样本、特征、标签、模型、学习算法等。以一个生活中的经验学习为例，假设我们要到市场上购买芒果，但是之前毫无挑选芒果的经验，那么我们如何通过学习来获取这些知识？首先，我们从市场上随机选取一些芒果，列出每个芒果的特征（feature），特 征 也 可 以 称 为 属 性包括颜色，大小，形状，产地，品牌，以及我们需要预测的标签（label）。标（attribute）。签可以连续值（比如关于芒果的甜度、水分以及成熟度的综合打分），也可以是离散值（比如“好”“坏”两类标签）。一个标记好特征以及标签的芒果可以看作是一个样本（sample）。一组样本样本（sample），也叫示例（instance）。构成的集合称为数据集（dataset）。一般将数据集分为两部分：训练集和测试集。训练集（training set）中的样本是用来训练模型的，也叫训练样本（trainingsample），而测试集（test本（test sample）。set）中的样本是用来检验模型好坏的，也叫测试样在很多领域，数据集也经常d 维向量x = [x , x , · · · , x ]T 表示一个芒果的所有特征构成的1 d2称为语料库（corpus）。我们用一个向量，称为特征向量（featurevector），其中每一维表示一个特征。并不是所有的样本特征都是数值型，需要通过转换表示为特征向量，参见第2.6节。假设训练集由N 个样本组成，其中每个样本都是独立同分布（Identicallyand Independently Distributed，IID）的，即独立地从相同的数据分布中抽取邱锡鹏：《神经网络与深度学习》https://nndl.github.io/
 2.1 基本概念2019 年 4 月 6 日27的，记为D = {(x(1) , y(1) ), (x(2), y(2)), · · · , (x(N ) , y(N ) )}.(2.1)给定训练集D，我们希望让计算机自动寻找一个函数f (x, θ) 来建立每个样本特性向量x 和标签y 之间的映射。对于一个样本x，我们可以通过决策函数来预测其标签的值yˆ = f (x, θ),(2.2)或标签的条件概率p(y|x) = fy(x, θ),(2.3)其中θ 为可学习的参数。通过一个学习算法（learning algorithm）A，在训练集上找到一组参数θ∗，使得函数f (x, θ∗) 可以近似真实的映射关系。这个过程称为学习（learning）或训练（training）过程，函数f(x, θ) 称为模型（model）。在有些文献中，学习算法也下次从市场上买芒果（测试样本）时，可以根据芒果的特征，使用学习到的模型f(x, θ∗)来预测芒果的好坏。为了评价的公正性，我们还是独立同分布地抽取一组样本作为测试集D′，并在测试集中所有样本上进行测试，计算预测结果的准确率。叫做学习器（learner）。Σ1Acc(f(x, θ∗)) =I f(x, θ∗) = y ,(2.4)|D′|(x,y)∈D′其中I(·) 为指示函数，|D′| 为测试集大小。第2.7节中会介绍更多的评价图2.2给出了机器学习的基本概念。对一个预测任务，输入特征向量为x，输 出标签为y，我们选择一个函数f(x, θ)，通过学习算法A 和一组训练样本D，找到一组最优的参数θ∗，得到最终的模型f(x, θ∗)。这样就可以对新的输入x进行预测。方法。xf (x, θ∗)y或p(y|x)输入输出模型{x(i), y(i)}NAi=1训练样本集合学习算法图 2.2 机器学习系统示例邱锡鹏：《神经网络与深度学习》https://nndl.github.io/
 282019 年 4 月 6 日第2 章 机器学习概述2.2 机器学习的三个基本要素机器学习是从有限的观测数据中学习（或“猜测”）出具有一般性的规律，并可以将总结出来的规律推广应用到未观测样本上。机器学习方法可以粗略地分为三个基本要素：模型、学习准则、优化算法。2.2.1 模型一个机器学习任务要先需要确定其输入空间X 和输出空间Y。不同机器学习任务的主要区别在于输出空间不同。在两类分类问题中Y = {+1, −1}，在C类分类问题中Y = {1, 2, · · · , C}，而在回归问题中Y = R。这里，输入空间默认为样本的特征空间。输入空间 X 和输出空间 Y 构成了一个样本空间。对于样本空间中的样本(x, y) ∈ X × Y，假定存在一个未知的真实映射函数g : X → Y 使得y = g(x),(2.5)或者真实条件概率分布pr(y|x),(2.6)机器学习的目标是找到一个模型来近似真实映射函数g(x) 或真实条件概率分布pr(y|x)。由于我们不知道真实的映射函数g(x) 或条件概率分布pr(y|x) 的具体形式，只能根据经验来确定一个假设函数集合F，称为假设空间（hypothesis space），然后通过观测其在训练集D上的特性，从中选择一个理想的假设（hypothesis）f∗ ∈ F 。假设空间F 通常为一个参数化的函数族F = {f(x, θ)|θ ∈ Rm},(2.7)其中f (x, θ) 为假设空间中的模型，θ 为一组可学习参数，m 为参数的数量。常见的假设空间可以分为线性和非线性两种，对应的模型f 也分别称为线性模型和非线性模型。2.2.1.1 线性模型线性模型的假设空间为一个参数化的线性函数族，对于分类问题，一般为广义线性函数，参见公式 (3.3)。f (x, θ) = wTx + b,其中参数θ 包含了权重向量w 和偏置b。邱锡鹏：《神经网络与深度学习》(2.8)https://nndl.github.io/
 2.2 机器学习的三个基本要素2.2.1.2 非线性模型2019 年 4 月 6 日29广义的非线性模型可以写为多个非线性基函数ϕ(x) 的线性组合f(x, θ) = w ϕ(x) + b,其中ϕ(x) = [ϕ (x), ϕ (x), · · · , ϕK (x)]T 为K 个非线性基函数组成的向量，参数T(2.9)12θ 包含了权重向量w 和偏置b。如果ϕ(x)本身为可学习的基函数，比如ϕk(x) = h(wTϕ′(x) + bk), ∀1 ≤ k ≤ K,(2.10)k其中h(·) 为非线性函数，ϕ′(x) 为另一组基函数，w 和b 为可学习的参数，则kkf(x, θ)就等价于神经网络模型。2.2.2 学习准则令训练集 D = {(x(n), y(n))}N是由N个独立同分布（Identically and In-n=1dependently Distributed，IID）的样本组成，即每个样本(x, y) ∈ X × Y 是从X 和 Y 的联合空间中按照某个未知分布 pr(x, y) 独立地随机产生的。这里要求样本分布pr (x, y) 必须是固定的（虽然可以是未知的），不会随时间而变化。如果pr(x, y) 本身可变的话，我们就无法通过这些数据进行学习。一个好的模型 f (x, θ∗) 应该在所有(x, y) 的可能取值上都与真实映射函数y = g(x) 一致，即|f(x, θ∗) − y| < ϵ,或与真实条件概率分布pr(y|x) 一致，即|f (x, θ∗) − p (y|x)| < ϵ,∀(x, y) ∈ X × Y,(2.11)这里两个分布相似性的定义不太严谨，更好的方式为KL∀(x, y) ∈ X × Y,(2.12)yr散度或交叉熵。其中ϵ是一个很小的正数，fy (x, θ∗)为模型预测的条件概率分布中 对应的概率。y模型f(x, θ) 的好坏可以通过期望风险（Expected Risk）ꢀ(θ) 来衡量。期望风险也称为期望错误（Expected Error）。ꢀ(θ) = E(x,y)∼pr (x,y)[L(y, f (x, θ))],(2.13)其中pr(x, y) 为真实的数据分布，L(y, f (x, θ)) 为损失函数，用来量化两个变量之间的差异。2.2.2.1 损失函数损失函数是一个非负实数函数，用来量化模型预测和真实标签之间的差异。下面介绍几种常用的损失函数。邱锡鹏：《神经网络与深度学习》https://nndl.github.io/
 302019 年 4 月 6 日第2 章 机器学习概述0-1 损失函数 最直观的损失函数是模型预测的错误率，即 0-1 损失函数（0-1Loss Function）。0if y = f(x, θ) 1 if y = f (x, θ)= I(y = f (x, θ)),L(y, f(x, θ)) =(2.14)(2.15)其中I(·) 是指示函数。虽然0-1 损失能够客观的评价模型的好坏，但缺点是数学性质不是很好：不连续且导数为0，难以优化。因此经常用连续可微的损失函数替代。平方损失函数 平方损失函数（Quadratic Loss Function）经常用在预测标签y为实数值的任务中。122L(y, f(x, θ)) =y − f(x, θ).(2.16)平方损失函数一般不适用于分类问题。参见习题2-1。交叉熵损失函数 交叉熵损失函数（Cross-Entropy Loss Function）一般用于分类问题。假设样本的标签y ∈ {1, · · · C} 为离散的类别，模型f (x, θ) ∈ [0, 1]C 的输出为类别标签的条件概率分布，即p(y = c|x, θ) = fc(x, θ),(2.17)并满足ΣCfc(x, θ) ∈ [0, 1],fc(x, θ) = 1.(2.18)c=1我们可以用一个C 维的one-hot向量y 来表示样本标签。假设样本的标签为k，那么标签向量y 只有第k 维的值为1，其余元素的值都为0。标签向量y 可以看作是样本标签的真实概率分布，即第c 维（记为yc，1 ≤ c ≤ C）是类别为c的真实概率。假设样本的类别为k，那么它属于第k 类的概率为1，其它类的概率为0。对于两个概率分布，一般可以用交叉熵来衡量它们的差异。标签的真实分交叉熵参见第E.3.1节。布y和模型预测分布f(x, θ) 之间的交叉熵为ΣCL(y, f(x, θ)) =−y log f (x, θ).(2.19)ccc=1邱锡鹏：《神经网络与深度学习》https://nndl.github.io/
 2.2 机器学习的三个基本要素2019 年 4 月 6 日31比如对于三类分类问题，一个样本的标签向量为y = [0, 0, 1]T ，模型预测的标签分布为f(x, θ) = [0.3, 0.3, 0.4]，则它们的交叉熵为TL(θ) = − 0 × log(0.3) + 0 × log(0.3) + 1 × log(0.4)= − log(0.4).因为y 为 one-hot 向量，公式(2.19) 也可以写为L(y, f (x, θ)) = − log fy(x, θ),(2.20)其中fy(x, θ) 可以看作真实类别y 的似然函数。因此，交叉熵损失函数也就是负对数似然损失函数（Negative Log-Likelihood Function）。Hinge 损失函数 对于两类分类问题，假设y 和f (x, θ) 的取值为{−1, +1}。Hinge损失函数（Hinge Loss Function）为L(y, f (x, θ)) = max (0, 1 − yf (x, θ)), [1 − yf (x, θ)]+.(2.21)(2.22)2.2.2.2 风险最小化准则一个好的模型f(x, θ)应当有一个比较小的期望错误，但由于不知道真实的数据分布和映射函数，实际上无法计算期望风险ꢀ(θ; x, y)。给定一个训练集D = {(x(n), y(n))}N ，我们可以计算的是经验风险（EmpiricalRisk），即在n=1训练集上的平均损失。经验风险也称为经验错误Σ1N（Empirical Error）。empDL(y(n), f (x(n), θ)).(2.23)ꢀ(θ) =Nn=1因此，一个切实可行的学习准则是找到一组参数θ∗使得经验风险最小，θ∗ = arg min ꢀemp(θ),(2.24)Dθ这就是经验风险最小化（Empirical Risk Minimization，ERM）准则。过拟合 根据大数定理可知，当训练集大小|D| 趋向于无穷大时，经验风险就趋向于期望风险。然而通常情况下，我们无法获取无限的训练样本，并且训练样本往往是真实数据的一个很小的子集或者包含一定的噪声数据，不能很好地反映全部数据的真实分布。经验风险最小化原则很容易导致模型在训练集上错误率很低，但是在未知数据上错误率很高。这就是所谓的过拟合（Overﬁtting）。如 何 选 择 训 练 样 本 个 数可 以参 考PAC 理论， 参见第2.8.1节。邱锡鹏：《神经网络与深度学习》https://nndl.github.io/
 322019 年 4 月 6 日第2 章 机器学习概述定义 2.1 – 过拟合： 给定一个假设空间F，一个假设f 属于F，如果存在其他的假设f ′ 也属于F, 使得在训练集上f 的损失比f′ 小，但在整个样本空间上f′ 比 f 的损失小，那么就说 假设f 过度拟合训练数据[Mitchell, 1997]。过拟合问题往往是由于训练数据少和噪声以及模型能力强等原因造成的。为了解决过拟合问题，一般在经验风险最小化的基础上再引入参数的正则化（regularization），来限制模型能力，使其不要过度地最小化经验风险。这种准则就是结构风险最小化（Structure Risk Minimization，SRM）准则。θ∗ = arg min ꢀstruct(θ)(2.25)Dθ= arg min ꢀemp(θ) +1 λ∥θ∥22(2.26)(2.27)DθΣN1= arg min(()) +L y n , f x n , θ( λ)∥θ( ∥) ,22Nθn=1其中∥θ∥ 是ℓ2 范数的正则化项，用来减少参数空间，避免过拟合；λ 用来控制正则化的强度。更 多 的 正 则 化 方 法 参 见第7.7节。正则化项也可以使用其它函数，比如ℓ 范数。ℓ 范数的引入通常会使得参数11有一定稀疏性，因此在很多算法中也经常使用。在贝叶斯学习的角度来讲，正则化是假设了参数的先验分布，不完全依赖训练数据。ℓ1 范 数 的 稀 疏 性 参 见第7.7.1节。正则化的贝叶斯解释参见总之，机器学习中的学习准则并不仅仅是拟合训练集上的数据，同时也要使得泛化错误最低。给定一个训练集，机器学习的目标是从假设空间中找到一个泛化错误较低的“理想”模型，以便更好地对未知的样本进行预测，特别是不在训练集中出现的样本。因此，机器学习可以看作是一个从有限、高维、有噪声的数据上得到更一般性规律的泛化问题。第2.3.1.4节。和过拟合相反的一个概念是欠拟合（underﬁtting），即模型不能很好地拟合训练数据，在训练集的错误率比较高。欠拟合一般是由于模型能力不足造成的。图2.3给出了欠拟合和过拟合的示例。邱锡鹏：《神经网络与深度学习》https://nndl.github.io/
 2.2 机器学习的三个基本要素2019 年 4 月 6 日33欠拟合正常过拟合图 2.3 欠拟合和过拟合示例2.2.3 优化算法在确定了训练集D、假设空间F 以及学习准则后，如何找到最优的模型f (x, θ∗) 就成了一个最优化（optimization）问题。机器学习的训练过程其实就是最优化问题的求解过程。参数与超参数在机器学习中，优化又可以分为参数优化和超参数优化。模型f (x, θ) 中的θ 称为模型的参数，可以通过优化算法进行学习。除了可学习的参数 θ 之外，还有一类参数是用来定义模型结构或优化策略的，这类参数叫做超参数（hyper-parameter）。在贝叶斯方法中，超参数可以理解为参数的参数，即控制模型参数分布的参数。常见的超参数包括：聚类算法中的类别个数、梯度下降法的步长、正则项的系数、神经网络的层数、支持向量机中的核函数等。超参数的选取一般都是组合优化问题，很难通过优化算法来自动学习。因此，超参数优化是机器学习的一个经验性很强的技术，通常是按照人的经验设定，或者通过搜索的方法对一组超参数组合进行不断试错调整。超参数的优化参见第7.6节。2.2.3.1 梯度下降法为了充分利用凸优化中一些高效、成熟的优化方法，比如共轭梯度、拟牛顿法等，很多机器学习方法都倾向于选择合适的模型和损失函数以构造一个凸函数作为优化目标。但也有很多模型（比如神经网络）的优化目标是非凸的，只能退而求其次找到局部最优解。不同机器学习算法的区别在于模型、学习准则（损失函数）和优化算法的差 异。相同的模型也可以有不同的学习算法。比如线性分类模型有感知器、logistic 回归和支持向量机，它们之间的差异在于使用了不同的学习准则和优化算法。在机器学习中，最简单、常用的优化算法就是梯度下降法，即通过迭代的梯度 下 降 法 参 见方法来计算训练集D 上风险函数的最小值。第C.2.0.2节。∂ꢀD(θ)θt+1 = θt−α(2.28)∂θ邱锡鹏：《神经网络与深度学习》https://nndl.github.io/
 342019 年 4 月 6 日第2 章 机器学习概述邱锡鹏：《神经网络与深度学习》https://nndl.github.io/
 2.2 机器学习的三个基本要素2019 年 4 月 6 日35Σ∂y(n), f (x(n), θL)N1,(2.29)= θt − α ·∂θN n=1其中θt 为第t 次迭代时的参数值，α为搜索步长。在机器学习中，α一般称为学习率（learning rate）。2.2.3.2 提前停止针对梯度下降的优化算法，除了加正则化项之外，还可以通过提前停止来防止过拟合。在梯度下降训练的过程中，由于过拟合的原因，在训练样本上收敛的参数， 并不一定在测试集上最优。因此，除了训练集和测试集之外，有时也会使用一个验证集（validation set）来进行模型选择，测试模型在验证集上是否最优。在每次迭代时，把新得到的模型f(x, θ)在验证集上进行测试，并计算错误率。如果在验证集上的错误率不再下降，就停止迭代。这种策略叫提前停止（early stop）。如果没有验证集，可以在训练集上划分出一个小比例的子集作为验证集。图2.4给出了提前停止的示例。验 证 集 也 叫 开 发 集（development set）。邱锡鹏：《神经网络与深度学习》https://nndl.github.io/
 错误率训练集验证集362019 年 4 月 6 日第2 章 机器学习概述提前停止过拟合迭代次数邱锡鹏：《神经网络与深度学习》https://nndl.github.io/
 2.2 机器学习的三个基本要素2019 年 4 月 6 日37图 2.4 前提停止2.2.3.3 随机梯度下降法在公式(2.28) 的梯度下降法中，目标函数是整个训练集上风险函数，这种方式称为批量梯度下降法（Batch Gradient Descent，BGD）。批量梯度下降法在每次迭代时需要计算每个样本上损失函数的梯度并求和。当训练集中的样本数量N 很大时，空间复杂度比较高，每次迭代的计算开销也很大。在机器学习中，我们假设每个样本都是独立同分布的从真实数据分布中随邱锡鹏：《神经网络与深度学习》https://nndl.github.io/
 382019 年 4 月 6 日第2 章 机器学习概述机抽取出来的，真正的优化目标是期望风险最小。批量梯度下降相当于是从真 实数据分布中采集 N 个样本，并由它们计算出来的经验风险的梯度来近似期望风险的梯度。为了减少每次迭代的计算复杂度，我们也可以在每次迭代时只集一个样本，计算这个样本损失函数的梯度并更新参数，即随机梯度下降法采（Stochastic Gradient Descent，SGD）。当经过足够次数的迭代时，随机梯度下降也可以收敛到局部最优解[Nemirovski et al., 2009]。随机梯度下降法也叫增量梯度下降。随机梯度下降法的训练过程如算法2.1所示。算法 2.1: 随机梯度下降法输入: 训练集D = {(x(n), y(n))}N ，验证集V，学习率αn=11 随机初始化θ;2 repeat345对训练集D 中的样本随机重排序;for n = 1 · · · N do从训练集D 中选取样本(x(n), y(n));// 更新参数∂L θ; x(n), y(n)6θ ← θ − αend;∂θ78until 模型f (x, θ) 在验证集V 上的错误率不再下降;输出: θ批量梯度下降和随机梯度下降之间的区别在于每次迭代的优化目标是对所有样本的平均损失函数还是单个样本的损失函数。随机梯度下降因为实现简单，收敛速度也非常快，因此使用非常广泛。随机梯度下降相当于在批量梯度下降的梯度上引入了随机噪声。当目标函数非凸时，反而可以使其逃离局部最优点。小批量梯度下降法随机梯度下降法的一个缺点是无法充分利用计算机的并行计算能力。小批量梯度下降法（Mini-Batch Gradient Descent）是批量梯度下降和随机梯度下降的折中。每次迭代时，我们随机选取一小部分训练样本来计算梯度并更新参数，这样既可以兼顾随机梯度下降法的优点，也可以提高训练效率。第 t 次迭代时，随机选取一个包含K 个样本的子集It，计算这个子集上每个样本损失函数的梯度并进行平均，然后再进行参数更新。K 通常不会设置很大，一般在 1 ∼ 100 之间。在实际应Σ∂L y, f (x, θ)1θt+1 ← θt − α ·.(2.30)用中为了提高计算效率，通tK∂θ(x,y)∈I邱锡鹏：《神经网络与深度学习》https://nndl.github.io/
 2.2 机器学习的三个基本要素2019 年 4 月 6 日39常设置为2 的 n 次方。邱锡鹏：《神经网络与深度学习》https://nndl.github.io/
 402019 年 4 月 6 日第2 章 机器学习概述在实际应用中，小批量随机梯度下降方法有收敛快，计算开销小的优点，因 此逐渐成为大规模的机器学习中的主要优化算法[Bottou, 2010]。2.3 机器学习的简单示例：线性回归在本节中，我们通过一个简单的模型（线性回归）来具体了解机器学习的一般过程，以及不同学习准则（经验风险最小化、结构风险最小化、最大似然估计、最大后验估计）之间的关系。线性回归（Linear Regression）是机器学习和统计学中最基础和广泛应用的模型，是一种对自变量和因变量之间关系进行建模的回归分析。自变量数量为1 时称为简单回归，自变量数量大于1 时称为多元回归。从机器学习的角度来看，自变量就是样本的特性向量x ∈ Rd（每一维对应一个自变量），因变量是标签y，这里y ∈ R 是连续值（实数或连续整数）。假设空间是一组参数化的线性函数f(x; w, b) = wTx + b,(2.31)其中权重向量w和偏置b 都是可学习的参数，函数f(x; w, b) ∈ R也称为线性模型。为了简单起见，我们将公式(2.31) 写为f (x; wˆ ) = wˆ T xˆ,(2.32)其中wˆ 和xˆ 分别称为增广权重向量和增广特征向量。x1..xˆ = x ⊕ 1,x=,(2.33) xk1邱锡鹏：《神经网络与深度学习》https://nndl.github.io/
 2.2 机器学习的三个基本要素2019 年 4 月 6 日411w1邱锡鹏：《神经网络与深度学习》https://nndl.github.io/
 422019 年 4 月 6 日第2 章 机器学习概述..,=,(2.34)wwˆ = w ⊕ b wkbb邱锡鹏：《神经网络与深度学习》https://nndl.github.io/
 2.2 机器学习的三个基本要素2019 年 4 月 6 日43其中⊕ 定义为两个向量的拼接操作。邱锡鹏：《神经网络与深度学习》https://nndl.github.io/
 

 2.3 机器学习的简单示例：线性回归2019 年 4 月 6 日37不失一般性，在本章后面的描述中我们采用简化的表示方法，直接用w 和x来表示增广权重向量和增广特征向量。即线性回归的模型简写为 f (x; w) =Tw x。2.3.1 参数学习给定一组包含N 个训练样本的训练集D = {(x(n), y(n))}, 1 ≤ n ≤ N，我们希望能够学习一个最优的线性回归的模型参数w。我们介绍四种不同的参数估计方法：经验风险最小化、结构风险最小化、最 大似然估计、最大后验估计。2.3.1.1 经验风险最小化由于线性回归的标签y 和模型输出都为连续的实数值，因此平方损失函数非常合适来衡量真实标签和预测标签之间的差异。平 方 损 失 函 数 参 见根据经验风险最小化准则，训练集D 上的的经验风险定义为第2.2.2.1节。NΣꢀ(w) = L(y(n), f (x(n), w))(2.35)(2.36)为了简化起见，这里的风险1 。n=1函数省略了NΣN=21y(n) − wT x(n)2n=1=1 ∥y − XTw∥2,(2.37)2其中y ∈ R 是由每个样本的真实标签y(1) · · · y( ) 组成的列向量， ∈N,,NXR(d+1)×N是所有输入 x(1), · · · , x(N ) 组成的矩阵x1(1)(2)(N)x1· · · x1......X =.(2.38)(1)d(2)d(N) xx· · ·· · ·xd111参见习题2-2。风险函数ꢀ(w)是关于w 的凸函数，其对w 的偏导数为(2.39)(2.40)∂ꢀ(w)∂w1 ∂ ∥y − XTw∥2=2∂w= −X(y − X w),T令∂ ꢀ(w) = 0，得到最优的参数w∗ 为∂w(XXT)−1X 也称为 X 的伪w邱锡鹏：《神经网络与深度学习》https://nndl.github.io/
 382019 年 4 月 6 日第2 章 机器学习概述∗ = (XX )−1XyT(2.41)逆矩阵。邱锡鹏：《神经网络与深度学习》https://nndl.github.io/
 2.3 机器学习的简单示例：线性回归2019 年 4 月 6 日39ΣΣN−1N=x(n) x(n)Tx( )n y n( ).(2.42)n=1n=1这种求解线性回归参数的方法也叫最小二乘法估计（Least Square Estimation，LSE）。图2.5给出了用最小二乘法估计方法来进行参数学习的示例。2y = 0.60·x+0.5210−1−1.5−1−0.50x0.511.5图 2.5 线性回归示例在最小二乘法估计方法中，X X T ∈ R(d+1)×(d+1)必须存在逆矩阵，即X X T是满秩的（rank(X X T ) = d+ 1）。也就是说，X 中的每一行特征之间是线性不相关的。一种常见的XX 不可逆情况是样本数量N 小于特征数量(d + 1)，XX的秩为N。这时会存在很多解w∗，可以使得ꢀ(w∗) = 0TT。参见习题2-3。当XXT 不可逆时，可以使用主成分分析等方法来预处理数据，消除不同特征之间的相关性，然后再使用最小二乘估计方法来求解。或者是通过用梯度下降法来求解。初始化w0 = 0，通过下面公式进行迭代，w ← w + αX(y − XTw),(2.43)其中α 是学习率。这种方法也称为最小均方误差（Least Mean Squares，LMS）算法。2.3.1.2 结构风险最小化最小二乘法估计的基本要求是各个特征之间要相互独立，保证XXT 可逆。共线性是指一个特征可以通过其他特征的线性组合来被较准确地预测。但即使XXT 可逆，如果特征之间可能会有较大的共线性（multicollinearity），也会使得XX(XXT)−1 发生大的改变，进而使得最小二乘法估计的计算变得很不稳定。为的逆在数值上无法准确计算。数据集X 上一些小的扰动就会导致T邱锡鹏：《神经网络与深度学习》https://nndl.github.io/
 402019 年 4 月 6 日第2 章 机器学习概述了解决这个问题，Hoerl and Kennard [1970] 提出了岭回归（Ridge Regression），给XX的参数w∗ 为的对角线元素都加上一个常数λI 使得(XX+ λI) 的秩不为0。最优TTw∗ = (XX+ λI)−1Xy,(2.44)T其中λ > 0 为预先设置的超参数，I 为单位矩阵。岭回归的解w∗可以看做是结构风险最小化准则下的最小二乘法估计。参见习题2-4。11T22ꢀ(w) =2 ∥y − X w∥ +2λ∥w∥ ,(2.45)其中λ > 0 为正则化系数。2.3.1.3 最大似然估计机器学习任务可以分为两类，一类是样本的特征向量x 和标签y 之间如果存在未知的函数关系 y = h(x)，另一类是条件概率 p(y|x) 服从某个未知分布。第2.3.1.1中介绍的最小二乘估计是属于第一类，直接建模x和标签y 之间的函数关系。此外，线性回归还可以通过建模条件概率p(y|x) 的角度来进行参数估计。假设标签y 为一个随机变量，其服从以均值为f (x, w) = w差为σ2 的高斯分布。Tx 为中心，方这里x 看作是确定值的参数。p(y|x, w, σ) = N(y|wTx, σ2)(2.46)(y−w x)2= √ 1expT.(2.47)−2σ22πσ参数 w 在训练集 D 上的似然函数（likelihood）为似然函数是关于统计模型的参数的函数。Np(y|X, w, σ) =p|(y(n) x(n), w, σ)(2.48)似然 p(x|w) 和概率 p(x|w)之 间 的 区 别 在 于： 概 率n=1YN(x|w) 是描述固定参数w 时，p()x(n , σ ),)2N|=(y n wT(2.49)随机变量 x 的分布情况，而似然p(x|w) 则是描述已知随机变量 x 时，不同的参数 w对其分布的影响。n=1其中y = [y(1), · · · , y(N )]T 为所有样本标签组成的向量，X = [x(1), · · · , x N ]为()所有样本特征向量组成的矩阵。为了方便计算，对似然函数取对数得到对数似然函数（loglikelihood），ΣNlog p(y|X, w, σ) =N ylog ( (n) w|x 2)(n), σ .(2.50)Tn=1最大似然估计（Maximum Likelihood Estimate，MLE）是指找到一组参数w 使得似然函数p(y|X, w, σ) 最大，等价于对数似然函数log p(y|X, w, σ) 最大。邱锡鹏：《神经网络与深度学习》https://nndl.github.io/
 2.3 机器学习的简单示例：线性回归2019 年 4 月 6 日41∂ log p(y|X, w, σ)令= 0，得到∂w参见习题2-5。wML = (XX)−1Xy.(2.51)T可以看出，最大似然估计的解和最小二乘估计的解相同。最小二乘估计解参见公式(2.41)。2.3.1.4 最大后验估计假设参数w 为一个随机向量，并服从一个先验分布p(w|ν)。简单起见，一般令p(w|ν)为各向同性的高斯分布p(w|ν) = N(w|0, ν2I),其中ν2 为每一维上的方差。(2.52)贝 叶 斯 公 式 参 见 公 式(D.32)。根据贝叶斯公式，那么参数w 的后验概率分布（posterior distribution）为p(w, y|X, ν, σ)分母为和w 无关的常量。p(w|X, y, ν, σ) =(2.53)p,(w|X,yν, σ)wꢀ p(y|X, w, σ)p(w|ν),(2.54)其中p(y|X, w, σ) 为w 的似然函数，定义见公式(2.48)，p(w|ν) 为w 的先验。这种估计参数 w 的后验概率分布的方法称为贝叶斯估计（Bayesian Esti-mation），是一种统计推断问题。采用贝叶斯估计的线性回归也称为贝叶斯线性回归（Bayesian Linear Regression）。统计推断参见第11.2节。贝叶斯估计是一种参数的区间估计，即参数在一个区间上的分布。如果我们希望得到一个最优的参数值（即点估计），可以使用最大后验估计。最大后验估计（Maximum A Posteriori Estimation，MAP）是指最优参数为后验分布p(w|X, y, ν, σ) 中概率密度最高的参数w。wMAP = arg max p(y|X, w, σ)p(w|ν),(2.55)w令似然函数p(y|X, w, σ) 为公式(2.49) 中定义的高斯密度函数，则后验分布p(w|X, y, ν, σ) 的对数为log p(w|X, y, ν, σ) ꢀ log p(y|X, w, σ) + log p(w|ν)(2.56)(2.57)Σ1N12ν22y(n) − wTx(n)∥ − X∥ −−wTw,ꢀ −2σ2n=1NΣ1 −.T=22Tyw22σ2ν(2.58)n=1w w可以看出，最大后验概率等价于平方损失的结构方法最小化，其中正则化系数λ = σ2/2ν2。邱锡鹏：《神经网络与深度学习》https://nndl.github.io/
 

 2.4 偏差-方差分解2019 年 4 月 6 日41最大似然估计和贝叶斯估计可以看作是频率学派和贝叶斯学派对需要估计的参数w 的不同解释。当ν → ∞ 时，先验分布p(w|ν) 退化为均匀分布，称为无信息先验（non-informative prior），最大后验估计退化为最大似然估计。2.4 偏差-方差分解为了避免过拟合，我们经常会在模型的拟合能力和复杂度之间进行权衡。拟合能力强的模型一般复杂度会比较高，容易导致过拟合。相反，如果限制模型的复杂度，降低其拟合能力，又可能会导致欠拟合。因此，如何在模型能力和复杂度之间取得一个较好的平衡对一个机器学习算法来讲十分重要。偏差-方差分解（Bias-Variance Decomposition）为我们提供一个很好的分析和指导工具。本节介绍的偏差-方差分解以回归问题为例，但其结论同样适用于分类问题。以回归问题为例，假设样本的真实分布为 pr(x, y)，并采用平方损失函数，模型f(x) 的期望错误为这里省略了模型参数θ。h2i.ꢀ(f ) = E(x ,y) ∼pr(x ,y) y − f (x)(2.59)那么最优的模型为参见习题2-8。f ∗(x) = Ey∼pr (y|x) y .(2.60)其中pr(y|x) 为样本的真实条件分布，f ∗(x) 为使用平方损失作为优化目标的最优模型，其损失为h2i.ε = E(x ,y) ∼pr(x ,y) y − f ∗(x)(2.61)损失ε 通常是由于样本分布以及噪声引起的，无法通过优化模型来减少。期望错误可以分解为2ꢀ(f ) = E(x,y)∼pr (x,y) y − f ∗(x) + f ∗(x) − f (x)(2.62)(2.63)2= Ex∼pr (x) f(x) − f∗(x)+ ε,根 据 公 式2.60，E E [y −x yf ∗(x)] = 0.其中第一项是机器学习算法可以优化的真实目标，是当前模型和最优模型之间的差距。在实际训练一个模型f (x) 时，训练集D 是从真实分布pr(x, y) 上独立同分布地采样出来的有限样本集合。不同的训练集会得到不同的模型。令fD(x) 表示在训练集D 学习到的模型，一个机器学习算法（包括模型以及优化算法）的能力可以用不同训练集上的模型的平均性能来评价。邱锡鹏：《神经网络与深度学习》https://nndl.github.io/
 422019 年 4 月 6 日第2 章 机器学习概述对于单个样本x，不同训练集D 得到模型fD(x) 和最优模型f ∗(x) 的上的期望差距为2ED fD(x) − f ∗(x)2fff= ED D (x) − ED D (x) + ED D (x) − f∗(x)(2.64)(2.65)=E f (x) − f∗(x)+22DDED fD(x) − ED fD(x).`˛¸(bias)2x`˛¸variancex其中第一项为偏差（bias），是指一个模型的在不同训练集上的平均性能和最优模型的差异。偏差可以用来衡量一个模型的拟合能力；第二项是方差（variance）， 是指一个模型在不同训练集上的差异，可以用来衡量一个模型是否容易过拟合。参见习题2.65。结合公式(2.63) 和 (2.65)，期望错误可以分解为ꢀ(f) = (bias) 2+ variance + ε.(2.66)其中2E f− f(bias)2 = ExD (x)∗(x),(2.67)(2.68)D2if− ED fD (x)variance = Ex ED D (x).最小化期望错误等价于最小化偏差和方差之和。图2.6给出了机器学习算法的偏差和方差的四种不同组合情况。每个图的中心点为最优模型f ∗(x)，蓝点为不同训练集D 上得到的模型fD(x)。图2.6a 给出了一种理想情况，方差和偏差都比较小。图2.6b的泛化能力很好，但拟合能力不足。图2.6c为高偏差低方差的情况，表示模型为低偏差高方差的情况，表示模型的拟合能力很好，但泛化能力比较差。当训练数据比较少时会导致过拟合。 图2.6d为高偏差高方差的情况，是一种最差的情况。参见习题2-9。方差一般会随着训练样本的增加而减少。当样本比较多时，方差比较少，我 们可以选择能力强的模型来减少偏差。然而在很多机器学习任务上，训练集上 往往都比较有限，最优的偏差和最优的方差就无法兼顾。随着模型复杂度的增加，模型的拟合能力变强，偏差减少而方差增大，从而导致过拟合。以结构错误最小化为例，我们可以调整正则化系数λ 来控制模型的复杂度。当λ 变大时，模型复杂度会降低，可以有效地减少方差，避免过拟合，但偏差会上升。当λ 过大时，总的期望错误反而会上升。因此，一个好的结构错误最小化参见公式(2.27)。正则化系数λ需要在偏差和方差之间取得比较好的平衡。图2.7给出了机器学习邱锡鹏：《神经网络与深度学习》https://nndl.github.io/
 2.4 偏差-方差分解2019 年 4 月 6 日43低偏差高偏差低方差(a)(b)高方差(c)(d)图 2.6 偏差和方差的四种组合模型的期望错误、偏差和方差随复杂度的变化情况。最优的模型并不一定是偏差曲线和方差曲线的交点。(bias)2varianceR(f)模型复杂度图 2.7 模型的期望错误、偏差和方差随复杂度的变化情况邱锡鹏：《神经网络与深度学习》https://nndl.github.io/
 442019 年 4 月 6 日第2 章 机器学习概述偏差和方差分解给机器学习模型提供了一种分析途径，但在实际操作中难以直接衡量。一般来说，当一个模型在训练集上的错误率比较高时，说明模型的拟合能力不够，偏差比较高。这种情况可以增加数据特征、提高模型复杂度，减少正则化系数等操作来改进模型。当模型在训练集上的错误率比较低，但验证集上的错误率比较高时，说明模型过拟合，方差比较高。这种情况可以通过降低模型复杂度，加大正则化系数，引入先验等方法来缓解。此外，还有一种有效的降低方差的方法为集成模型，即通过多个高方差模型的平均来降低方差。集成模型参见第10.1节。2.5 机器学习算法的类型机器学习算法可以按照不同的标准来进行分类。比如按函数f(x, θ)的不同，机器学习算法可以分为线性模型和非线性模型；按照学习准则的不同，机器学习算法也可以分为统计方法和非统计方法。但一般来说，我们会按照训练样本提供的信息以及反馈方式的不同，将机器学习算法分为以下几类：监督学习 如果机器学习的目标是通过建模样本的特征 x 和标签 y 之间的关系：y= f (x, θ) 或 p(y|x, θ)，并且训练集中每个样本都有标签，那么这类机器学习称为监督学习（Supervised Learning）。根据标签类型的不同，监督学习又可以分为回归和分类两类。1. 回归（Regression）问题中的标签y 是连续值（实数或连续整数），f (x, θ)的输出也是连续值。2. 分类（Classiﬁcation）问题中的标签y 是离散的类别（符号）。在分类问题中，学习到模型也称为分类器（Classiﬁer）。分类问题根据其类别数量又可分为两类分类（Binary Classiﬁcation）和多类分类（Multi-class Classiﬁcation）问题。3. 结构化学习（Structured Learning）的输出是结构化的对象，比如序列、树或图等。由于结构化学习的输出空间比较大，因此我们一般定义一个联合特征空间，将x, y 映射为该空间中的联合特征向量ϕ(x, y)，预测模型可以写为yˆ = arg max f ϕ(x, y), θ ,(2.69)y∈Gen(x)其中Gen(x) 表示输入x 所有可能的输出目标集合。计算arg max 的过程也称为解码（decoding）过程，一般通过动态规划的方法来计算。一种基于感知器的结构化学习参见第3.4.4节。无监督学习 无监督学习（Unsupervised Learning，UL）是指从不包含目标标签的训练样本中自动学习到一些有价值的信息。典型的无监督学习问题有聚类、 密度估计、特征学习、降维等。无监督学习参见第9章。邱锡鹏：《神经网络与深度学习》https://nndl.github.io/
 2.6 数据的特征表示2019 年 4 月 6 日45强化学习 强化学习（Reinforcement Learning，RL）是一类通过交互来学习的机器学习算法。在强化学习中，智能体根据环境的状态做出一个动作，并得到即时或延时的奖励。智能体在和环境的交互中不断学习并调整策略，以取得最大化的期望总回报。强化学习参见第14章。表2.1给出了三种机器学习类型的比较。监督学习无监督学习训练集强化学习训练集训练样本智能体和环境交互的{(x(n), y(n) )}N{xn }Nn=1n=1轨迹τ 和累积奖励Gτ优化目标 y = f (x) 或 p(y|x)p(x) 或带隐变量 期望总回报E [G ]τ τz的 p(x|z)期望风险最小化最大似然估计最小重构错误策略评估策略改进学习准则最大似然估计表 2.1 三种机器学习类型的比较监督学习需要每个样本都有标签，而无监督学习则不需要标签。一般而言，监督学习通常大量的有标签数据集，这些数据集是一般都需要由人工进行标注，成本很高。因此，也出现了很多弱监督学习（Weak Supervised Learning）和半监督学习（Semi-Supervised Learning）的方法，希望从大规模的无标注数据中充分挖掘有用的信息，降低对标注样本数量的要求。强化学习和监督学习的不同在于强化学习不需要显式地以“输入/输出对”的方式给出训练样本，是一种在线的学习机制。2.6 数据的特征表示在实际应用中，数据的类型多种多样，比如文本、音频、图像、视频等。不同类型的数据，其原始特征（raw features）的空间也不相同。比如一张灰度图像（像素数量为n）的特征空间为[0, 255] ，一个自然语言句子（长度为 ）的nLL特征空间为|V| ，其中V 为词表集合。而很多机器学习算法要求是输入的样本特征是数学上可计算的，因此，在机器学习之前我们需要将这些不同类型的数据转换为向量表示。也有一些机器学习算法（比如决策树）不需要向量形式的特征。图像特征 在手写体数字识别任务中，样本x 为待识别的图像。为了识别x 是什么数字，我们可以从图像中抽取一些特征。如果图像是一张大小为m × n 的图像，其特征向量可以简单地表示为m × n 维的向量，每一维的值为图像中对应像素的灰度值。为了提高模型准确率，也会经常加入一个额外的特征，比如直邱锡鹏：《神经网络与深度学习》https://nndl.github.io/
 462019 年 4 月 6 日第2 章 机器学习概述方图、宽高比、笔画数，纹理特征、边缘特征等。假设我们总共抽取了d 个特征，这些特征可以表示为一个向量x ∈ Rd。文本特征 在文本情感分类任务中，样本x 为自然语言文本，类别y ∈ {+1, −1}分别表示正面或负面的评价。为了将样本x从文本形式转为为向量形式，一种简单的方式是使用词袋模型（Bag-of-Words，BoW）模型。假设训练集合中的词都来自一个词表V，大小为|V|，则每个样本可以表示为一个|V|维的向量x ∈ R|V|，向量中每一维xi 的值为词表中的第i 个词是否在x 中出现。如果出现值为1，否则为0。词袋模型在信息检索中也叫做向量空间模型（VectorSpace Model，VSM）比如两个文本“我 喜欢 读书”和“我 讨厌 读书”中共有“我”、“喜欢”、“讨厌”、“读书”四个词，它们的BoW 表示分别为v1 = [1 1 0 1 ]T ,v2 = [1 0 1 1 ]T .单独一个单词的BoW 表示为one-hot 向量。词袋模型将文本看做是词的集合，不考虑词序信息，不能精确地表示文本信息。一种改进方式是使用n 元组合特征，即每n 个连续词构成一个基本单元，然后再用词袋模型进行表示。以最简单的二元特征（即两个词的组合特征）为例，上面的两个文本中共有“$ 我”、“我喜欢”、“我讨厌”、“喜欢读书”、“讨厌读书”、“读书#”六个特征单元，它们的二元特征BoW 表示分别为$ 和 # 分别表示文本的开始和结束。v1 = [1 1 0 1 0 1]T,v2 = [1 0 1 0 1 1]T.随着n 数量的增长，n 元特征的数量会指数上升，上限为|V|n。因此，在实际应用中，文本特征维数通常在十万或百万级别以上的。参见习题2-11。方法。表示学习可以看作是一个特殊的机器学习任务，即有自己的模型、学习准则和优化邱锡鹏：《神经网络与深度学习》https://nndl.github.io/
 2.6 数据的特征表示2019 年 4 月 6 日47但即使这样，人工设计的特征在很多任务上也不能满足需要。因此，如何让机器自动地学习出有效的特征也成为机器学习中的一项重要研究内容，称为特征学习（Feature Learning），也叫表示学习（Representation Learning）。特征表示学习 如果直接用数据的原始特征来进行预测，对机器学习模型的能力要求比较高。这些原始特征可能存在以下几种不足：（ 1） 特 征 比 较单一，需要进行（ 非 线 性 的 ）组合才能发挥其作用；（2）特征之间冗余度比较高；（3）并不是所有的特征都对预测有用；（4）很多特征通常是易变的；（5）特征中往往存在一些噪声。为了提高机器学习算法的能力，我们需要抽取有效、稳定的特征。传统的特征提取是通过人工方式进行的，需要大量的人工和专家知识。一个成功的机器学习系统通常需要尝试大量的特征，称为特征工程（FeatureEngineering）。邱锡鹏：《神经网络与深度学习》https://nndl.github.io/
 482019 年 4 月 6 日第2 章 机器学习概述学习在一定程度上也可以减少预测模型复杂性、缩短训练时间、提高模型泛化能力、避免过拟合等。2.6.1 传统的特征学习传统的特征学习一般是通过人为地设计一些准则，然后根据这些准则来选取有效的特征，具体又可以分为两种：特征选择和特征抽取。2.6.1.1 特征选择特征选择（Feature Selection）是选取原始特征集合的一个有效子集，使得基于这个特征子集训练出来的模型准确率最高。简单地说，特征选择就是保留有用特征，移除冗余或无关的特征。子集搜索 一种直接的特征选择方法为子集搜索（subset search）。假设原始特征数为d，则共有2d 个候选子集。特征选择的目标是选择一个最优的候选子集。最暴力的做法是测试每个特征子集，看机器学习模型哪个子集上的准确率最高。 但是这种方式效率太低。常用的方法是采用贪心的策略：由空集合开始，每一轮添加该轮最优的特征，称为前向搜索（forward search）；或者从原始特征集合开始，每次删除最无用的特征，称为反向搜索（backward search）。子集搜索方法又可以分为过滤式和包裹式的方法。过滤式（ﬁlter）方法不依赖具体的机器学习模型。每次增加最有信息量的特征，或删除最没有信息量的特征[Hall, 1999]。信息量可以通过信息增益（information gain）来衡量。包裹式（wrapper）方法是用后续机器学习模型的准确率来评价一个特征子集。每次增加对后续机器学习模型最有用的特征，或删除对后续机器学习任务最无用的特征。这种方法是将机器学习模型包裹到特征选择过程的内部。ℓ 正则化 此外，我们还可以通过ℓ 正则化来实现特征选择。由于ℓ 正则化会111导致稀疏特征，间接实现了特征选择。2.6.1.2 特征抽取特征抽取（Feature Extraction）是构造一个新的特征空间，并将原始特征投影在新的空间中。以线性投影为例，原始特征向量x ∈ Rd，经过线性投影后得到在新空间中的特征向量x′。x′ = P x,(2.70)其中P ∈ Rk×d 为映射矩阵。邱锡鹏：《神经网络与深度学习》https://nndl.github.io/
 2.6 数据的特征表示2019 年 4 月 6 日49特征抽取又可以分为监督和无监督的方法。监督的特征学习的目标是抽取 对一个特定的预测任务最有用的特征，比如线性判别分析（Linear DiscriminantAnalysis，LDA）。而无监督的特征学习和具体任务无关，其目标通常是减少冗余信息和噪声，比如主成分分析（Principle Components Analysis，PCA）。表2.2列出了一些传统的特征选择和特征抽取方法。监督学习无监督学习特征选择特征抽取标签相关的子集搜索、ℓ1 正则 标签无关的子集搜索化、决策树线性判别分析主成分分析、独立成分分析、流形学习、自编码器表 2.2 传统的特征选择和特征抽取方法特征选择和特征抽取的优点是可以用较少的特征来表示原始特征中的大部分相关信息，去掉噪声信息，并进而提高计算效率和减小维度灾难（Curse OfDimensionality）。对于很多没有正则化的模型，特征选择和特征抽取非常必要。经过特征选择或特征抽取后，特征的数量一般会减少，因此特征选择和特征抽取也经常称为维数约减或降维（Dimension Reduction）。正则化参见第7.7节。2.6.2 深度学习方法传统的特征抽取一般是和预测模型的学习分离的。我们会先通过主成分分析或线性判别分析等方法抽取出有效的特征，然后再基于这些特征来训练一个具体的机器学习模型。如果我们将特征的表示学习和机器学习的预测学习有机地统一到一个模型中，建立一个端到端的学习算法，可以有效地避免它们之间准则的不一致性。这种表示学习方法就称为深度学习（Deep Learning，DL）。深度学习方法的难点是如何评价表示学习对最终系统输出结果的贡献或影响，即贡献度分配问题。 目前比较有效的模型是神经网络，即将最后的输出层作为预测学习，其它层作为表示学习。参见第1.4节。2.7 评价指标为了衡量一个机器学习模型的好坏，需要给定一个测试集，用模型对测试集中的每一个样本进行预测，并根据预测结果计算评价分数。对于分类问题，常见的评价标准有正确率、准确率、召回率和F值等。邱锡鹏：《神经网络与深度学习》 https://nndl.github.io/
 502.7 评价指标2019 年2 041 9月年64日月 6 日第2 章 机器学习概述49给定测试集 ꢀ = (x(1), y(1)), · · · , (x(N ), y(N))，假设标签 y(n) ∈ {1, ∙∙∙∙∙∙, C}，用学习好得模型f (x, θ)对测试集中的每一个样本进行预测，结果为Y = yˆ(1), ∙∙∙∙∙∙ ˆ, y(N )。准确率 最常用的的评价指标为准确率（Accuracy）Σ1NI(y (n) = yˆ(n) ),(2.71)ACC =Nn=1其中I(·) 为指示函数。错误率 和准确率相对应的就是错误率（Error Rate）。ꢀ = 1 − ACC(2.72)(2.73)Σ1N=( ( ) = ˆ( ))n nI yy.Nn=1查准率和查全率 准确率是所有类别整体性能的平均，如果希望对每个类都进行性能估计，就需要计算查准率和查全率。查准率和查全率是广泛用于信息检索 和统计学分类领域的两个度量值，在机器学习的评价中也被大量使用。对于类别c来说，模型在测试集上的结果可以分为以下四种情况：1. 真正例（True Positive，TP）：一个样本的真实类别为c 并且模型正确地预测为类别c。这类样本数量记为TP 表示。ΣNT Pc =I(y(n) = yˆ(n) = c).(2.74)n=12. 假负例（False Negative，FN）：一个样本的真实类别为c，模型错误地预测为其它类。这类样本数量记为ΣNF Nc =I(y n = c yˆ(n) c).(2.75)()∧n=13. 假正例（False Positive，FP）一个样本的真实类别为其它类，模型错误地预测为类c。这类样本数量记为ΣNFPc =I(y(n) c ∧ yˆ(n) = c).(2.76)n=14. 真负例（True Negative，TN）：一个样本的真实类别为其它类，模型也预测为其它类。这类样本数量记为TNc。对于类别c 来说，这种情况一般不需要关注。邱锡鹏：《神经网络与深度学习》https://nndl.github.io/
 

 502019 年 4 月 6 日第2 章 机器学习概述预测类别yˆ = c yˆ = cy = c TPcy = c FPcFNcTNc真实类别表 2.3 类别c 的预测结果的混淆矩阵这四种情况的关系如表2.3所示的混淆矩阵来表示。查准率（Precision），也叫精确率或精度，类别c 的查准率为是所有预测为类别c 的样本中，预测正确的比例。TPcPc =,(2.77)TPc+ FPc查全率（Recall），也叫召回率，类别c 的查全率为是所有真实标签为类别c的样本中，预测正确的比例。TPcꢀc =,(2.78)TP+FNccF 值（F Measure）是一个综合指标，为查准率和查全率的调和平均。(1 + β2) × Pc × ꢀcFc =,(2.79)β2 × Pc +ꢀc其中β 用于平衡查全率和查准率的重要性，一般取值为1。β = 1 时的F 值称为F1 值，是查准率和查全率的调和平均。宏平均和微平均 为了计算分类算法在所有类别上的总体准确率、召回率和F1值，经常使用两种平均方法，分别称为宏平均（macro average）和微平均（microaverage）[Yang, 1999]。宏平均是每一类的性能指标的算术平均值，ΣC1Pmacro=1Pc,(2.80)Cc=1Cꢀꢀ ,=Ccmacroc=1(2.81)2 × Pmacro × R=macro .Pmacro + Rmacro(2.82)F1macro邱锡鹏：《神经网络与深度学习》https://nndl.github.io/
 2.8 理论和定理2019 年 4 月 6 日51文 献 上，F1 值 的均 为 F1macroF1c。=而微平均是每一个样本的性能指标的算术平均。对于单个样本而言，它的准确率和召回率是相同的（要么都是1，要么都是0）。因此准确率的微平均和召回率的微平均是相同的。同理，F1值的微平均指标是相同的。当不同类别的样本数量不均衡时，使用宏平均会比微平均更合理些。宏平均会更关注于小类别上的评价指标。1在实际应用中，我们通过调整分类模型的阈值来进行更全面的评价，比如AUC（Area Under Curve）、ROC（Receiver Operating Characteristic）曲线、PR（Precision-Recall）曲线等。此外，很多任务还有自己专门的评价方式，比如TopN准确率。关于更详细的模型评价指标，可以参考《机器学习》[周志华, 2016] 的第二章。交叉验证 交叉验证（Cross Validation）是一种比较好的可能衡量机器学习模型的统计分析方法，可以有效避免划分训练集和测试集时的随机性对评价结果造成的影响。我们可以把原始数据集平均分为K 组不重复的子集，每次选K − 1组子集作为训练集，剩下的一组子集作为验证集。这样可以进行K 次试验并得到K 个模型。这K 个模型在各自验证集上的错误率的平均作为分类器的评价。K 一般大于3。2.8 理论和定理在机器学习中，有一些非常有名的理论或定理，对理解机器学习的内在特性非常有帮助。2.8.1 PAC 学习理论当使用机器学习方法来解决某个特定问题时，通常靠经验或者多次试验来选择合适的模型、训练样本数量以及学习算法收敛的速度等。但是经验判断或多次试验往往成本比较高，也不太可靠，因此希望有一套理论能够分析问题难度、 计算模型能力，为学习算法提供理论保证，并指导机器学习模型和学习算法的设计。这就是计算学习理论。计算学习理论（Computational Learning Theory）是关于机器学习的理论基础，其中最基础的理论就是可能近似正确（ProbablyApproximately Correct，PAC）学习理论。机器学习中一个很关键的问题是期望错误和经验错误之间的差异，称为泛化错误（Generalization Error）。泛化错误可以衡量一个机器学习模型f 是否可以很好地泛化到未知数据。“泛化错误”在有些文献中也指“期望错误”，指在未知样本上的错误。empGD(f ) = ꢀ(f ) − ꢀ (f ).(2.83)D根据大数定律，当训练集大小|D| 趋向于无穷大时，泛化错误趋向于0，即邱锡鹏：《神经网络与深度学习》https://nndl.github.io/
 522019 年 4 月 6 日第2 章 机器学习概述经验风险趋近于期望风险。emplim ꢀ(f) − ꢀ (f ) = 0.(2.84)D|D|→∞由于我们不知道真实的数据分布 p(x, y)，也不知道真实的目标函数 g(x)，因此期望从有限的训练样本上学习到一个期望错误为0 的函数f (x) 是不切实际的。因此，需要降低对学习算法能力的期望，只要求学习算法可以以一定的概率学习到一个近似正确的假设，即PAC 学习。PAC 学习可以分为两部分：一是“近似正确”（Approximately Correct）。一个假设 f ∈ F 是“近似正确”的，是指其在泛化错误G (f) 小于一个界限ϵ。ϵ 一般为0 到 1 之间的数，D20 < ϵ < 1 。如果G (f) 比较大，说明模型不能用来做正确的“预测”。2D二是“可能”。一个学习算法A 有“可能”以1 − δ 的概率学习到这样一个“近似正确”的假设。δ 一般为0 到 1 之间的数，0 < δ < 1 。22一个PAC 可学习的算法是指该学习算法能够在多项式时间内从合理数量的训练数据中学习到一个近似正确的f(x)。empP(ꢀ(f ) − ꢀ (f )) ≤ ϵ ≥ 1 − δ,(2.85)D其中ϵ,δ 是和样本数量n、假设空间F 相关的变量。如果固定ϵ,δ，可以反过来计算出样本复杂度为12n(ϵ, δ) ≥(ln |F| + ln δ ),(2.86)2ϵ2其中|F| 为假设空间的大小。[Blum et al., 2016]定理5.3。PAC 学习理论也可以帮助分析一个机器学习方法在什么条件下可以学习到一个近似正确的分类器。从公式(2.86) 可以看出，如果希望模型的假设空间越大，泛化错误越小，其需要的样本数量越多。2.8.2 没有免费午餐定理没有免费午餐定理（No Free Lunch Theorem，NFL）是由Wolpert 和Mac-erday在最优化理论中提出的。没有免费午餐定理证明：对于基于迭代的最优化算法，不存在某种算法对所有问题（有限的搜索空间内）都有效。如果一个算法对某些问题有效，那么它一定在另外一些问题上比纯随机搜索算法更差。也就是说，不能脱离具体问题来谈论算法的优劣，任何算法都有局限性。必须要“具体问题具体分析”。没有免费午餐定理对于机器学习算法也同样适用。不存在一种机器学习算法适合于任何领域或任务。如果有人宣称自己的模型在所有问题上都好于其他模型，那么他肯定是在吹牛。邱锡鹏：《神经网络与深度学习》https://nndl.github.io/
 2.8 理论和定理2019 年 4 月 6 日532.8.3 丑小鸭定理丑小鸭定理（Ugly Duckling Theorem）是1969 年由渡边慧提出的[Watan-able, 1969]。“丑小鸭与白天鹅之间的区别和两只白天鹅之间的区别一样大”。这个定理初看好像不符合常识，但是仔细思考后是非常有道理的。因为世界上不 存在相似性的客观标准，一切相似性的标准都是主观的。如果以体型大小的角 度来看，丑小鸭和白天鹅的区别大于两只白天鹅的区别；但是如果以基因的角 度来看，丑小鸭与它父母的差别要小于他父母和其他白天鹅之间的差别。渡边慧（Satosi Watanabe），1910-1993，美籍日本学者，理论物理学家，也是模式识别的最早研究者之一。这里的“丑小鸭”是指白天鹅的幼雏，而不是“丑陋的小鸭子”。2.8.4 奥卡姆剃刀奥卡姆剃刀（Occam’s Razor）是由14 世纪逻辑学家William of Occam 提出的一个解决问题的法则：“如无必要，勿增实体”。奥卡姆剃刀的思想和机器学习上正则化思想十分类似：简单的模型泛化能力更好。如果有两个性能相近的模型，我们应该选择更简单的模型。因此，在机器学习的学习准则上，我们 经常会引入参数正则化来限制模型能力，避免过拟合。奥卡姆剃刀的一种形式化是最小描述长度（Minimum Description Length，MDL）原则，即对一个数据集D，最好的模型f ∈ F 是会使得数据集的压缩效果最好，即编码长度最小。最小描述长度也可以通过贝叶斯学习的观点来解释[MacKay and Mac Kay,2003]。模型f 在数据集D 上的对数后验概率为max log p(f|D) = max log p(D|f) + log p(f)(2.87)(2.88)ff= mfin − log p(D|f) − log p(f),其中− log p(f ) 和 − log p(D|f ) 可以分别看作是模型f 的编码长度和在该模型下数据集D 的编码长度。也就是说，我们不但要使得模型f 可以编码数据集D，也要使得模型f 尽可能简单。2.8.5 归纳偏置在机器学习中，很多学习算法经常会对学习的问题做一些假设，这些假设就称为归纳偏置（Inductive Bias）Mitchell [1997]。比如在最近邻分类器中，我们会假设在特征空间中，一个小的局部区域中的大部分样本都同属一类。在朴素贝叶斯分类器中，我们会假设每个特征的条件概率是相互独立的。归纳偏置在贝叶斯学习中也经常称为先验（priors）。邱锡鹏：《神经网络与深度学习》https://nndl.github.io/
 542019 年 4 月 6 日第2 章 机器学习概述2.9 总结和深入阅读本章简单地介绍了机器学习的基础知识，并为后面介绍的神经网络进行一 些简单的铺垫。机器学习算法虽然种类繁多，但其中三个基本的要素为：模型、学 习准则、优化算法。大部分的机器学习算法都可以看作是这三个基本要素的不同 组合。如果需要快速全面地了解机器学习的基本概念和体系可以阅读《PatternClassiﬁcation》 [Duda et al., 2001]、《Machine Learning: a Probabilistic Per- spective》[Murphy, 2012] 和《机器学习》[周志华, 2016]。目前机器学习中最主流的一类方法是统计学习方法，将机器学习问题看作是统计推断问题，并且又可以进一步分为频率学派和贝叶斯学派。频率学派将模型参数θ 看作是固定常数；而贝叶斯学派将参数θ 看作是随机变量，并且存在某种先验分布。想进一步深入了解统计学习的知识，可以阅读《Pattern Recog-nition and Machine Learning》[Bishop, 2007] 和《The Elements of StatisticalLearning》[Hastie et al., 2009]。关于统计学习理论的知识可以参考[Vapnik,1998]。此外，机器学习中一个重要内容是表示学习。Bengio et al. [2013] 系统地给出了关于表示学习的全面综述。传统的表示学习方法，即特征选择和特征抽取，可以参考《机器学习》[周志华, 2016] 中的第10 章和第11 章。习题习题 2-1分析为什么平方损失函数不适用于分类问题。习题 2-2 在线性回归中，如果我们给每个样本(x(n), y(n)) 赋予一个权重r(n)，经验风险函数为Σ2N12ꢀ(w) =r(n) y (n) −wTx(n),(2.89)n=1计算其最优参数w∗，并分析权重r(n) 的作用。习题2-3 在线性回归中，如果样本数量N 小于特征数量d + 1，则XX秩最大为N。T的习题2-4 在线性回归中，验证岭回归的解为结构风险最小化准则下的最小二乘法估计，见公式(2.45)。邱锡鹏：《神经网络与深度学习》https://nndl.github.io/
 参考文献2019 年 4 月 6 日55习题 2-5 在线性回归中，若假设标签y ∼ N(w x, β)，并用最大似然估计T来优化参数时，验证最优参数为公式(2.51) 的解。习题 2-6 假设有 N 个样本 x(1), x(2), ∙∙∙∙∙∙, x(N) 服从正态分布 N(µ, σ2)，其中 µ 未知。（1）使用最大似然估计来求解最优参数µML。（2）若参数µ 为随机变量，并服从正态分布N(µ , σ2)，使用最大后验估计来求解最优参数µMAP。00习题2-7 在习题2-6中，证明当N → ∞时，最大后验估计趋向于最大似然估计。习题 2-8 验证公式(2.60)。习题 2-9 试分析在什么因素会导致模型出现图2.6所示的高偏差和高方差情况。习题 2-10 验证公式(2.65)。习题 2-11 分别用一元、二元和三元特征的词袋模型表示文本“我打了张三”和“张三打了我”，并分析不同模型的优缺点。习题 2-12 对于一个三类分类问题，数据集的真实标签和模型的预测标签如下：真实标签预测标签111222223333331322分别计算模型的查准率、查全率、F1 值以及它们的宏平均和微平均。参考文献周志华. 机器学习. 清华大学出版社, 北京,telligence, 35(8):1798–1828, 2013.2016. ISBN 978-7-302-206853-6.Christopher M. Bishop. Pattern recogni-tion and machine learning, 5th Edition. In-formation science and statistics. Springer,2007. ISBN 9780387310732.Yoshua Bengio, Aaron Courville, and Pas-cal Vincent. Representation learning: A re-view and new perspectives. IEEE transac-tions on pattern analysis and machine in-Avrim Blum, John Hopcroft, and Ravin-邱锡鹏：《神经网络与深度学习》https://nndl.github.io/
 562019 年 4 月 6 日参考文献dran Kannan. Foundations of data science.David JC MacKay and David JC Mac Kay.Information theory, inference and learn-ing algorithms. Cambridge university press,2003.Vorabversion eines Lehrbuchs, 2016.Léon Bottou. Large-scale machine learningwith stochastic gradient descent. In Pro-ceedings of COMPSTAT, pages 177–186.Tom M. Mitchell. Machine learning.McGraw Hill series in computer science.McGraw-Hill, 1997. ISBN 978-0-07-042807-2.Springer, 2010.Richard O. Duda, Peter E. Hart, andDavid G. Stork. Pattern classiﬁcation, 2ndEdition. Wiley, 2001. ISBN 9780471056690.Mark Andrew Hall. Correlation-based fea-Kevin P. Murphy. Machine learning- aprobabilistic perspective. Adaptive compu-tation and machine learning series. MITPress, 2012. ISBN 0262018020.ture selection for machine learning. PhDthesis, University of Waikato Hamilton,1999.Trevor Hastie, Robert Tibshirani, andArkadi Nemirovski, Anatoli Juditsky,Guanghui Lan, and Alexander Shapiro.Robust stochastic approximation approachto stochastic programming. SIAM Journalon optimization, 19(4):1574–1609, 2009.Jerome H. Friedman. The elements of sta-tistical learning: data mining, inference,and prediction, 2nd Edition. Springer se-ries in statistics. Springer, 2009. ISBN9780387848570.Arthur E Hoerl and Robert W Kennard.Vladimir Vapnik. Statistical learning the-ory. Wiley, New York, 1998.Ridge regression: Biased estimation forS Watanable. Knowing and guessing: Aquantitative study of inference and informa-tion, 1969.nonorthogonal problems. Technometrics, 12(1):55–67, 1970.Yann LeCun, Corinna Cortes, and Christo-pher JC Burges. MNIST handwritten digitdatabase. Online, 1998. URL http://yann.lecun.com/exdb/mnist.Yiming Yang. An evaluation of statisticalapproaches to text categorization. Informa-tion retrieval, 1(1-2):69–90, 1999.邱锡鹏：《神经网络与深度学习》https://nndl.github.io/
 第3 章 线性模型正确的判断来自于经验，而经验来自于错误的判断。— Frederick P. Brooks线性模型（Linear Model）是机器学习中应用最广泛的模型，指通过样本特征的线性组合来进行预测的模型。给定一个d 维样本[x , · · · , x ]T ，其线性组1d合函数为f(x, w) = w x + w x + · · · + w x + b(3.1)简单起见，这里用f(x, w)来表示f(x, w, b)。1122d d= wTx + b,(3.2)其中w = [w , · · · , w ]T 为d 维的权重向量，b为偏置。上一章中介绍的线性回1d归就是典型的线性模型，直接用f(x, w) 来预测输出目标y = f(x, w)。在分类问题中，由于输出目标 y 是一些离散的标签，而 f (x, w) 的值域为实数，因此无法直接用 f (x, w) 来进行预测，需要引入一个非线性的决策函数（decision function）g(·) 来预测输出目标y = g f(x, w) ,(3.3)其中f (x, w) 也称为判别函数（discriminant function）。对于两类分类问题，g(·) 可以是符号函数（sign function）g f(x, w) = sgn f(x, w)f (x, w) > 0,(3.4)(3.5), +1ifif −1f (x, w) < 0.当 f(x, w) = 0 时不进行预测。公式(3.5) 定义了一个典型的两类分类问题的决策函数，其结构如图3.1所示。
 582019 年 4 月 6 日第3 章 线性模型1x1x2bw1w2∑+/−wd.x图 3.1 两类分类的线性模型在本章，我们主要介绍四种不同线性分类模型：logistic 回归、softmax 回归、感知器和支持向量机，这些模型区别主要在于使用了不同的损失函数。3.1 线性判别函数和决策边界从公式(3.3)可知，一个线性分类模型（Linear Classiﬁcation Model）或线性分类器（Linear Classiﬁer），是由一个（或多个）线性的判别函数f (x, w) =Tw x +b和非线性的决策函数g(·)组成。我们首先考虑两类分类的情况，然后在扩展到多类分类的情况。3.1.1 两类分类两类分类（Binary Classiﬁcation）的类别标签y 只有两种取值，通常可以设为{+1, −1}。y 有时也会表示为{0, 1}。在两个分类中，我们只需要一个线性判别函数f (x, w) = w间 Rd 中所有满足f (x, w) = 0x + b。特征空T的点组成用一个分割超平面（hyperplane），称为决策边界（decision boundary）或决策平面（decision surface）。决策边界将超平面就是三维空间中的平面在更高维空间的推广。d 维空间中的超平面是 d − 1 维的。在二维空间中，决策边界为一个直线；在三维空间中，决策边界为一个平面；在高 维空间中，决策边界为一个 超平面。特征空间一分为二，划分成两个区域，每个区域对应一个类别。所谓“线性分类模型”就是指其决策边界是线性超平面。在特征空间中，决策平面与权重向量 w 正交。特征空间中每个样本点到决策平面的有向距离（signed distance）为f(x, w)γ =.(3.6)∥w∥参见习题3-2。γ 也可以看作是点x 在 w 方向上的投影。图3.2给出了一个两维数据的线性决策边界示例，其中样本特征向量 x =[x , x ]，权重向量w = [w , w ]。1212邱锡鹏：《神经网络与深度学习》https://nndl.github.io/
 3.1 线性判别函数和决策边界2019 年 4 月 6 日59x1x2图 3.2 两类分类的决策边界示例给定N 个样本的训练集D = {(x(n), y(n))}N，其中y(n) ∈ {+1, −1}，线n=1性模型试图学习到参数w∗，使得对于每个样本(x(n), y(n)) 尽量满足f(x(n), w∗) > 0f(x(n), w∗) < 0if y(n) = 1,(3.7)(3.8)if y(n) = −1.上面两个公式也可以合并，即参数w∗ 尽量满足y(n)f (x(n), w∗) > 0,∀n ∈ [1, N].}N定义 3.1 – 两类线性可分： 对于训练集 D = (x(n), y(n))n=1，如果存在权重向量w∗，对所有样本都满足yf (x, w∗) > 0，那么训练集D是线性可分的。为了学习参数w，我们需要定义合适的损失函数以及优化方法。对于两类分类问题，最直接的损失函数为0-1 损失函数，即L01 y, f (x, w) = I yf(x, w) > 0 ,(3.9)其中 I(·) 为指示函数。但0-1 损失函数的数学性质不好，其关于 w 的导数为0，从而导致无法优化w。邱锡鹏：《神经网络与深度学习》https://nndl.github.io/
 602019 年 4 月 6 日第3 章 线性模型3.1.2 多类分类多类分类（Multi-class Classiﬁcation）问题是指分类的类别数C 大于2。多类分类一般需要多个线性判别函数，但设计这些判别函数有很多种方式。假设一个多类分类问题的类别为{1, 2, · · · , C}，常用的方式有以下三种：1. “一对其余”方式：把多类分类问题转换为C 个“一对其余”的两类分类问题。这种方式共需要C 个判别函数，其中第c 个判别函数fc 是将类c 的样本和不属于类c 的样本分开。2.“一对一”方式：把多类分类问题转换为C(C − 1)/2 个“一对一”的两类分类问题。这种方式共需要C(C − 1)/2 个判别函数，其中第(i, j) 个判别函数是把类i 和类j 的样本分开。1 ≤ i < j ≤ C3.“argmax”方式：这是一种改进的“一对其余”方式，共需要C 个判别函数f (x, w ) = w x + bc,cTc = [1, · · · , C](3.10)cc如果存在类别c，对于所有的其他类别c˜(c˜ ≠ c) 都满足f (x, w ) > f (x, w )ccc˜c˜，那么x 属于类别c。即Cy = arg max f (x, w ).(3.11)ccc=1参见习题3-3。“一对其余”方式和“一对一”方式都存在一个缺陷：特征空间中会存在一些难以确定类别的区域，而“argmax”方式很好地解决了这个问题。图3.3给出了用这三种方式进行三类分类的示例，其中不用颜色的区域表示预测的类别，红色直线表示判别函数f(·) = 0 的直线。在“argmax”方式中，相邻两类i 和 j的决策边界实际上是由fi(x, wi) − fj (x, wj ) = 0决定，其法向量为wi − wj 。ꢀꢀꢀꢀꢀꢀꢀꢀ13ꢀ1?ꢀ1???ꢀꢀꢀꢀꢀ12?ꢀꢀꢀ(a) “一对其余”方式(b) “一对一”方式(c) “argmax”方式图 3.3 三个多类分类方式邱锡鹏：《神经网络与深度学习》https://nndl.github.io/
 3.2 Logistic 回归2019 年 4 月 6 日61}N定义 3.2 – 多类线性可分： 对于训练集 D = (x(n), y(n)果存在 C 个权重向量 w∗, 1 ≤ c ≤ C)n=1，如，对所有第 c 类的样本都满足f (x, w ) > f (x, w ), ∀c˜ = c，那么训练集D 是线性可分的。ccc˜c˜从上面定义可以，如果数据集可以多类线性可分的，那么一定存在一个“argmax” 方式的线性分类器可以将它们正确分开。参见习题3-4。3.2 Logistic 回归Logistic 回归（Logistic Regression，LR）是一种常用的处理两类分类问题的线性模型。在本节中我们采用y ∈ {0, 1} 以符合logistic 回归的描述习惯。为了解决连续的线性函数不适合进行分类的问题，我们引入非线性函数gRd → (0, 1) 来预测类别标签的后验概率p(y = 1|x)。:p(y = 1|x) = g(f(x, w)),(3.12)其中g(·) 通常称为激活函数（activation function），其作用是把线性函数的值域从实数区间“挤压”到了(0, 1) 之间，可以用来表示概率。在统计文献中，g(·)的逆函数g−1(·)也称为联系函数（link function）。在logistic 回归中，我们使用logistic 函数来作为激活函数。标签y = 1 的后logistic 函数参见第B.2.3节。验概率为p(y = 1|x) = σ(wTx)1(3.13)(3.14),,简单起见 ，[x , · · · , x , 1]T1这 里1 + exp(−wTx)x=d和 w = [w , · · · , w , b]T分1d标签y = 0 的后验概率为别为 d + 1 维的增广特征向量和增广权重向量。p(y = 0|x) = 1 − p(y = 1|x)exp(−wTx)(3.15)(3.16)=.1 + exp(−wTx)图3.4给出了使用线性回归和logistic回归来解决一维的两类分类问题示例。将公式(3.14) 进行变换后得到p(y = 1|x)wTx = log(3.17)(3.18)1 − p(y = 1|x)p(y = 1|x)= log,p(y = 0|x)邱锡鹏：《神经网络与深度学习》https://nndl.github.io/
 622019 年 4 月 6 日第3 章 线性模型1.5121w = 6, b = 9y = 0.50·x+0.530.50w = 10, b = 150−1−0.5−3−2−101−1.5−1−0.500.511.5xx(a) 线性回归(b) Logistic 回归图 3.4 一维数据的两类问题示例其中 pp((yy==10|x|x) )为样本x为正反例后验概率的比值，称为几率（odds），几率的对数称为对数几率（log odds，或logit）。公式(3.17) 的左边是线性函数，logistic回归可以看作是预测值为“标签的对数几率”的线性回归模型。因此，logistic回归也称为对数几率回归（Logit Regression）。3.2.1 参数学习Logistic 回归采用交叉熵作为损失函数，并使用梯度下降法来对参数进行优化。给定N 个训练样本{(x(n), y(n))}Nn=，1用logistic 回归模型对每个样本x(n)进行预测，并用输出x(n) 的标签为 的后验概率，记为yˆ(n)，1yˆ(n) = σ(wT x(n)),1≤ n ≤ N.(3.19)由于y(n)∈{ 0, 1}，样本(x(n), y(n)) 的真实条件概率可以表示为pr(y(n) = 1|x(n)) = y(n),(3.20)(3.21)pr(y(n) = 0|x(n)) = 1 − y(n).使用交叉熵损失函数，其风险函数为：简单起见，这里忽略了正则化项。ΣN1(n)()( )(n)( )( )ꢀ(w) = − Npr(y = 1|x n ) log yˆ n + pr(y= 0|x n ) log(1 yˆ n )(3.22)(3.23)−n=1ΣN1= −y n log yˆ n + (1 − y n ) log(1 − yˆ n ).()()( )()Nn=1邱锡鹏：《神经网络与深度学习》https://nndl.github.io/
 3.3 Softmax 回归2019 年 4 月 6 日63风险函数ꢀ(w) 关于参数w 的偏导数为：yˆ(n)(1 yˆ(n)1 − yˆ(n)−)Σ()x(n)yˆ 为 Logistic 函数， 因此有(3.24)(3.25)N∂ꢀ(w)∂w1Nyˆ(n)(1 − yˆ(n))∂yˆ= yˆ(n)(1 − yˆ(n))。参y(n )( n) − − y(1 n )= −= −x∂wyˆ(n)Σn=1N见第B.2.3节。1Ny n (1 − yˆ n )x n − (1 − y n )yˆ n x n( )()( )()( )( )n=1()()( )N= −x n y n − yˆ n.Σ(3.26)Nn=11采用梯度下降法，logistic 回归的训练过程为：初始化w0 ← 0，然后通过下式来迭代更新参数。ΣN1Nwt+1 ← wt +αx(n) y (n) − (n)yˆ,(3.27)wtn=1其中α 是学习率，yˆ( 是当参数为w 时，logistic回归模型的输出。n)wtt从公式(3.23) 可知，风险函数ꢀ(w) 是关于参数w 的连续可导的凸函数。因此除了梯度下降法之外，logistic 回归还可以用高阶的优化方法，比如牛顿法，来进行优化。3.3 Softmax 回归Softmax 回归（Softmax Regression），也称为多项（multinomial）或多类（multi-class）的 logistic 回归，是 logistic 回归在多类分类问题上的推广。Softmax 回归也可以看作是一种条件最大熵模型，参见第11.1.5.1节。对于多类问题，类别标签y ∈ {1, 2, · · · , C} 可以有C 个取值。给定一个样本 x，softmax 回归预测的属于类别c 的条件概率为：p(y = c|x) = softmax(wTx)(3.28)cexp(wꢀ x),(3.29)= Σ Cexp(wꢀ x)c=1其中wc 是第c 类的权重向量。softmax 函第B.2.4节。数参见Softmax 回归的决策函数可以表示为：Cyˆ = arg max p(y = c|x)(3.30)(3.31)c=1= argCmax wT x.cc=1与 logistic 回归的关系 当类别数C = 2 时，softmax 回归的决策函数为yˆ = arg max wTy x(3.32)邱锡鹏：《神经网络与深度学习》https://nndl.github.io/
 642019 年 4 月 6 日第3 章 线性模型y∈{0,1}邱锡鹏：《神经网络与深度学习》https://nndl.github.io/
 3.3 Softmax 回归2019 年 4 月 6 日65= I wT1x − w0Tx > 0x > 0 ,0(3.33)(3.34)= I (w − w )T1其中I(·) 是指示函数。对比公式(3.5) 中的两类分类决策函数，可以发现两类分类中的权重向量w = w − w 。10向量表示 公式(3.29) 用向量形式可以写为：yˆ = softmax(W T x)exp(WTx)(3.35)=,(3.36)1 exp (W x)TT其中W = [w1, · · · , wC ]是由C 个类的权重向量组成的矩阵，1 为全1 向量，yˆ ∈RC 为所有类别的预测条件概率组成的向量，第 c 维的值是第 c 类的预测条件概率。3.3.1 参数学习给定N 个训练样本{(x(n), y(n))}Nsoftmax回归使用交叉熵损失函数来，n=1学习最优的参数矩阵W 。为了方便起见，我们用C 维的one-hot向量y ∈ {0, 1}C 来表示类别标签。对于类别c，其向量表示为y = [I(1 = c), I(2 = c), · · · , I(C = c)]T ,(3.37)其中I(·) 是指示函数。采用交叉熵损失函数，softmax 回归模型的风险函数为：简单起见，这里忽略了正则化项。NCΣ Σ1ꢀ(W ) = −= −(n)(n)(3.38)(3.39)ylog yˆcNcΣn=1 c=1N (y( ))T log yˆ(n)1,Nnn=1x(n)其中yˆ(n) = softmax(W T x(n)) 为样本在每个类别的后验概率。风险函数ꢀ(W ) 关于W 的梯度为ΣTN∂ꢀ(W )∂W1N= −x(n) y(n) − yˆ(n).(3.40)n=1证明. 计算公式(3.40) 中的梯度，关键在于计算每个样本的损失函数L(n)(W ) =−(y(n))T log yˆ(n) 关于参数W 的梯度，其中需要用到的两个导数公式为：邱锡鹏：《神经网络与深度学习》https://nndl.github.io/
 662019 年 4 月 6 日第3 章 线性模型1. 若 y = softmax(z)，则 ∂y = diag (y) − yyꢀ。softmax 函数的导数参见第B.2.4节。∂z2. 若z = W T x = [wT x, wT x, · · · , wT x]T ，则 ∂z 为第c 列为x，其余为0的12C∂wc矩阵。∂z∂w x ∂w x∂w xT1T2∂wcT= [,, · · · ,C](3.41)∂wc∂wc∂wc= [0, 0, · · · , x, · · · , 0]Mc(x).根据链式法则，L(n)(W ) = −(y(n))T log(3.42)(3.43),yˆ(n)关于wc 的偏导数为(n) T(n)∂L(n)(W )∂ (y ) log yˆ−−==(3.44)(3.45)∂∂wcwc∂z(n) ∂yˆ ∂ log yˆ(n)(n)(n)∂wc ∂z(n)y∂yˆ(n)−1= −M (x(n)) diag yˆ(n) − yˆ(n)(yˆ(n))T diag(yˆ(n))y(n)(3.46)(3.47)(3.48)(3.49)(3.50)yT diag(y)−1 = 1T 为全 1 的c行向量。= −M (x(n)) I − y(n)1T y(n)ˆc= −Mc(x(n)) y(n) − yˆ(n)1T y(n)因为y 为 onehot向量，所以1Ty = 1。= −Mc(x(n)) y(n)−yˆ(n)= −x(n) y(n) − yˆ(n).c公式(3.50) 也可以表示为非向量形式，∂L(n)(W )= −x(n) I(y (n) = c) − yˆ(cn),(3.51)(3.52)∂wc其中I(·) 是指示函数。根据公式(3.50) 可以得到∂L(n)(W )T= −x(n) y(n) − yˆ(n).∂W采用梯度下降法，softmax 回归的训练过程为：初始化W0 ← 0，然后通过下式进行迭代更新。!ΣN1NT+αx(n) y(n) − (n)yˆWt+1 ← Wt,(3.53)Wtn=1其中α 是学习率，yˆ( 是当参数为Wt 时，softmax回归模型的输出。n)Wt要注意的是，softmax 回归中使用的C 个权重向量是冗余的，即对所有的权重向量都减去一个同样的向量 v，不改变其输出结果。因此，softmax 往往需要使用正则化来约束其参数。此外，我们可以利用这个特性来避免计算softmax 函数时在数值计算上溢出问题。邱锡鹏：《神经网络与深度学习》https://nndl.github.io/
 3.3 Softmax 回归2019 年 4 月 6 日673.4 感知器感知器（Perceptron）由Frank Roseblatt 于1957 年提出，是一种广泛使用的线性分类器。感知器可谓是最简单的人工神经网络，只有一个神经元。Frank Rosenblatt，1928 年-1971 年，美国心理学家，人工智能领域开拓者。感知器是对生物神经元的简单数学模拟，有与生物神经元相对应的部件，如 权重（突触）、偏置（阈值）及激活函数（细胞体），输出为+1 或-1。感知器是一种简单的两类线性分类模型，其分类准则与公式(3.5)yˆ = sgn(wT x).相同。(3.54)最早发明的感知器是一台机器而不是一种算法，后来才被实现为IBM 704 机器上可运行的程序。3.4.1 参数学习感知器学习算法也是一个经典的线性分类器的参数学习算法。给定N 个样本的训练集: {(x(n), y(n))}Nn=，1其中y(n) ∈ {+1, −1}，感知器试图学习感知器试图学习到参数w∗，使得对于每个样本(x(n), y(n))有y(n)w∗Tx(n) > 0,∀n ∈ [1, N].(3.55)感知器的学习算法是一种错误驱动的在线学习算法[Rosenblatt, 1958]。先初始化一个权重向量w ← 0（通常是全零向量），然后每次分错一个样本(x, y)时，即ywTx < 0，就用这个样本来更新权重。w ← w + yx.(3.56)具体的感知器参数学习策略如算法3.1所示。算法 3.1: 两类感知器算法输入: 训练集{(x(n), y(n))}N ，迭代次数Tn=11 初始化：w0 ← 0, k ← 0 ;2 for t = 1 · · · T do345678随机对训练样本进行随机排序;for n = 1 · · · N do选取一个样本(x(n), y(n));if wT(y(n)x(n)) ≤ 0 thenkwk+1 ← wk + y(n)x(n);k ← k + 1;9endend11 end输出: wk10邱锡鹏：《神经网络与深度学习》https://nndl.github.io/
 

 3.4 感知器2019 年 4 月 6 日67根据感知器的学习策略，可以反推出感知器的损失函数为：L(w; x, y) = max(0, −ywTx).(3.57)(3.58)采用随机梯度下降，其每次更新的梯度为0ifywTx > 0,∂L(w; x, y)=T∂w −yxif yw x< 0.图3.5给出了感知器参数学习的更新过程，其中红色实心点为正例，蓝色空心点为负例。黑色箭头表示权重向量，红色虚线箭头表示权重的更新方向。10.5010.50w2-++--0.5-1-0.5-1w1-1-0.500.51-1-0.500.5110.5010.50w4-w3+-0.5-1-0.5-1- +-1-0.500.51-1-0.500.51图 3.5 感知器参数学习的更新过程3.4.2 感知器的收敛性Novikoﬀ [1963] 证明对于两类问题，如果训练集是线性可分的，那么感知器算法可以在有限次迭代后收敛。然而，如果训练集不是线性分隔的，那么这个算法则不能确保会收敛。邱锡鹏：《神经网络与深度学习》https://nndl.github.io/
 682019 年 4 月 6 日第3 章 线性模型}N当数据集是两类线性可分时，对于训练集D =(x(n), y(n))，其中x(n)n=1参见定义3.1。为样本的增广特征向量，y( n) ∈ {−1, 1}，那么存在一个正的常数γ(γ > 0) 和权重向量w∗，并且∥w∗∥ = 1，对所有n 都满足(w∗)T(y(n)x(n)) ≥ γ。我们可以证明如下定理。邱锡鹏：《神经网络与深度学习》https://nndl.github.io/
 }N定理 3.1 – 感知器收敛性：给定一个训练集D = (x(n), y(n)假设R 是训练集中最大的特征向量的模，)n=1，年 4 月 6 日69R = mnax ∥x(n)∥.如果训练集D 线性可分，感知器学习算法3.1的权重更新次数不超2过 R  。γ2邱锡鹏：《神经网络与深度学习》https://nndl.github.io/
 702019 年 4 月 6 日第3 章 线性模型证明. 感知器的权重向量的更新方式为wk = wk−1 + y(k)x(k),(3.59)其中x(k), y(k) 表示第k 个错误分类的样本。因为初始权重向量为0，在第K 次更新时感知器的权重向量为ΣKwK =y(k)x(k).(3.60)k=1分别计算∥wK ∥2 的上下界：（1）∥wK ∥2 的上界为：∥w ∥ = ∥w2+ y(K) x(K)∥ 2K −1(3.61)(3.62)(3.63)(3.64)(3.65)K= ∥wK −1∥2 + ∥y(K )≤ ∥wK −1∥2 + R2≤ ∥wK −2∥2 + 2R2x(K )∥ + y2(K )wTK−1ykwKT − 1 x(K) ≤ 0.2x(K)≤ KR2邱锡鹏：《神经网络与深度学习》https://nndl.github.io/
 3.4 感知器2019 年 4 月 6 日71（2）∥wK ∥2 的下界为：∥w ∥2 = ∥w∗∥2 · ∥w ∥2(3.66)(3.67)∥w∗∥ = 1.KK≥ ∥w∗T w ∥2K两个向量内积的平方一定小于等于这两个向量的模的乘积K= ∥w∗T(y(k)x(k)∥) 2(3.68)k=1K= ∥w∗T(y(k)x(k))2w∗T (y(n )x(n)) ≥ γ, ∀n.(3.69)(3.70)k=1∥≥ K2 2γ .由公式(3.65) 和 (3.70)，得到K γ ≤ ||w || ≤ K R .(3.71)2222K取最左和最右的两项，进一步得到，K2γ2 ≤ KR2。然后两边都除K，最终得到R2K ≤.(3.72)γ22因此，在线性可分的条件下，算法3.1会在 R 步内收敛。γ2虽然感知器在线性可分的数据上可以保证收敛，但其存在以下不足之处：1. 在数据集线性可分时，感知器虽然可以找到一个超平面把两类数据分开，但并不能保证能其泛化能力。2. 感知器对样本顺序比较敏感。每次迭代的顺序不一致时，找到的分割超平面也往往不一致。3. 如果训练集不是线性可分的，就永远不会收敛[Freund and Schapire, 1999]。3.4.3 参数平均感知器根据定理3.1，如果训练数据是线性可分的，那么感知器可以找到一个判别函数来分割不同类的数据。如果间隔γ 越大，收敛越快。但是感知器并不能保证找到的判别函数是最优的（比如泛化能力高），这样可能导致过拟合。感知器的学习到的权重向量和训练样本的顺序相关。在迭代次序上排在后 面的错误样本，比前面的错误样本对最终的权重向量影响更大。比如有1, 000 个训练样本，在迭代100 个样本后，感知器已经学习到一个很好的权重向量。在接下来的899 个样本上都预测正确，也没有更新权重向量。但是在最后第1, 000 个样本时预测错误，并更新了权重。这次更新可能反而使得权重向量变差。邱锡鹏：《神经网络与深度学习》https://nndl.github.io/
 722019 年 4 月 6 日第3 章 线性模型为了改善这种情况，可以使用“参数平均”的策略来提高感知器的鲁棒性，也叫投票感知器（Voted Perceptron）[Freund and Schapire, 1999]。投票感知器记录第 k 次更新后得到的权重 wk 在之后的训练过程中正确分投票感知器是一种集成模型，参见第10.1节。类样本的次数c 。这样最后的分类器形式为：kΣKyˆ = sgnc sgn(wT x)(3.73)kkk=1其中sgn(·) 为符号函数。投票感知器虽然提高了感知器的泛化能力，但是需要保存 K 个权重向量。在实际操作中会带来额外的开销。因此，人们经常会使用一个简化的版本，也叫做平均感知器（Averaged Perceptron）[Collins, 2002]。ΣKyˆ = sgnc (wT x)(3.74)kkk=1ΣK= sgn ( c w )Tx(3.75)(3.76)kkk=1= sgn(w¯T x),其中w¯ 为平均的权重向量。假设wt,n 是在第t 轮更新到第n 个样本时权重向量的值，平均的权重向量Σ T Σ nw¯ 也可以写为w¯ =wt,n(3.77)t=1n=1nT这个方法非常简单，只需要在算法3.1中增加一个w¯，并且在处理每一个样本后，更新w¯ ← w¯ + wt,n.(3.78)但这个方法需要在处理每一个样本时都要更新w¯。因为w¯ 和wt,n 都是稠密向量，因此更新操作比较费时。为了提高迭代速度，有很多改进的方法，让这个更新只需要在错误预测发生时才进行更新。算法3.2给出了一个改进的平均感知器算法的训练过程[Daumé III]。参见习题3-7。3.4.4 扩展到多类分类原始的感知器是一种两类分类模型，但也可以很容易地扩展到多类分类问题，甚至是更一般的结构化学习问题[Collins, 2002]。邱锡鹏：《神经网络与深度学习》https://nndl.github.io/
 3.4 感知器2019 年 4 月 6 日73算法 3.2: 平均感知器算法输入: 训练集{(x(n), y(n))}N，最大迭代次数Tn=11 初始化：w ← 0, u ← 0, c ← 0 ;2 for t = 1 · · · T do34随机对训练样本进行随机排序;for n = 1 · · · N do选取一个样本(x(n), y(n));计算预测类别yˆt;if yˆt = yt thenw ← w + y(n)x(n);u ← u + cy(n)x(n);end56789101112c ← c + 1 ;end13 end14 w¯ = wT − u ;1c输出: w¯之前介绍的分类模型中，分类函数都是在输入x 的特征空间上。为了使得感知器可以处理更复杂的输出，我们引入一个构建输入输出联合空间上的特征函数ϕ(x, y)，将样本(x, y)对映射到一个特征向量空间。在联合特征空间中，我们可以建立一个广义的感知器模型，yˆ = arg max wT ϕ(x, y),(3.79)通过引入特征函数 ϕ(x, y)，感知器不但可以用于多类分类问题，也可以用于结构化学习问题，比如输出是序列形式。y∈Gen(x)其中w为权重向量，Gen(x)表示输入x 所有的输出目标集合。当处理C 类分类问题时，Gen(x) = {1, · · · , C}。在C 类分类中，一种常用的特征函数ϕ(x, y) 是y 和x 的外积，其中y 为类别的one-hot向量表示。ϕ(x, y) = vec(yxT) ∈ R(d×C),(3.80)其中vec 是向量化算子。邱锡鹏：《神经网络与深度学习》https://nndl.github.io/
 742019 年 4 月 6 日第3 章 线性模型给定样本(x, y)，若x ∈ R ， 为第 维为 的dyc1one-hot向量，则.0x1← 第(c − 1) × d + 1 行ϕ(x, y) =.(3.81)xd←第(c − 1) × d + d 行0.广义感知器算法的训练过程如算法3.3所示。算法 3.3: 广义感知器参数学习算法输入: 训练集:{(x(n), y(n))}N ，最大迭代次数Tn=11 初始化：w0 ← 0, k ← 0 ;2 for t = 1 · · · T do34随机对训练样本进行随机排序;for n = 1 · · · N do5选取一个样本(x(n), y(n));用公式(3.79) 计算预测类别yˆ(n)6;yˆ(n)ify(n) thenwk+1 ← wk + ϕ(x(n), y(n)) − ϕ(x(n), yˆ(n))k = k + 1 ;endend78;9101112 end输出: wk3.4.4.1 广义感知器的收敛性广义感知器在满足广义线性可分条件时，也能够保证在有限步骤内收敛。广义线性可分条件的定义如下：广义线性可分是多类线性可分的扩展，参见定义3.2。}N定义 3.3 – 广义线性可分： 对于训练集 D = (x(n), y(n))n=1，如果存在一个正的常数 γ(γ > 0) 和权重向量 w∗，并且∥w∗∥ = 1，对所有 n 都满足⟨w∗, ϕ(x(n), y(n))⟩ − ⟨w∗, ϕ(x(n), y)⟩ ≥ γ, y ≠ y(n)邱锡鹏：《神经网络与深度学习》https://nndl.github.io/
 3.5 支持向量机2019 年 4 月 6 日73（ϕ(x(n), y(n)) ∈ Rd 为样本x(n), y(n) 的联合特征向量），那么训练集D在联合特征向量空间中是线性可分的。邱锡鹏：《神经网络与深度学习》https://nndl.github.io/
 定理 3.2 – 广义感知器收敛性： 对于满足广义线性可分的训练集}ND = (x(n), y(n)签在特征空间ϕ(x, y) 最远的距离。)n=1，假设R 是所有样本中真实标签和错误标6 日第3 章 线性模型R = max max ∥ϕ(x(n), y(n)) − ϕ(x(n), z)∥.nz≠y(n)R2γ2那么广义感知器参数学习算法3.3 的权重更新次数不超过。邱锡鹏：《神经网络与深度学习》https://nndl.github.io/
 3.5 支持向量机2019 年 4 月 6 日75Collins [2002] 给出了广义感知器在广义线性可分的收敛性证明，具体推导过程和两类感知器比较类似。参见习题3-8。3.5 支持向量机支持向量机（Support Vector Machine，SVM）是一个经典两类分类算法，其找到的分割超平面具有更好的鲁棒性，因此广泛使用在很多任务上，并表现出了很强优势。给定一个两类分类器数据集D = {(x(n), y(n))}Nn=，1其中 yn∈ {+1, −1}，如果两类样本是线性可分的，即存在一个超平面本节中不使用增广的特征向量和特征权重。Tw x + b = 0(3.82)(3.83)将两类样本分开，那么对于每个样本都有y(n)(wD 中每个样本x(n) 到分割超平面的距离为：x(n) + b) > 0。数据集T∥wTx(n) + b∥∥w∥y(n)(w x(n) + b)Tγ(n) ==.∥w∥我们定义整个数据集D中所有样本到分割超平面的最短距离为间隔（Margin）γγ = min γ(n).(3.84)n如果间隔γ 越大，其分割超平面对两个数据集的划分越稳定，不容易受噪声等因素影响。支持向量机的目标是寻找一个超平面(w∗, b∗) 使得γ 最大，即maxw,bγ(3.85)邱锡鹏：《神经网络与深度学习》https://nndl.github.io/
 762019 年 4 月 6 日第3 章 线性模型y(n)(wTx(n) + b)s.t.≥ γ, ∀n∥w∥令∥w∥ · γ = 1，则公式(3.85) 等价于1maxw,b(3.86)∥w∥2s.t.y(n)(wTx(n) + b) ≥ 1, ∀n数据集中所有满足y(n)(wx(n)+b)= 1 的样本点，都称为支持向量（Support Vector）。T对于一个线性可分的数据集，其分割超平面有很多个，但是间隔最大的超平面是唯一的。图3.6给定了支持向量机的最大间隔分割超平面的示例，其红色样本点为支持向量。x2x1图 3.6 支持向量机示例3.5.1 参数学习为了找到最大间隔分割超平面，将公式(3.86)的目标函数写为凸优化问题12∥w∥2(3.87)minw,bs.t.1 − y(n)(wTx(n) + b) ≤ 0,∀n使用拉格朗日乘数法，公式(3.87) 的拉格朗日函数为参见第??节。N12Λ(w, b, λ) =∥w 2 +λn 1 − y(n)(wx(n) + b),(3.88)∥Tn=1邱锡鹏：《神经网络与深度学习》https://nndl.github.io/
 3.5 支持向量机2019 年 4 月 6 日77其中λ ≥ 0, · · · , λ ≥ 0 为拉格朗日乘数。计算Λ(w, b, λ) 关于w 和 b 的导数，1N并令其等于0 得到ΣNw =λny(n)x(n),(3.89)(3.90)n=1NΣ0 =λny(n).n=1将公式(3.89) 代入公式(3.88)，并利用公式(3.90)，得到拉格朗日对偶函数Σ ΣNNNΣ1Γ(λ) = −2λ λ y(m)y(n)(x(m))nx(n) +λn.(3.91)Tmn=1 m=1n=1支持向量机的主优化问题为凸优化问题，满足强对偶性，即主优化问题可以通过最大化对偶函数maxλ≥0 Γ(λ) 来求解。对偶函数Γ(λ) 是一个凹函数，因此最大化对偶函数是一个凸优化问题，可以通过多种凸优化方法来进行求解，得到拉格朗日乘数的最优值λ∗。但由于其约束条件的数量为训练样本数量，一般的优化方法代价比较高，因此在实践中通常采用比较高效的优化方法，比如SMO（Sequential Minimal Optimization）算法[Platt, 1998] 等。参见公式(C.26)。根据KKT 条件中的互补松弛条件，最优解满足nλ∗ 1−y(n)(w∗Tx(n)+b∗) = 0。如果样本x(n) 不在约束边界上，上，λ∗ ≥ 0。这些在约束边界上样本点称为支持向量（support ector），即离决λ =0，其约束失效；如果样本x(n) 在约束边界nv策平面距离最近的点。再计算出λ∗ 后，根据公式(3.89) 计算出最优权重w∗，最优偏置b∗ 可以通过任选一个支持向量(˜,˜)计算得到。b∗ = y˜ − w∗T x˜.(3.92)最优参数的支持向量机的决策函数为f (x) = sgn(w∗Tx + b∗)(3.93)(3.94)!ΣNλny(n)(x(n))Tx +b∗.= sgnn=1支持向量机的决策函数只依赖λn > 0的样本点，即支持向量。支持向量机的目标函数可以通过SMO等优化方法得到全局最优解，因此比其它分类器的学习效率更高。此外，支持向量机的决策函数只依赖与支持向量， 与训练样本总数无关，分类速度比较快。邱锡鹏：《神经网络与深度学习》https://nndl.github.io/
 782019 年 4 月 6 日第3 章 线性模型3.5.2 核函数支持向量机还有一个重要的优点是可以使用核函数（kernel function）隐式地将样本从原始特征空间映射到更高维的空间，并解决原始特征空间中的线性不可分问题。比如在一个变换后的特征空间ϕ 中，支持向量机的决策函数为f (x) = sgn(w∗Tϕ(x) + b∗)(3.95)(3.96)!ΣNn)K (x(n), b∗λ y(x) +n,= sgnn=1其中K(x, z) = ϕ(x) ϕ(z) 为核函数。通常我们不需要显式地给出ϕ(x) 的具体T形式，可以通过核技巧（kernel trick）来构造。比如以x, z ∈ R2 为例，我们可以构造一个核函数参见习题3-10。K(x, z) = (1 + x z)2 = ϕ(x)TTϕ(z),(3.97)来√ 隐式地计算x, z 在特征空间ϕ 中的内积，其中ϕ(x) = [1, √2x1, √2x2,2x x , x2, x2]T 。12123.5.3 软间隔在支持向量机的优化问题中，约束条件比较严格。如果训练集中的样本在特征空间中不是线性可分的，就无法找到最优解。为了能够容忍部分不满足约束的样本，我们可以引入松弛变量ξ，将优化问题变为Σ1minw∥2 + C N ξ(3.98)2∥nw,bn=1s.t.1 − y(n)(wTx(n) + b) − ξn ≤ 0,∀n∀nξn ≥ 0,其中参数C > 0 用来控制间隔和松弛变量惩罚的平衡。引入松弛变量的间隔称为软间隔（soft margin）。公式(3.98) 也可以表示为经验风险+正则化项的形式。ΣN1C1w 2∥ ∥ ,minmax 0,1− y (n)(wT x(n) + b) +·(3.99)2w,bn=1其中max 0, 1 − y(n)(wx(n) + b) 称为hinge 损失函数， 1 可以看作是正则化TC系数。参见公式(2.21)。参见习题3-11。软间隔支持向量机的参数学习和原始支持向量机类似，其最终决策函数也只和支持向量有关，即满足1 − y(n)(w x(n) + b) − ξn = 0 的样本。T邱锡鹏：《神经网络与深度学习》https://nndl.github.io/
 3.6 损失函数对比2019 年 4 月 6 日773.6 损失函数对比本章介绍的三种两类分类模型：logistic 回归、感知器和支持向量机。虽然它们的决策函数相同，但由于使用了不同的损失函数以及相应的优化方法，导致它们之间在实际任务上的表现存在一定的差异。为了比较这些损失函数，我们统一定义类别标签 y∈ {+1, −1}，并定义f (x, w) = w x + b。这样对于样本(x, y)，若yf (x, w) > 0，则分类正确，相反T则分类错误。这样为了方便比较这些模型，我们可以将它们的损失函数都表述为定义在yf(x, w) 上的函数。logistic 回归的损失函数可以改写为LLR = − log p(y|x)= −I(y = 1) log σ f(x, w) − I(y = −1) log σ − f(x, w)(3.100)(3.101)1 − σ(x) = σ(−x).= log 1 + exp − yf(x, w).(3.102)感知器的损失函数为Lp = max 0, −yf(x, w) .(3.103)(3.104)软间隔支持向量机的损失函数为Lhinge = max 0, 1 − yf(x, w) .平方损失可以重写为Lsquared = y − f(x, w) 2= 1 − 2yf(x, w) + (yf(x, w))2= 1 − yf(x, w) 2.(3.105)(3.106)(3.107)y2 = 1.图3.7给出了不同损失函数的对比。对于两类分类来说，当yf(x, w) > 0时，分类器预测正确，并且yf(x, w)越大，模型的预测越正确；当yf (x, w) < 0时，分类器预测错误，并且yf(x, w) 越小，模型的预测越错误。因此，一个好的损失函数应该随着yf(x, w)的增大而减少。从图3.7中看出，除了平方损失，其它损失函数都比较适合于两类分类问题。邱锡鹏：《神经网络与深度学习》https://nndl.github.io/
 782019 年 4 月 6 日第3 章 线性模型邱锡鹏：《神经网络与深度学习》https://nndl.github.io/
 L4321交叉熵损失hinge 损失感知器损失平方损失0-1 损失邱锡鹏：《神经网络与深度学习》https://nndl.github.io/
 802019 年 4 月 6 日−2 −1第3 章 线性模型3−3012yf(x,w)图 3.7 不同损失函数的对比3.7 总结和深入阅读和回归问题不同，分类问题中的目标标签y 是离散的类别标签，因此分类问题中的决策函数需要输出离散值或是标签的后验概率。线性分类模型一般是一个广义线性函数，即一个线性判别函数f (x, w) = wTx 加上一个非线性激活函数g(·)。表3.1给出了几种常见的线性模型的比较。在logistic 回归和softmax回归中，y 为类别的one-hot 向量表示；在感知器和支持向量机中，y 为{+1, −1}。Logistic 回归是一种概率模型，其通过使用logistic 函数来将一个实数值映射到[0, 1] 之间。事实上，还有很多函数也可以达到此目的，比如正态分布的累积概率密度函数，即probit 函数。这些知识可以参考《Pattern Recognition andMachine Learning》[Bishop, 2007]的第四章。Rosenblatt [1958] 最早提出了两类感知器算法，并随后给出了感知机收敛定理。但是感知器的输出是离散的以及学习算法比较简单，不能解决线性不可分问题，限制了其应用范围。Minsky and Seymour [1969] 在《感知器》一书中分析了感知器的局限性，证明感知器不能解决非常简单的异或（XOR）问题。从现在的视角看，Minsky and Seymour [1969] 仅仅给出了一个显而易见的证明：邱锡鹏：《神经网络与深度学习》https://nndl.github.io/
 3.7 总结和深入阅读2019 年 4 月 6 日79激活函数损失函数优化方法线性回归-(y − wy log σ(wx) y log softmax(Wmax(0, −yw x)max(0, 1 − ywTx)2最小二乘、梯度下降梯度下降Logistic 回归Softmax 回归感知器σ(wTx)Tx)softmax(WTTx) 梯度下降sgn(wTx)x)T随机梯度下降支持向量机sgn(wTTx)二次规划、SMO 等表 3.1 几种不同的线性模型对比线性模型不能解决非线性问题，但依然给感知器以及人工智能领域的研究造成了很大的负面影响。虽然书中也认为多层的网络可以解决非线性问题，但遗憾的是，在当时这个问题还不可解。直到 1980 年以后，Geoﬀrey Hinton、YannLeCun 等人用连续输出代替离散的输出，并将反向传播算法[Werbos, 1974] 引入到多层感知器[Williams and Hinton, 1986]，人工神经网络才又重新引起人们的注意。Minsky and Papert [1987] 也修正之前的看法。另外一方面，人们对感知器本身的认识也在不断发展。Freund and Schapire [1999] 提出了使用核技巧改进感知器学习算法，并用投票感知器来提高泛化能力。Collins [2002] 将感知器算法扩展到结构化学习，给出了相应的收敛性证明，并且提出一种更加有效并且实用的参数平均化策略。McDonald et al. [2010] 又扩展了平均感知器算法， 使得感知器可以在分布式计算环境中并行计算，这样感知器可以用在大规模机器学习问题上。要深入了解支持向量机以及核方法，可以参考《Learning with Kernels:Support Vector Machines, Regularization, Optimization, and Beyond》[Scholkopfand Smola, 2001]。习题习题 3-1证明在两类线性分类中，权重向量w 与决策平面正交。习题 3-2 在线性空间中，证明一个点x 到平面f(x, w) = w距离为|f(x, w)|/∥w∥。Tx + b = 0 的习题3-3 在线性分类中，决策区域是凸的。即若点x 和x 被分为类c，则12邱锡鹏：《神经网络与深度学习》https://nndl.github.io/
 802019 年 4 月 6 日参考文献点ρx + (1 − ρ)x 也会被分为类c，其中ρ ∈ (0, 1)。12习题 3-4在多类分类中，1）如果一个数据集中每个类的样本都可以其它类是线性可分的，则该数据集一定是线性可分的；2）如果一个数据集中每两个类的样本是线性可分的，则该数据集不一定是线性可分的。习题3-5 在logistic回归中，是否可以用yˆ = σ(wT x) 去逼近正确的标签y，并用平方损失(y − yˆ)2 最小化来优化参数w？习题 3-6 在 softmax 回归的风险函数（公式(3.39)）中，如果去掉正则化项会有什么影响？习题 3-7 验证平均感知器训练算法3.2中给出的平均权重向量的计算方式和公式(3.78)等价。习题 3-8 证明定理3.2。习题3-9 若数据集线性可分，证明支持向量机中将两类样本正确分开的最大间隔分割超平面存在且唯一。习题 3-10 验证公式(3.97)。习题 3-11 在软间隔支持向量机中，试给出原始优化问题的对偶问题，并列出其KKT 条件。参考文献Christopher M. Bishop. Pattern recogni-tion and machine learning, 5th Edition. In-formation science and statistics. Springer,2007. ISBN 9780387310732.tational Linguistics, 2002.Hal Daumé III. A course in machine learn-ing. http://ciml.info/. [Online].Yoav Freund and Robert E Schapire. Largemargin classiﬁcation using the perceptronalgorithm. Machine learning, 37(3):277–Michael Collins. Discriminative trainingmethods for hidden markov models: The-ory and experiments with perceptron algo-rithms. In Proceedings of the conference onEmpirical methods in natural language pro-cessing, pages 1–8. Association for Compu-296, 1999.Ryan McDonald, Keith Hall, and GideonMann. Distributed training strategies forthe structured perceptron. In Human Lan-guage Technologies: The 2010 Annual Con-邱锡鹏：《神经网络与深度学习》https://nndl.github.io/
 参考文献2019 年 4 月 6 日81ference of the North American Chapter ofthe Association for Computational Linguis-tics, pages 456–464. Association for Com-putational Linguistics, 2010.Frank Rosenblatt. The perceptron: a prob-abilistic model for information storage andorganization in the brain. Psychological re-view, 65(6):386, 1958.Marvin Minsky and Papert Seymour. Per-Bernhard Scholkopf and Alexander J Smola.Learning with kernels: support vector ma-chines, regularization, optimization, andbeyond. MIT press, 2001.ceptrons. 1969.Marvin L Minsky and Seymour A Papert.Perceptrons - Expanded Edition: An Intro-duction to Computational Geometry. MITpress Boston, MA:, 1987.Albert BJ Novikoﬀ. On convergenceproofsPaul Werbos. Beyond regression: New toolsfor prediction and analysis in the behavioralsciences. 1974.for perceptrons. Technical report, DTICDocument, 1963.John Platt. Sequential minimal optimiza-DE Rumelhart GE Hinton RJ Williamsand GE Hinton. Learning representationsby back-propagating errors. Nature, pages323–533, 1986.tion: A fast algorithm for training supportvector machines. Technical report, April1998.邱锡鹏：《神经网络与深度学习》https://nndl.github.io/
 

 第二部分基础模型

 

 第4 章 前馈神经网络神经网络是一种大规模的并行分布式处理器，天然具有存储并使用经验知识的能力。它从两个方面上模拟大脑：（1）网络获取的知识是通过学习来获取的；（2）内部神经元的连接强度，即突触权重，用于储存获取的知识。— Haykin [1994]人工神经网络（Artiﬁcial Neural Network，ANN）是指一系列受生物学和神经学启发的数学模型。这些模型主要是通过对人脑的神经元网络进行抽象，构建人工神经元，并按照一定拓扑结构来建立人工神经元之间的连接，来模拟生物神经网络。在人工智能领域，人工神经网络也常常简称为神经网络（NeuralNetwork，NN）或神经模型（Neural Model）。神经网络最早是作为一种主要的连接主义模型。20 世纪 80 年代后期，最流行的一种连接主义模型是分布式并行处理（Parallel Distributed Processing，PDP）网络[Rumelhart et al., 1986]，其有3 个主要特性：1）信息表示是分布式的（非局部的）；2）记忆和知识是存储在单元之间的连接上；3）通过逐渐改变单元之间的连接强度来学习新的知识。连接主义的神经网络有着多种多样的网络结构以及学习方法，虽然早期模型强调模型的生物可解释性（biological plausibility），但后期更关注于对某种特定认知能力的模拟，比如物体识别、语言理解等。尤其在引入误差反向传播来 改进其学习能力之后，神经网络也越来越多地应用在各种模式识别任务上。随 着训练数据的增多以及（并行）计算能力的增强，神经网络在很多模式识别任 务上已经取得了很大的突破，特别是语音、图像等感知信号的处理上，表现出 了卓越的学习能力。后面我们会介绍一种用来进行记忆存储和检索的神经网络，参见第8.3.4节。在本章中，我们主要关注于采用误差反向传播来进行学习的神经网络，即作为一种机器学习模型的神经网络。从机器学习的角度来看，神经网络一般可 以看作是一个非线性模型，其基本组成单位为具有非线性激活函数的神经元，通
 862019 年 4 月 6 日第4 章 前馈神经网络过大量神经元之间的连接，使得神经网络成为一种高度非线性的模型。神经元之间的连接权重就是需要学习的参数，可以通过梯度下降方法来进行学习。4.1 神经元人工神经元（Artiﬁcial Neuron），简称神经元（Neuron），是构成神经网络的基本单元，其主要是模拟生物神经元的结构和特性，接受一组输入信号并产出输出。生物学家在20 世纪初就发现了生物神经元的结构。一个生物神经元通常具有多个树突和一条轴突。树突用来接受信息，轴突用来发送信息。当神经元所获得的输入信号的积累超过某个阈值时，它就处于兴奋状态，产生电脉冲。轴突尾端有许多末梢可以给其他个神经元的树突产生连接（突触），并将电脉冲信 号传递给其它神经元。1943 年，心理学家McCulloch 和数学家Pitts 根据生物神经元的结构，提出了一种非常简单的神经元模型，MP 神经元[McCulloch and Pitts, 1943]。现代神经网络中的神经元和M-P 神经元的结构并无太多变化。不同的是，MP 神经元中的激活函数f 为0或1的阶跃函数，而现代神经元中的激活函数通常要求是连续可导的函数。假设一个神经元接受d 个输入x , x , · · · , x ，令向量x = [x ; x ; · · · ; x ] 来12d12d表示这组输入，并用净输入（Net Input）ꢀ ∈ R 表示一个神经元所获得的输入信号 x 的加权和，净输入也叫净活性值（netactivation）。Σd=w x + b(4.1)iii= 1= wTx + b,(4.2)其中w = [w ; w ; · · · ; w ] ∈ R 是 维的权重向量，b ∈ Rdd是偏置。12d净输入ꢀ 在经过一个非线性函数f(·)后，得到神经元的活性值（Activation）a，a = f ( ),(4.3)其中非线性函数f(·)称为激活函数（Activation Function）。图4.1给出了一个典型的神经元结构示例。邱锡鹏：《神经网络与深度学习》https://nndl.github.io/
 4.1 神经元2019 年 4 月 6 日871x1bw1∑w2x2fawd激活函数.权重xd输入图 4.1 典型的神经元结构激活函数 激活函数在神经元中非常重要的。为了增强网络的表示能力和学习能力，激活函数需要具备以下几点性质：1. 连续并可导（允许少数点上不可导）的非线性函数。可导的激活函数可以直接利用数值优化的方法来学习网络参数。2. 激活函数及其导函数要尽可能的简单，有利于提高网络计算效率。3. 激活函数的导函数的值域要在一个合适的区间内，不能太大也不能太小，否则会影响训练的效率和稳定性。下面介绍几种在神经网络中常用的激活函数。4.1.1 Sigmoid 型激活函数Sigmoid 型函数是指一类S 型曲线函数，为两端饱和函数。常用的Sigmoid型函数有Logistic 函数和Tanh 函数。数学小知识 | 饱和对于函数f (x)，若x → −∞ 时，其导数f ′(x) → 0，则称其为左饱和。若x → +∞ 时，其导数f ′(x) → 0，则称其为右饱和。当同时满足 ♣左、右饱和时，就称为两端饱和。邱锡鹏：《神经网络与深度学习》https://nndl.github.io/
 882019 年 4 月 6 日第4 章 前馈神经网络Logistic 函数 Logistic 函数定义为1σ(x) =.(4.4)1 + exp(−x)Logistic 函数可以看成是一个“挤压”函数，把一个实数域的输入“挤压”到(0, 1)。当输入值在0 附近时，Sigmoid 型函数近似为线性函数；当输入值靠近两端时，对输入进行抑制。输入越小，越接近于0；输入越大，越接近于1。这样的特点也和生物神经元类似，对一些输入会产生兴奋（输出为1），对另一些输入产生抑制（输出为0）。和感知器使用的阶跃激活函数相比，Logistic 函数是连续可导的，其数学性质更好。因为Logistic 函数的性质，使得装备了Logistic 激活函数的神经元具有以下两点性质：1）其输出直接可以看作是概率分布，使得神经网络可以更好地和统计学习模型进行结合。2）其可以看作是一个软性门（Soft Gate），用来控制其它神经元输出信息的数量。参见第6.6节。Tanh 函数 Tanh 函数是也一种Sigmoid 型函数。其定义为exp(x) − exp(−x)tanh(x) =.(4.5)(4.6)exp(x) + exp(−x)Tanh 函数可以看作是放大并平移的Logistic 函数，其值域是(−1, 1)。tanh(x) = 2σ(2x) − 1.图4.2给出了Logistic 函数和Tanh 函数的形状。Tanh 函数的输出是零中心化的（Zero-Centered），而Logistic 函数的输出恒大于0。非零中心化的输出会使得其后一层的神经元的输入发生偏置偏移（Bias Shift），并进一步使得梯度下降的收敛速度变慢。参见第7.4节。参见习题4-1。邱锡鹏：《神经网络与深度学习》https://nndl.github.io/
 4.1 神经元2019 年 4 月 6 日8910.5Logistic 函数Tanh 函数−6−4−2246− 0 .5−1图 4.2 Logistic 函数和Tanh 函数4.1.1.1 Hard-Logistic 和 Hard-Tanh 函数Logistic 函数和Tanh 函数都是Sigmoid 型函数，具有饱和性，但是计算开销较大。因为这两个函数都是在中间（0 附近）近似线性，两端饱和。因此，这两个函数可以通过分段函数来近似。以Logistic 函数σ(x) 为例，其导数为σ′(x) = σ(x)(1 − σ(x))。Logistic 函数在 0 附近的一阶泰勒展开（Taylor expansion）为gl(x) ≈ σ(0) + x × σ′(0)= 0.25x + 0.5.(4.7)(4.8)用分段来近似Logistic 函数，得到1gl (x) ≥ 1(4.9)hard-logistic(x) = gl 0 < gl(x) < 10gl(x) ≤ 0= max(min(gl(x), 1), 0)(4.10)(4.11)= max(min(0.25x + 0.5, 1), 0).同样，Tanh 函数在0 附近的一阶泰勒展开为gt(x) ≈ tanh(0) + x × tanh′(0)= x,(4.12)(4.13)邱锡鹏：《神经网络与深度学习》https://nndl.github.io/
 902019 年 4 月 6 日第4 章 前馈神经网络这样Tanh 函数也可以用分段函数hard-tanh(x)来近似。hard-tanh(x) = max(min(gt(x), 1), −1)= max(min(x, 1), −1).(4.14)(4.15)图4.3给出了hard-Logistic 和 hard-Tanh 函数两种函数的形状。110.50.80.60.40.200−0.5−1logistic 函数hard logistic 函数tanh 函数hard tanh 函数−4−20246−4−20246(a) Hard Logistic 函数(b) Hard Tanh 函数图 4.3 Hard Sigmoid 型激活函数4.1.2 修正线性单元修正线性单元（Rectiﬁed Linear Unit，ReLU）[Nair and Hinton, 2010]，也叫 rectiﬁer 函数[Glorot et al., 2011]，是目前深层神经网络中经常使用的激活函数。ReLU 实际上是一个斜坡（ramp）函数，定义为xx ≥ 0ReLU(x) =(4.16)(4.17)0 x < 0= max(0, x).优点 采用ReLU 的神经元只需要进行加、乘和比较的操作，计算上更加高效。ReLU 函数被认为有生物上的解释性，比如单侧抑制、宽兴奋边界（即兴奋程度也可以非常高）。在生物神经网络中，同时处于兴奋状态的神经元非常稀疏。人脑中在同一时刻大概只有1 ∼ 4% 的神经元处于活跃状态。Sigmoid 型激活函数 会导致一个非稀疏的神经网络，而ReLU 却具有很好的稀疏性，大约50% 的神经元会处于激活状态。在优化方面，相比于Sigmoid 型函数的两端饱和，ReLU 函数为左饱和函数，且在x > 0时导数为1，在一定程度上缓解了神经网络的梯度消失问题，加速梯度下降的收敛速度。参见第4.6.2节。邱锡鹏：《神经网络与深度学习》https://nndl.github.io/
 4.1 神经元2019 年 4 月 6 日91缺点ReLU 函数的输出是非零中心化的，给后一层的神经网络引入偏置偏移，会影响梯度下降的效率。此外，ReLU 神经元在训练时比较容易“死亡”。在训练时，如果参数在一次不恰当的更新后，第一个隐藏层中的某个ReLU 神经元在所有的训练数据上都不能被激活，那么这个神经元自身参数的梯度永远都会是 0，在以后的训练过程中永远不能被激活。这种现象称为死亡ReLU 问题（Dying ReLUProblem），并且也有可能会发生在其它隐藏层。ReLU 神经元指采用 ReLU作为激活函数的神经元。参见公式(4.61)。参见习题4-3。在实际使用中，为了避免上述情况，有几种ReLU4.1.2.1 带泄露的 ReLU的变种也会被广泛使用。带泄露的ReLU（Leaky ReLU）在输入 x < 0 时，保持一个很小的梯度λ。这样当神经元非激活时也能有一个非零的梯度可以更新参数，避免永远不能被激活[Maas et al., 2013]。带泄露的ReLU 的定义如下：xif x > 0γx if x ≤ 0= max(0, x) + γ min(0, x),LeakyReLU(x) =(4.18)(4.19)其中 γ 是一个很小的常数，比如0.01。当γ < 1时，带泄露的ReLU也可以写为LeakyReLU(x) = max(x, γx), (4.20)相当于是一个比较简单的maxout 单元。4.1.2.2 带参数的 ReLU参见第4.1.4节。带参数的ReLU（Parametric ReLU，PReLU）引入一个可学习的参数，不同神经元可以有不同的参数[He et al., 2015]。对于第i 个神经元，其PReLU 的定义为xifx >0PReLU (x) =(4.21)i γix if x ≤0= max(0, x) + γi min(0, x),(4.22)其中γ 为 x ≤ 0 时函数的斜率。因此，PReLU 是非饱和函数。如果γ = 0，那ii么 PReLU 就退化为ReLU。如果γi 为一个很小的常数，则PReLU 可以看作带泄露的ReLU。PReLU 可以允许不同神经元具有不同的参数，也可以一组神经元共享一个参数。邱锡鹏：《神经网络与深度学习》https://nndl.github.io/
 922019 年 4 月 6 日第4 章 前馈神经网络4.1.2.3 ELU指数线性单元（Exponential Linear Unit，ELU）[Clevert et al., 2015] 是一个近似的零中心化的非线性函数，其定义为xif x > 0ELU(x) = (4.23)γ(exp(x) − 1) if x ≤ 0= max(0, x) + min(0, γ(exp(x) − 1)),(4.24)其中 γ ≥ 0 是一个超参数，决定x ≤ 0 时的饱和曲线，并调整输出均值在0 附近。参见第7.5.1节。4.1.2.4 Softplus 函数Softplus 函数[Dugas et al., 2001] 可以看作是rectiﬁer 函数的平滑版本，其定义为Softplus(x) = log(1 + exp(x)).(4.25)Softplus 函数其导数刚好是Logistic 函数。Softplus 函数虽然也有具有单侧抑制、宽兴奋边界的特性，却没有稀疏激活性。图4.4给出了ReLU、Leaky ReLU、ELU 以及Softplus 函数的示例。邱锡鹏：《神经网络与深度学习》https://nndl.github.io/
 44.1 3 神经元2019 年 4 月 6 日93ReLULeaky ReLUELUsoftplus21−4−224−1邱锡鹏：《神经网络与深度学习》https://nndl.github.io/
 942019 年 4 月 6 日第4 章 前馈神经网络图 4.4 ReLU、Leaky ReLU、ELU 以及Softplus 函数邱锡鹏：《神经网络与深度学习》https://nndl.github.io/
 4.1 神经元2019 年 4 月 6 日954.1.3 Swish 函数Swish 函数是一种自门控（Self-Gated）激活函数 [Ramachandran et al.,2017]，定义为swish(x) = xσ(βx),(4.26)其中σ(·)为Logistic函数，β 为可学习的参数或一个固定超参数。σ(·) ∈ (0, 1)可以看做是一种软性的门控机制。当σ(βx)接近于1时，门处于“开”状态，激活函数的输出近似于x 本身；当σ(βx) 接近于0时，门的状态为“关”，激活函数的输出近似于0。图4.5给出了Swish 函数的示例。邱锡鹏：《神经网络与深度学习》https://nndl.github.io/
 4296β = 0 .5β = 12019 年 4 月 6 日第4 章 前馈神经网络β = 0β = 100−4−224−2邱锡鹏：《神经网络与深度学习》https://nndl.github.io/
 4.1 神经元2019 年 4 月 6 日图 4.5 Swish 函数97当β = 0时，Swish函数变成线性函数x/2。当β = 1时，Swish函数在x > 0时近似线性，在x < 0 时近似饱和，同时具有一定的非单调性。当β → +∞ 时，σ(βx)趋向于离散的0-1函数，Swish函数近似为ReLU函数。因此，Swish函数可以看作是线性函数和ReLU 函数之间的非线性插值函数，其程度由参数β 控制。4.1.4 Maxout 单元Maxout 单元[Goodfellow et al., 2013] 也是一种分段线性函数。Sigmoid 型采用maxout 单元的神经网络也就做maxout 网络。函数、ReLU等激活函数的输入是神经元的净输入ꢀ，是一个标量。而maxout单元的输入是上一层神经元的全部原始输入，是一个向量x = [x ; x ; · · · , x ]。12d每个maxout 单元有K 个权重向量w ∈ R 和偏置db (1 ≤ k ≤ K)。对于kk邱锡鹏：《神经网络与深度学习》https://nndl.github.io/
 982019 年 4 月 6 日第4 章 前馈神经网络输入x，可以得到K 个净输入ꢀk, 1 ≤ k ≤ K。= wk Tx + bk,(4.27)k其中wk = [wk,1, · · · , wk,d]T 为第k 个权重向量。Maxout 单元的非线性函数定义为maxout(x) = max ( k).(4.28)k∈[1,K]Maxout 单元不单是净输入到输出之间的非线性映射，而是整体学习输入到输出之间的非线性映射关系。Maxout激活函数可以看作任意凸函数的分段线性近似，并且在有限的点上是不可微的。4.2 网络结构一个生物神经细胞的功能比较简单，而人工神经元只是生物神经细胞的理想化和简单实现，功能更加简单。要想模拟人脑的能力，单一的神经元是远远不够的，需要通过很多神经元一起协作来完成复杂的功能。这样通过一定的连接方式或信息传递方式进行协作的神经元可以看作是一个网络，就是神经网络。到目前为止，研究者已经发明了各种各样的神经网络结构。目前常用的神经网络结构有以下三种：4.2.1 前馈网络前馈网络中各个神经元按接受信息的先后分为不同的组。每一组可以看作一个神经层。每一层中的神经元接受前一层神经元的输出，并输出到下一层神经元。整个网络中的信息是朝一个方向传播，没有反向的信息传播，可以用一个有向无环路图表示。前馈网络包括全连接前馈网络[本章中的第4.3节] 和卷积神经网络[第5章]等。前馈网络可以看作一个函数，通过简单非线性函数的多次复合，实现输入空间到输出空间的复杂映射。这种网络结构简单，易于实现。4.2.2 反馈网络反馈网络中神经元不但可以接收其它神经元的信号，也可以接收自己的反 馈信号。和前馈网络相比，反馈网络中的神经元具有记忆功能，在不同的时刻具 有不同的状态。反馈神经网络中的信息传播可以是单向或双向传递，因此可用 一个有向循环图或无向图来表示。反馈网络包括循环神经网络[第6章]，Hopﬁeld 网络[第6章]、玻尔兹曼机[第12章]等。邱锡鹏：《神经网络与深度学习》https://nndl.github.io/
 4.3 前馈神经网络2019 年 4 月 6 日95反馈网络可以看作一个程序，具有更强的计算和记忆能力。为了增强记忆网络的记忆容量，可以引入外部记忆单元和读写机制，用来保 存一些网络的中间状态，称为记忆增强网络（Memory-Augmented Neural Net-work）[第8章]，比如神经图灵机[Graves et al., 2014] 和记忆网络[Sukhbaataret al., 2015]等。4.2.3 图网络前馈网络和反馈网络的输入都可以表示为向量或向量序列。但实际应用中很多数据是图结构的数据，比如知识图谱、社交网络、分子（molecular ）网络等。前馈网络和反馈网络很难处理图结构的数据。图网络是定义在图结构数据上的神经网络[第6.8.2节]。图中每个节点都一 个或一组神经元构成。节点之间的连接可以是有向的，也可以是无向的。每个 节点可以收到来自相邻节点或自身的信息。图网络是前馈网络和记忆网络的泛化，包含很多不同的实现方式，比如图卷积网络（Graph Convolutional Network，GCN）[Kipf and Welling, 2016]、消息传递网络（Message Passing Neural Network，MPNN）[Gilmer et al., 2017]等。图4.6给出了前馈网络、反馈网络和图网络的网络结构示例。邱锡鹏：《神经网络与深度学习》https://nndl.github.io/
 962019 年 4 月 6 日第4 章 前馈神经网络邱锡鹏：《神经网络与深度学习》https://nndl.github.io/
 4.3 前馈神经网络(a) 前馈网络2019 年 4 月 6 日97(b) 反馈网络(c) 图网络图 4.6 三种不同的网络模型4.3 前馈神经网络给定一组神经元，我们可以以神经元为节点来构建一个网络。不同的神经网络模型有着不同网络连接的拓扑结构。一种比较直接的拓扑结构是前馈网络。前馈神经网络（Feedforward Neural Network，FNN）是最早发明的简单人工神经网络。邱锡鹏：《神经网络与深度学习》https://nndl.github.io/
 982019 年 4 月 6 日第4 章 前馈神经网络在前馈神经网络中，各神经元分别属于不同的层。每一层的神经元可以接收前一层神经元的信号，并产生信号输出到下一层。第0 层叫输入层，最后一层叫输出层，其它中间层叫做隐藏层。整个网络中无反馈，信号从输入层向输出层单向传播，可用一个有向无环图表示。前馈神经网络也经常称为多层感知器（Multi-Layer Perceptron，MLP）。但多层感知器的叫法并不是十分合理，因为前馈神经网络其实是由多层的Logistic 回归模型（连续的非线性函数）组成，而不是由多层的感知器（不连续的非线性函数）组成 [Bishop, 2007]。图4.7给出了前馈神经网络的示例。输入层隐藏层隐藏层输出层x1x2x3x4y图 4.7 多层前馈神经网络我们用下面的记号来描述一个前馈神经网络：层数一般只考虑隐藏层和输出层。• L：表示神经网络的层数；• m(l)：表示第l 层神经元的个数；• fl(·)：表示l 层神经元的激活函数；• W (l) ∈ Rm(l)×ml−1 ：表示l − 1层到第l 层的权重矩阵；• b(l) ∈ Rml ：表示l − 1 层到第l 层的偏置；• z(l) ∈ Rml ：表示 层神经元的净输入（净活性值）；l•a(l) ∈ Rml ：表示l 层神经元的输出（活性值）。前馈神经网络通过下面公式进行信息传播，z(l) = W (l) · a(l−1) + b(l),a(l) = fl(z(l)).(4.29)(4.30)公式(4.29) 和 (4.30) 也可以合并写为：z(l) = W (l) · fl−1(z(l−1)) + b(l),(4.31)邱锡鹏：《神经网络与深度学习》https://nndl.github.io/
 4.3 前馈神经网络2019 年 4 月 6 日99或者a(l) = fl(W (l) · a(l−1) + b(l)).(4.32)这样，前馈神经网络可以通过逐层的信息传递，得到网络最后的输出a(L)。整个网络可以看作一个复合函数ϕ(x; W, b)，将向量x作为第1 层的输入a(0)，将第 L 层的输出a(L) 作为整个函数的输出。x = a(0) → z(1) → a(1) → z(2) → · · · → a(L−1) → z(L) → a(L) = φ(x; W, b)),(4.33)其中W, b 表示网络中所有层的连接权重和偏置。4.3.1 通用近似定理前馈神经网络具有很强的拟合能力，常见的连续非线性函数都可以用前馈神经网络来近似。定理 4.1 – 通用近似定理（Universal Approximation Theorem）[Cybenko, 1989, Hornik et al., 1989]： 令 φ(·) 是一个非常数、有界、单调递增的连续函数，I 是一个d维的单位超立方体[0, 1] ，ddC(I ) 是定义在I 上的连续函数集合。对于任何一个函数 f ∈ddC(I )，存在一个整数 m，和一组实数 v , b ∈ R 以及实数向量di iwi ∈ Rd，i = 1, · · · , m，以至于我们可以定义函数ΣmF (x) =v φ(wT x + b ),(4.34)(4.35)iiii= 1作为函数f 的近似实现，即|F (x) − f(x)| < ϵ, ∀x ∈ Id.其中ϵ > 0 是一个很小的正数。通用近似定理在实数空间Rd 中的有界闭集上依然成立。定义在实数空间Rd 中的有根据通用近似定理，对于具有线性输出层和至少一个使用“挤压”性质的激 活函数的隐藏层组成的前馈神经网络，只要其隐藏层神经元的数量足够，它可 以以任意的精度来近似任何从一个定义在实数空间Rd 中的有界闭集函数[Fu-nahashi and Nakamura, 1993, Hornik et al., 1989]。所谓“挤压”性质的函数界闭集上的任意连续函数，也称为Borel 可测函数。邱锡鹏：《神经网络与深度学习》https://nndl.github.io/
 102019 年 4 月 6 日第4 章 前馈神经网络是指像Sigmoid 函数的有界函数，但神经网络的通用近似性质也被证明对于其它类型的激活函数，比如ReLU，也都是适用的。参见习题4-6。通用近似定理只是说明了神经网络的计算能力可以去近似一个给定的连续函数，但并没有给出如何找到这样一个网络，以及是否是最优的。此外，当应用到机器学习时，真实的映射函数并不知道，一般是通过经验风险最小化和正则化来进行参数学习。因为神经网络的强大能力，反而容易在训练集上过拟合。4.3.2 应用到机器学习根据通用近似定理，神经网络在某种程度上可以作为一个“万能”函数来使用，可以用来进行复杂的特征转换，或逼近一个复杂的条件分布。在机器学习中，输入样本的特征对分类器的影响很大。以监督学习为例，好 的特征可以极大提高分类器的性能。因此，要取得好的分类效果，需要样本的 原始特征向量x 转换到更有效的特征向量φ(x)，这个过程叫做特征抽取。参见第2.6.1.2节。多层前馈神经网络可以看作是一个非线性复合函数φ : Rd → Rd′ ，将输入x ∈ Rd 映射到输出φ(x) ∈ Rd′ 。因此，多层前馈神经网络也可以看成是一种特征转换方法，其输出φ(x) 作为分类器的输入进行分类。给定一个训练样本 (x, y)，先利用多层前馈神经网络将x 映射到φ(x)，然后再将φ(x)输入到分类器g(·)。yˆ = g(φ(x), θ),(4.36)其中g(·) 为线性或非线性的分类器，θ为分类器g(·) 的参数，yˆ为分类器的输出。特别地，如果分类器g(·) 为Logistic 回归分类器或softmax 回归分类器，那么 g(·) 也可以看成是网络的最后一层，即神经网络直接输出不同类别的后验概率。反之，Logistic 回归或soft-max 回归也可以看作是只有一层的神经网络。对于两类分类问题 y ∈ {0, 1}，并采用 Logistic 回归，那么 Logistic 回归分类器可以看成神经网络的最后一层。也就是说，网络的最后一层只用一个神经元，并且其激活函数为Logistic 函数。网络的输出可以直接可以作为类别y = 1的后验概率。Logistic 回归参见第3.3节。p(y = 1|x) = a(L),(4.37)其中a(L)∈ R 为第L 层神经元的活性值。对于多类分类问题y ∈ {1, · · · , C}，如果使用softmax 回归分类器，相当于网络最后一层设置C 个神经元，其激活函数为softmax 函数。网络的输出可以作为每个类的后验概率。Softmax 回归参见第3.3节。(L) ,yˆ = softmax(z)(4.38)邱锡鹏：《神经网络与深度学习》https://nndl.github.io/
 4.3 前馈神经网络2019 年 4 月 6 日10其中z(L) ∈ R为第L 层神经元的净输入；yˆ ∈ RC 为第L 层神经元的活性值，分别是不同类别标签的预测后验概率。4.3.3 参数学习如果采用交叉熵损失函数，对于样本(x, y)，其损失函数为L(y, yˆ) = −yT log yˆ,(4.39)其中y ∈ {0, 1} 为标签 对应的one-hot向量表示。Cy给定训练集为D = {(x(n), y(n))}Nn=，1将每个样本x(n) 输入给前馈神经网络，得到网络输出为yˆ(n)，其在数据集D上的结构化风险函数为：Σꢀ(W, b) =N L,λ∥W ∥ ,1nn()(())FnN Σ(y 2y) +nN=11NLn ,( λ)∥W ∥ ,=F2n=1(y y) +其中 W 和 b 分别表示网络中所有的权重矩阵和偏置向量；∥W ∥2F是正则化项，用来防止过拟合；λ 是为正数的超参数。λ 越大，W 越接近于 0。这里的 ∥W ∥2 F一般使用Frobenius 范数：注意这里的正则化项只包含权重参数W ，而不包含偏置b。Σ Σ ΣL m (l) m (l−1)(l) 2∥W ∥2F =(W ) .(4.42)ijl=1 i=1 j=1有了学习准则和训练样本，网络参数可以通过梯度下降法来进行学习。在梯度下降方法的每次迭代中，第l 层的参数W (l) 和 b(l) 参数更新方式为W (l) ← W (l) − α∂ꢀ(W, b) ,(4.43)∂W (l)!ΣN1N(∂L(y(n) (n), y )= W (l) − α) + λW (l) ,(4.44)(4.45)(4.46)∂W (l)n=1∂ꢀ(W, b)b(l) ← b(l) − α,∂b(l)!ΣN∂ (y(n), yˆ(n)1)L= b(l) − α,N∂b(l)n=1其中α 为学习率。梯度下降法需要计算损失函数对参数的偏导数，如果通过链式法则逐一对每个参数进行求偏导效率比较低。在神经网络的训练中经常使用反向传播算法来计算高效地梯度。邱锡鹏：《神经网络与深度学习》https://nndl.github.io/
 102019 年 4 月 6 日第4 章 前馈神经网络4.4 反向传播算法假设采用随机梯度下降进行神经网络参数学习，给定一个样本(x, y)，将其输入到神经网络模型中，得到网络输出为yˆ。假设损失函数为L(y, yˆ)，要进行参数学习就需要计算损失函数关于每个参数的导数。∂L(y,yˆ)链式法则参见第B.11节。不失一般性，对第l 层中的参数W (l) 和 b(l) 计算偏导数。因为的计∂W (l)算涉及矩阵微分，十分繁琐，因此我们先计算偏导数 ∂L(y,yˆ)。根据链式法则，!∂W (l)ijT∂z(l)∂L(y, yˆ)∂L(y, yˆ)∂W∂Wiji(jl)==(l).(4.48)∂b(l)∂z(l)邱锡鹏：《神经网络与深度学习》https://nndl.github.io/
 4.3 前馈神经网络2019 年 4 月 6 日10,(4.47)∂z(l)邱锡鹏：《神经网络与深度学习》https://nndl.github.io/
 102019 年 4 月 6 日∂L(y, yˆ)第4 章 前馈神经网络∂z(l)T∂L(y, yˆ)∂b(l)公式(4.47) 和 (4.48) 中的第二项是都为目标函数关于第l 层的神经元z(l)的∂z(l)，偏导数，称为误差项，因此可以共用。我们只需要计算三个偏导数，分别为(l)ij∂W∂L(y, yˆ)∂z(l)∂z(l)。和∂b(l)下面分别来计算这三个偏导数。∂z(l)因为z(l)和W (l) 的函数关系为 zij(l) = W (l) a(l−1) + b(l)，（1） 计算偏导(l)∂Wij数因此偏导数∂z(l)∂(W (l)a(l−1) + b(l))=(4.49)(l)(l)∂Wij∂Wij∂(W(l)a(l−1)+b(l))1:∂W0.(l)..ij=∂(W (l)a(l−1)+b(l))=  (l−1)(4.50).∂Waj .(l)i:ij0.a(l−1)+b(l))∂(W (l)邱锡鹏：《神经网络与深度学习》https://nndl.github.io/
 4.3 前馈神经网络2019 年 4 月 6 日10← 第 i 行m (l):, Ii(i:邱锡鹏：《神经网络与深度学习》https://nndl.github.io/
 102019 年 4 月 6 日第4 章 前馈神经网络(l−1)),aj∂W ij(4.51)(l)邱锡鹏：《神经网络与深度学习》https://nndl.github.io/
 4.3 前馈神经网络2019 年 4 月 6 日10其中W (l) 为权重矩阵W (l) 的第i 行。∂z的函数关系为 (l)(l)和 b(l)= W (l)因z(l)此偏导数（2） 计算偏导数因为z∂b(l)邱锡鹏：《神经网络与深度学习》https://nndl.github.io/
 102019 年 4 月 6 日第4 章 前馈神经网络a (l−1)+b(l)，邱锡鹏：《神经网络与深度学习》https://nndl.github.io/
 4.3 前馈神经网络2019 年 4 月 6 日10= Im(l),∂z(l)∂b(l)邱锡鹏：《神经网络与深度学习》https://nndl.github.io/
 112019 年 4 月 6 日第4 章 前馈神经网络(4.52)邱锡鹏：《神经网络与深度学习》https://nndl.github.io/
 4.4 反向传播算法2019 年 4 月 6 日101为 m(l) × m(l) 的单位矩阵。∂L(y, yˆ)（3） 计算误差项我们用δ(l) 来定义第l 层神经元的误差项，∂z(l)∂L(y, yˆ)∂z(l)δ(l) =∈Rm (l).(4.53)误差项δ(l) 来表示第l 层神经元对最终损失的影响，也反映了最终损失对第l 层神经元的敏感程度。误差项也间接反映了不同神经元对网络能力的贡献程度，从 而比较好地解决了“贡献度分配问题”。根据z(l+1) = W (l+1)a(l) + b(l+1)，有∂z(l+1)= (W (l+1))T.(4.54)∂a(l)根据a(l) = fl(z(l))，其中f (·)l为按位计算的函数，因此有∂a(l)∂z(l)∂fl(z(l))∂z(l)(4.55)== diag(fl′(z(l))).(4.56)因此，根据链式法则，第l 层的误差项为∂ (y, yˆ)∂z(l)Lδ(l),(4.57)(4.58)∂a(l) ∂z(l+1)L y, y∂ ( ˆ)==··∂z(l)∂a(l)∂z(l+1)diag(f (z(l))) · (W′(l+1) T) · δ(l+1)(4.59)(4.60)l= fl′(z(l)) ⊙ (W (l+1))Tδ(l+1) ,其中⊙ 是向量的点积运算符，表示每个元素相乘。从公式(4.60) 可以看出，第l 层的误差项可以通过第l + 1 层的误差项计算得到，这就是误差的反向传播。反向传播算法的含义是：第l 层的一个神经元的误差项（或敏感性）是所有与该神经元相连的第l + 1 层的神经元的误差项的权重和。然后，再乘上该神经元激活函数的梯度。在计算出上面三个偏导数之后，公式(4.47) 可以写为∂L(y, yˆ)(l−1).(4.61)(l−1)) δ(l) = (l)= I (aTajδiij(l)∂Wij进一步，L(y, yˆ) 关于第l 层权重W (l) 的梯度为∂L(y, yˆ)= δ(l)(a(l−1))T .(4.62)∂W (l)邱锡鹏：《神经网络与深度学习》https://nndl.github.io/
 1022019 年 4 月 6 日第4 章 前馈神经网络同理可得，L(y, yˆ) 关于第l 层偏置b(l) 的梯度为∂L(y, yˆ)= δ(l).(4.63)∂b(l)在计算出每一层的误差项之后，我们就可以得到每一层参数的梯度。因此，基于误差反向传播算法（backpropagation，BP）的前馈神经网络训练过程可以分为以下三步：1. 前馈计算每一层的净输入z(l) 和激活值a(l)，直到最后一层；2. 反向传播计算每一层的误差项δ(l)；3. 计算每一层参数的偏导数，并更新参数。算法4.1给出使用随机梯度下降的误差反向传播算法的具体训练过程。算法 4.1: 基于随机梯度下降的反向传播算法输入: 训练集D = {(x(n), y(n))}N , 验证集V, 学习率α, 正则化系数n=1λ, 网络层数L, 神经元数量m(l), 1 ≤ l ≤ L.1 随机初始化 W, b ;2 repeat34567对训练集D 中的样本随机重排序;for n = 1 · · · N do从训练集D 中选取样本(x(n), y(n));前馈计算每一层的净输入z(l) 和激活值a(l)，直到最后一层;反向传播计算每一层的误差δ(l);// 计算每一层参数的导数// 公式 (4.60)(n) ,y(n)ˆ)∀l,∀l,∂L(y∂W (l)(n) ,y(n)= δ(l)(a 1))T ;(l−// 公式(4.62)// 公式(4.63)89∂L(yˆ)= δ(l);∂b(l)// 更新参数(l) ← W (l) − α(δ(l)(a(l−1)) + λW (l));b(l) ← b(l) − αδ(l);1011WT12end13 until 神经网络模型在验证集V 上的错误率不再下降;输出: W, b4.5 自动梯度计算神经网络的参数主要通过梯度下降来进行优化的。当确定了风险函数以及 网络结构后，我们就可以手动用链式法则来计算风险函数对每个参数的梯度，并 用代码进行实现。但是手动求导并转换为计算机程序的过程非常琐碎并容易出邱锡鹏：《神经网络与深度学习》https://nndl.github.io/
 4.5 自动梯度计算2019 年 4 月 6 日103错，导致实现神经网络变得十分低效。目前，几乎所有的主流深度学习框架都包含了自动梯度计算的功能，即我们可以只考虑网络结构并用代码实现，其梯度可以自动进行计算，无需人工干预。这样开发的效率就大大提高了。自动计算梯度的方法可以分为以下三类：4.5.1 数值微分数值微分（Numerical Diﬀerentiation）是用数值方法来计算函数f (x) 的导数。函数f(x) 的点x 的导数定义为f(x + ∆x) − f(x)f′(x) = lim.(4.64)∆x∆x→0要计算函数f (x) 在点x 的导数，可以对x 加上一个很少的非零的扰动∆x，通过上述定义来直接计算函数f(x) 的梯度。数值微分方法非常容易实现，但找到一个合适的扰动∆x 却十分困难。如果∆x 过小，会引起数值计算问题，比如舍入误差；如果∆x过大，会增加截断误差，使得导数计算不准确。因此，数值微分的实用性比较差。在实际应用，经常使用下面公式来计算梯度，可以减少截断误差。舍 入 误 差 （ Round-oﬀError)是指数值计算中由于数字舍入造成的近似值和精确值之间的差异，比如用浮点数来表示实数。截断误差（Truncation Er-f(x + ∆x) − f(x − ∆x)f′(x) = lim.(4.65)ror）是数学模型的理论解与数值计算问题的精确解之间的误差。2∆x∆x→0数值微分的另外一个问题是计算复杂度。假设参数数量为n，则每个参数都需要单独施加扰动，并计算梯度。假设每次正向传播的计算复杂度为O(n)，则计算数值微分的总体时间复杂度为O(n2)。4.5.2 符号微分符号微分（Symbolic Diﬀerentiation）是一种基于符号计算的自动求导方法。符号计算，也叫代数计算，是指用计算机来处理带有变量的数学表达式。这里的变量看作是符号（Symbols），一般不需要代入具体的值。符号计算的输入和输出都是数学表达式，一般包括对数学表达式的化简、因式分解、微分、积分、解代数方程、求解常微分方程等运算。和符号计算相对应的概念是数值计算，即将数值代入数学表示中进行计算。比如数学表达式的化简：输入：3x − x + 2x + 1输出：4x + 1.(4.66)(4.67)符号计算一般来讲是对输入的表达式，通过迭代或递归使用一些事先定义的规则进行转换。当转换结果不能再继续使用变换规则时，便停止计算。邱锡鹏：《神经网络与深度学习》https://nndl.github.io/
 1042019 年 4 月 6 日第4 章 前馈神经网络符号微分可以在编译时就计算梯度的数学表示，并进一步利用符号计算方法进行优化。此外，符号计算的一个优点是符号计算和平台无关，可以在CPU或GPU上运行。符号微分也有一些不足之处。一是编译时间较长，特别是对于循环，需要很长时间进行编译；二是为了进行符号微分，一般需要设计一种专门的语言来表示数学表达式，并且要对变量（符号）进行预先声明；三是很难对程序进行调试。4.5.3 自动微分自动微分（Automatic Diﬀerentiation，AD）是一种可以对一个（程序）函数进行计算导数的方法。符号微分的处理对象是数学表达式，而自动微分的处理对 象是一个函数或一段程序。而自动微分可以直接在原始程序代码进行微分。自 动微分的基本原理是所有的数值计算可以分解为一些基本操作，包含+, −, ×, / 和一些初等函数exp, log, sin, cos 等。自动微分也是利用链式法则来自动计算一个复合函数的梯度。我们以一个神经网络中常见的复合函数的例子来说明自动微分的过程。为了简单起见，令复合函数f(x; w, b) 为1( ; w, b) =,(4.68)f xexp − (wx + b) + 1其中x 为输入标量，w 和 b 分别为权重和偏置参数。首先，我们将复合函数f(x; w, b)分解为一系列的基本操作，并构成一个计算图（Computational Graph）。计算图是数学运算的图形化表示。计算图中的每个非叶子节点表示一个基本操作，每个叶子节点为一个输入变量或常量。图4.8给出了当x = 1, w = 0, b = 0 时复合函数f(x; w, b) 的计算图，其中连边上的红色数字表示前向计算时复合函数中每个变量的实际取值。1h1h2hh4h5h63100×012x×+∂h4∂h2exp+/f(x;w, b)∂h3 = −1∂h61∂h1∂h2= exp(h )∂h5= −= w= 1= 14h5∂x∂h1∂h3邱锡鹏：《神经网络与深度学习》https://nndl.github.io/
 4.5 自动梯度计算2019 年 4 月 6 日1053∂h∂h52邱锡鹏：《神经网络与深度学习》https://nndl.github.io/
 1062019 年 4 月 6 日第4 章 前馈神经网络= 0∂h1 = x∂w0= 1−0.250=∂h2= 1∂b= 1wb−11图 4.8 复合函数f(x; w, b)的计算图从计算图上可以看出，复合函数f (x; w, b) 由 6 个基本函数hi, 1 ≤ i ≤ 6 组成。如表4.1所示，每个基本函数的导数都十分简单，可以通过规则来实现。邱锡鹏：《神经网络与深度学习》https://nndl.github.io/
 4.5 自动梯度计算2019 年 4 月 6 日107函数导数∂h∂h1 = w∂x∂hh1 = x × w1 = x∂w∂h∂h22h = h + b= 1= 121∂b1∂h3h3 = h× −1=−12∂h2∂h4h = exp(h )= exp(h3)43∂h35∂hh = h + 1= 1154∂h4∂h6h6 = 1/h5∂h5= − h25表 4.1 复合函数f(x; w, b) 的6 个基本函数及其导数整个复合函数 f (x; w, b) 关于参数 w 和 b 的导数可以通过计算图上的节点f(x; w, b)与参数w 和b 之间路径上所有的导数连乘来得到，即∂f(x; w, b)∂w∂f(x; w, b)∂f(x; w, b) ∂h ∂h ∂h ∂h ∂h ∂h1 ,==65432(4.69)(4.70)∂h6∂h ∂h ∂h ∂h ∂h ∂w54321∂f(x; w, b) ∂h ∂h ∂h ∂h ∂h65432 .∂b∂h6∂h ∂h ∂h ∂h ∂b5432以 ∂f(x∂;ww,b) 为例，当x = 1, w = 0, b = 0 时，可以得到∂f(x; w, b)∂f(x; w, b) ∂h ∂h ∂h ∂h ∂h ∂h6 5 4 3 2 1(4.71)|x=1,w=0,b=0=∂h6∂h ∂h ∂h ∂h ∂h ∂w5 4 3 2 1∂w= 1 × −0.25 × 1 × 1 × −1 × 1 × 1= 0.25.(4.72)(4.73)如果函数和参数之间有多条路径，可以将这多条路径上的导数再进行相加，得到最终的梯度。按照计算导数的顺序，自动微分可以分为两种模式：前向模式和反向模式。前向模式前向模式是按计算图中计算方向的相同方向来递归地计算梯度。以∂f(x;∂ww,b) 为例，当x = 1, w = 0, b = 0 时，前向模式的累积计算顺序如下：∂h1= x = 1(4.74)(4.75)∂w∂h2∂w∂h ∂h21== 1 × 1 = 1∂h1 ∂w邱锡鹏：《神经网络与深度学习》https://nndl.github.io/
 1082019 年 4 月 6 日第4 章 前馈神经网络(4.76)∂h3∂h3 ∂h2∂h2 ∂w== −1 × 1∂w..(4.77)∂h6∂h6 ∂h5== −0.25 −1 = 0.25×(4.78)∂w∂h5 ∂w∂f(x; w, b)∂f(x; w, b) ∂h=6 = 1 × 0.25 = 0.25(4.79)∂w∂h6∂w反向模式反向模式是按计算图中计算方向的相反方向来递归地计算梯度。以∂f(x;∂ww,b) 为例，当x = 1, w = 0, b = 0 时，反向模式的累积计算顺序如下：∂f(x; w, b)= 1(4.80)(4.81)(4.82)∂h6∂f(x; w, b)∂h5∂f(x; w, b) ∂h6 = 1 × −0.25∂h==∂h65∂f(x; w, b)∂f(x; w, b) ∂h5= −0.25 1 = 0 25×− .∂h4∂h5∂h4..(4.83)(4.84)∂f(x; w, b)∂f(x; w, b) ∂h1== 0.25 × 1 = 0.25∂w∂h1∂w前向模式和反向模式可以看作是应用链式法则的两种梯度累积方式。从反向模式的计算顺序可以看出，反向模式和反向传播的计算梯度的方式相同。对于一般的函数形式f : Rn → Rm，前向模式需要对每一个输入变量都进行一遍遍历，共需要n遍。而反向模式需要对每一个输出都进行一个遍历，共需要m 遍。当n > m 时，反向模式更高效。在前馈神经网络的参数学习中，风险函数为f : Rn → R，输出为标量，因此采用反向模式为最有效的计算方式，只需要一遍计算。符号微分和自动微分符号微分和自动微分都利用计算图和链式法则来自动求解导数。符号微分在编译阶段先构造一个复合函数的计算图，通过符号计算得到导数的表达式，还可以对导数表达式进行优化，在程序运行阶段才代入变量的具体数值进行计算导数。而自动微分则无需事先编译，在程序运行阶段边计算边记录计算图，计算图上的局部梯度都直接代入数值进行计算，然后用前向或反向模式来计算最终的梯度。图4.9给出了符号微分与自动微分的对比。邱锡鹏：《神经网络与深度学习》https://nndl.github.io/
 4.6 优化问题2019 年 4 月 6 日107符号微分自动微分数学表达式 f (x)数学表达式 f ′(x)程序实现程序实现程序函数 function f(x){· · · }程序函数 function df(x){· · · }图 4.9 符号微分与自动微分对比静态计算图和动态计算图 计算图的构建可以分为静态计算图和动态计算图。静态计算图是在编译时构建计算图，计算图构建好之后在程序运行时不能改变，而 动态计算图是在程序运行时动态构建。两种构建方式各有优缺点。静态计算图 在构建时可以进行优化，并行能力强，但灵活性比较差。动态计算图则不容易 优化，当不同输入的网络结构不一致时，难以并行计算，但是灵活性比较高。在目前深度学习框架里，Theano 和 Tensorﬂow 采用的是静态计算图，而DyNet，Chainer 和PyTorch 采用的是动态计算图。4.6 优化问题神经网络的参数学习比线性模型要更加困难，主要原因有两点：（1）非凸优化问题和（2）梯度消失问题。4.6.1 非凸优化问题神经网络的优化问题是一个非凸优化问题。以一个最简单的1-1-1结构的2层神经网络为例来其损失函数与参数的可视化例子。y = σ(w σ(w x)),(4.85)21其中w 和w 为网络参数，激活函数为Logistic 函数σ(·)。12给定一个输入样本(1, 1)，分别使用两种损失函数，第一种损失函数为平方误差损失：L(w , w ) = (1−y)2，第二种损失函数为交叉熵损失L(w , w ) = ln y。1212当x = 1, y = 1 时，其平方误差和交叉熵损失函数分别为：L(w , w ) = (1 − y)212和 L(w , w ) = ln y。损失函数与参数w 和 w 的关系如图4.10所示，可以看出1212损失函数关于两个参数是一种非凸的函数关系。4.6.2 梯度消失问题在神经网络中误差反向传播的迭代公式为δ(l) = f ′(z(l)) ⊙ W (l+1)Tδ(l+1),(4.86)l邱锡鹏：《神经网络与深度学习》https://nndl.github.io/
 1082019 年 4 月 6 日第4 章 前馈神经网络1.00650.750.500.250.0043LL0.2520.50100.751.00142440422w220020w222w142w1444(a) 平方误差损失(b) 交叉熵损失图 4.10 神经网络y = σ(w σ(w x)) 的损失函数21误差从输出层反向传播时，在每一层都要乘以该层的激活函数的导数。当我们使用Sigmoid 型函数：Logistic 函数σ(x) 或 Tanh 函数时，其导数为σ′(x) = σ(x) 1 − σ(x) ∈ [0, 0.25]tanh′(x) = 1 − tanh(x) 2 ∈ [0, 1].(4.87)(4.88)Sigmoid 型函数导数的值域都小于1，如图4.11所示。0.250.20.150.15 · 10−2邱锡鹏：《神经网络与深度学习》https://nndl.github.io/
 邱锡鹏：《神经网络与深度学习》https://nndl.github.io/
 1102019 年 4 月 6 日第4 章 前馈神经网络−4−2024610.80.60.40.20(a) Logistic 函数的导数邱锡鹏：《神经网络与深度学习》https://nndl.github.io/
 邱锡鹏：《神经网络与深度学习》https://nndl.github.io/
 1122019 年 4 月 6 日(b) Tanh 函数的导数第4 章 前馈神经网络−4−20246图 4.11 激活函数的导数由于Sigmoid 型函数的饱和性，饱和区的导数更是接近于0。这样，误差经过每一层传递都会不断衰减。当网络层数很深时，梯度就会不停的衰减，甚至消 失，使得整个网络很难训练。这就是所谓的梯度消失问题（Vanishing GradientProblem），也叫梯度弥散问题。梯度消失问题在过去的二三十年里一直没有有效地解决，是阻碍神经网络发展的重要原因之一。在深层神经网络中，减轻梯度消失问题的方法有很多种。一种简单有效的方式是使用导数比较大的激活函数，比如ReLU 等。邱锡鹏：《神经网络与深度学习》https://nndl.github.io/
 4.7 总结和深入阅读2019 年 4 月 6 日1094.7 总结和深入阅读神经网络是一种典型的分布式并行处理模型，通过大量神经元之间的交互来处理信息，每一个神经元都发送兴奋和抑制的信息到其它神经元[Rumel-hart et al., 1986]。和感知器不同，神经网络中的激活函数一般为连续可导函数。表4.2给出了常见激活函数及其导数。在一个神经网络中选择合适的激活函数十分重要。Ramachandran et al. [2017] 设计了不同形式的函数组合方式，并通过强化学习来搜索合适的激活函数，在多个任务上发现Swish 函数具有更好的性能。激活函数函数导数f (x) =1Logistic 函数f ′(x) = f (x) 1 − f (x)f′(x) = 1 − f(x)21+exp(−x)exp(x) exp( x)exp(x)+exp(−x)TanhReLUELU−函f (x) = max(0, x)f ′(x) = I(x > 0)f(x) = max(0, x) +min 0, γ(exp(x) − 1)f ′(x) = I(x > 0) + I(x ≤0) · γ exp(x)f(x) = log 1 + exp(x)f ′(x) =1SoftPlus 函数1+exp(−x)表 4.2 常见激活函数及其导数本章介绍的前馈神经网络是一种类型最简单的网络，相邻两层的神经元之间为全连接关系，也称为全连接神经网络（Fully Connected Neural Network，FCNN）或多层感知器。前馈神经网络作为一种机器学习方法在很多模式识别和机器学习的教材中都有介绍，比如《Pattern Recognition and Machine Learning》[Bishop, 2007]，《Pattern Classiﬁcation》[Duda et al., 2001]等。前馈神经网络作为一种能力很强的非线性模型，其能力可以由通用近似定理来保证。关于通用近似定理的详细介绍可以参考[Haykin, 2009]。前馈神经网络在20 世纪80 年代后期就已被广泛使用，但是基本上都是两层网络（即一个隐藏层和一个输出层），神经元的激活函数基本上都是Sigmoid型函数，并且使用的损失函数大多数是平方损失。虽然当时前馈神经网络的参数学习依然有很多难点，但其作为一种连接主义的典型模型，标志人工智能从 高度符号化的知识期向低符号化的学习期开始转变。TensorFlow 游乐场1 提供了一个非常好的神经网络训练过程可视化系统。1 http://playground.tensorﬂow.org邱锡鹏：《神经网络与深度学习》https://nndl.github.io/
 1102019 年 4 月 6 日参考文献习题习题4-1 对于一个神经元σ(w x + b)，并使用梯度下降优化参数w时，如T果输入x 恒大于0，其收敛速度会比零均值化的输入更慢。习题 4-2 试设计一个前馈神经网络来解决XOR 问题，要求该前馈神经网络具有两个隐藏神经元和一个输出神经元，并使用ReLU 作为激活函数。习题 4-3 试举例说明“死亡ReLU 问题”，并提出解决方法。习题 4-4 计算Swish 函数的导数。参见第4.1.3节。习题4-5 如果限制一个神经网络的总神经数量为N，层数为L，每个隐藏层的神经元数量为 NL−−11，试分析参数数量和层数L 的关系。习题4-6 证明通用近似性质对于具有线性输出层和至少一个使用ReLU 激活函数的隐藏层组成的前馈神经网络，也都是适用的。参见定理4.1。习题 4-7 为什么在神经网络模型的结构化风险函数中不对偏置 b 进行正则化？习题 4-8为什么在用反向传播算法进行参数学习时要采用随机参数初始化的方式而不是直接令W = 0, b = 0？习题 4-9梯度消失问题是否可以通过增加学习率来缓解？参考文献Christopher M. Bishop. Pattern recogni-tion and machine learning, 5th Edition. In-formation science and statistics. Springer,2007. ISBN 9780387310732.Djork-Arné Clevert, Thomas Unterthiner,and Sepp Hochreiter. Fast and accu-rate deep network learning by exponen-tial linear units (elus). arXiv preprintarXiv:1511.07289, 2015.George Cybenko. Approximations by su-perpositions of a sigmoidal function. Math-ematics of Control, Signals and Systems, 2:183–192, 1989.Richard O. Duda, Peter E. Hart, andDavid G. Stork. Pattern classiﬁcation, 2ndEdition. Wiley, 2001. ISBN 9780471056690.邱锡鹏：《神经网络与深度学习》https://nndl.github.io/
 参考文献2019 年 4 月 6 日111Charles Dugas, Yoshua Bengio, FrançoisBélisle, Claude Nadeau, and René Gar-cia. Incorporating second-order functionalknowledge for better option pricing. Ad-vances in Neural Information ProcessingSystems, pages 472–478, 2001.of the IEEE International Conference onComputer Vision, pages 1026–1034, 2015.Kurt Hornik, Maxwell Stinchcombe, andHalbert White. Multilayer feedforward net-works are universal approximators. Neuralnetworks, 2(5):359–366, 1989.Ken-ichi Funahashi and Yuichi Nakamura.Approximation of dynamical systems bycontinuous time recurrent neural networks.Neural networks, 6(6):801–806, 1993.Thomas N Kipf and Max Welling. Semi-supervised classiﬁcation with graph con-volutional networks.arXiv preprintarXiv:1609.02907, 2016.Justin Gilmer, SamuelSSchoenholz,Andrew L Maas, Awni Y Hannun, and An-drew Y Ng. Rectiﬁer nonlinearities improveneural network acoustic models. In Pro-ceedings of the International Conference onMachine Learning, 2013.Patrick F Riley, Oriol Vinyals, andGeorge E Dahl. Neural message passingfor quantum chemistry. arXiv preprintarXiv:1704.01212, 2017.Xavier Glorot, Antoine Bordes, and YoshuaBengio. Deep sparse rectiﬁer neural net-works. In International Conference on Arti-ﬁcial Intelligence and Statistics, pages 315–323, 2011.Warren S McCulloch and Walter Pitts. Alogical calculus of the ideas immanent innervous activity. The bulletin of mathemat-ical biophysics, 5(4):115–133, 1943.Vinod Nair and Geoﬀrey E Hinton. Rec-tiﬁed linear units improve restricted boltz-mann machines. In Proceedings of the Inter-national Conference on Machine Learning,pages 807–814, 2010.IanJGoodfellow, David Warde-Farley,Courville, andMehdi Mirza, AaronCYoshua Bengio. Maxout networks. In Pro-ceedings of the International Conference onMachine Learning, pages 1319–1327, 2013.Alex Graves, Greg Wayne, and Ivo Dani-helka. Neural turing machines. arXivpreprint arXiv:1410.5401, 2014.Prajit Ramachandran, Barret Zoph, andQuoc V Le. Searching for activation func-tions. arXiv preprint arXiv:1710.05941,2017.Simon Haykin. Neural networks: A compre-hensive foundation: Macmillan college pub-lishing company. New York, 1994.DavidJamesERumelhart, GeoﬀreyEAHinton,generalLMcClelland, et al.framework for parallel distributed process-ing. Parallel distributed processing: Explo-rations in the microstructure of cognition,1:45–76, 1986.Simon Haykin. Neural networks and learn-ing machines, volume 3. Pearson UpperSaddle River, NJ, USA:, 2009.Kaiming He, Xiangyu Zhang, ShaoqingRen, and Jian Sun. Delving deep into recti-ﬁers: Surpassing human-level performanceon imagenet classiﬁcation. In ProceedingsSainbayar Sukhbaatar, Jason Weston, RobFergus, et al. End-to-end memory networks.In Advances in Neural Information Process-ing Systems, pages 2431–2439, 2015.邱锡鹏：《神经网络与深度学习》https://nndl.github.io/
 

 第 5 章 卷积神经网络一切都应该尽可能地简单，但不能过于简单。— 艾伯特· 爱因斯坦卷积神经网络（Convolutional Neural Network，CNN 或ConvNet）是一种具有局部连接、权重共享等特性的深层前馈神经网络。卷积神经网络最早是主要用来处理图像信息。如果用全连接前馈网络来处理图像时，会存在以下两个问题：（1） 参数太多：如果输入图像大小为100 × 100 × 3（即图像高度为100，宽度为100，3个颜色通道：RGB）。在全连接前馈网络中，第一个隐藏层的每个神经元到输入层都有100 × 100 × 3 = 30, 000 个相互独立的连接，每个连接都对应一个权重参数。随着隐藏层神经元数量的增多，参数的规模也会急剧增加。这会导致整个神经网络的训练效率会非常低，也很容易出现过拟合。（2） 局部不变性特征：自然图像中的物体都具有局部不变性特征，比如在尺度缩放、平移、旋转等操作不影响其语义信息。而全连接前馈网络很难提取这些局部不变特征，一般需要进行数据增强来提高性能。卷积神经网络是受生物学上感受野的机制而提出。感受野（Receptive Field）主要是指听觉、视觉等神经系统中一些神经元的特性，即神经元只接受其所支配的刺激区域内的信号。在视觉神经系统中，视觉皮层中的神经细胞的输出依赖于视网膜上的光感受器。视网膜上的光感受器受刺激兴奋时，将神经冲动信号传到视觉皮层，但不是所有视觉皮层中的神经元都会接受这些信号。一个神经元的感受野是指视网膜上的特定区域，只有这个区域内的刺激才能够激活该神经元。目前的卷积神经网络一般是由卷积层、汇聚层和全连接层交叉堆叠而成的前馈神经网络，使用反向传播算法进行训练。卷积神经网络有三个结构上的特全连接层一般在卷积网络的最顶层。
 1142019 年 4 月 6 日第5 章 卷积神经网络性：局部连接，权重共享以及汇聚。这些特性使得卷积神经网络具有一定程度上的平移、缩放和旋转不变性。和前馈神经网络相比，卷积神经网络的参数更少。卷积神经网络主要使用在图像和视频分析的各种任务上，比如图像分类、人 脸识别、物体识别、图像分割等，其准确率一般也远远超出了其它的神经网络型。近年来卷积神经网络也广泛地应用到自然语言处理、推荐系统等领域。模5.1 卷积卷积（Convolution），也叫摺积，是分析数学中一种重要的运算。在信号处理或图像处理中，经常使用一维或二维卷积。这里我们只考虑离散序列的情况。一维卷积 一维卷积经常用在信号处理中，用于计算信号的延迟累积。假设一个信号发生器每个时刻t 产生一个信号x ，其信息的衰减率为w ，即在k − 1 个时间tk步长后，信息为原来的w 倍。假设w = 1, w = 1/2, w = 1/4，那么在时刻 tk123收到的信号yt 为当前时刻产生的信息和以前时刻延迟信息的叠加，y = 1 × x + 1/2 × x + 1/4 × xt−2(5.1)(5.2)ttt−1= w × x + w × x + w3 × xt−21t2t−1Σ3=wk ·xt−k+1.(5.3)k=1我们把w , w , · · · 称为滤波器（Filter）或卷积核（Convolution Kernel）。12假设滤波器长度为m，它和一个信号序列x , x , · · · 的卷积为12Σmyt =wk · xt−k+1,(5.4)(5.5)k=1信号序列x 和滤波器w 的卷积定义为y = w ⊗ x,其中⊗ 表示卷积运算。一般情况下滤波器的长度m 远小于信号序列长度n。当滤波器fk = 1/m, 1 ≤k ≤ m 时，卷积相当于信号序列的移动平均。图5.1给出了一维卷积示例。滤波器为[−1, 0, 1]，连接边上的数字为滤波器中的权重。邱锡鹏：《神经网络与深度学习》https://nndl.github.io/
 5.1 卷积2019 年 4 月 6 日115-1 2 1 1 0-11-11-11-11-10000011 1 2 -1 1 -2 1图 5.1 一维卷积示例二维卷积 卷积也经常用在图像处理中。因为图像为一个两维结构，所以需要将一维卷积进行扩展。给定一个图像X ∈ RM ×N ，和滤波器<< M, n << N ，其卷积为W ∈ Rm×n，一般mΣ Σmnyij =wuv ·xi−u+1,j−v+1.(5.6)u=1 v=1图5.2给出了二维卷积示例。1 1 1 1 1×− 1×0×0-1 0 -3 0 11 0 00 0 00 0 -10 -2 -12 2 4-1 0 0×01 -1 0×0×0⊗=2 10010 -1 1 2 11 2 1 1 1图 5.2 二维卷积示例常用的均值滤波（mean ﬁlter）就是当前位置的像素值设为滤波器窗口中所有像素的平均值，也就是fuv=1。mn在图像处理中，卷积经常作为特征提取的有效方法。一幅图像在经过卷积操作后得到结果称为特征映射（Feature Map）。图5.3给出在图像处理中几种常用的滤波器，以及其对应的特征映射。图中最上面的滤波器是常用的高斯滤波器，可以用来对图像进行平滑去噪；中间和最下面的过滤器可以用来提取边缘特征。邱锡鹏：《神经网络与深度学习》https://nndl.github.io/
 1162019 年 4 月 6 日第5 章 卷积神经网络11618116181418===116181160101-41010⊗原始图像010110-1-1 -1滤波器输出特征映射图 5.3 图像处理中几种常用的滤波器示例5.1.1 互相关在机器学习和图像处理领域，卷积的主要功能是在一个图像（或某种特征）上滑动一个卷积核（即滤波器），通过卷积操作得到一组新的特征。在计算卷积的过程中，需要进行卷积核翻转。在具体实现上，一般会以互相关操作来代替卷积，从而会减少一些不必要的操作或开销。互相关（Cross-Correlation）是一个衡量两个序列相关性的函数，通常是用滑动窗口的点积计算来实现。给定一个图像X ∈ RM ×N 和卷积核W ∈ Rm×n，它们的互相关为翻转就是从两个维度（从上到下、从左到右）颠倒次序，即旋转180度。Σ Σmnyij =wuvxi+u−1,j+v−1.(5.7)·u=1 v=1和公式(5.6) 对比可知，互相关和卷积的区别在于卷积核仅仅是否进行翻转。因此互相关也可以称为不翻转卷积。互相关和卷积的区别也可以理解为图像是否进行翻转。在神经网络中使用卷积是为了进行特征抽取，卷积核是否进行翻转和其特征抽取的能力无关。特别是当卷积核是可学习的参数时，卷积和互相关是等价邱锡鹏：《神经网络与深度学习》https://nndl.github.io/
 5.1 卷积2019 年 4 月 6 日117的。因此，为了实现上（或描述上）的方便起见，我们用互相关来代替卷积。事实上，很多深度学习工具中卷积操作其实都是互相关操作。在本书之后描述中，除非特别声明，卷积一般指“互相关”。公式(5.7) 可以表述为Y = W ⊗ X,其中Y ∈ RM −m+1,N −n+1 为输出矩阵。(5.8)5.1.2 卷积的变种在卷积的标准定义基础上，还可以引入滤波器的滑动步长和零填充来增加卷积的多样性，可以更灵活地进行特征抽取。滤波器的步长（Stride）是指滤波器在滑动时的时间间隔。图5.4a给出了步长为2的卷积示例。步长也可以小于1，即微步卷积参见第5.5.1节。零填充（Zero Padding）是在输入向量两端进行补零。图5.4b给出了输入的两端各补一个零后的卷积示例。-1101 1 2 -1 1 -3 1(a) 步长s = 2-1 -1 2 1 2 0 -30 1 1 2 -1 1 -3 1 0(b) 零填充p = 1图 5.4 卷积的步长和零填充通常可以通过选择合适的卷积大小以及步长来使得(n − m + 2p)/s + 1 为整数。假设卷积层的输入神经元个数为n，卷积大小为m，步长（stride）为s，输入神经元两端各填补 p 个零（zero padding），那么该卷积层的神经元数量为(n − m + 2p)/s + 1。邱锡鹏：《神经网络与深度学习》https://nndl.github.io/
 1182019 年 4 月 6 日第5 章 卷积神经网络一般常用的卷积有以下三类：在早期的文献中，卷积一般默认为窄卷积；而目前的文献中，卷积一般默认为等宽卷积。• 窄卷积（Narrow Convolution）：步长s = 1，两端不补零p = 0，卷积后输出长度为n − m + 1。• 宽卷积（Wide Convolution）：步长s = 1，两端补零p = m − 1，卷积后输出长度n + m − 1。• 等宽卷积（Equal-Width Convolution）：步长s = 1，两端补零p = (m −1)/2，卷积后输出长度n。图5.4b就是一个等长卷积示例。更 多 的 卷 积 变 种 参 见第5.5节。5.1.3卷积的数学性质卷积有很多很好的数学性质。在本节中，我们介绍一些二维卷积的数学性质，但是这些数学性质同样可以适用到一维卷积的情况。5.1.3.1 交换性如果不限制两个卷积信号的长度，卷积是具有交换性的，即x ⊗ y = y ⊗ x。当输入信息和卷积核有固定长度时，它们的宽卷积依然具有交换性。对于两维图像X ∈ RM ×N 和卷积核W ∈ Rm×n，对图像X 的两个维度进行零填充，两端各补m − 1 和n − 1 个零，得到全填充（Full Padding）的图像X˜∈ R(M +2m−2)×(N +2n−2)。图像X和卷积核W 的宽卷积（Wide Convolution）定义为W ⊗˜X , W ⊗X˜,W ⊗˜X = X ⊗˜W.(5.9)˜其中⊗为宽卷积操作。宽卷积具有交换性，即参见习题5-1。(5.10)5.1.3.2 导数假设Y = W ⊗X ，其中X ∈ RM ×N， ， ，W ∈ Rm×n Y ∈ R(M −m+1)×(N −n+1)函 数 f(Y ) ∈ R 为一个标量函数，则M −m +1 N −n+1Σ Σ∂f (Y )∂wuv∂yij ∂f (Y )∂wuv ∂yij=(5.11)i=1j=1M −m +1 N −n+1Σ Σ∂f(Y )yij =xi+u−1,j+v−1=(5.12)∂yijuvΣM −m +1 N −n+1Σi= 1xi+u− 1,j+v− 1w邱锡鹏：《神经网络与深度学习》https://nndl.github.io/
 5.1 卷积2019 年 4 月 6 日119j=1u,vΣ ∂f(Y )xu+i−1,v+j−1=(5.13)∂yiji= 1j=1邱锡鹏：《神经网络与深度学习》https://nndl.github.io/
 

 5.2 卷积神经网络2019 年 4 月 6 日119从公式(5.13) 可以看出，f (Y ) 关于W 的偏导数为X 和 ∂∂f(YY ) 的卷积∂f(Y )∂W∂f(Y )∂Y=⊗ X.(5.14)同理得到，M −m +1 N −n+1Σ ΣΣ∂f (Y )∂xst∂yij ∂f (Y )∂xst ∂yij=(5.15)(5.16)i=1j=1∂f(Y )∂yijM −m +1 N −n+1,=ws−i+1,t−j+1i= 1j= 1其中当(s − i + 1) < 1，或(s − i + 1) > m，或(t − j + 1) < 1，或(t − j + 1) > n时，w= 0。即相当于对W 进行了p = (M − m, N − n) 的零填充。s− +1,t− +1ij从公式(5.16) 可以看出，f (Y ) 关于X 的偏导数为W 和 ∂∂f(YY ) 的宽卷积。公式 (5.16)中的卷积是真正的卷积而不是互相关，为了一致性，我们用互相关的“卷积”，即∂f (Y )∂f (Y )= rot180()⊗˜ W(5.17)(5.18)∂X∂Y∂f(Y )= rot180(W ) ˜,⊗∂Y其中rot180(·) 表示旋转180 度。5.2 卷积神经网络卷积神经网络一般由卷积层、汇聚层和全连接层构成。5.2.1 用卷积来代替全连接在全连接前馈神经网络中，如果第l 层有nl 个神经元，第l − 1 层有n(l−1)个神经元，连接边有n(l) × n(l−1) 个，也就是权重矩阵有n(l) × n(l−1) 个参数。当m 和n 都很大时，权重矩阵的参数非常多，训练的效率会非常低。如果采用卷积来代替全连接，第l 层的净输入z(l) 为第l − 1 层活性值a(l−1)和滤波器w(l) ∈ Rm 的卷积，即z(l) = w(l) ⊗ a(l−1) + b(l),(5.19)其中滤波器w(l) 为可学习的权重向量，b(l) ∈ Rnl− 1 为可学习的偏置。根据卷积的定义，卷积层有两个很重要的性质：邱锡鹏：《神经网络与深度学习》https://nndl.github.io/
 1202019 年 4 月 6 日第5 章 卷积神经网络局部连接 在卷积层（假设是第l 层）中的每一个神经元都只和下一层（第l − 1层）中某个局部窗口内的神经元相连，构成一个局部连接网络。如图5.5b所示，卷积层和下一层之间的连接数大大减少，有原来的nl × nl−1 个连接变为nl × m个连接，m 为滤波器大小。权重共享 从公式(5.19) 可以看出，作为参数的滤波器w( 对于第 层的所有的l)l神经元都是相同的。如图5.5b中，所有的同颜色连接上的权重是相同的。(a) 全连接层邱锡鹏：《神经网络与深度学习》https://nndl.github.io/
 5.2 卷积神经网络2019 年 4 月 6 日121邱锡鹏：《神经网络与深度学习》https://nndl.github.io/
 1222019 年 4 月 6 日第5 章 卷积神经网络(b) 卷积层图 5.5 全连接层和卷积层对比由于局部连接和权重共享，卷积层的参数只有一个m 维的权重w( 和 维l)1的偏置b(l)，共m + 1个参数。参数个数和神经元的数量无关。此外，第 层的l神经元个数不是任意选择的，而是满足n(l) = n(l−1) − m + 1。5.2.2 卷积层卷积层的作用是提取一个局部区域的特征，不同的卷积核相当于不同的特征提取器。上一节中描述的卷积层的神经元和全连接网络一样都是一维结构。既然卷积网络主要应用在图像处理上，而图像为两维结构，因此为了更充分地利用图像的局部信息，通常将神经元组织为三维结构的神经层，其大小为高度M × 宽度N × 深度D，有D 个 M × N 大小的特征映射构成。特征映射（Feature Map）为一幅图像（或其它特征映射）在经过卷积提取到的特征，每个特征映射可以作为一类抽取的图像特征。为了提高卷积网络的邱锡鹏：《神经网络与深度学习》https://nndl.github.io/
 5.2 卷积神经网络2019 年 4 月 6 日123表示能力，可以在每一层使用多个不同的特征映射，以更好地表示图像的特征。在输入层，特征映射就是图像本身。如果是灰度图像，就是有一个特征映射，深度D = 1；如果是彩色图像，分别有RGB 三个颜色通道的特征映射，输入层深度D = 3。不失一般性，假设一个卷积层的结构如下：• 输入特征映射组：X ∈ RM ×N ×D 为三维张量（tensor），其中每个切片(slice) 矩阵Xd ∈ RM ×N 为一个输入特征映射，1 ≤ d ≤ D；• 输出特征映射组：Y ∈ RM ′×N ′×P 为三维张量，其中每个切片矩阵Y p ∈RM′×N ′为一个输出特征映射，1 ≤ p ≤ P ；• 卷积核：W ∈ Rm×n×D×P 为四维张量，其中每个切片矩阵W p,d ∈ Rm×n为一个两维卷积核，1 ≤ d ≤ D, 1 ≤ p ≤ P 。图5.6给出卷积层的三维结构表示。特征映射 Xd特征映射 Y p卷积核 Wp特征映射组 X高度 M宽度 N深度 D图 5.6 卷积层的三维结构表示为了计算输出特征映射Y p，用卷积核W p,1, W p,2, · · · , W p,D 分别对输入特征映射X1, X2, · · · , XD 进行卷积，然后将卷积结果相加，并加上一个标量偏置b 得到卷积层的净输入Zp，再经过非线性激活函数后得到输出特征映射Y p。ΣDZp = Wp ⊗X + bp =Y p = f (Zp).W p,d ⊗Xd + bp,(5.20)(5.21)d=1其中Wp ∈ Rm×n×D 为三维卷积核，f (·) 为非线性激活函数，一般用ReLU函数。整个计算过程如图5.7所示。如果希望卷积层输出P 个特征映射，可以将上述计算机过程重复P 次，得到P 个输出特征映射Y 1, Y 2, · · · , Y P 。在输入为X ∈ RM ×N ×D，输出为Y ∈ RM ′×N ′×P 的卷积层中，每一个输入特征映射都需要D 个滤波器以及一个偏置。假设每个滤波器的大小为m × n，那么共需要P × D × (m × n) + P 个参数。邱锡鹏：《神经网络与深度学习》https://nndl.github.io/
 1242019 年 4 月 6 日第5 章 卷积神经网络X1偏置.bp滤波器 Wp,1.输入∑.输出.f+p.Y特征映射特征映射.XD滤波器 Wp,D图 5.7 卷积层中从输入特征映射组X 到输出特征映射Y p 的计算示例5.2.3 汇聚层汇聚层（Pooling Layer）也叫子采样层（Subsampling Layer），其作用是进行特征选择，降低特征数量，并从而减少参数数量。卷积层虽然可以显著减少网络中连接的数量，但特征映射组中的神经元个数并没有显著减少。如果后面接一个分类器，分类器的输入维数依然很高，很容易出现过拟合。为了解决这个问题，可以在卷积层之后加上一个汇聚层，从而降低特征维数，避免过拟合。减少特征维数也可以通过增加卷积步长来实现。假设汇聚层的输入特征映射组为X ∈ RM ×N ×D ，对于其中每一个特征映射Xd，将其划分为很多区域 Rmd,n , 1 ≤ m ≤ M ′, 1 ≤ n ≤ N ′，这些区域可以重叠，也可以不重叠。汇聚(Pooling) 是指对每个区域进行下采样（Down Sampling）得到一个值，作为这个区域的概括。常用的汇聚函数有两种：1. 最大汇聚（Maximum Pooling）：一般是取一个区域内所有神经元的最大值。d= max x ,iY(5.22)m,ni∈Rdm ,n其中x 为区域Rd 内每个神经元的激活值。ik2. 平均汇聚（MeanPooling）：一般是取区域内所有神经元的平均值。Σ1Y d=x i.(5.23)m,nd|R|m,ni∈Rdm ,n邱锡鹏：《神经网络与深度学习》https://nndl.github.io/
 5.2 卷积神经网络2019 年 4 月 6 日125对每一个输入特征映射Xd 的 M ′×N ′ 个区域进行子采样，得到汇聚层的输出特征映射Y d = {Ymd,n }, 1 ≤ m ≤ M ′, 1 ≤ n ≤ N ′。图5.8给出了采样最大汇聚进行子采样操作的示例。可以看出，汇聚层不但可以有效地减少神经元的数量，还可以使得网络对一些小的局部形态改变保持不变性，并拥有更大的感受野。邱锡鹏：《神经网络与深度学习》https://nndl.github.io/
 2019 年 4 月 6 日第5 章 卷积神经网络邱锡鹏：《神经网络与深度学习》https://nndl.github.io/
 5.2 卷积神经网络2019 年 4 月 6 日127输出特征映射组 Y输入特征映射组 X10001100211102311023max pooling输出特征映射 Yd输入特征映射 Xd图 5.8 汇聚层中最大汇聚过程示例目前主流的卷积网络中，汇聚层仅包含下采样操作。但在早期的一些卷积网络（比如LeNet-5）中，有时也会在汇聚层使用非线性激活函数，比如Y ′d = f wd · Y d + bd,(5.24)其中Y ′d 为汇聚层的输出，f (·) 为非线性激活函数，wd 和bd 为可学习的标量权重和偏置。典型的汇聚层是将每个特征映射划分为2 × 2 大小的不重叠区域，然后使用最大汇聚的方式进行下采样。汇聚层也可以看做是一个特殊的卷积层，卷积核大小为m × m，步长为s × s，卷积核为max 函数或mean 函数。过大的采样区域会急剧减少神经元的数量，会造成过多的信息损失。5.2.4 典型的卷积网络结构一个典型的卷积网络是由卷积层、汇聚层、全连接层交叉堆叠而成。目前常用的卷积网络结构图5.9所示。一个卷积块为连续M 个卷积层和b 个汇聚层（M 通常设置为2 ∼ 5，b 为 0 或 1）。一个卷积网络中可以堆叠N 个连续的卷积块，然后在接着K 个全连接层（N 的取值区间比较大，比如1 ∼ 100 或者更大；K 一般为0 ∼ 2）。邱锡鹏：《神经网络与深度学习》https://nndl.github.io/
 1282019 年 4 月 6 日第5 章 卷积神经网络卷积ReLU汇聚层输入全连接层softmax×M×b×K×N图 5.9 典型的卷积网络结构目前，整个网络结构趋向于使用更小的卷积核（比如1 × 1 和 3 × 3）以及更深的结构（比如层数大于50）。此外，由于卷积的操作性越来越灵活（比如不同的步长），汇聚层的作用变得也越来越小，因此目前比较流行的卷积网络中， 汇聚层的比例也逐渐降低，趋向于全卷积网络。5.3 参数学习在卷积网络中，参数为卷积核中权重以及偏置。和全连接前馈网络类似，卷 积网络也可以通过误差反向传播算法来进行参数学习。在全连接前馈神经网络中，梯度主要通过每一层的误差项δ 进行反向传播，并进一步计算每层参数的梯度。参见公式(4.60)。在卷积神经网络中，主要有两种不同功能的神经层：卷积层和汇聚层。而参数为卷积核以及偏置，因此只需要计算卷积层中参数的梯度。这里假设汇聚层中没有参数。参见公式(5.20)。不失一般性，对第 l 层为卷积层，第 l − 1 层的输入特征映射为 X(l−1) ∈RM ×N ×D，通过卷积计算得到第l 层的特征映射净输入Z(l) ∈ RM层的第p(1 ≤ p ≤ P ) 个特征映射净输入′×N ′×P。 第 lΣDZ(l,p) =W (l,p,d)⊗X(l−1,d) + b(l,p),(5.25)d=1其中W (l,p,d) 和 b(l,p) 为卷积核以及偏置。第 层中共有P × D 个卷积核和P个l偏置，可以分别使用链式法则来计算其梯度。参见公式(5.14)。根据公式(5.14)和(5.25)，损失函数关于第l 层的卷积核W (l,p,d) 的偏导数为∂L(Y, Yˆ )∂W (l,p,d)L Y Yˆ∂ ( ,)∂Z(l,p)= δ(l,p) ⊗ X(l−1,d),=⊗X (l−1,d)(5.26)(5.27)l,p) = ∂L(Y ,Yˆ )为损失函数关于第 层的第p个特征映射净输入Z (l,p)的偏l其中δ(∂Z(l,p)导数。邱锡鹏：《神经网络与深度学习》https://nndl.github.io/
 5.3 参数学习2019 年 4 月 6 日125同理可得，损失函数关于第l 层的第p个偏置b(l,p) 的偏导数为ˆ∂L(Y, Y )=Σ [δ(l,p)i,j]i,j .(5.28)∂b(l,p)卷积网络中，每层参数的梯度依赖其所在层的误差项δ(l,p)。5.3.1 误差项的计算卷积层和汇聚层中，误差项的计算有所不同，因此我们分别计算其误差项。汇聚层 当第l +1层为汇聚层时，因为汇聚层是下采样操作，l +1层的每个神经元的误差项δ 对应于第l 层的相应特征映射的一个区域。l 层的第p 个特征映射中的每个神经元都有一条边和 l + 1 层的第 p 个特征映射中的一个神经元相连。根据链式法则，第l 层的一个特征映射的误差项δ(l,p)，只需要将l + 1 层对应特征映射的误差项δ(l+1,p) 进行上采样操作（和第 层的大小一样），再和 层特征映ll射的激活值偏导数逐元素相乘，就得到了δ(l,p)。第l 层的第p 个特征映射的误差项δ(l,p) 的具体推导过程如下：∂L(Y, Yˆ )∂Z(l,p)∂X(l,p)δ(l,p),∂L(Y, Yˆ )∂Z(l+1,p)=邱锡鹏：《神经网络与深度学习》https://nndl.github.io/
 1302019 年 4 月 6 日第5 章 卷积神经网络(5.29)··(5.30)(5.31)∂Z(l,p)∂X(l,p)∂Z(l+1,p)= f ′(Z(l,p)) ⊙ up(δ(l+1,p)),l其中f (·)为第 层使用的激活函数导数，up为上采样函数（upsampling），与 汇′ll卷积并非真正的矩阵乘积，因此这里计算的偏导数并非真正的矩阵偏导数，我们可以把X, Z 都看作向量。聚层中使用的下采样操作刚好相反。如果下采样是最大汇聚（max pooling），误差项 δ(l+1,p) 中每个值会直接传递到上一层对应区域中的最大值所对应的神经元，该区域中其它神经元的误差项的都设为0。如果下采样是平均汇聚（mean pooling），误差项δ(l+1,p) 中每个值会被平均分配到上一层对应区域中的所有神经元上。卷积层 当l + 1 层为卷积层时，假设特征映射净输入Z(l+1) ∈ RM ′×N ′×P ，其中第 p(1 ≤ p ≤ P ) 个特征映射净输入参见公式(5.20)。ΣDZ(l+1,p) =W (l+1,p,d)X(l,d) + b(l+1,p),(5.32)⊗d=1其中W (l+1,p,d) 和b(l+1,p)个卷积核和P 个偏置。为第l+1 层的卷积核以及偏置。第l+1 层中共有P × D邱锡鹏：《神经网络与深度学习》https://nndl.github.io/
 

 1262019 年 4 月 6 日第5 章 卷积神经网络第l 层的第d 个特征映射的误差项δ(l,d) 的具体推导过程如下：∂L(Y, Yˆ )δ(l,d),===(5.33)(5.34)∂Z(l,d)∂X(l,d)L Y Yˆ∂ ( ,∂X(l,d))·!∂Z(l,d)Σ∂L(Y, Yˆ )Pf ′ Z(l)根据公式(5.18)())rot180(W (l+1,p,d) )⊗˜⊙(5.35)(5.36)l∂Z(l+1 ,p)Σp=1rot180()˜(Pf ′ Z(l)W (l+1,p,d) ⊗δ(l+1,p),⊙lp=1˜其中⊗为宽卷积。参见习题5-6。5.4 几种典型的卷积神经网络本节介绍几种广泛使用的典型深层卷积神经网络。5.4.1 LeNet-5LeNet-5[LeCun et al., 1998] 虽然提出的时间比较早，但是是一个非常成功的神经网络模型。基于LeNet-5 的手写数字识别系统在90 年代被美国很多银行使用，用来识别支票上面的手写数字。LeNet-5 的网络结构如图5.10所示。C1: 卷积层输入图像6@28 × 2832 × 32C3: 卷积层16@10 × 10C5：卷积层输出层F6：全连接层S2: 汇聚层6@14 × 14S4: 汇聚层16@5 × 5图 5.10 LeNet-5 网络结构（图片根据[LeCun et al., 1998] 绘制）不计输入层，LeNet-5 共有7 层，每一层的结构为：1. 输入层：输入图像大小为32 × 32 = 1024。2. C1 层是卷积层，使用6 个 5 × 5 的滤波器，得到6 组大小为28 × 28 = 784的特征映射。因此，C1 层的神经元数量为6 × 784 = 4, 704，可训练参数数量为6 × 25 + 6 = 156，连接数为156 × 784 = 122, 304（包括偏置在内，下同）。邱锡鹏：《神经网络与深度学习》https://nndl.github.io/
 5.4 几种典型的卷积神经网络2019 年 4 月 6 日1273. S2层为汇聚层，采样窗口为2× 2，使用平均汇聚，并使用一个如公式(5.24)的非线性函数。神经元个数为6 × 14 × 14 = 1, 176，可训练参数数量为6 × (1 + 1) = 12，连接数为6 × 196 × (4 + 1) = 5, 880。4. C3 层为卷积层。LeNet-5 中用一个连接表来定义输入和输出特征映射之间的依赖关系，如图5.11所示，共使用60个5 × 5的滤波器，得到16组大小为10 × 10的特征映射。神经元数量为16 × 100 = 1, 600，可训练参数数量为(60 × 25) + 16 = 1, 516，连接数为100 × 1, 516 = 151, 600。连接表参见公式 (5.37)。如果不使用连接表，则需要96 个 5 × 5 的滤波器。5. S4 层是一个汇聚层，采样窗口为2 × 2，得到16 个5 × 5 大小的特征映射，可训练参数数量为16 × 2 = 32，连接数为16 × 25 × (4 + 1) = 2000。6. C5 层是一个卷积层，使用120 × 16 = 1, 920 个 5 × 5 的滤波器，得到120组大小为1 × 1 的特征映射。C5 层的神经元数量为120，可训练参数数量为1, 920 × 25 + 120 = 48, 120，连接数为120 × (16 × 25 + 1) = 48, 120。7. F6 层是一个全连接层，有84 个神经元，可训练参数数量为84×(120+1) =10, 164。连接数和可训练参数个数相同，为10, 164。8. 输出层：输出层由10 个欧氏径向基函数（Radial Basis Function，RBF）函数组成。这里不再详述。连接表 从公式(5.20) 可以看出，卷积层的每一个输出特征映射都依赖于所有输入特征映射，相当于卷积层的输入和输出特征映射之间是全连接的关系。实际上，这种全连接关系不是必须的。我们可以让每一个输出特征映射都依赖于少数几个输入特征映射。定义一个连接表（Link Table）T 来描述输入和输出特征映射之间的连接关系。如果第p 个输出特征映射依赖于第d 个输入特征映射，则Tp,d = 1，否则为0。ΣY p = fW p,d ⊗X d + bp ,(5.37)d,Tp,d=1其中T 为P × D 大小的连接表。假设连接表T 的非零个数为K，每个滤波器的大小为m × n，那么共需要K × m × n + P 参数。在LeNet-5 中，连接表的基本设定如图5.11所示。C3 层的第0-5 个特征映射依赖于S2 层的特征映射组的每3 个连续子集，第6-11 个特征映射依赖于S2 层的特征映射组的每4 个连续子集，第12-14 个特征映射依赖于S2 层的特征映射的每4 个不连续子集，第15 个特征映射依赖于S2 层的所有特征映射。邱锡鹏：《神经网络与深度学习》https://nndl.github.io/
 1282019 年 4 月 6 日第5 章 卷积神经网络图 5.11 LeNet-5 中 C3 层的连接表（图片来源于[LeCun et al., 1998]）5.4.2 AlexNetAlexNet[Krizhevsky et al., 2012] 是第一个现代深度卷积网络模型，其首次使用了很多现代深度卷积网络的一些技术方法，比如使用GPU 进行并行训练， 采用了ReLU 作为非线性激活函数，使用Dropout 防止过拟合，使用数据增强 来提高模型准确率等。AlexNet 赢得了2012 年 ImageNet 图像分类竞赛的冠军。AlexNet的结构如图5.12所示，包括5 个卷积层、3 个全连接层和1 个softmax层。因为网络规模超出了当时的单个GPU 的内存限制，AlexNet 将网络拆为两半，分别放在两个GPU 上，GPU 间只在某些层（比如第3 层）进行通讯。图 5.12 AlexNet 网络结构（图片来源于[Krizhevsky et al., 2012]）AlexNet 的具体结构如下：这里的卷积核使用四维张量来描述。1. 输入层，224 × 224 × 3 的图像；2. 第一个卷积层，使用两个11 × 11 × 3 × 48 的卷积核，步长s = 4，零填充p = 3，得到两个55 × 55 × 48 的特征映射组。3. 第一个汇聚层，使用大小为3 × 3的最大汇聚操作，步长s = 2，得到两个27 × 27 × 48 的特征映射组。4. 第二个卷积层，使用两个 5 × 5 × 48 × 128 的卷积核，步长s = 1，零填充p = 1，得到两个27 × 27 × 128 的特征映射组。邱锡鹏：《神经网络与深度学习》https://nndl.github.io/
 5.4 几种典型的卷积神经网络2019 年 4 月 6 日1295. 第二个汇聚层，使用大小为3 × 3的最大汇聚操作，步长s = 2，得到两个13 × 13 × 128 的特征映射组。6. 第三个卷积层为两个路径的融合，使用一个 3 × 3 × 256 × 384 的卷积核，步长s = 1，零填充p = 1，得到两个13 × 13 × 192 的特征映射组。7. 第四个卷积层，使用两个 3 × 3 × 192 × 192 的卷积核，步长s = 1，零填充p = 1，得到两个13 × 13 × 192 的特征映射组。8. 第五个卷积层，使用两个 3 × 3 × 192 × 128 的卷积核，步长s = 1，零填充p = 1，得到两个13 × 13 × 128 的特征映射组。9. 汇聚层，使用大小为3× 3的最大汇聚操作，步长s = 2，得到两个6× 6× 128的特征映射组。10. 三个全连接层，神经元数量分别为4096，4096 和 1000。5.4.3 Inception 网络在卷积网络中，如何设置卷积层的卷积核大小是一个十分关键的问题。在Inception网络中，一个卷积层包含多个不同大小的卷积操作，称为Inception模块。Inception 网络是由有多个 inception 模块和少量的汇聚层堆叠而成。Inception 模块受到Inception 模块同时使用1 × 1、3 × 3、5 × 5 等不同大小的卷积核，并将得 “Network in network”[Linet al., 2013] 的启发。到的特征映射在深度上拼接（堆叠）起来作为输出特征映射。图5.13给出了 v1 版本的Inception 模块，采用了 4 组平行的特征抽取方式，分别为1 × 1、3 × 3、5 × 5 的卷积和3 × 3 的最大汇聚。同时，为了提高计算效率，减少参数数量，Inception模块在进行3 × 3、5 × 5 的卷积之前、3 × 3 的最大汇聚之后，进行一次1 × 1的卷积来减少特征映射的深度。如果输入特征映射之间存在冗余信息，1 × 1 的卷积相当于先进行一次特征抽取。Inception模块中的卷积和最大汇聚都是等宽的。堆叠3 × 3 卷积1 × 1 卷积5 × 5 卷积1 × 1 卷积1 × 1 卷积1 × 1 卷积 3 × 3 最大汇聚x图 5.13 Inception v1 的模块结构邱锡鹏：《神经网络与深度学习》https://nndl.github.io/


 softmax2SoftmaxActivationFCAveragePool7x7+1(V)DepthConcatConvConvConvConv1x1+1(S)3x3+1(S)5x5+1(S)1x1+1(S)Conv1x1+1(S)Conv1x1+1(S)MaxPool3x3+1(S)DepthConcatConv1x1+1(S)Conv3x3+1(S)Conv5x5+1(S)Conv1x1+1(S)softmax1Conv1x1+1(S)Conv1x1+1(S)MaxPool3x3+1(S)SoftmaxActivationMaxPool3x3+2(S)FCFCDepthConcatConv1x1+1(S)Conv3x3+1(S)Conv5x5+1(S)Conv1x1+1(S)Conv1x1+1(S)Conv1x1+1(S)Conv1x1+1(S)MaxPool3x3+1(S)AveragePool5x5+3(V)DepthConcatConvConvConvConv1x1+1(S)3x3+1(S)5x5+1(S)1x1+1(S)Conv1x1+1(S)Conv1x1+1(S)MaxPool3x3+1(S)DepthConcatsoftmax0Conv1x1+1(S)Conv3x3+1(S)Conv5x5+1(S)Conv1x1+1(S)SoftmaxActivationConv1x1+1(S)Conv1x1+1(S)MaxPool3x3+1(S)FCFCDepthConcatConv1x1+1(S)Conv3x3+1(S)Conv5x5+1(S)Conv1x1+1(S)Conv1x1+1(S)Conv1x1+1(S)Conv1x1+1(S)MaxPool3x3+1(S)AveragePool5x5+3(V)DepthConcatConvConvConvConv1x1+1(S)3x3+1(S)5x5+1(S)1x1+1(S)Conv1x1+1(S)Conv1x1+1(S)MaxPool3x3+1(S)MaxPool3x3+2(S)DepthConcatConvConvConvConv1x1+1(S)3x3+1(S)5x5+1(S)1x1+1(S)Conv1x1+1(S)Conv1x1+1(S)MaxPool3x3+1(S)DepthConcatConvConvConvConv1x1+1(S)3x3+1(S)5x5+1(S)1x1+1(S)Conv1x1+1(S)Conv1x1+1(S)MaxPool3x3+1(S)MaxPool3x3+2(S)LocalRespNormConv3x3+1(S)Conv1x1+1(V)LocalRespNormMaxPool3x3+2(S)Conv7x7+2(S)input


 5.5 其它卷积方式2019 年 4 月 6 日131图5.15给出了一个典型的残差单元示例。残差单元由多个级联的（等长）卷积层和一个跨层的直连边组成，再经过ReLU 激活后得到输出。残差网络就是将很多个残差单元串联起来构成的一个非常深的网络。ReLU+等宽卷积f(x, θ)ReLU等宽卷积x图 5.15 一个简单的残差单元结构和残差网络类似的还有highway network[Srivastava et al., 2015]。5.5 其它卷积方式在第5.1.2节中介绍了一些卷积的变种，可以通过步长和零填充来进行不同的卷积操作。本节介绍一些其它的卷积方式。5.5.1 转置卷积我们一般可以通过卷积操作来实现高维特征到低维特征的转换。比如在一维卷积中，一个5 维的输入特征，经过一个大小为3 的卷积核，其输出为3 维特征。如果设置步长大于1，可以进一步降低输出特征的维数。但在一些任务中， 我们需要将低维特征映射到高维特征，并且依然希望通过卷积操作来实现。假设有一个高维向量为x ∈ Rd 和一个低维向量为z ∈ Rp，p < d。如果用仿射变换来实现高维到低维的映射，不失一般性，这里忽略了平z = W x,(5.39) 移项。其中W ∈ Rp×d 为转换矩阵。我们可以很容易地通过转置W 来实现低维到高维的反向映射，即x = WTz.(5.40)邱锡鹏：《神经网络与深度学习》https://nndl.github.io/
 1322019 年 4 月 6 日第5 章 卷积神经网络需要说明的是，公式(5.39) 和(5.40) 并不是逆运算，两个映射只是形式上的转置关系。在全连接网络中，忽略激活函数，前向计算和反向传播就是一种转置关系。比如前向计算时，第l + 1 层的净输入为z(l+1) = W (l+1)z(l)，反向传播时，第l层的误差项为δ(l) = (W (l+1)) δ(l+1)。T参见公式(4.60)。卷积操作也可以写为仿射变换的形式。假设一个5维向量x，经过大小为3的卷积核w = [w , w , w ]T 进行卷积，得到3维向量z。卷积操作可以写为123z = w ⊗ x(5.41)w1 w2 w3000=· x(5.420w1 w2 w300w1 w2 w3= Cx,(5.43)其中C 是一个稀疏矩阵，其非零元素来自于卷积核w 中的元素。如果要实现 3 维向量 z 到 5 维向量 x 的映射，可以通过仿射矩阵的转置来实现。参见习题5-4。x = CTz(5.44)(5.45)(5.46)w100ww30w021=ww1 · zw3 w2200w3= rot180(w)⊕˜z,其中rot180(·) 表示旋转180 度。从公式(5.42) 和 (5.45) 可以看出，从仿射变换的角度来看两个卷积操作z =w ⊗x 和 x = rot180(w)⊕z也是形式上的转置关系。因此，我们将低维特征映射到高维特征的卷积操作称为转置卷积（Transposed Convolution）[Dumoulinand Visin, 2016]，也称为反卷积（Deconvolution）[Zeiler et al., 2011]。˜反卷积（Deconvolution）的名字并不是适合，它不是指卷积的逆运算。和卷积网络中，卷积层的前向计算和反向传播也是一种转置关系。参见习题5-6。对一个p 维的向量z，和大小为m 的卷积核，如果希望通过卷积操作来映射到高维向量，只需要对向量z进行两端补零p = m − 1，然后进行卷积，可以得即宽卷积。邱锡鹏：《神经网络与深度学习》https://nndl.github.io/
 5.5 其它卷积方式2019 年 4 月 6 日133到 p + m − 1 维的向量。转置卷积同样适用于二维卷积。图5.16给出了一个步长 s = 1，无零填充p = 0 的两维卷积和其对应的转置卷积。转置卷积的动图见https://nndl.github.io/v/cnn-conv-more(a) 卷积，s = 1, p = 0(b) 转置卷积，s = 1, p = 2图 5.16 步长s = 1，无零填充p = 0 的两维卷积和其对应的转置卷积https://nndl.github.io/v/cnn-conv-more微步卷积 我们可以通过增加卷积操作的步长s > 1 来实现对输入特征的降采样操作，大幅降低特征维数。同样，我们也可以通过减少转置卷积的步长s < 1来实现上采样操作，大幅提高特征维数。步长s < 1的转置卷积也称为微步卷积（Fractionally-Strided Convolution）[Long et al., 2015]。为了实现微步卷积，我们可以在输入特征之间插入0 来间接地使得步长变小。如果卷积操作的步长为s > 1，希望其对应的转置卷积的步长为 1s，需要在输入特征之间插入s − 1 个0 来使得其移动的速度变慢。以一维转置卷积为例，对一个p 维的向量z，和大小为m 的卷积核，通过对向量z 进行两端补零p = m − 1，并且在每两个向量元素之间插入s − 1 个0，然后进行步长为1 的卷积，可以得到s × (p − 1) + m 维的向量。图5.16给出了一个步长s = 2，无零填充p = 0 的两维卷积和其对应的转置卷积。邱锡鹏：《神经网络与深度学习》https://nndl.github.io/
 1342019 年 4 月 6 日第5 章 卷积神经网络(a) 卷积，s = 2, p = 0(b) 转置卷积，s = 1, p = 2图 5.17 步长s = 2，无零填充p = 0 的两维卷积和其对应的转置卷积5.5.2 空洞卷积对于一个卷积层，如果希望增加输出单元的感受野，一般可以通过三种方 式实现：（1）增加卷积核的大小；（2）增加层数；（3）在卷积之前进行汇聚操作。前两种操作会增加参数数量，而第三种会丢失一些信息。空洞卷积（Atrous Convolution），或称为膨胀卷积（Dilated Convolution），是一种不增加参数数量，同时增加输出单元感受野的一种方法[Chen et al.,2018, Yu and Koltun, 2015]。Atrous 一 词 来 源 于 法 语 àtrous，意为“空洞，多孔”。空洞卷积通过给卷积核插入“空洞”来变相地增加其大小。如果在卷积核的每两个元素之间插入d − 1 个空洞，卷积核的有效大小为m′ = m + (m − 1) × (d − 1),(5.47)其中d 称为膨胀率（Dilation Rate）。当d = 1 时卷积核为普通的卷积核。图5.18给出了空洞卷积的示例。邱锡鹏：《神经网络与深度学习》https://nndl.github.io/
 5.6 总结和深入阅读2019 年 4 月 6 日135空洞卷积的动图(a) 膨胀率 d = 1(b) 膨胀率 d = 2见https://nndl.github.io/v/cnn-conv-more图 5.18 空洞卷积5.6 总结和深入阅读卷积神经网络是受生物学上感受野的机制而提出。David Hubel 和 TorstenWiesel 在 1959 年发现，在猫的初级视觉皮层中存在两种细胞：简单细胞和复杂细胞，这两种细胞承担不同层次的视觉感知功能 [Hubel and Wiesel, 1959,1962]。简单细胞的感受野是狭长型的，每个简单细胞只对感受野中特定角度（orientation）的光带敏感，而复杂细胞对于感受野中以特定方向（direction）移动的某种角度（orientation）的光带敏感。受此启发，1980年，福岛邦彦（KunihikoDavidHubel 和 TorstenWiesel 在此方面的贡献，与1981年获得诺贝尔生理学或医学奖。Fukushima）提出了一种带卷积和子采样操作的多层神经网络：新知机（Neocognitron）[Fukushima, 1980]。但当时还没有反向传播算法，新知机采用了无监督学习的方式来训练。Yann LeCun 在1989 年将反向传播算法引入了卷积神经网络[LeCunet al., 1989]，并在手写体数字识别上取得了很大的成功[LeCun et al., 1998]。AlexNet[Krizhevsky et al., 2012] 是第一个现代深度卷积网络模型，可以说是深度学习技术在图像分类上真正突破的开端。AlexNet不用预训练和逐层训练，首次使用了很多现代深度网络的一些技术方法，比如使用GPU进行并行训练，采用了ReLU 作为非线性激活函数，使用dropout 防止过拟合，使用数据增 强来提高模型准确率等。这些技术极大地推动了端到端的深度学习模型的发展。在 AlexNet 之后，出现了很多优秀的卷积网络，比如VGG 网络[Simonyanand Zisserman, 2014]，Inception v1, v2,v4网络[Szegedy et al., 2015, 2016, 2017]，残差网络[He et al., 2016]等。目前，卷积神经网络已经成为计算机视觉领域的主流模型。通过引入跨层的直连边，可以训练上百层乃至上千层的卷积网络。随着网络层数的增加，卷积层越来越多地使用1 × 1 和 3 × 3 大小的小卷积核，也出现了一些不规则的卷积操作，比如空洞卷积[Chen et al., 2018, Yu and Koltun, 2015]、可变形卷积邱锡鹏：《神经网络与深度学习》https://nndl.github.io/
 1362019 年 4 月 6 日参考文献[Dai et al., 2017] 等。网络结构也逐渐趋向于全卷积网络（Fully ConvolutionalNetwork，FCN）[Long et al., 2015]，减少汇聚层和全连接层的作用。Dumoulin and Visin [2016] 给出了各种卷积操作的可视化示例。习题习题 5-1证明宽卷积具有交换性，即公式(5.10)。习题 5-2 分析卷积神经网络中用1 × 1 的滤波器的作用。习题 5-3 对于一个输入为100 × 100 × 256 的特征映射组，使用3 × 3 的卷积核，输出为100 × 100 × 256 的特征映射组的卷积层，求其时间和空间复杂度。如果引入一个1 × 1卷积核先得到100 × 100 × 64的特征映射，再进行3 × 3的卷积，得到100 × 100 × 256 的特征映射组，求其时间和空间复杂度。习题 5-4 对于一个两维卷积，输入为3 × 3，卷积核大小为2 × 2，试将卷积操作重写为仿射变换的形式。参见公式(5.42)。习题 5-5 在最大汇聚层中，计算函数y = max(x , · · · , x ) 的梯度。函数1dy = arg max(x , · · · , x ) 的梯度呢？1d习题 5-6忽略激活函数，分析卷积网络中卷积层的前向计算和反向传播（公式(5.36)）是一种转置关系。习题5-7 在空洞卷积中，当卷积核大小为m，膨胀率为d 时，如何设置零填充p 的值以使得卷积为等宽卷积。参考文献Liang-Chieh Chen, George Papandreou, Ia-sonas Kokkinos, Kevin Murphy, and Alan LYuille. Deeplab: Semantic image segmen-tation with deep convolutional nets, atrousconvolution, and fully connected CRFs.IEEE transactions on pattern analysis andmachine intelligence, 40(4):834–848, 2018.Jifeng Dai, Haozhi Qi, Yuwen Xiong, Yi Li,Guodong Zhang, Han Hu, and Yichen Wei.Deformable convolutional networks. CoRR,abs/1703.06211, 1(2):3, 2017.Vincent Dumoulin and Francesco Visin. Aguide to convolution arithmetic for deeplearning. ArXiv e-prints, mar 2016.邱锡鹏：《神经网络与深度学习》https://nndl.github.io/
 参考文献2019 年 4 月 6 日137Kunihiko Fukushima. Neocognitron: A self-organizing neural network model for amechanism of pattern recognition unaf-fected by shift in position. Biological cyber-netics, 36(4):193–202, 1980.works for semantic segmentation. In Pro-ceedings of the IEEE conference on com-puter vision and pattern recognition, pages3431–3440, 2015.Karen Simonyan and Andrew Zisserman.Very deep convolutional networks for large-scale image recognition. arXiv preprintarXiv:1409.1556, 2014.Kaiming He, Xiangyu Zhang, ShaoqingRen, and Jian Sun. Deep residual learningfor image recognition. In Proceedings of theIEEE conference on computer vision andpattern recognition, pages 770–778, 2016.David H Hubel and Torsten N Wiesel. Re-ceptive ﬁelds of single neurones in the cat’sstriate cortex. The Journal of physiology,148(3):574–591, 1959.Rupesh Kumar Srivastava, Klaus Greﬀ, andJürgen Schmidhuber. Highway networks.arXiv preprint arXiv:1505.00387, 2015.Christian Szegedy, Wei Liu, Yangqing Jia,Pierre Sermanet, Scott Reed, DragomirAnguelov, Dumitru Erhan, Vincent Van-houcke, and Andrew Rabinovich. Goingdeeper with convolutions. In Proceedings ofthe IEEE Conference on Computer Visionand Pattern Recognition, pages 1–9, 2015.Christian Szegedy, Vincent Vanhoucke,Sergey Ioﬀe, Jon Shlens, and ZbigniewDavid H Hubel and Torsten N Wiesel.Receptive ﬁelds, binocular interaction andfunctional architecture in the cat’s visualcortex. The Journal of physiology, 160(1):106–154, 1962.Alex Krizhevsky, Ilya Sutskever, and Ge-oﬀrey E Hinton. Imagenet classiﬁcationwith deep convolutional neural networks. InAdvances in neural information processingsystems, pages 1097–1105, 2012.Wo-jna.Rethinking the inceptionarchitec-ture for computer vision. InProceedings ofthe IEEE Conference onComputer Visionand Pattern Recognition,pages 2818–2826,2016.Yann LeCun, Bernhard Boser, JohnDenker, Donnie Henderson, RichardSEChristian Szegedy, Sergey Ioﬀe, Vin-cent Vanhoucke, and Alexander A Alemi.Inception-v4, inception-resnet and the im-pact of residual connections on learning. InAAAI, pages 4278–4284, 2017.Howard, Wayne Hubbard, and Lawrence DJackel. Backpropagation applied to hand-written zip code recognition. Neural com-putation, 1(4):541–551, 1989.Yann LeCun, Léon Bottou, Yoshua Ben-gio, and Patrick Haﬀner. Gradient-basedlearning applied to document recognition.Proceedings of the IEEE, 86(11):2278–2324,1998.Fisher Yu and Vladlen Koltun. Multi-scale context aggregation by dilated convo-lutions. arXiv preprint arXiv:1511.07122,2015.Matthew D Zeiler, Graham W Taylor, andRob Fergus. Adaptive deconvolutional net-works for mid and high level feature learn-ing. In Proceedings of the IEEE Inter-national Conference on Computer Vision,pages 2018–2025. IEEE, 2011.Min Lin, Qiang Chen, and ShuichengYan. Network in network. arXiv preprintarXiv:1312.4400, 2013.Jonathan Long, Evan Shelhamer, andTrevor Darrell. Fully convolutional net-邱锡鹏：《神经网络与深度学习》https://nndl.github.io/
 

 第6 章 循环神经网络经验是智慧之父，记忆是智慧之母。— 谚语在前馈神经网络中，信息的传递是单向的，这种限制虽然使得网络变得更容易学习，但在一定程度上也减弱了神经网络模型的能力。在生物神经网络中，神经元之间的连接关系要复杂的多。前馈神经网络可以看着是一个复杂的函数，每次输入都是独立的，即网络的输出只依赖于当前的输入。但是在很多现实任务中，网络的输入不仅和当前时刻的输入相关，也和其过去一段时间的输出相关。比如一个有限状态自动机，其下一个时刻的状态（输出）不仅仅和当前输入相关，也和当前状态（上一个时刻的输出）相关。此外，前馈网络难以处理时序数据，比如视频、语音、文本等。时序数据的长度一般是不固定的，而前馈神经网络要求输入和输出的维数都是固定的，不能任意改变。因此，当处理这一类和时序相关的问题时，就需要一种能力更强的模型。循环神经网络（Recurrent Neural Network，RNN）是一类具有短期记忆能力的神经网络。在循环神经网络中，神经元不但可以接受其它神经元的信息，也 可以接受自身的信息，形成具有环路的网络结构。和前馈神经网络相比，循环神 经网络更加符合生物神经网络的结构。循环神经网络已经被广泛应用在语音识 别、语言模型以及自然语言生成等任务上。循环神经网络的参数学习可以通过 随时间反向传播算法[Werbos, 1990] 来学习。随时间反向传播算法即按照时间的逆序将错误信息一步步地往前传递。当输入序列比较长时，会存在梯度爆炸 和消失问题 [Bengio et al., 1994, Hochreiter and Schmidhuber, 1997, Hochreiter et al.,2001]，也称为长期依赖问题。为了解决这个问题，人们对循环神经网络进行了很多的改进，其中最有效的改进方式引入门控机制。此外，循环神经网络可以很容易地扩展到两种更广义的记忆网络模型：递归神经网络和图网络。
 1402019 年 4 月 6 日第6 章 循环神经网络6.1 给网络增加记忆能力为了处理这些时序数据并利用其历史信息，我们需要让网络具有短期记忆能力。而前馈网络是一个静态网络，不具备这种记忆能力。一般来讲，我们可以通过以下三种方法来给网络增加短期记忆能力。此外，还有一种增加记忆能力的方法是引入外部记忆单6.1.1 延时神经网络元，参见第8.3节。一种简单的利用历史信息的方法是建立一个额外的延时单元，用来存储网络的历史信息（可以包括输入、输出、隐状态等）。比较有代表性的模型是延时神经网络（Time Delay Neural Network，TDNN）[Lang et al., 1990, Waibelet al., 1989]。延时神经网络在时间维度上共享权值，以降低参数数量。因此对于序列输入来讲，延时神经网络就相当于卷积神经网络。延时神经网络是在前馈网络中的非输出层都添加一个延时器，记录最近几次神经元的输出。在第t 个时刻，第l + 1 层神经元和第l 层神经元的最近p 次输出相关，即(l+1)= f(ht h h(l), (l) , · · · , (l)t−1 t−p+1h).(6.1)t通过延时器，前馈网络就具有了短期记忆的能力。6.1.2 有外部输入的非线性自回归模型自回归模型（Autoregressive Model，AR）是统计学上常用的一类时间序列模型，用一个变量yt 的历史信息来预测自己。Σpy = w +wpyt−i + ϵt,(6.2)t0i= 1其中p 为超参数，w 为参数，ϵ ∼ N(0, σ2) 为第t 个时刻的噪声，方差σ2 和时pt间无关。有外部输入的非线性自回归模型（Nonlinear Autoregressive with Exoge-nous Inputs Model，NARX）[Leontaritis and Billings, 1985] 是自回归模型的扩展，在每个时刻t 都有一个外部输入x ，产生一个输出y 。NARX 通过一个tt延时器记录最近几次的外部输入和输出，第t 个时刻的输出yt 为y = f (x , xt−1, · · · , xt−p, yt−1, yt−2, · · · , yt−q),(6.3)tt其中f(·)表示非线性函数，可以是一个前馈网络，p 和q 为超参数。邱锡鹏：《神经网络与深度学习》https://nndl.github.io/
 6.2 简单循环网络2019 年 4 月 6 日1416.1.3 循环神经网络循环神经网络通过使用带自反馈的神经元，能够处理任意长度的时序数据。RNN 也 经 常 被 翻 译 为 递归神经网络。这里为了区别与另外一种递归神经网络 （ Recursive Neural Net-work），我们称为循环神经网络。给定一个输入序列x1:T = (x , x , . . . , x , . . . , x )，循环神经网络通过下面12tT公式更新带反馈边的隐藏层的活性值ht：ht = f (ht−1, xt),(6.4)其中h0 = 0，f(·) 为一个非线性函数，也可以是一个前馈网络。图6.1给出了循环神经网络的示例。输出层htht隐藏层延迟器xt输入层ht−1图 6.1 循环神经网络从数学上讲，公式(6.4) 可以看成一个动力系统。动力系统（Dynamical Sys-tem）是一个数学上的概念，指系统状态按照一定的规律随时间变化的系统。具体地讲，动力系统是使用一个函数来描述一个给定空间（如某个物理系统的状态空间）中所有点随时间的变化情况。因此，隐藏层的活性值ht 在很多文献上也称为状态（state）或隐状态（hidden states）。理论上，循环神经网络可以近似任意的非线性动力系统（参见第6.2.1节）。生活中很多现象都可以动力系统来描述，比如钟摆晃动、台球轨迹等。6.2 简单循环网络简单循环网络（Simple Recurrent Network，SRN）[Elman, 1990] 是一个非常简单的循环神经网络，只有一个隐藏层的神经网络。在一个两层的前馈神经网络中，连接存在相邻的层与层之间，隐藏层的节点之间是无连接的。而简单循环网络增加了从隐藏层到隐层的反馈连接。假设在时刻t 时，网络的输入为xt，隐藏层状态（即隐藏层神经元活性值）为h 不仅和当前时刻的输入x 相关，也和上一个时刻的隐藏层状态h 相关。ttt−1zt = U ht−1 + W xt + b,h = f (z ),(6.5)(6.6)tt邱锡鹏：《神经网络与深度学习》https://nndl.github.io/
 1422019 年 4 月 6 日第6 章 循环神经网络其中zt 为隐藏层的净输入，f(·)是非线性激活函数，通常为logistic函数或tanh函数，U 为状态-状态权重矩阵，W 为状态-输入权重矩阵,b 为偏置。公式(6.5)和 (6.6) 也经常直接写为ht = f(Uht−1 + W xt + b).(6.7)如果我们把每个时刻的状态都看作是前馈神经网络的一层的话，循环神经网络可以看作是在时间维度上权值共享的神经网络。图6.2给出了按时间展开的循环神经网络。y1h1x1y2h2x2y3h3x3y4h4x4· · ·· · ·· · ·yThTxT图 6.2 按时间展开的循环神经网络6.2.1 循环神经网络的计算能力由于循环神经网络具有短期记忆能力，相当于存储装置，因此其计算能力十分强大。前馈神经网络可以模拟任何连续函数，而循环神经网络可以模拟任何程序。我们先定义一个完全连接的循环神经网络，其输入为x ，输出为y ，ttht = f (U ht−1 + W xt + b),y = V h ,(6.8)(6.9)tt其中h 为隐状态，f(·) 为非线性激活函数，U、W 、b 和V 为网络参数。6.2.1.1 通用近似定理一个完全连接的循环网络是任何非线性动力系统的近似器。定理 6.1 – 通用近似定理 [Haykin, 2009]： 如果一个完全连接的循环神经网络有足够数量的sigmoid 型隐藏神经元，它可以以任意的准确率去近似任何一个非线性动力系统st = g(st−1, xt),y = o(s ),(6.10)(6.11)tt其中s 为每个时刻的隐状态，x 是外部输入，g(·) 是可测的状态tt邱锡鹏：《神经网络与深度学习》https://nndl.github.io/
 6.2 简单循环网络2019 年 4 月 6 日143转换函数，o(·)是连续输出函数，，并且对状态空间的紧致性没有限制。证明.（1）根据通用近似定理，两层的前馈神经网络可以近似任意有界闭集上的任通 用 近 似 定 理 参 见意连续函数。因此，动力系统的两个函数可以用两层的全连接前馈网络近似。第4.3.1节。首先，非线性动力系统的状态转换函数st = g(st−1, xt) 可以由一个两层的神经网络st = Cf(Ast−1 + Bx + b ) 来近似，可以分解为t1s′t = f(Ast−1 + Bxt + b)= f (AC st−1 + Bxt + b),s = Cs ,(6.12)(6.13)(6.14)tt其中A, B, C 为权重矩阵，b 为偏置向量。本 证 明 参 考 文 献 [Schäferand Zimmermann, 2006]。同理，非线性动力系统的输出函数y = o(s ) = o(g(st−1, xt)) 也可以用一tt个两层的前馈神经网络近似。y′ = f (A′st−1 + B′xt= f (A′Cs′−1 + B′xt + b′),+b′)(6.15)(6.16)(6.17)yt = Dy′ ,其中A′, B′, D 为权重矩阵，b′ 为偏置向量。（2）公式(6.13) 和 (6.16) 可以合并为bAC0s′−1 Bs tf +.(6.18)=+xA CBtt−1y′ 0′t′y′b′邱锡鹏：《神经网络与深度学习》https://nndl.github.io/
 1442019 年 4 月 6 日第6 章 循环神经网络公式(6.17)可以改写为s t yt =D.(6.19)0yt令 h = [s ; y ]，则非线性动力系统可以由下面的全连接循环神经网络来′′t近似。ht = f (U ht−1 + W xt + b),y = V h ,(6.20)(6.21)t tACBb其中U =0，W =，b =，V =。0A C0BbD′ ′′邱锡鹏：《神经网络与深度学习》https://nndl.github.io/
 6.2 简单循环网络2019 年 4 月 6 日1456.2.1.2 图灵完备图灵完备（Turing Completeness）是指一种数据操作规则，比如一种计算机编程语言，可以实现图灵机（Turing Machine）的所有功能，解决所有的可计算问题。目前主流的编程语言（比如C++，Java，Python 等）都是图灵完备的。图灵机是一种抽象的信息处理装置，可以用来解决任所有的可计算机问题。参见第8.3.3.2节。定理 6.2 – 图灵完备 [Siegelmann and Sontag, 1991]： 所有的图灵机都可以被一个由使用sigmoid 型激活函数的神经元构成的全连接循环网络来进行模拟。因此，一个完全连接的循环神经网络可以近似解决所有的可计算问题。6.3 应用到机器学习循环神经网络可以应用到很多不同类型的机器学习任务。根据这些任务的特点可以分为以下几种模式：序列到类别模式、同步的序列到序列模式、异步的序列到序列模式。下面我们分别来看下这几种应用模式。6.3.1 序列到类别模式序列到类别模式主要用于序列数据的分类问题：输入为序列，输出为类别。比如在文本分类中，输入数据为单词的序列，输出为该文本的类别。假设一个样本x1:T = (x , · · · , x ) 为一个长度为T 的序列，输出为一个类1T别 y ∈ {1, · · · , C}。我们可以将样本 x 按不同时刻输入到循环神经网络中，并得到不同时刻的隐藏状态h , · · · , h 。我们可以将h 看作整个序列的最终表示1TT（或特征），并输入给分类器g(·) 进行分类（如图6.3a所示）。yˆ = g(hT ),(6.22)其中g(·) 可以是简单的线性分类器（比如Logistic 回归）或复杂的分类器（比如多层前馈神经网络）。邱锡鹏：《神经网络与深度学习》https://nndl.github.io/
 1462019 年 4 月 6 日第6 章 循环神经网络yˆh1x1h2x2· · ·· · ·hTxTx1(a) 正常模式邱锡鹏：《神经网络与深度学习》https://nndl.github.io/
 6.2 简单循环网络2019 年 4 月 6 日147hTxThh2x2yˆh1· · ·· · ·(b) 按时间进行平均采样模式图 6.3 序列到类别模式邱锡鹏：《神经网络与深度学习》https://nndl.github.io/
 148 6.3 应用到机器学习2019 年2 041 9月年6 4日月 6 日第6 章 循环神经网络145除了将最后时刻的状态作为序列表示之外，我们还可以对整个序列的所有状态进行平均，并用这个平均状态来作为整个序列的表示（如图6.3b所示）。Σ1Tyˆ = g(ht).(6.23)Tt=16.3.2 同步的序列到序列模式同步的序列到序列模式主要用于序列标注（Sequence Labeling）任务，即每一时刻都有输入和输出，输入序列和输出序列的长度相同。比如词性标注（Part-of-Speech Tagging）中，每一个单词都需要标注其对应的词性标签。参见第??节。在同步的序列到序列模式（如图6.4所示）中，输入为一个长度为T 的序列x1:T = (x , · · · , x )，输出为序列y = (y , · · · , y )。样本x 按不同时刻输入1T1:T1T到循环神经网络中，并得到不同时刻的隐状态h , · · · , h 。每个时刻的隐状态ht1T代表了当前时刻和历史的信息，并输入给分类器g(·)得到当前时刻的标签yˆt。yˆ = g(h ), ∀t ∈ [1, T ].(6.24)tt邱锡鹏：《神经网络与深度学习》https://nndl.github.io/
 · · ·yˆ1yˆ2yˆTh1h2hT· · ·邱锡鹏：《神经网络与深度学习》https://nndl.github.io/
 1502019 年 4 月 6 日第6 章 循环神经网络x1x2· · ·xT图 6.4 同步的序列到序列模式6.3.3 异步的序列到序列模式异步的序列到序列模式也称为编码器-解码器（Encoder-Decoder）模型，即输入序列和输出序列不需要有严格的对应关系，也不需要保持相同的长度。比如在机器翻译中，输入为源语言的单词序列，输出为目标语言的单词序列。参见第??节。在异步的序列到序列模式中（如图6.5所示），输入为一个长度为T 的序列x1:T = (x , · · · , x )，输出为长度为M 的序列y= (y , · · · , y )。经常通过1 M1T1:M先编码后解码的方式来实现。先将样本x 按不同时刻输入到一个循环神经网络（编码器）中，并得到其编码hT 。然后在使用另一个循环神经网络（解码器）中，得到输出序列yˆ1:M 。为了建立输出序列之间的依赖关系，在解码器中通常使用非线性的自回归模型。自回归模型参见第6.1.2节。h = f (ht−1, xt),∀t ∈ [1, T ](6.25)t1邱锡鹏：《神经网络与深度学习》https://nndl.github.io/
 

 1462019 年 4 月 6 日第6 章 循环神经网络hT +t = f2(hT +t−1, yˆt−1),∀t ∈ [1, M ](6.26)(6.27)yˆt = g(hT +t),∀t ∈ [1, M ].其中f (·), f (·) 分别为用作编码器和解码器的循环神经网络，g(·) 为分类器，yˆt12为预测输出yˆt 的向量表示。yˆ1yˆ2· · ·· · ·yˆMh1h2x2· · ·· · ·hTxThT +1hT +2hT +Mx1< EO S >图 6.5 异步的序列到序列模式6.4 参数学习循环神经网络的参数可以通过梯度下降方法来进行学习。不失一般性，这里我们以同步的序列到序列模式为例来介绍循环神经网络的参数学习。以随机梯度下降为例，给定一个训练样本(x, y)，其中x1:T = (x1, · · · , xT )为长度是T 的输入序列，y1:T = (y , · · · , y ) 是长度为T 的标签序列。即在每个1T时刻t，都有一个监督信息yt，我们定义时刻t 的损失函数为L = L(y , g(h )),(6.28)ttt其中g(ht) 为第t 时刻的输出，L 为可微分的损失函数，比如交叉熵。那么整个序列上损失函数为TLLt.=(6.29)(6.30)t=1整个序列的损失函数L 关于参数U 的梯度为ΣT∂L∂U∂Lt∂U=,t=1即每个时刻损失Lt 对参数U 的偏导数之和。循环神经网络中存在一个递归调用的函数f (·)，因此其计算参数梯度的方式和前馈神经网络不太相同。在循环神经网络中主要有两种计算梯度的方式：随 时间反向传播（BPTT）和实时循环学习（RTRL）算法。邱锡鹏：《神经网络与深度学习》https://nndl.github.io/
 6.4 参数学习2019 年 4 月 6 日1476.4.1 随时间反向传播算法随时间反向传播（Backpropagation Through Time，BPTT）算法的主要思想是通过类似前馈神经网络的错误反向传播算法[Werbos, 1990] 来进行计算梯度。BPTT 算法将循环神经网络看作是一个展开的多层前馈网络，其中“每一层”对应循环网络中的“每个时刻”（图6.2）。这样，循环神经网络就可以按按照前馈网络中的反向传播算法进行计算参数梯度。在“展开”的前馈网络中， 所有层的参数是共享的，因此参数的真实梯度是将所有“展开层”的参数梯度之和。计算偏导数 ∂Lt先来计算公式(6.30)中第t 时刻损失对参数U 的偏导数∂Lt 。∂U∂U因为参数 U 和隐藏层在每个时刻 k(1 ≤ k ≤ t) 的净输入 zk = U hk−1W x + b 有关，因此第t 时刻损失的损失函数L 关于参数U 的梯度为：+ktijΣt∂t L∂Uij∂L ∂+ztTk= tr()(6.31)(6.32)链式法则参见公式(B.10)。∂zk ∂Uijtk=1T∂LΣt ,∂zk∂+zk=∂Uijk=1其中 ∂+z表示“直接”偏导数，即公式 zk = U hk−1 + W xk+ b 中保持hk−1k不∂Uij变，对Uij 进行求偏导数，得到0.∂+zk] ),(6.33)=[h, I ([h]ik−1 jk−1 j∂Uij.0其中[hk−1]j 为第k − 1 时刻隐状态的第j 维；Ii(x) 除了第i 行值为x 外，其余都为 0 的向量。定义δt,k数，则=∂Lt∂zk为第 时刻的损失对第 时刻隐藏神经层的净输入 的导tkzk∂Lt∂zδt,k==(6.34)(6.35)k∂h  ∂zk+1∂Ltk邱锡鹏：《神经网络与深度学习》https://nndl.github.io/
 1482019 年 4 月 6 日第6 章 循环神经网络∂zk ∂hk ∂zk+1= diag(f ′(zk))U δt,k+1T.(6.36)邱锡鹏：《神经网络与深度学习》https://nndl.github.io/
 

 1482019 年 4 月 6 日第6 章 循环神经网络邱锡鹏：《神经网络与深度学习》https://nndl.github.io/
 Lt−2Lt−1Ltδδt,t− 1δt,tt,t− 2δδt− 1 ,t− 1t− 1 ,t− 2δt− 2 ,t− 2ht−2邱锡鹏：《神经网络与深度学习》https://nndl.github.io/
 ht−1xt−1h1502019 年 4 月 6 日第6 章 循t 环神经网络xt−2xt图 6.6 随时间反向传播算法示例将公式(6.36) 和 (6.33) 代入公式(6.32) 得到Σt∂Lt∂Uij=[δ ] .t,k i k−1 j] [h(6.37)(6.38)k=1将上式写成矩阵形式为t∂Lt =δt,k hT.k−1∂Uk=1图6.6给出了误差项随时间进行反向传播算法的示例。参数梯度 将公式(6.38) 代入到将公式(6.30) 得到整个序列的损失函数L 关于参数U 的梯度ΣTΣt∂L∂U=δt,k hT.(6.39)k−1t=1 k=1同理可得，L关于权重W 和偏置b 的梯度为ΣTΣt∂L∂W=δt,kxT,(6.40)(6.41)kt=1 k=1ΣTΣt∂L∂b=δt,k.t=1 k=1计算复杂度 在BPTT 算法中，参数的梯度需要在一个完整的“前向”计算和“反向”计算后才能得到并进行参数更新。6.4.2 实时循环学习算法与反向传播的BPTT算法不同的是，实时循环学习（Real-Time RecurrentLearning，RTRL）是通过前向传播的方式来计算梯度 [Williams and Zipser,1995]。邱锡鹏：《神经网络与深度学习》https://nndl.github.io/
 6.5 长期依赖问题2019 年 4 月 6 日149假设循环网络网络中第t + 1 时刻的状态ht+1为梯度前向传播可以参考自动微分中的前向模式，参见ht+1 = f(zt+1 ) = f(Uht + W xt+1 + b),(6.42)(6.43)第4.5.3节。其关于参数Uij 的偏导数为∂ht∂h∂h∂+zt+1∂Uijt+1t+1t+1=+∂zU∂Uij∂Uij∂ht∂Uij= diag(f′(z)) I ([h ] ) + Ut j(6.44)(6.45)t+1i∂ht∂Uij= f ′(z) ⊙ I ([h ] ) + Ut+1t j,i其中Ii(x) 除了第i 行值为x 外，其余都为0 的向量。RTRL算法从第1个时刻开始，除了计算循环神经网络的隐状态之外，还利用公式(6.45)依次前向计算偏导数∂∂Uh1 , ∂h2 , ∂h3 , · · · 。∂U∂Uijijij这样，假设第t 个时刻存在一个监督信息，其损失函数为Lt，就可以同时计算损失函数对Uij 的偏导数∂Lt =∂Uij∂ht∂UijT∂Lt∂ht(6.46).这样在第t 时刻，可以实时地计算损失Lt 关于参数U 的梯度，并更新参数。参数 W 和 b 的梯度也可以同样按上述方法实时计算。两种算法比较 RTRL算法和BPTT算法都是基于梯度下降的算法，分别通过前向模式和反向模式应用链式法则来计算梯度。在循环神经网络中，一般网络输出维度远低于输入维度，因此BPTT 算法的计算量会更小，但是BPTT 算法需要保存所有时刻的中间梯度，空间复杂度较高。RTRL算法不需要梯度回传，因此非常适合用于需要在线学习或无限序列的任务中。6.5 长期依赖问题循环神经网络在学习过程中的主要问题是长期依赖问题。在BPTT 算法中，将公式(6.36)展开得到tY−1δt,k=diag(f′(zi))U δ .(6.47)(6.48)Tt,ti=k如果定义γ = ∥ diag(f′(z ))UT ∥，则iδt,k = γt−k δt,t.邱锡鹏：《神经网络与深度学习》https://nndl.github.io/
 1502019 年 4 月 6 日第6 章 循环神经网络若γ > 1，当t− k → ∞ 时，γt−k → ∞，会造成系统不稳定，称为梯度爆炸问 题（Gradient Exploding Problem）；相反，若γ < 1，当t− k → ∞ 时，γt−k → 0，会出现和深度前馈神经网络类似的梯度消失问题（gradient vanishing problem）。要注意的是，在循环神经网络中的梯度消失不是说 ∂ L的梯度消失了，t∂U而是 ∂Lt 的梯度消失了（当t − k 比较大时）。也就是说，参数U 的更新∂hk主要靠当前时刻k 的几个相邻状态h 来更新，长距离的状态对U 没有k影响。由于循环神经网络经常使用非线性激活函数为logistic 函数或tanh 函数作为非线性激活函数，其导数值都小于1；并且权重矩阵∥U ∥ 也不会太大，因此如果时间间隔t − k 过大，δt,k 会趋向于0，因此经常会出现梯度消失问题。虽然简单循环网络理论上可以建立长时间间隔的状态之间的依赖关系，但是由于梯度爆炸或消失问题，实际上只能学习到短期的依赖关系。这样，如果t 时刻的输出yt 依赖于t−k 时刻的输入xt−k ，当间隔k 比较大时，简单神经网络很难建模这种长距离的依赖关系，称为长期依赖问题（Long-Term DependenciesProblem）。6.5.1 改进方案为了避免梯度爆炸或消失问题，一种最直接的方式就是选取合适的参数，同 时使用非饱和的激活函数，尽量使得diag(f ′(zi))U ≈ 1，这种方式需要足够的人T工调参经验，限制了模型的广泛应用。比较有效的方式是通过改进模型或优 化方法来缓解循环网络的梯度爆炸和梯度消失问题。梯度爆炸 一般而言，循环网络的梯度爆炸问题比较容易解决，一般通过权重衰减或梯度截断来避免。梯度截断是一种启发式的解决梯度爆炸问题的有效方法，参见第7.2.3.4节。权重衰减是通过给参数增加 ℓ1 或 ℓ2 范数的正则化项来限制参数的取值范围，从而使得γ ≤ 1。梯度截断是另一种有效的启发式方法，当梯度的模大于一定阈值时，就将它截断成为一个较小的数。梯度消失 梯度消失是循环网络的主要问题。除了使用一些优化技巧外，更有效的方式就是改变模型，比如让U = I，同时使用f′(zi) = 1，即ht = ht−1 + g(xt; θ),(6.49)其中g(·) 是一个非线性函数，θ 为参数。邱锡鹏：《神经网络与深度学习》https://nndl.github.io/
 6.6 基于门控的循环神经网络2019 年 4 月 6 日151公式(6.49) 中，ht 和 ht−1 之间为线性依赖关系，且权重系数为1，这样就不存在梯度爆炸或消失问题。但是，这种改变也丢失了神经元在反馈边上的非线性激活的性质，因此也降低了模型的表示能力。为了避免这个缺点，我们可以采用一个更加有效的改进策略：ht = ht−1 + g(xt, ht−1; θ),(6.50)这样ht 和ht−1 之间为既有线性关系，也有非线性关系，在一定程度上可以缓解梯度消失问题。但这种改进依然有一个问题就是记忆容量（memory capacity）。随着ht 不断累积存储新的输入信息，会发生饱和现象。假设g(·) 为logistic 函数，则随着时间t 的增长，ht 会变得越来越大，从而导致h 变得饱和。也就是说， 隐状态ht 可以存储的信息是有限的，随着记忆单元存储的内容越来越多，其丢失的信息也越来越多。为了解决容量问题，可以有两种方法。一种是增加一些额外的存储单元：外 部记忆；另一种是进行选择性的遗忘，同时也进行有选择的更新。增加外部记 忆的方法将在第8章中介绍，本章主要介绍后一种方法。6.6 基于门控的循环神经网络为了解决上节中提到的记忆容量问题，一种非常好的解决方案是引入门控Hochreiter and Schmidhuber [1997] 来控制信息的累积速度，包括有选择地加入新的信息，并有选择地遗忘之前累积的信息。这一类网络可以称为基于门控 的循环神经网络（Gated RNN）。本节中，主要介绍两种基于门控的循环神经网络：长短期记忆（LSTM）网络和门控循环单元（GRU）网络。6.6.1 长短期记忆网络长短期记忆（Long Short-Term Memory，LSTM）网络[Gers et al., 2000,Hochreiter and Schmidhuber, 1997] 是循环神经网络的一个变体，可以有效地解决简单循环神经网络的梯度爆炸或消失问题。在公式(6.50) 的基础上，LSTM 网络主要改进在以下两个方面：新的内部状态 LSTM 网络引入一个新的内部状态（internal state）ct 专门进行线性的循环信息传递，同时（非线性）输出信息给隐藏层的外部状态ht。c = f ⊙ c+ i ⊙˜ ,(6.51)ttt−1tth = o ⊙ tanh(c ),(6.52)ttt邱锡鹏：《神经网络与深度学习》https://nndl.github.io/
 1522019 年 4 月 6 日第6 章 循环神经网络其中ft，it 和 ot 为三个门（gate）来控制信息传递的路径；⊙ 为向量元素乘积；ct−1 为上一时刻的记忆单元；˜t 是通过非线性函数得到候选状态，˜ = tanh(W x + U h + bc).c t−1(6.53)tct在每个时刻t，LSTM 网络的内部状态ct 记录了到当前时刻为止的历史信息。公 式 (6.53)∼(6.56) 中 的W , U , b 为可学习的网络∗∗∗参数，其中 ∗ ∈ {i, f, o, c}。门机制 LSTM 网络引入门机制（gating mechanism）来控制信息传递的路径。公式(6.51) 和(6.51) 中三个“门”分别为输入门i , 遗忘门f 和输出门o ，ttt在数字电路中，门（gate）为一个二值变量{0, 1}，0 代表关闭状态，不许任何信息通过；1代表开放状态，允许所有信息通过。LSTM网络中的“门”是一种“软”门，取值在(0, 1)之间，表示以一定的比例运行信息通过。LSTM网络中三个门的作用为• 遗忘门ft 控制上一个时刻的内部状态ct−1 需要遗忘多少信息。• 输入门i 控制当前时刻的候选状态˜ 有多少信息需要保存。tt• 输出门o 控制当前时刻的内部状态c 有多少信息需要输出给外部状态h 。ttt当f = 0, i = 1 时，记忆单元将历史信息清空，并将候选状态向量˜ 写入。ttt但此时记忆单元c 依然和上一时刻的历史信息相关。当f = 1, i = 0 时，记忆ttt单元将复制上一时刻的内容，不写入新的信息。三个门的计算方式为：i = σ(Wix + Uih + bi),t−1(6.54)ttf = σ(W x + U h + bf ),(6.55)(6.56)tftft−1o = σ(W x + U h + bo),totot−1其中σ(·) 为 logistic 函数，其输出区间为(0, 1)，xt 为当前时刻的输入，ht−1为上一时刻的外部状态。图6.7给出了LSTM 网络的循环单元结构，其计算过程为：（1）首先利用上一时刻的外部状态ht−1 和当前时刻的输入xt，计算出三个门，以及候选状态˜ ；（2）结合遗忘门f 和输入门i 来更新记忆单元c ；（3）结合输出门o ，将ttttt内部状态的信息传递给外部状态ht。邱锡鹏：《神经网络与深度学习》https://nndl.github.io/
 6.6 基于门控的循环神经网络2019 年 4 月 6 日153邱锡鹏：《神经网络与深度学习》https://nndl.github.io/
 1542019 年 4 月 6 日第6 章 循环神经网络ct−1+ct××˜ttanhtanhftitot×σσσht−1htxt×+向量和向量拼接向量元素乘邱锡鹏：《神经网络与深度学习》https://nndl.github.io/
 6.6 基于门控的循环神经网络2019 年 4 月 6 日155图 6.7 LSTM 循环单元结构通过LSTM 循环单元，整个网络可以建立较长距离的时序依赖关系。公式(6.51)∼(6.56)可以简洁地描述为tanh˜tot  =  σW+ b ,(6.57)xtiσσtft邱锡鹏：《神经网络与深度学习》https://nndl.github.io/
 1562019 年 4 月 6 日第6 章 循环神经网络ht−1邱锡鹏：《神经网络与深度学习》https://nndl.github.io/
 6.6 基于门控的循环神经网络2019 年 4 月 6 日157c = f ⊙ c+ i ⊙˜ ,(6.58)ttt−1tth = o ⊙ tanh (c ) ,(6.59)ttt其中x ∈ R 为当前时刻的输入，eW ∈ R4d×(d+e)和 b ∈ R4d 为网络参数。t记忆循环神经网络中的隐状态h 存 储 了 历 史 信 息 ，可以看作是一种记忆（memory）。在简单循环网络中，隐状态每个时刻都会被重写，因此可以看作是一种短期记忆（short-term memory）。在神经网络中，长期记忆（long-term memory）可以看作是网络参数，隐含了从训练数据中学到的经验，并更新周期要远远慢于短期记忆。而在LSTM 网络中，记忆单元c 可以在某个时刻捕捉到某个关键信息，并有能力将此关键信息保存一定的时间间隔。记忆单元c中保存信息的生命周期要长于短期记忆h，但又远远短于长期记忆，因此称为长的短期记忆（long short-term memory）。邱锡鹏：《神经网络与深度学习》https://nndl.github.io/
 1582019 年 4 月 6 日第6 章 循环神经网络一般在深度网络参数学习时，参数初始化的值一般都比较小。但是在训练 LSTM网络时，过小的值会使得遗忘门的值比较小。这意味着前一时刻的信息大部分都丢失了，这样网络很难捕捉到长距离的依赖信息。 并且相邻时间间隔的梯度会非常小，这会导致梯度弥散问题。因此遗忘的参数初始值一般都设得比较大，其偏置向量bf 设为1 或2.6.6.2 LSTM 网络的各种变体目前主流的LSTM 网络用的三个门来动态地控制内部状态的应该遗忘多少历史信息，输入多少新信息，以及输出多少信息。我们可以对门机制进行改进并获得LSTM 网络的不同变体。无遗忘门的LSTM 网络 Hochreiter and Schmidhuber [1997] 最早提出的LSTM网络是没有遗忘门的，其内部状态的更新为ct = ct−1 + i ⊙˜ .(6.60)tt如之前的分析，记忆单元c 会不断增大。当输入序列的长度非常大时，记忆单元的容量会饱和，从而大大降低LSTM 模型的性能。peephole 连接 另外一种变体是三个门不但依赖于输入 xt 和上一时刻的隐状态ht−1，也依赖于上一个时刻的记忆单元ct−1。i = σ(Wix + Uih + Vict−1 + bi),(6.61)(6.62)(6.63)ttt−1f = σ(W x + U h + Vf ct−1 + bf ),tftft−1o = σ(W x + U h + V c + b ),totot−1oto其中V ，V 和V 为对角阵形式的参数。ifo耦合输入门和遗忘门 LSTM 网络中的输入门和遗忘门有些互补关系，因此同时用两个门比较冗余。为了减少LSTM 网络的计算复杂度，将这两门合并为一个门。令f = 1 − i .(6.64)tt这样，内部状态的更新方式为c = (1 − i ) ⊙ c+ i ⊙˜ .t t(6.65)ttt−16.6.3 门控循环单元网络门控循环单元（Gated Recurrent Unit，GRU）网络 [Cho et al., 2014, Chunget al., 2014] 是一种比LSTM 网络更加简单的循环神经网络。邱锡鹏：《神经网络与深度学习》https://nndl.github.io/
 6.6 基于门控的循环神经网络2019 年 4 月 6 日159GRU 网络也是在公式(6.50) 的基础上，引入门机制来控制信息更新的方式。在LSTM网络中，输入门和遗忘门是互补关系，用两个门比较冗余。GRU将输入门与和遗忘门合并成一个门：更新门。同时，GRU 也不引入额外的记忆单元， 直接在当前状态ht 和历史状态ht−1 之间引入线性依赖关系。˜在GRU网络中，当前时刻的候选状态h 为t˜计算候选状态 ht 时，使用tanh 激活函数是由于其导数有比较大的值域，缓解梯度消失问题。˜Uhh = tanh(W x + (rt ⊙ h ) + bh ),(6.66)tt−1ht˜其中r ∈ [0, 1]为重置门（reset gate），用来控制候选状态h 的计算是否依赖tt上一时刻的状态ht−1。公式 (6.66)∼(6.69) 中的W , U , b 为可学习的网络∗∗∗r = σ(W x + U h+ b ),(6.67)参数，其中∗ ∈ {b, r, ꢀ}。tr trt−1r˜当 r = 0时，候选状态h = tanh(W x + b) 只和当前输入x 相关，和历史状ttctt˜态无关。当r = 1 时，候选状态h = tanh(W x + U h + bh) 和当前输入xth t−1ttht和历史状态ht−1 相关，和简单循环网络一致。GRU 网络的隐状态ht 更新方式为+ (1 − z ) ⊙h ,˜(6.68)h = z ⊙ httt−1tt¯其中z ∈ [0, 1] 为更新门（update gate），用来控制当前状态需要从历史状态中保留多少信息（不经过非线性变换），以及需要从候选状态中接受多少新信息。z = σ(W x + U h + bꢀ).(6.69)tꢀtꢀt−1当 z = 0 时，当前状态h 和历史状态h 之间为非线性函数。若同时有ttt−1z = 0, r = 1时，GRU网络退化为简单循环网络；若同时有z = 0, r = 0时，当tt前状态h 只和当前输入x 相关，和历史状态h 无关。当zt = 1 时，当前状ttt−1态ht = ht−1) 等于上一时刻状态h ，和当前输入x 无关。t−1图6.8给出了GRU 循环单元结构。邱锡鹏：《神经网络与深度学习》thttps://nndl.github.io/
 1602019 年 4 月 6 日第6 章 循环神经网络邱锡鹏：《神经网络与深度学习》https://nndl.github.io/
 6.6 基于门控的循环神经网络2019 年 4 月 6 日161ht−1×+ht1−××˜htztrttanhσσxt× 向量元素乘+向量和向量拼接邱锡鹏：《神经网络与深度学习》https://nndl.github.io/
 1622019 年 4 月 6 日图 6.8 GRU 循环单元结构第6 章 循环神经网络6.7 深层循环神经网络如果将深度定义为网络中信息传递路径长度的话，循环神经网络可以看作 是既“深”又“浅”的网络。一方面来说，如果我们把循环网络按时间展开，长时间间隔的状态之间的路径很长，循环网络可以看作是一个非常深的网络了。从 另一方面来说，如果同一时刻网络输入到输出之间的路径x → y ，这个网络是非tt常浅的。因此，我们可以增加循环神经网络的深度从而增强循环神经网络的能力。增 加循环神经网络的深度主要是增加同一时刻网络输入到输出之间的路径 x → y ，tt比如增加隐状态到输出h → y ，以及输入到隐状态x → h 之间的路径的深度tttt。6.7.1 堆叠循环神经网络一种常见的做法是将多个循环网络堆叠起来，称为堆叠循环神经网络（StackedRecurrent Neural Network，SRNN）。一个堆叠的简单循环网络（stacked SRN）也称为循环网络循环多层感知器（Recurrent Multi-Layer Perceptron，RMLP）Parlos et al. [1991]。图6.9给出了按时间展开的堆叠循环神经网络。第l 层网络的输入是第l − 1层网络的输出。我们定义ht(l) 为在时刻t 时第l 层的隐状态+ W (l)h(l−1) + b(l)),(6.70)(l)hf U (l) (l)h= (tt−1t其中U (l)，W (l) 和 b(l) 为权重矩阵和偏置向量，h(0) = xt。t邱锡鹏：《神经网络与深度学习》https://nndl.github.io/
 6.7 深层循环神经网络2019 年 4 月 6 日157y1y2y3y4· · ·· · ·· · ·· · ·· · ·yT(3)(3)2(3)(3)4(3)Thhhhhhh13(2)1(2)2(2)3(2)4(2)hhhhhhhhT(1)1(1)2(1)3(1)4(1)Tx1x2x3x4xT图 6.9 按时间展开的堆叠循环神经网络6.7.2 双向循环神经网络在有些任务中，一个时刻的输出不但和过去时刻的信息有关，也和后续时刻的信息有关。比如给定一个句子，其中一个词的词性由它的上下文决定，即包含左右两边的信息。因此，在这些任务中，我们可以增加一个按照时间的逆序来传递信息的网络层，来增强网络的能力。双向循环神经网络（bidirectional recurrent neural network，Bi-RNN）由两层循环神经网络组成，它们的输入相同，只是信息传递的方向不同。假设第1 层按时间顺序，第2 层按时间逆序，在时刻t 时的隐状态定义为ht(1)和ht(2)，则(1)t(1)xt + b(1)),(6.71)h= (f U (1) (1) + Wht−1+ W (2)xt + b(2)),(6.72)(2)= ( hf U (2) (2)htt+1h = h(1) ⊕ h(2),(6.73)ttt其中⊕ 为向量拼接操作。图6.10给出了按时间展开的双向循环神经网络。y1y2y3y4· · ·· · ·· · ·· · ·· · ·yT(2)1(2)2(2)3(2)4(2)Thhhhh(1)1(1)2(1)3(1)4(1)Thhhhhx1x2x3x4xT图 6.10 按时间展开的双向循环神经网络邱锡鹏：《神经网络与深度学习》https://nndl.github.io/
 1582019 年 4 月 6 日第6 章 循环神经网络6.8 扩展到图结构如果将循环神经网络按时间展开，每个时刻的隐状态ht 看做一个节点，那么这些节点构成一个链式结构，每个节点t 都收到其父节点的消息（message），更新自己的状态，并传递给其子节点。而链式结构是一种特殊的图结构，我们可以比较容易地将这种消息传递（message passing）的思想扩展到任意的图结构上。6.8.1 递归神经网络递归神经网络（Recursive Neural Network，RecNN）是循环神经网络在有向无循环图上的扩展 [Pollack, 1990]。递归神经网络的一般结构为树状的层次结构，如图6.11a所示。yyh3h3h2x3h1h2h1x2x1x2x3x4x1(b) 退化结构0(a) 一般结构图 6.11 递归神经网络以图6.11a中的结构为例，有三个隐藏层h 、h 和h ，其中h 由两个输入1231x 和 x 计算得到，h 由另外两个输入层x 和 x 计算得到，h 由两个隐藏层122343h 和 h 计算得到。12对于一个节点hi，它可以接受来自父节点集合πi 中所有节点的消息，并更新自己的状态。hi = f (hπi ),(6.74)其中h 表示集合π 中所有节点状态的拼接，f (·) 是一个和节点位置无关的非πii线性函数，可以为一个单层的前馈神经网络。比如图6.11a所示的递归神经网络具体可以写为x1h1 = σ(W+ b),(6.75)x2邱锡鹏：《神经网络与深度学习》https://nndl.github.io/
 6.8 扩展到图结构2019 年 4 月 6 日+ b),159x3h = σ(W (6.76)(6.77)2x4h1h = σ(W + b),3h2其中σ(·) 表示非线性激活函数，W 和 b 是可学习的参数。同样，输出层y 可以为一个分类器，比如h1y = g(W ′+ b′),(6.78)h2其中g(·) 为分类器，W ′ 和 b′ 为分类器的参数。当递归神经网络的结构退化为线性序列结构（图6.11b）时，递归神经网络就等价于简单循环网络。参见习题6-5。递归神经网络主要用来建模自然语言句子的语义[Socher et al., 2011, 2013]。给定一个句子的语法结构（一般为树状结构），可以使用递归神经网络来按照句法的组合关系来合成一个句子的语义。句子中每个短语成分可以在分成一些子成分，即每个短语的语义都可以由它的子成分语义组合而来，并进而合成整句的语义。同样，我们也可以用门机制来改进递归神经网络中的长距离依赖问题，比如树结构的长短期记忆模型（Tree-Structured LSTM）[Tai et al., 2015, Zhuet al., 2015] 就是将LSTM 模型的思想应用到树结构的网络中，来实现更灵活的组合函数。6.8.2 图网络在实际应用中，很多数据是图结构的，比如知识图谱、社交网络、分子网络等。而前馈网络和反馈网络很难处理图结构的数据。图网络（Graph Network，GN）是将消息传递的思想扩展到图结构数据上的神经网络。对于一个任意的图结构G(V, ꢀ)，其中V 表示节点集合，ꢀ 表示边集合。每条边表示两个节点之间的依赖关系。节点之间的连接可以是有向的，也可以是 无向的。图中每个节点v 都用一组神经元来表示其状态h(v)，初始状态可以为节点v 的输入特征 x(v)。每个节点可以收到来自相邻节点的消息，并更新自己的状态。Σf h v , h u , e(u,v) ,(6.79)mt (v)=( )( )t−1 t−1u∈N (v)邱锡鹏：《神经网络与深度学习》https://nndl.github.io/
 1602019 年 4 月 6 日第6 章 循环神经网络h(v) = g h(v) , m(v) ,(6.80)tt−1t其中N (v) 表示节点v 的邻居，m(v) 表示在第t 时刻节点v 收到的信息，e(u,v) 为t边 e(u,v) 上的特征。公式(6.79) 和 (6.80) 是一种同步的更新方式，所有的结构同时接受信息并更新自己的状态。而对于有向图来说，使用异步的更新方式会更有效率，比如循环神经网络或递归神经网络。在整个图更新T 次后，可以通过一个读出函数（readout function）g(·) 来得到整个网络的表示。y = g {h(v)|v ∈ V} .(6.81)tT6.9 总结和深入阅读循环神经网络可以建模时间序列数据之间的相关性。和 延时神经网络[Langet al., 1990, Waibel et al., 1989] 以及有外部输入的非线性自回归模型[Leontari-tis and Billings, 1985] 相比，循环神经网络可以更方便地建模长时间间隔的相关性。常用的循环神经网络的参数学习算法是BPTT 算法[Werbos, 1990]，其计算时间和空间要求会随时间线性增长。为了提高效率，当输入序列的长度比较大时，可以使用带截断（truncated）的 BPTT 算法[Williams and Peng, 1990]，只计算固定时间间隔内的梯度回传。一个完全连接的循环神经网络有着强大的计算和表示能力，可以近似任何非线性动力系统以及图灵机，解决所有的可计算问题。然而由于梯度爆炸和梯度消失问题，简单循环网络存在长期依赖问题[Bengio et al., 1994, Hochreiteret al., 2001]。为了解决这个问题，人们对循环神经网络进行了很多的改进，其中最有效的改进方式为引入门控机制，比如LSTM 网络 [Gers et al., 2000, Hochre- iterand Schmidhuber, 1997] 和 GRU 网络[Chung et al., 2014]。当然还有一些其它方法，比如时钟循环神经网络（Clockwork RNN）[Koutnik et al., 2014]、乘法RNN[Sutskever et al., 2011, Wu et al., 2016] 以及引入注意力机制等。注意力机制参见第8.1节。LSTM 网络是目前为止最成功的循环神经网络模型，成功应用在很多领域，比如语音识别、机器翻译[Sutskever et al., 2014]、语音模型以及文本生成。LSTM 网络通过引入线性连接来缓解长距离依赖问题。虽然LSTM功，其结构的合理性一直受到广泛关注。人们不断有尝试对其进行改进来寻找最优结构，比如减少门的数量、提高并行能力等。关于LSTM 网络的分析可以网络取得了很大的成参考文献[Greﬀ et al., 2017, Jozefowicz et al., 2015, Karpathy et al., 2015]。LSTM 网络的线性连接以及门控机制是一种十分有效的避免梯度消失问题的方法。这种机制也可以用在深层的前馈网络中，比如残差网络[He et al., 2016]邱锡鹏：《神经网络与深度学习》https://nndl.github.io/
 参考文献2019 年 4 月 6 日161和高速网络[Srivastava et al., 2015] 都通过引入线性连接来训练非常深的卷积网络。对于循环神经网格，这种机制也可以用在深度方向上，Gird LSTM 网络[Kalchbrenner et al., 2015]、Depth Gated RNN[Chung et al., 2015] 等。此外，循环神经网络可以很容易地扩展到两种更广义的图结构数据上，称为图网络[Scarselli et al., 2009]。比如递归神经网络就是一种有向无环图上的图网络。图网络是目前比较新兴的研究方向，还没有比较成熟的网络模型。在不同 的网络结构以及任务上，都有很多不同的具体实现方式。其中比较有名图网络 模型有图卷积网络（Graph Convolutional Network，GCN）[Kipf and Welling,2016]、消息传递网络（Message Passing Neural Network，MPNN）[Gilmer et al.,2017] 等。关于图网络的综述可以参考文献[Battaglia et al., 2018]。习题习题 6-1分析延时神经网络、卷积神经网络和循环神经网络的异同点。习题 6-2 计算公式(6.40) 和公式(6.41) 中的梯度。习题 6-3 计算LSTM 网络中参数的梯度，并分析其避免梯度消失的效果。习题 6-4 计算GRU 网络中参数的梯度，并分析其避免梯度消失的效果。习题6-5 证明当递归神经网络的结构退化为线性序列结构时，递归神经网络就等价于简单循环神经网络。参考文献Peter W Battaglia, Jessica B Hamrick, Vic-tor Bapst, Alvaro Sanchez-Gonzalez, Vini-cius Zambaldi, Mateusz Malinowski, An-drea Tacchetti, David Raposo, Adam San-toro, Ryan Faulkner, et al. Relational induc-tive biases, deep learning, and graph net-works. arXiv preprint arXiv:1806.01261,2018.166, 1994.Kyunghyun Cho, Bart Van Merriënboer,Caglar Gulcehre, Dzmitry Bahdanau, FethiBougares, Holger Schwenk, and YoshuaBengio. Learning phrase representationsusing RNN encoder-decoder for statisti-cal machine translation. arXiv preprintarXiv:1406.1078, 2014.Yoshua Bengio, Patrice Simard, and PaoloFrasconi. Learning long-term dependencieswith gradient descent is diﬀcult. NeuralNetworks, IEEE Transactions on, 5(2):157–JunyoungChung,CaglarGulcehre,KyungHyun Cho, and Yoshua Bengio.Empirical evaluation of gated recurrent邱锡鹏：《神经网络与深度学习》https://nndl.github.io/
 1622019 年 4 月 6 日参考文献neural networks on sequence modeling.Andrej Karpathy, Justin Johnson, andLi Fei-Fei. Visualizing and understand-ing recurrent networks. arXiv preprintarXiv:1506.02078, 2015.arXiv preprint arXiv:1412.3555, 2014.Junyoung Chung,CaglarGulcehre,Kyunghyun Cho, and Yoshua Bengio.Gated feedback recurrent neural networks.In International Conference on MachineLearning, pages 2067–2075, 2015.Thomas N Kipf and Max Welling. Semi-supervised classiﬁcation with graph con-volutional networks.arXiv preprintJeﬀrey L Elman. Finding structure inarXiv:1609.02907, 2016.time.Jan Koutnik, Klaus Greﬀ, Faustino Gomez,and Juergen Schmidhuber. clockworkCognitive science, 14(2):179–211, 1990.Felix A Gers, Jürgen Schmidhuber, andFred Cummins. Learning to forget: Con-tinual prediction with lstm. Neural Com-putation, 2000.Arnn. In Proceedings of The 31st Inter-national Conference on Machine Learning,pages 1863–1871, 2014.Kevin J Lang, Alex H Waibel, and Geof-frey E Hinton. A time-delay neural networkarchitecture for isolated word recognition.Neural networks, 3(1):23–43, 1990.IJ Leontaritis and Stephen A Billings. Input-output parametric models for non- linearsystems part i: deterministic non- linearsystems. International journal of control,41(2):303–328, 1985.Justin Gilmer, SamuelS Schoenholz,Patrick F Riley, Oriol Vinyals, andGeorge E Dahl. Neural message passingfor quantum chemistry. arXiv preprintarXiv:1704.01212, 2017.Klaus Greﬀ, RupeshKoutník, Bas Steunebrink, and JürgenSchmidhuber. Lstm: search spaceK Srivastava, JanRAodyssey. IEEE transactions on neural net-works and learning systems, 2017.A Parlos, A Atiya, K Chong, W Tsai,andB Fernandez. Recurrent multilayerSimon Haykin. Neural networks and learn-ing machines, volume 3. Pearson UpperSaddle River, NJ, USA:, 2009.perceptron for nonlinear system identiﬁca-tion. In Neural Networks, 1991., IJCNN- 91-Seattle International Joint Conferenceon,volume 2, pages 537–540. IEEE, 1991.JordanKaiming He, Xiangyu Zhang, ShaoqingRen, and Jian Sun. Deep residual learningfor image recognition. In Proceedings of theIEEE conference on computer vision andpattern recognition, pages 770–778, 2016.Sepp Hochreiter and Jürgen Schmidhuber.Long short-term memory. Neural computa-tion, 9(8):1735–1780, 1997.BPollack. Recursive distributedrepresentations. Artiﬁcial Intelligence, 46(1):77–105, 1990.Franco Scarselli, Marco Gori, Ah ChungTsoi, Markus Hagenbuchner, and GabrieleMonfardini. The graph neural networkmodel. IEEE Transactions on Neural Net-works, 20(1):61–80, 2009.Sepp Hochreiter, Yoshua Bengio, PaoloFrasconi, and Jürgen Schmidhuber. Gradi-ent ﬂow in recurrent nets: the diﬀculty oflearning long-term dependencies, 2001.Rafal Jozefowicz, Wojciech Zaremba, andIlya Sutskever. An empirical explorationof recurrent network architectures. In Pro-ceedings of the 32nd International Confer-ence on Machine Learning, pages 2342–2350, 2015.Anton Maximilian Schäfer and Hans GeorgZimmermann. Recurrent neural networksare universal approximators. In Interna-tional Conference on Artiﬁcial Neural Net-works, pages 632–640. Springer, 2006.Hava T Siegelmann and Eduardo D Son-tag. Turing computability with neural nets.Applied Mathematics Letters, 4(6):77–80,1991.Nal Kalchbrenner, Ivo Danihelka, and AlexGraves. Grid long short-term memory.arXiv preprint arXiv:1507.01526, 2015.Richard Socher, CliﬀManning, and Andrewnatural scenesCLin, ChrisYNg. Parsing邱锡鹏：《神经网络与深度学习》https://nndl.github.io/
 参考文献2019 年 4 月 6 日163and natural language with recursive neu-ral networks. In Proceedings of the Inter-national Conference on Machine Learning,2011.Alex Waibel, Toshiyuki Hanazawa, Geof-frey Hinton, Kiyohiro Shikano, and Kevin JLang. Phoneme recognition using time-delay neural networks. IEEE transactionson acoustics, speech, and signal processing,37(3):328–339, 1989.Richard Socher, Alex Perelygin, JeanYWu, Jason Chuang, Christopher D Man-ning, Andrew Y Ng, and Christopher Potts.Recursive deep models for semantic com-positionality over a sentiment treebank. InProceedings of EMNLP, 2013.Paul J Werbos. Backpropagation throughtime: what it does and how to do it.Proceedings of the IEEE, 78(10):1550–1560,1990.Rupesh Kumar Srivastava, Klaus Greﬀ, andJürgen Schmidhuber. Highway networks.arXiv preprint arXiv:1505.00387, 2015.Ilya Sutskever, James Martens, and Geof-frey E Hinton. Generating text with recur-rent neural networks. In Proceedings of the28th International Conference on MachineLearning, pages 1017–1024, 2011.Ronald J Williams and Jing Peng. An ef-ﬁcient gradient-based algorithm for on-linetraining of recurrent network trajectories.Neural computation, 2(4):490–501, 1990.RonaldJWilliams and David Zipser.Gradient-based learning algorithms for re-current networks and their computationalcomplexity. Backpropagation: Theory, ar-chitectures, and applications, 1:433–486,1995.Ilya Sutskever, Oriol Vinyals, and Quoc VVLe. Sequence to sequence learning with neu-ral networks. In Advances in Neural In-formation Processing Systems, pages 3104–3112, 2014.Yuhuai Wu, Saizheng Zhang, Ying Zhang,Yoshua Bengio, and Ruslan R Salakhut-dinov. On multiplicative integration withrecurrent neural networks. In Advancesin neural information processing systems,pages 2856–2864, 2016.Kai Sheng Tai, Richard Socher, andChristopherD Manning. Improved se-mantic representations from tree-structuredlong short-term memory networks. In Pro-ceedings of the 53rd Annual Meeting of theAssociation for Computational Linguistics,2015.Xiaodan Zhu, Parinaz Sobihani, andHongyu Guo. Long short-term memoryover recursive structures. In Proceedings ofLCML, pages 1604–1612, 2015.邱锡鹏：《神经网络与深度学习》https://nndl.github.io/
 

 第 7 章 网络优化与正则化任何数学技巧都不能弥补信息的缺失。— Cornelius Lanczos，1964虽然神经网络具有非常强的表达能力，但是当应用神经网络模型到机器学习时依然存在一些难点。主要分为两大类：（1） 优化问题：神经网络模型是一个非凸函数，再加上在深度网络中的梯度消失问题，很难进行优化；另外，深层神经网络模型一般参数比较多，训练数据也比较大，会导致训练的效率比较低。（2） 泛化问题：因为神经网络的拟合能力强，反而容易在训练集上产生过拟合。因此，在训练深层神经网络时，同时也需要通过一定的正则化方法来改进网络的泛化能力。目前，研究者从大量的实践中总结了一些经验技巧，从优化和正则化两个方面来提高学习效率并得到一个好的网络模型。7.1 网络优化深层神经网络是一个高度非线性的模型，其风险函数是一个非凸函数，因此风险最小化是一个非凸优化问题，会存在很多局部最优点。7.1.1 网络优化的难点有效地学习深层神经网络的参数是一个具有挑战性的问题，其主要原因有以下几个方面。
 1662019 年 4 月 6 日第7 章 网络优化与正则化7.1.1.1 网络结构多样性神经网络的种类非常多，比如卷积网络、循环网络等，其结构也非常不同。有些比较深，有些比较宽。不同参数在网络中的作用也有很大的差异，比如连接权重和偏置的不同，以及循环网络中循环连接上的权重和其它权重的不同。由于网络结构的多样性，我们很难找到一种通用的优化方法。不同的优化方法在不同网络结构上的差异也都比较大。此外，网络的超参数一般也比较多，这也给优化带来很大的挑战。7.1.1.2 高维变量的非凸优化低维空间的非凸优化问题主要是存在一些局部最优点。基于梯度下降的优化方法会陷入局部最优点，因此低维空间非凸优化的主要难点是如何选择初始化参数和逃离局部最优点。深层神经网络的参数非常多，其参数学习是在非常高维空间中的非凸优化问题，其挑战和在低维空间的非凸优化问题有所不同。鞍点 在高维空间中，非凸优化的难点并不在于如何逃离局部最优点，而是如何逃离鞍点（Saddle Point）[Dauphin et al., 2014]。鞍点的梯度是0，但是在一些维度上是最高点，在另一些维度上是最低点，如图7.1所示。鞍点的叫法是因为其形状像马鞍。11/201/2111/2101/201/21/211图 7.1 鞍点示例在高维空间中，局部最优点要求在每一维度上都是最低点，这种概率非常低。假设网络有10, 000 维参数，一个点在某一维上是局部最低点的概率为p，那么在整个参数空间中，局部最优点的概率为p10,000，这种可能性非常小。也就是说高维空间中，大部分梯度为0 的点都是鞍点。基于梯度下降的优化方法会在鞍点附近接近于停滞，同样很难从这些鞍点中逃离。邱锡鹏：《神经网络与深度学习》https://nndl.github.io/
 7.2 优化算法2019 年 4 月 6 日167平坦底部 深层神经网络的参数非常多，并且有一定的冗余性，这导致每单个参数对最终损失的影响都比较小，这导致了损失函数在局部最优点附近是一个平坦的区域，称为平坦最小值（Flat Minima）[Hochreiter and Schmidhuber, 1997, Liet al., 2017a]。并且在非常大的神经网络中，大部分的局部最小值是相等的。虽然神经网络有一定概率收敛于比较差的局部最小值，但随着网络规模增加，网络陷入局部最小值的概率大大降低[Choromanska et al., 2015]。图7.2给出了一种简单的平坦底部示例。2.001.751.501.251.000.750.500.250.002.01.51.00.50.00.5 w21.01.52.02.01.51.00.50.00.5w11.01.52.0图 7.2 神经网络中的平坦底部示例7.2 优化算法目前，深层神经网络的参数学习主要是通过梯度下降方法来寻找一组可以最小化结构风险的参数。在具体实现中，梯度下降法可以分为：批量梯度下降、随机梯度下降以及小批量梯度下降三种形式。根据不同的数据量和参数量，可以选择一种具体的实现形式。除了在收敛效果和效率上的差异，这三种方法都存在一些共同的问题，比如1）如何初始化参数；2）预处理数据；3）如何选择合适的学习率，避免陷入局部最优等。7.2.1 小批量梯度下降目前，在训练深层神经网络时，训练数据的规模比较大。如果在梯度下降时，每次迭代都要计算整个训练数据上的梯度需要比较多的计算资源。此外，大规模训练集中的数据通常也会非常冗余，也没有必要在整个训练集上计算梯度。 因此，在训练深层神经网络时，经常使用小批量梯度下降算法。邱锡鹏：《神经网络与深度学习》https://nndl.github.io/
 1682019 年 4 月 6 日第7 章 网络优化与正则化令f (x, θ) 表示一个深层神经网络，θ 为网络参数，在使用小批量梯度下降进行优化时，每次选取K 个训练样本It = {(x(k), y(k))}kK=1 。第t 次迭代（iteration）时损失函数关于参数θ 的偏导数为Σ1∂L y(k), f (x(k), θ)gt(θ) =,(7.1)t邱锡鹏：《神经网络与深度学习》https://nndl.github.io/
 7.2 优化算法2019 年 4 月 6 日169K∂θ(x(k),y(k))∈I邱锡鹏：《神经网络与深度学习》https://nndl.github.io/
 1702019 年 4 月 6 日第7 章 网络优化与正则化其中L(·) 为可微分的损失函数，K 称为批量大小（Batch Size）。这里的损失函数忽略了正则化项。加上ℓp 正则化的损失第 t 次更新的梯度gt 定义为函数参见第7.7.1节。,gt gt(θt−1).(7.2)(7.3)使用梯度下降来更新参数，θt ← θt−1 − αgt,其中α > 0 为学习率。每次迭代时参数更新的差值∆θt 定义为∆θt θt − θt−1,.(7.4)∆θ 和梯度g 并不需要完全一致。∆θ 为每次迭代时参数的实际更新方向，即tttθt = θt−1 + ∆θ 。在标准的小批量梯度下降中，∆θ = −αg 。ttt图7.3给出了在MNIST数据集上，批量大小对损失下降的影响。一般批量大值得注意的是，图7.3中的三种批量大小对应的学习率并不一致，因此并不是严格对比。小较小时，需要设置较小的学习率较，否则模型会不收敛。从图7.3a可以看出，每次迭代选取的批量样本数越多，下降效果越明显，并且下降曲线越平滑。 当每次选取一个样本时（相当于随机梯度下降），损失整体是下降趋势，但局部看会来回震荡。从图7.3b可以看出，如果按整个数据集上的迭代次数（Epoch） 的来看损失变化情况，则是批量样本数越小，下降效果越明显。Epoch（回合） 和Iteration（单次更新） 的关系为 1 个epoch 等 于 ( 训练样本的数量N)批量大小K101101次 Iterations。SGD(batchsize=1 learningrate=0.01)SGD(batchsize=32 learningrate=0.5)SGD(batchsize=2048 learningrate=0.5)SGD(batchsize=1 learningrate=0.05)SGD(batchsize=32 learningrate=0.5)SGD(batchsize=2048 learningrate=0.5)10010-110-210010-110-210-310-3 010002000300040005000012345678iterationsepochs(a) 按每次小批量更新的损失变化(b) 按整个数据集迭代的损失变化图 7.3 批量大小对损失下降的影响邱锡鹏：《神经网络与深度学习》https://nndl.github.io/
 7.2 优化算法2019 年 4 月 6 日171为了更有效地进行训练深层神经网络，在标准的小批量梯度下降方法的基础上，也经常使用一些改进方法以加快优化速度。常见的改进方法主要从以下两个方面进行改进：学习率衰减和梯度方向优化。这些改进的优化方法也同样可以应用在批量或随机梯度下降方法上。7.2.2 学习率衰减在梯度下降中，学习率α的取值非常关键，如果过大就不会收敛，如果过小则收敛速度太慢。从经验上看，学习率在一开始要保持大些来保证收敛速度， 在收敛到最优点附近时要小些以避免来回震荡。因此，比较简单直接的学习率调整可以通过学习率衰减（Learning Rate Decay）的方式来实现。假设初始化学习率为α ，在第t 次迭代时的学习率α 。常用的衰减方式为0t可以设置为按迭代次数进行衰减。比如逆时衰减（inverse time decay）1αt = α0,(7.5)1 + β × t或指数衰减（exponential decay）α = α βt,(7.6)(7.7)t0或自然指数衰减（natural exponential decay）α = α exp(−β × t),t0其中β 为衰减率，一般取值为0.96。除了这些固定衰减率的调整学习率方法外，还有些自适应地调整学习率的方法，比如AdaGrad、RMSprop、AdaDelta等。这些方法都对每个参数设置不同的学习率。7.2.2.1 AdaGrad 算法在标准的梯度下降方法中，每个参数在每次迭代时都使用相同的学习率。由于每个参数的维度上收敛速度都不相同，因此根据不同参数的收敛情况分别设置学习率。AdaGrad（Adaptive Gradient）算法[Duchi et al., 2011] 是借鉴L2 正则化的思想，每次迭代时自适应地调整每个参数的学习率。在第t 迭代时，先计算每个参数梯度平方的累计值ΣtGt =ggτ ,(7.8)⊙ττ =1其中⊙为按元素乘积，gτ ∈ R|θ| 是第τ 次迭代时的梯度。邱锡鹏：《神经网络与深度学习》https://nndl.github.io/
 1722019 年 4 月 6 日第7 章 网络优化与正则化AdaGrad算法的参数更新差值为α∆θt = −√G t+ ϵ ⊙ gt,(7.9)其中α 是初始的学习率，ϵ 是为了保持数值稳定性而设置的非常小的常数，一般取值e−7 到e−10。此外，这里的开平方、除、加运算都是按元素进行的操作。在 Adagrad 算法中，如果某个参数的偏导数累积比较大，其学习率相对较小；相反，如果其偏导数累积较小，其学习率相对较大。但整体是随着迭代次数的增加，学习率逐渐缩小。Adagrad 算法的缺点是在经过一定次数的迭代依然没有找到最优点时，由于这时的学习率已经非常小，很难再继续找到最优点。7.2.2.2 RMSprop 算法RMSprop算法是 Geoﬀ Hinton 提出的一种自适应学习率的方法[Tielemanand Hinton, 2012]，可以在有些情况下避免AdaGrad 算法中学习率不断单调下降以至于过早衰减的缺点。RMSprop 算法首先计算每次迭代梯度gt 平方的指数衰减移动平均，Gt = βGt−1 + (1 − β)gt ⊙ gt(7.10)(7.11)t−= (1 β)βt−τ gτgτ ,τ =1⊙其中β 为衰减率，一般取值为0.9。RMSprop 算法的参数更新差值为α∆θt = −√⊙ gt,(7.12)Gt + ϵ其中α 是初始的学习率，比如0.001。从上式可以看出，RMSProp 算法和Adagrad 算法的区别在于Gt 的计算由累积方式变成了指数衰减移动平均。在迭代过程中，每个参数的学习率并不是呈衰减趋势，既可以变小也可以变大。7.2.2.3 AdaDelta 算法AdaDelta算法[Zeiler, 2012] 也是 Adagrad 算法的一个改进。和RMSprop 算法类似，AdaDelta 算法通过梯度平方的指数衰减移动平均来调整学习率。此外，AdaDelta 算法还引入了每次参数更新差∆θ 的平方的指数衰减权移动平均。第t 次迭代时，每次参数更新差∆θτ , 1 ≤ τ ≤ t−1 的指数衰减权移动平均为∆Xt2−1 = β1∆X2+(1− β1)∆θ⊙∆θt−1.(7.13)t−2t−1邱锡鹏：《神经网络与深度学习》https://nndl.github.io/
 7.2 优化算法2019 年 4 月 6 日173其中β1 为衰减率。此时∆θ 还未知，因此只能计算到∆X 。tt−1AdaDelta 算法的参数更新差值为q∆X2+ ϵ∆θ = −邱锡鹏：《神经网络与深度学习》https://nndl.github.io/
 1742019 年 4 月 6 日第7 章 网络优化与正则化(7.14)t−1√g邱锡鹏：《神经网络与深度学习》https://nndl.github.io/
 7.2 优化算法2019 年 4 月 6 日175ttGt + ϵ其中Gt 的计算方式和RMSprop算法一样（公式(7.10)），∆X∆θ 的指数衰减权移动平均。为参数更新差2t−1从上式可以看出，AdaDelta 算法将RMSprop 算法中的初始学习率 α 改为q动态计算的 ∆X2t−1，在一定程度上平抑了学习率的波动。7.2.3 梯度方向优化除了调整学习率之外，还可以通过使用最近一段时间内的平均梯度来代替当前时刻的梯度来作为参数更新的方向。从图7.3看出，在小批量梯度下降中，如果每次选取样本数量比较小，损失会呈现震荡的方式下降。有效地缓解梯度下降中的震荡的方式是通过用梯度的移动平均来代替每次的实际梯度，并提高优化速度，这就是动量法。7.2.3.1 动量法动量是模拟物理中的概念。一般而言，一个物体的动量指的是这个物体在它 运动方向上保持运动的趋势，是物体的质量和速度的乘积。动量法（Momentum Method）[Rumelhart et al., 1988] 是用之前积累动量来替代真正的梯度。每次迭代的梯度可以看作是加速度。在第t 次迭代时，计算负梯度的“加权移动平均”作为参数的更新方向，∆θt = ρ∆θt−1 − αgt,(7.15)其中ρ 为动量因子，通常设为0.9，α 为学习率。参见习题7-1。这样，每个参数的实际更新差值取决于最近一段时间内梯度的加权平均值。当某个参数在最近一段时间内的梯度方向不一致时，其真实的参数更新幅度变小；相反，当在最近一段时间内的梯度方向都一致时，其真实的参数更新幅度变大，起到加速作用。一般而言，在迭代初期，梯度方法都比较一致，动量法会起到加速作用，可以更快地到达最优点。在迭代后期，梯度方法会取决不一致，在收敛值附近震荡，动量法会起到减速作用，增加稳定性。从某种角度来说，当前梯度叠加上部分的上次梯度，一定程度上可以近似看作二阶梯度。邱锡鹏：《神经网络与深度学习》https://nndl.github.io/
 1762019 年 4 月 6 日第7 章 网络优化与正则化7.2.3.2 Nesterov 加速梯度Nesterov 加速梯度（Nesterov Accelerated Gradient，NAG），也叫 Nes-terov 动量法（Nesterov Momentum）是一种对动量法的改进 [Nesterov, 2013,Sutskever et al., 2013]。在动量法中，实际的参数更新方向∆θt 为上一步的参数更新方向∆θt−1和当前梯度−g 的叠加。这样，∆θ 可以被拆分为两步进行，先根据∆θ 更新一ttt−1ˆ次得到参数θ ，再用g 进行更新。tˆ+ ρ∆θt−1θ = θ,(7.16)t−1ˆθ = θ − αg ,(7.17)tt其中梯度g 为点θ 上的梯度，因此在第二步更新中有些不太合理。更合理的tt−1ˆ更新方向应该为θ上的梯度。这样，合并后的更新方向为∆θt = ρ∆θt−1 − αgt(θt−1 + ρ∆θt−1),+ ρ∆(7.18)其中gt(θt−1 + ρ∆θt−1) 表示损失函数在点θ = θˆθt−1 上的偏导数。t−1gt 的定义参见公式(7.1)。图7.4给出了动量法和Nesterov 加速梯度在参数更新时的比较。ρ∆θt−1◦θt−1•∆θθtt•∆θt−1θt−2•−αgt(θt−1)◦(a) 动量法ˆ◦θρ∆θt−1−ˆαg (θ)tθt−1•θt◦∆θt−1∆θtθt−2•(b) Nesterov 加速梯度图 7.4 动量法和Nesterov 加速梯度的比较7.2.3.3 AdaM 算法自适应动量估计（Adaptive Moment Estimation，Adam）算法[Kingma andBa, 2015] 可以看作是动量法和RMSprop 的结合，不但使用动量作为参数更新方向，而且可以自适应调整学习率。邱锡鹏：《神经网络与深度学习》https://nndl.github.io/
 7.2 优化算法2019 年 4 月 6 日177Adam 算法一方面计算梯度平方 g2 t的指数加权平均（和 RMSprop 类似），另一方面计算梯度gt 的指数加权平均（和动量法类似）。M = β M + (1 − β )g ,(7.19)(7.20)t1t−11tG = β G + (1 − β )g ⊙ g ,t2t−12tt其中β 和β 分别为两个移动平均的衰减率，通常取值为β = 0.9, β = 0.99。1212M 可以看作是梯度的均值（一阶矩），G 可以看作是梯度的未减去均值的tt方差（二阶矩）。假设M = 0, G = 0，那么在迭代初期M 和 G 的值会比真实的均值和方00tt差要小。特别是当β 和β 都接近于1时，偏差会很大。因此，需要对偏差进行12修正。参见习题7-2。MtMˆtGˆt==,.(7.21)(7.22)1 − βt1Gt1 − βt2Adam 算法的参数更新差值为α∆= − √Mˆ ,(7.23)θttGˆt + ϵα0其中学习率α 通常设为0.001，并且也可以进行衰减，比如α = √ 。ttAdam 算法是RMSProp 与动量法的结合，因此一种自然的Adam 的改进方法是引入Nesterov 加速梯度，称为Nadam 算法 [Dozat, 2016]。7.2.3.4 梯度截断在深层神经网络或循环神经网络中，除了梯度消失之外，梯度爆炸是影响学习效率的主要因素。在基于梯度下降的优化过程中，如果梯度突然增大，用大的梯度进行更新参数，反而会导致其远离最优点。为了避免这种情况，当梯度的模大于一定阈值时，就对梯度进行截断，称为梯度截断（gradient clipping）[Pascanu et al., 2013]。梯度截断是一种比较简单的启发式方法，把梯度的模限定在一个区间，当梯度的模小于或大于这个区间时就进行截断。一般截断的方式有以下几种：按值截断 在第t 次迭代时，梯度为gt，给定一个区间[a, b]，如果一个参数的梯度小于a 时，就将其设为a；如果大于b 时，就将其设为b。g = max(min(g , b), a).(7.24)tt邱锡鹏：《神经网络与深度学习》https://nndl.github.io/
 1782019 年 4 月 6 日第7 章 网络优化与正则化按模截断 按模截断是将梯度的模截断到一个给定的截断阈值b。如果∥g ∥2 ≤ b，保持g 不变。如果∥g ∥2 > b，令tttbg =gt.(7.25)t∥gt∥截断阈值b 是一个超参数，也可以根据一段时间内的平均梯度来自动调整。实验中发现，训练过程对阈值b 并不十分敏感，通常一个小的阈值就可以得到很好的结果[Pascanu et al., 2013]。在训练循环神经网络时，按模截断是避免梯度爆炸问题的有效方法。图7.5给 出了一个循环神经网络的损失函数关于参数的曲面。图中的曲面为只有一个隐 藏神经元的循环神经网络h = σ(wh + b) 的损失函数，其中w 和b 为参数。假如tt1h0 初始值为0.3，损失函数为L = (h100 − 0.65)2。0.300.250.200.150.100.054.04.24.44.64.85.05.25.45.6W2.252.00 1.751.501.251.00b3.002.752.50图 7.5 梯度爆炸问题示例7.2.4 优化算法小结本节介绍的几种优化方法大体上可以分为两类：一是调整学习率，使得优化更稳定；二是调整梯度方向，优化训练速度。表7.1汇总了本节介绍的几种神经网络常用优化方法。邱锡鹏：《神经网络与深度学习》https://nndl.github.io/
 7.3 参数初始化2019 年 4 月 6 日175学习率衰减梯度方向优化AdaGrad、RMSprop、AdaDelta 动量法、Nesterov 加速梯度、梯度截断Adam≈动量法+RMSprop表 7.1 神经网络常用优化方法的汇总图7.6给出了这几种优化方法在MNIST 数据集上收敛性的比较。100AdaGradRMSpropAdaDeltaMomentumAdam10-110-210-3Nesterov010002000300040005000iterations图 7.6 不同优化方法的比较7.3 参数初始化神经网络的训练过程中的参数学习是基于梯度下降法进行优化的。梯度下降法需要在开始训练时给每一个参数赋一个初始值。这个初始值的选取十分关键。在感知器和logistic 回归的训练中，我们一般将参数全部初始化为0。但是这在神经网络的训练中会存在一些问题。因为如果参数都为0，在第一遍前向计算时，所有的隐层神经元的激活值都相同。这样会导致深层神经元没有区分 性。这种现象也称为对称权重现象。为了打破这个平衡，比较好的方式是对每个参数都随机初始化，这样使得不同神经元之间的区分性更好。但是一个问题是如何选取随机初始化的区间呢？如果参数太小，会导致神经元的输入过小。经过多层之后信号就慢慢消失了。参数过小还会使得sigmoid邱锡鹏：《神经网络与深度学习》https://nndl.github.io/
 1762019 年 4 月 6 日第7 章 网络优化与正则化型激活函数丢失非线性的能力。以logistic 函数为例，在0 附近基本上是近似线性的。这样多层神经网络的优势也就不存在了。如果参数取得太大，会导致输入状态过大。对于sigmoid 型激活函数来说，激活值变得饱和，从而导致梯度接近于0。因此，如果要高质量地训练一个网络，给参数选取一个合适的初始化区间是非常重要的。一般而言，参数初始化的区间应该根据神经元的性质进行差异化的设置。如果一个神经元的输入连接很多，它的每个输入连接上的权重就应该小一些，以避免神经元的输出过大（当激活函数为ReLU 时）或过饱和（当激活函数为sigmoid函数时）。经常使用的初始化方法有以下几种：7.3.0.1 Gaussian 分布初始化Gaussian 初始化方法是最简单的初始化方法，参数从一个固定均值（比如0）和固定方差（比如0.01）的 Gaussian 分布进行随机初始化。初始化一个深度网络时，一个比较好的初始化方案是保持每个神经元输入的方差为一个常量。当一个神经元的输入连接数量为n 时，可以设置其输入in1连接权重以(0, nin ) 的 Gaussian 分布进行初始化。如果同时考虑输出连接Nr2的数量nout，则可以按 N (0,7.3.0.2 均匀分布初始化) 的 Gaussian 分布进行初始化。nin + nout均匀分布初始化是在一个给定的区间[−r, r] 内采用均匀分布来初始化参数。超参数r 的设置也可以按神经元的连接数量进行自适应的调整。Xavier 初 始 化 方 法 中，Xavier 是 发 明 者 XavierGlorot 的名字。Xavier 初始化方法 Glorot and Bengio [2010] 提出一个自动计算超参数r 的方法，参数可以在[−r, r]内采用均匀分布进行初始化。如果神经元激活函数为logistic 函数，对于第l − 1 到 l 层的权重参数区间r可以设置为r6r =,(7.26)nl−1 + nl这里nl 是第l 层神经元个数，nl−1 是第l − 1 层神经元个数。对于tanh 函数，r 可以设置为rr = 46.(7.27)nl−1 + nl邱锡鹏：《神经网络与深度学习》https://nndl.github.io/
 7.3 参数初始化2019 年 4 月 6 日177假设第l 层的一个隐藏层神经元ꢀl，其接受前一层的nl−1 个神经元的输出(l−1)，i ∈ [1, n(l−1)]，ain(l−1)Σl(l−1).w ai il(7.28)=i=1为了避免初始化参数使得激活值变得饱和，我们需要尽量使得ꢀl 处于激活函数的线性区间，也就是其绝对值比较小的值。这时该神经元的激活值为al =f(ꢀl) ≈ ꢀl。假设wl 和a(l−1) 都是相互独立，并且均值都为0，则al 的均值为iiΣΣn(l−1)n(l−1)E[al] = E[E[w ]E[ (l−1)] = 0.(7.29)(7.30)(l−1)iil=w a]aiii= 1i= 1al 的方差为Σn(l−1)l =var[a ] var[l(l−1)]w aiii=1Σn(l−1)=var[w ]var[la(l−1)](7.31)(7.32)iii= 1= n(l−1) var[w ]var[al](l−1) .ii也就是说，输入信号的方差在经过该神经元后被放大或缩小了n(l−1) var[w ]倍。li为了使得在经过多层网络后，信号不被过分放大或过分减弱，我们尽可能保持每个神经元的输入和输出的方差一致。这样n(l−1)var[w ]设为 比较合理，即l1i1l =var[w ].(7.33)in l( −1)同理，为了使得在反向传播中，误差信号也不被放大或缩小，需要将wil 的方差保持为1l =var[w ].(7.34)in(l)作为折中，同时考虑信号在前向和反向传播中都不被放大或缩小，可以设置2l =var[w ].(7.35)in(l−1) + n(l)假设随机变量x 在区间[a, b] 内均匀分布，则其方差为：(b − a)2var[x] =.(7.36)12因此，若让wl ∈ [−r, r]，并且var[wl] = 1，则 的取值为riinl−1+邱锡鹏：《神经网络与深度学习》https://nndl.github.io/
 1782019 年 4 月 6 日第7 章 网络优化与正则化r6r =.(7.37)邱锡鹏：《神经网络与深度学习》https://nndl.github.io/
 7.3 参数初始化2019 年 4 月 6 日1797.4 数据预处理一般而言，原始的训练数据中，每一维特征的来源以及度量单位不同，会造成这些特征值的分布范围往往差异很大。当我们计算不同样本之间的欧氏距离时，取值范围大的特征会起到主导作用。这样，对于基于相似度比较的机器学习方法（比如最近邻分类器），必须先对样本进行预处理，将各个维度的特征 归一化到同一个取值区间，并且消除不同特征之间的相关性，才能获得比较理想的结果。虽然神经网络可以通过参数的调整来适应不同特征的取值范围，但 是会导致训练效率比较低。假设一个只有一层的网络 y = tanh(w x + w x + b)，其中 x ∈ [0, 10]，11221x2 ∈ [0, 1]。之前我们提到tanh 函数的导数在区间[−2, 2] 上是敏感的，其余的导数接近于0。因此，如果w x + w x + b 过大或过小，都会导致梯度过小，难以训112 2练。为了提高训练效率，我们需要使w x + w x + b 在[−2, 2] 区间，我们需要112 2将w1 设得小一点，比如在[−0.1, 0.1] 之间。可以想象，如果数据维数很多时，我们很难这样精心去选择每一个参数。因此，如果每一个特征的取值范围都在相似的区间，比如[0, 1] 或者[−1, 1]，我们就不太需要区别对待每一个参数， 减少人工干预。除了参数初始化之外，不同特征取值范围差异比较大时还会梯度下降法的搜索效率。图7.7给出了数据归一化对梯度的影响。其中，图7.7a为未归一化数据的等高线图。取值范围不同会造成在大多数位置上的梯度方向并不是最优的搜索方向。当使用梯度下降法寻求最优解时，会导致需要很多次迭代才能收敛。如果我们把数据归一化为取值范围相同，如图7.7b所示，大部分位置的梯度方向近似于最优搜索方向。这样，在梯度下降求解时，每一步梯度的方向都基本指向最小值，训练效率会大大提高。w2w2w1w1(a) 未归一化数据的梯度(b) 归一化数据的梯度图 7.7 数据归一化对梯度的影响归一化的方法有很多种，比如之前我们介绍的sigmoid邱锡鹏：《神经网络与深度学习》型函数等都可以将https://nndl.github.io/
 180 7.4 数据预处理2019 年2 041 9月年6 4日月 6 日第7 章 网络优化与正则化179不同取值范围的特征挤压到一个比较受限的区间。这里，我们介绍几种在神经网络中经常使用的归一化方法。缩放归一化 缩放归一化是一种非常简单的归一化方法，通过缩放将每一个特征的取值范围归一到[0, 1] 或[−1, 1] 之间。对于每一维特征x，x(i) − mini(x(i))xˆ(i)=,(7.38)max (x(i)) − min (x(i))ii其中min(x) 和max(x) 分别是特征x 在所有样本上的最小值和最大值。标准归一化 标准归一化也叫z-score 归一化，来源于统计上的标准分数。将每一个维特征都处理为符合标准正态分布（均值为0，标准差为1）。假设有N 个样本{x(i)}, i = 1, · · · , N ，对于每一维特征x，我们先计算它的均值和标准差：ΣN1µ =x(i),(7.39)Ni= 1ΣN1Nσ2 =(x(i) − µ)2.(7.40)i= 1然后，将特征x(i) 减去均值，并除以标准差，得到新的特征值ˆx(i)。x(i) − µxˆ(i)=,(7.41)σ这里σ 不能为0。如果标准差为0，说明这一维特征没有任务区分性，可以直接删掉。在标准归一化之后，每一维特征都服从标准正态分布。白化 白化（Whitening）是一种重要的预处理方法，用来降低输入数据特征之间的冗余性。输入数据经过白化处理后，特征之间相关性较低，并且所有特征具有相同的方差。白化的一个主要实现方式是使用主成分分析（Principal Component Anal-ysis，PCA）方法去除掉各个成分之间的相关性。参见第9.1.1节。图7.8给出了标准归一化和PCA 白化的比较。原始数据标准归一化PCA 白化图 7.8 标准归一化和PCA 白化邱锡鹏：《神经网络与深度学习》https://nndl.github.io/
 

 1802019 年 4 月 6 日第7 章 网络优化与正则化7.5 逐层归一化在深层神经网络中，中间某一层的输入是其之前的神经层的输出。因此，其 之前的神经层的参数变化会导致其输入的分布发生较大的差异。在使用随机梯 度下降来训练网络时，每次参数更新都会导致网络中间每一层的输入的分布发 生改变。越深的层，其输入的分布会改变得越明显。就像一栋高楼，低楼层发 生一个较小的偏移，都会导致高楼层较大的偏移。邱锡鹏：《神经网络与深度学习》https://nndl.github.io/
 机器学习小知识 | 协变量偏移月 6 日181在传统机器学习中，一个常见的问题的协变量偏移（CovariateShift）。协变量是一个统计学概念，是可能影响预测结果的统计变量。在机器学习中，协变量可以看作是输入。一般的机器学习算法都要求输入在训练集和测试集上的分布是相似的。如果不满足这个假设，在训练集上学习到的模型在测试集上的表现会比较差。训练集测试集0.30.20.10♣−4−202468邱锡鹏：《神经网络与深度学习》https://nndl.github.io/
 1822019 年 4 月 6 日第7 章 网络优化与正则化数需要重新学习，这种现象叫做内部协变量偏移（Internal Covariate Shift）。为了解决内部协变量偏移问题，就要使得每一个神经层的输入的分布在训练过程中要保持一致。最简单直接的方法就是对每一个神经层都进行归一化操作，使其分布保存稳定。下面介绍几种比较常用的逐层归一化方法：批量归一化、层归一化和其它一些方法。这里的逐层归一化方法是指可以应用在深层神经网络中的任何一个中间层。实际上并不需要对所有层进行归一化。7.5.1 批量归一化批量归一化（Batch Normalization，BN）方法[Ioﬀe and Szegedy, 2015] 是一种有效的逐层归一化方法，可以对神经网络中任意的中间层进行归一化操作。邱锡鹏：《神经网络与深度学习》https://nndl.github.io/
 7.5 逐层归一化2019 年 4 月 6 日183对于一个深层神经网络，令第l 层的净输入为z(l)，神经元的输出为a(l)，即a(l) = f (z(l)) = f (W a(l−1) + b),(7.42)其中f(·) 是激活函数，W 和b 是可学习的参数。为了减少内部协变量偏移问题，就要使得净输入z(l) 的分布一致，比如都归一化到标准正态分布。我们可以利用第7.4节中介绍的数据预处理方法进行对z(l) 进行归一化，相当于每一层都进行一次数据预处理，从而加速收敛速度。但是逐层归一化需要在中间层进行操作，要求效率比较高，因此复杂度比较高的白化方法就不太合适。为了提高归一化效率，一般使用标准归一化，将净输入z(l) 的每一维都归一到标准正态分布。虽然归一化操作可以应用在输入 a(l−1) 上，但其分布性质不如z(l) 稳定。因此，在实践中归一化操作一般应用仿射变换之后，在激活函数之前。z(l) − E[z(l)]ˆ(l) = √,(7.43)var(z是指当前参数) 下，z(l) 的每一维在整个训练集上的期望和l ) + ϵ (其中E[z(l)]和var( (l))z方差。因为目前主要的训练方法是基于小批量的随机梯度下降方法，所以准确地计算z(l) 的期望和方差是不可行的。因此，z(l) 的期望和方差通常用当前小批量样本集的均值和方差近似估计。给定一个包含 K 个样本的小批量样本集合，第 l 层神经元的净输入 z(1,l),· · · , z(K,l) 的均值和方差为ΣKz(k,l),1µB =(7.44)(7.45)KΣKk=11K( (zk,l)− µB) ⊙ (z(k,l) − µB).σ2 =Bk=1对净输入z(l) 的标准归一化会使得其取值集中的0 附近，如果使用sigmoid型激活函数时，这个取值区间刚好是接近线性变换的区间，减弱了神经网络的非线性性质。因此，为了使得归一化不对网络的表示能力造成负面影响，我们可以通过一个附加的缩放和平移变换改变取值区间。(l) − µBzˆ(l) =+√β(7.46)⊙+σBϵ, BN (z ),(7.47)(l)γ,β其中γ 和 β 分别代表缩放和平移的参数向量。从最保守的角度考虑，可以通过来标准归一化的逆变换来使得归一化后的变量可以被还原为原来的值。当γ =√(l) = (l)z。σ 2 ，β = µ 时，ˆBB批量归一化操作可以看作是一个特殊的神经层，加在每一层非线性激活函数之前，即a(l) = f (BN (z(l))) = f BN (W a(l−1)) ,(7.48)γ,βγ,β邱锡鹏：《神经网络与深度学习》https://nndl.github.io/
 1842019 年 4 月 6 日第7 章 网络优化与正则化其中因为批量归一化本身具有平移变换，因此仿射变换W a(l−1) 不再需要偏置参数。这里要注意的是，每次小批量样本的µ 和方差σ2 是净输入z( 的函数，而l)BB不是常量。因此在计算参数梯度时需要考虑µ 和σ 2的影响。当训练完成时，用整个数据集上的均值µ 和方差σ 来分别代替每次小批量样本的µ 和方差σ2 。在BBBB实践中，µ 和σ2 也可以用移动平均来计算。BB7.5.2 层归一化批量归一化是对一个中间层的单个神经元进行归一化操作，因此要求小批量样本的数量不能太小，否则难以计算单个神经元的统计信息。此外，如果一个神经元的净输入的分布在神经网络中是动态变化的，比如循环神经网络，那么就无法应用批量归一化操作。参见习题7-3。层归一化（Layer Normalization）[Ba et al., 2016] 是和批量归一化非常类似的方法。和批量归一化不同的是，层归一化是对一个中间层的所有神经元进行归一化。对于一个深层神经网络中，令第l 层神经的净输入为z(l)，其均值和方差为Σnl1nl(l)µ(l) =(7.49)(7.50)i,i=1Σnl1nlσ(l)2 =(ꢀ(l) − µ(l))2,ik=1其中nl 为第l 层神经元的数量。层归一化定义为z(l) − µ(l)(7.51)ˆ(l) =γ + β√⊙2σ(l) + ϵ, LN (z ),(7.52)(l)γ,β其中γ 和β 分别代表缩放和平移的参数向量，和z(l) 维数相同。循环神经网络中的层归一化 层归一化可以应用在循环神经网络中，对循环神经层进行归一化操作。假设在时刻t，循环神经网络的隐藏层为ht，其层归一化的更新为参见公式(6.6)。zt = U ht−1 + W xt,h = f (LN (z )),(7.53)(7.54)tγ,βt其中输入为xt 为第t 时刻的输入，U, W 为网络参数。邱锡鹏：《神经网络与深度学习》https://nndl.github.io/
 7.5 逐层归一化2019 年 4 月 6 日185在标准循环神经网络中，循环神经层的净输入一般会随着时间慢慢变大或变小，从而导致梯度爆炸或消失。而层归一化的循环神经网络可以有效地缓解这种状况。层归一化和批量归一化整体上是十分类似的，差别在于归一化的方法不同。对于K 个样本的一个小批量集合Z (l) = [z(1,l); · · · ; z(K ,l)]，层归一化是对矩阵Z(l)对每一列进行归一化，而批量归一化是对每一行进行归一化。一般而言，批量归一化是一种更好的选择。当小批量样本数量比较小时，可以选择层归一化。7.5.3 其它归一化方法除了上述两种归一化方法外，也有一些其它的归一化方法。7.5.3.1 权重归一化权重归一化（Weight Normalization）[Salimans and Kingma, 2016] 是对神经网络的连接权重进行归一化，通过再参数化（Reparameterization）方法，将连接权重分解为长度和方向两种参数。假设第l 层神经元a(l) = f W a(l−1)(+b)，我们将W 再参数化为g∥vWi,:=i v ,1 ≤ i ≤ nl(7.55)i其中Wi,: 表示权重W 的第i 行，nl 为神经元数量。新引入的参数gi 为标量，vi和 a(l−1) 维数相同。由于在神经网络中权重经常是共享的，权重数量往往比神经元数量要少，因 此权重归一化的开销会比较小。7.5.3.2 局部响应归一化局部响应归一化（Local Response Normalization，LRN）[Krizhevsky et al.,2012] 是一种受生物学启发的归一化方法，通常用在基于卷积的图像处理上。假设一个卷积层的输出特征映射 Y ∈ RM ′×N ′×P 为三维张量，其中每个切片矩阵Y p ∈ RM ′×N ′ 为一个输出特征映射，1 ≤ p ≤ P。参见公式(5.21)。局部响应归一化是对邻近的特征映射进行局部归一化。 βˆmin(P,p+ n )Σpp2j2Y = Y / k + α(Y ) (7.56)j=max(1,p− n2), LRNn,k,α,β(Y p),(7.57)其中除和幂运算都是按元素运算，n, k, α, β 为超参，n为局部归一化的特征窗口大小。在AlexNet 中，这些超参的取值为n = 5, k = 2, α = 10e−4, β = 0.75。邱锡鹏：《神经网络与深度学习》https://nndl.github.io/
 1842019 年 4 月 6 日第7 章 网络优化与正则化局部响应归一化和层归一化都是对同层的神经元进行归一化。不同的是局部响应归一化应用在激活函数之后，只是对邻近的神经元进行局部归一化，并且不减去均值。邻近的神经元指对应同样位置的邻近特征映射局部响应归一化和生物神经元中的侧抑制（lateral inhibition）现象比较类似，即活跃神经元对相邻神经元具有抑制作用。当使用 ReLU 作为激活函数时，神经元的活性值是没有限制的，局部响应归一化可以起到平衡和约束左右。如果一个神经元的活性值非常大，那么和它邻近的神经元就近似地归一化为0，从而起到抑制作用，增强模型的泛化能力。最大汇聚也具有侧抑制作用。但最大汇聚是对同一个特征映射中的邻近位置中的神经元进行抑制，而局部响应归一化是对同一个位置的邻近特征映射中的神经元进行抑制。上述的归一化方法可以根据需要应用在神经网络的中间层，从而减少前面网络参数更新对后面网络输入带来的内部协变量偏移问题，提高深层神经网络的训练效率。同时，归一化方法也可以作为一种有效的正则化方法，从而提高网络的泛化能力，避免过拟合。7.6 超参数优化在神经网络中，除了可学习的参数之外，还存在很多超参数。这些超参数对 网络性能的影响也很大。不同的机器学习任务需要往往需要不同的超参数。常 见的超参数有• 网络结构，包括神经元之间的连接关系、层数、每层的神经元数量、激活函数的类型等；• 优化参数，包括优化方法、学习率、小批量的样本数量等；• 正则化系数。超参数优化（Hyperparameter Optimization）主要存在两方面的困难。（1）超参数优化是一个组合优化问题，无法像一般参数那样通过梯度下降方法来优化，也没有一种通用有效的优化方法。（2）评估一组超参数配置（Conﬁguration） 的时间代价非常高，从而导致一些优化方法（比如演化算法（Evolution Algo-rithm））在超参数优化中难以应用。假设一个神经网络中总共有K 个超参数，每个超参数配置表示为一个向量x ∈ X，X ⊂ RK 是超参数配置的取值空间。超参数优化的目标函数定义为f (x) : X → R，f (x) 是衡量一组超参数配置x 效果的函数，一般设置为开发集上的错误率。目标函数f (x) 可以看作是一个黑盒（block-box）函数，不需要知道其具体形式。虽然在神经网络的超参数优化中，f (x) 的函数形式虽然已知，但f (x) 不是关于x 的对于超参数的设置，比较简单的方法有人工搜索、网格搜索和随机搜索。连续锡函鹏数：《，并神且经x网不络同与，f深(x度) 学习》https://nndl.github.io/
 7.6 超参数优化2019 年 4 月 6 日185的函数形式也不同，因此无邱锡鹏：《神经网络与深度学习》https://nndl.github.io/
 

 7.6 超参数优化2019 年 4 月 6 日1857.6.1 网格搜索网格搜索（grid search）是一种通过尝试所有超参数的组合来寻址合适一组超参数配置的方法。假设总共有K 个超参数，第k 个超参数的可以取mk 个值。那么总共的配置组合数量为m × m ×· · · × m 。如果超参数是连续的，可12K以将超参数离散化，选择几个“经验”值。比如学习率α，我们可以设置α ∈ {0.01, 0.1, 0.5, 1.0}.一般而言，对于连续的超参数，我们不能按等间隔的方式进行离散化，需要根据超参数自身的特点进行离散化。网格搜索根据这些超参数的不同组合分别训练一个模型，然后测试这些模型在开发集上的性能，选取一组性能最好的配置。7.6.2 随机搜索如果不同超参数对模型性能的影响有很大差异。有些超参数（比如正则化系数）对模型性能的影响有限，而有些超参数（比如学习率）对模型性能影响比较大。在这种情况下，采用网格搜索会在不重要的超参数上进行不必要的尝试。一种在实践中比较有效的改进方法是对超参数进行随机组合，然后选取一个性能最好的配置，这就是随机搜索（Random Search）[Bergstra and Bengio,2012]。随机搜索在实践中更容易实现，一般会比网格搜索更加有效。网格搜索和随机搜索都没有利用不同超参数组合之间的相关性，即如果模型的超参数组合比较类似，其模型性能也是比较接近的。因此这两种搜索方式一般都比较低效。下面我们介绍两种自适应的超参数优化方法：贝叶斯优化和动态资源分配。7.6.3 贝叶斯优化贝叶斯优化（Bayesian optimization）[Bergstra et al., 2011, Snoek et al.,2012] 是一种自适应的超参数搜索方法，根据当前已经试验的超参数组合，来预测下一个可能带来最大收益的组合。一种比较比较常用的贝叶斯优化方法为时序模型优化（Sequential Model-Based Optimization，SMBO）[Hutter et al.,2011]。假设超参数优化的函数f (x) 服从高斯过程，则p(f (x)|x) 为一个正态分布。贝叶斯优化过程是根据已有的N 组试验结果H = {x , y }N （y 为 f (x )nnnnn=1的观测值）来建模高斯过程，并计算f (x) 的后验分布pGP (f (x)|x, H)。高斯过程参见第D.3.2节。为了使得pGP (f (x)|x, H) 接近其真实分布，就需要对样本空间进行足够多的采样。但是超参数优化中每一个样本的生成成本很高，需要用尽可能少的样本来使得 pθ(f (x)|x, H) 接近于真实分布。因此，需要通过定义一个收益函数邱锡鹏：《神经网络与深度学习》https://nndl.github.io/

 1862019 年 4 月 6 日第7 章 网络优化与正则化（acquisition function）a(x, H) 来判断一个样本是否能够给建模 pθ(f (x)|x, H)提供更多的收益。收益越大，其修正的高斯过程会越接近目标函数的真实分布。收益函数的定义有很多种方式，一个常用的是期望改善（Expected Im-provement，EI）函数。假设 y∗=min{yn, 1 ≤ n ≤ N } 是当前已有样本中的最优值，期望改善函数为，∫∞EI(x, H) =max(y∗ − y, 0)p GP (y|x, H)dy.(7.58)−∞期望改善是定义一个样本x 在当前模型pGP (f (x)|x, H) 下，f (x) 超过最好结果y∗ 的 期 望 。 除 了 期 望 改 善 函 数 之 外 ， 收 益 函 数 还 有 其 它 定 义 形 式 ， 比 如 改 善 概 率（Probability ofImprovement）、高斯过程置信上界（GP Upper Conﬁdence Bound，GP-UCB）等。时序模型优化的过程如算法7.1所示。算法 7.1: 时序模型优化，一种贝叶斯优化方法输入: 优化目标函数f (x)，迭代次数：T ，收益函数a(x, H)1 H ← ∅;2随机初始化高斯过程，并计算pGP (f (x)|x, H);3 for t ← 1 to T dox′ ← arg maxx a(x, H);4567评价y′ = f(x′) ; // 代价高H ← H ∪ (x′, y′);根据H 重新建模高斯过程，并计算pGP (f (x)|x, H);8 end输出: H贝叶斯优化的一个缺点是高斯过程建模需要计算协方差矩阵的逆，时间复杂度是O(n3)，因此不能很好地处理高维情况。深层神经网络的超参数一般比较多，为了使用贝叶斯优化来搜索神经网络的超参数，需要一些更高效的高斯过程建模。也有一些方法可以将时间复杂度降从O(n3) 降低到O(n)[Snoek et al.,2015]。7.6.4 动态资源分配在超参数优化中，每组超参数配置的评估代价比较高。如果我们可以在较早的阶段就可以估计出一组配置的效果会比较差，那么我们就可以中止这组配置的评估，将更多的资源留给其它配置。这个问题可以归结为多臂赌博机问题的一个泛化问题：最优臂问题（best-arm problem），即在给定有限的机会次数下，如何玩这些赌博机并找到收益最大的臂。和多臂赌博机类似，最优臂问题也是在利用和探索之间找到最佳的平衡。多 臂 赌 博 机 问 题 参 见第14.1.1节。邱锡鹏：《神经网络与深度学习》https://nndl.github.io/
 7.6 超参数优化2019 年 4 月 6 日187由于目前神经网络的优化方法一般都采取随机梯度下降，因此我们可以通过一组超参数的学习曲线来预估这组超参数配置是否有希望得到比较好的结果。如果一组超参数配置的学习曲线不收敛或者收敛比较差，我们可以应用早期停止（early-stopping）策略来中止当前的训练。动态资源分配的一种有效方法是逐次减半（successive halving）方法[Jamiesonand Talwalkar, 2016]，将超参数优化看作是一种非随机的最优臂问题。假设要尝试N 组超参数配置，总共可利用的资源预算（摇臂的次数）为B，我们可以通过 T = ⌈log2(N )⌉ − 1 轮逐次减半的方法来选取最优的配置，具体过程如算法7.2所示。算法 7.2: 一种逐次减半的动态资源分配方法输入: 预算B，N 个超参数配置{x }Nn n=11 T ← ⌈log2(N )⌉ − 1;2 随机初始化S = {x }n=1N;0n3 for t ← 1 to T doB|St| ×4rt ← ⌊⌋;567给S 中的每组配置分配r 的资源;tt运行S 所有配置，评估结果为y ;tt根据评估结果，选取|St|/2 组最优的配置S ← arg max(S , y , |S |/2) ; // arg max(S, y, m) 为从集合Stttt中选取m 个元素，对应最优的m 个评估结果。8 end输出: 最优配置 SK在逐次减半方法中，尝试的超参数配置数量N 十分关键。如果N 越大，得到最佳配置的机会也越大，但每组配置分到的资源就越少，这样早期的评估结果可能不准确。反之如果N 越小，每组超参数配置的评估会越准确，但有可能无法得到最优的配置。因此，如何设置N 是平衡“利用-探索”的一个关键因素。一种改进的方法是HyperBand 方法[Li et al., 2017b]，通过尝试不同的N 来选取最优参数。7.6.4.1 神经架构搜索上面介绍的超参数优化方法都是在固定（或变化比较小）的超参数空间X中进行最优配置搜索，而最重要的神经网络架构一般还是需要由有经验的专家来进行设计。神经架构搜索（neural architecture search，NAS）[Zoph and Le,2017] 是一个新的比较有前景的研究方向，通过神经网络来自动实现网络架构的设深度学习使得机器学习中的“特征工程”问题转变为“网络架构工程”问题。计。一个神经网络的架构可以用一个变长的字符串来描述。利用元学习的思，神经架构搜索利用一个控制器来生成另一个子网络的架构描述。控制器可想邱锡鹏：《神经网络与深度学习》https://nndl.github.io/
 1882019 年 4 月 6 日第7 章 网络优化与正则化以由一个循环神经网络来实现。控制器的训练可以通过强化学习来完成，其奖励信号为生成的子网络在开发集上的准确率。强化学习参见第14.1节。7.7 网络正则化机器学习模型的关键是泛化问题，即在样本真实分布上的期望风险最小化。而训练数据集上的经验风险最小化和期望风险并不一致。由于神经网络的拟合能力非常强，其在训练数据上的错误率往往都可以降到非常低，甚至可以到0， 从而导致过拟合。因此，如何提高神经网络的泛化能力反而成为影响模型能力的最关键因素。参见第2.8.1节。正则化（Regularization）是一类通过限制模型复杂度，从而避免过拟合，提高泛化能力的方法，包括引入一些约束规则，增加先验、提前停止等。在传统的机器学习中，提高泛化能力的方法主要是限制模型复杂度，比如采用ℓ 和ℓ 正则化等方式。而在训练深层神经网络时，特别是在过度参数（Over-12Parameterized）时，ℓ1 和 ℓ2 正则化的效果往往不如浅层机器学习模型中显著。因此训练深度学习模型时，往往还会使用其它的正则化方法，比如数据增强、提前停止、丢弃法、集成法等。过度参数是指模型参数的数量远远大于训练数据的数量。7.7.1 ℓ 和 ℓ 正则化12ℓ1 和ℓ2 正则化是机器学习中最常用的正则化方法，通过约束参数的ℓ1 和ℓ2范数来减小模型在训练数据集上的过拟合现象。范数参见第A.1.3节。通过加入ℓ 和 ℓ 正则化，优化问题可以写为12ΣN1θ∗ = arg minL y(n), f(x(n), θ) + λℓp(θ),(7.59)Nθn=1其中L(·)为损失函数，N 为训练样本数量，f(·)为待学习的神经网络，θ 为其参数，ℓ 为范数函数，p 的取值通常为{1, 2} 代表ℓ 和ℓ 范数，λ 为正则化系数。p12带正则化的优化问题等价于下面带约束条件的优化问题，参见第C.1.2节。ΣN1Nθ∗ = arg minL y(n), f (x(n), θ) ,(7.60)(7.61)θn=1subject to ℓp(θ) ≤ 1.图A.1给出了不同范数约束条件下的最优化问题示例。邱锡鹏：《神经网络与深度学习》https://nndl.github.io/
 7.7 网络正则化2019 年 4 月 6 日189邱锡鹏：《神经网络与深度学习》https://nndl.github.io/
 1902019 年 4 月 6 日第7 章 网络优化与正则化θ∗Fθ邱锡鹏：《神经网络与深度学习》https://nndl.github.io/
 7.7 网络正则化2019 年 4 月 6 日191邱锡鹏：《神经网络与深度学习》https://nndl.github.io/
 1922019 年 4 月 6 日第7 章 网络优化与正则化θ∗Fθ邱锡鹏：《神经网络与深度学习》https://nndl.github.io/
 7.7 网络正则化2019 年 4 月 6 日193邱锡鹏：《神经网络与深度学习》https://nndl.github.io/
 1942019 年 4 月 6 日第7 章 网络优化与正则化θ∗Fθ邱锡鹏：《神经网络与深度学习》https://nndl.github.io/
 7.7 网络正则化p = 12019 年 4 月 6 日195p = 2p = ∞图 7.9 不同范数约束条件下的最优化问题示例，红线表示函数ℓp = 1，F 为函数f(θ)的等高线（简单起见，这里用直线表示）从图A.1可以看出，ℓ1 范数的约束通常会使得最优解位于坐标轴上，而从使得最终的参数为稀疏性向量。此外，ℓ 范数在零点不可导，因此经常下式来近似：1Σ qℓ1(θ) =θ2 + ϵ(7.62)ii其中ϵ 为一个非常小的常数。一种折中的正则化方法是弹性网络正则化（Elastic Net Regularization）[Zouand Hastie, 2005]，同时加入ℓ 和ℓ 正则化。12ΣN1Nθ∗ = arg minL y(n), f (x(n), θ) + λ ℓ (θ) + λ ℓ (θ),(7.63)112 2θn=1其中λ 和λ 分别为两个正则化项的系数。127.7.2 权重衰减权重衰减（Weight Decay）也是一种有效的正则化手段[Hanson and Pratt,1989]，在每次参数更新时，引入一个衰减系数。θt ← (1 − w)θt−1 − αgt,(7.64)其中gt 为第t 更新的梯度，α 为学习率，w 为权重衰减系数，一般取值比较小，比如0.0005。在标准的随机梯度下降中，权重衰减正则化和ℓ2 正则化的效果相同。因此，权重衰减在一些深度学习框架中通过ℓ2 正则化来实现。但是，在较为复杂的优化方法（比如Adam）中，权重衰减和ℓ2 正则化并不等价[Loshchilov andHutter, 2017]。参见习题7-4。7.7.3 提前停止提前停止（early stop）对于深层神经网络来说是一种简单有效的正则化方法。由于深层神经网络的拟合能力非常强，因此比较容易在训练集上过拟合。在邱锡鹏：《神经网络与深度学习》https://nndl.github.io/
 1962019 年 4 月 6 日第7 章 网络优化与正则化使用梯度下降法进行优化时，我们可以使用一个和训练集独立的样本集合，称为验证集（validation set），并用验证集上的错误来代替期望错误。当验证集上的错误率不再下降，就停止迭代。提 前 停 止 也 可 以 参 见第2.2.3.2节。然而在实际操作中，验证集上的错误率变化曲线并不一定是图2.4中所示的平衡曲线，很可能是先升高再降低。因此，提前停止的具体停止标准需要根据实际任务上进行优化[Prechelt, 1998]。7.7.4 丢弃法当训练一个深层神经网络时，我们可以随机丢弃一部分神经元（同时丢弃其对应的连接边）来避免过拟合，这种方法称为丢弃法（Dropout Method）[Sri-vastava et al., 2014]。每次选择丢弃的神经元是随机的。最简单的方法是设置一个固定的概率p。对每一个神经元都一个概率p 来判定要不要保留。对于一个神经层y = f (W x + b)，我们可以引入一个丢弃函数d(·) 使得y = f (Wd(x) + b)。丢弃函数d(·)的定义为m ⊙ x 当训练阶段时d(x) =(7.65)px当测试阶段时其中m ∈ {0, 1}d 是丢弃掩码（dropout mask），通过以概率为p 的贝努力分布随机生成。p 可以通过验证集来选取一个最优的值。或者p 也可以设为0.5，这对大部分的网络和任务有比较有效。在训练时，激活神经元的平均数量为原来的 p 倍。而在测试时，所有的神经元都是可以激活的，这会造成训练和测试时网络的输出不一致。为了缓解这个问题，在测试时需要将每一个神经元的输出乘以p，也相当于把不同的神经网络做了平均。图7.10给出了一个网络应用dropout 方法后的示例。邱锡鹏：《神经网络与深度学习》https://nndl.github.io/
 7.7 网络正则化2019 年 4 月 6 日197邱锡鹏：《神经网络与深度学习》https://nndl.github.io/
 1982019 年 4 月 6 日第7 章 网络优化与正则化邱锡鹏：《神经网络与深度学习》https://nndl.github.io/
 7.7 网络正则化2019 年 4 月 6 日199(a) 标准网络(b) Dropout 后的网络图 7.10 丢弃法示例一般来讲，对于隐藏层的神经元，其丢弃率p = 0.5 时效果最好。当p = 0.5时，在训练时有一半的神经元被丢弃，只剩余一半的神经元是可以激活的，随机生成的网络结构最具多样性。对于输入层的神经元，其丢弃率通常设为更接近 1 的数，使得输入变化不会太大。对输入层神经元进行丢弃时，相当于给数据增加噪声，以此来提高网络的鲁棒性。丢弃法一般是针对神经元进行随机丢弃，但是也可以扩展到对神经元之间的连接进行随机丢弃[Wan et al., 2013]，或每一层进行随机丢弃。集成学习的解释每做一次丢弃，相当于从原始的网络中采样得到一个子网络。如果一个神经网络有n 个神经元，那么总共可以采样出2n 个子网络。每次迭代都相当于训练一个不同的子网络，这些子网络都共享原始网络的参数。那么，最终的网络可以近似看作是集成了指数级个不同网络的组合模型。贝叶斯学习的解释 丢弃法也可以解释为一种贝叶斯学习的近似[Gal and Ghahra-mani, 2016a]。用y = f (x, θ) 来表示要学习的神经网络，贝叶斯学习是假设参数θ 为随机向量，并且先验分布为q(θ)，贝叶斯方法的预测为∫Eq(θ)[y] = f (x, θ)q(θ)dθ(7.66)qΣM1≈f(x, θm),(7.67)Mm=1其中f (x, θ )为第m 次应用丢弃方法后的网络，其参数θ 为对全部参数θ 的一mm次采样。邱锡鹏：《神经网络与深度学习》https://nndl.github.io/
 2002019 年 4 月 6 日第7 章 网络优化与正则化7.7.4.1 循环神经网络上的丢弃法当在循环神经网络上应用丢弃法，不能直接对每个时刻的隐状态进行随机丢弃，这样会损害循环网络在时间维度上记忆能力。一种简单的方法是对非时间维度的连接（即非循环连接）进行随机丢失[Zaremba et al., 2014]。如图7.11所示，虚线边表示进行随机丢弃，不同的颜色表示不同的丢弃掩码。邱锡鹏：《神经网络与深度学习》https://nndl.github.io/
 7.7 网络正则化2019 年 4 月 6 日yˆ2201· · ·yˆ1yˆTh1h2hT邱锡鹏：《神经网络与深度学习》https://nndl.github.io/
 2022019 年 4 月 6 日第7 章 网络优化与正则化· · ·x1x2· · ·xT图 7.11 针对非循环连接的丢弃法然而根据贝叶斯学习的解释，丢弃法是一种对参数θ 的采样。每次采样的参数需要在每个时刻保持不变。因此，在对循环神经网络上使用丢弃法时，需要对参数矩阵的每个元素进行随机丢弃，并在所有时刻都使用相同的丢弃掩码。这种方法称为变分丢弃法（Variational Dropout）[Gal and Ghahramani, 2016b]。图7.12给出了变分丢弃法的示例，相同颜色表示使用相同的丢弃掩码。邱锡鹏：《神经网络与深度学习》https://nndl.github.io/
 7.7 网络正则化2019 年 4 月 6 日yˆ2203· · ·yˆ1yˆTh1h2hT邱锡鹏：《神经网络与深度学习》https://nndl.github.io/
 2042019 年 4 月 6 日第7 章 网络优化与正则化· · ·x1x2· · ·xT图 7.12 变分丢弃法7.7.5 数据增强深层神经网络一般都需要大量的训练数据才能获得比较理想的效果。在数据量有限的情况下，可以通过数据增强（Data Augmentation）来增加数据量，提高模型鲁棒性，避免过拟合。目前，数据增强还主要应用在图像数据上，在文本等其它类型的数据还没有太好的方法。图像数据的增强主要是通过算法对图像进行转变，引入噪声等方法来增加数据的多样性。增强的方法主要有几种：• 旋转（Rotation）：将图像按顺时针或逆时针方向随机旋转一定角度；邱锡鹏：《神经网络与深度学习》https://nndl.github.io/
 7.8 总结和深入阅读2019 年 4 月 6 日193• 翻转（Flip）：将图像沿水平或垂直方法随机翻转一定角度；• 缩放（Zoom In/Out）：将图像放大或缩小一定比例；• 平移（Shift）：将图像沿水平或垂直方法平移一定步长；• 加噪声（Noise）：加入随机噪声。7.7.6 标签平滑在数据增强中，我们可以给样本特征加入随机噪声来避免过拟合。同样，我 们也可以给样本的标签引入一定的噪声。假设训练数据集中，有一些样本的标 签是被错误标注的，那么最小化这些样本上的损失函数会导致过拟合。一种改 善的正则化方法是标签平滑（Label Smoothing），即在输出标签中添加噪声来避免模型过拟合[Szegedy et al., 2016]。一个样本x 的标签一般用onehot 向量表示y = [0, · · · , 0, 1, 0,∙∙∙∙∙∙∙, 0] ,T这种标签可以看作是硬目标（Hard Targets）。如果使用softmax 分类器并使用交叉熵损失函数，最小化损失函数会使得正确类和其它类的权重差异变得很大。根据softmax 函数的性质可知，如果要使得某一类的输出概率接近于1，其未归一化的得分需要远大于其它类的得分，可能会导致其权重越来越大，并导致过拟合。此外，如果样本标签是错误的，会导致更严重的过拟合现象。为了改善这种情况，我们可以引入一个噪声对标签进行平滑，即假设样本以ϵ的概率为其它类。平滑后的标签为ϵϵϵϵy˜ = [, · · · ,, 1 − ϵ,, · · · ,]T .K − 1K − 1K − 1K − 1其中K 为标签数量，这种标签可以看作是软目标（Soft Targets）。标签平滑可以避免模型的输出过拟合到硬目标上，并且通常不会损害其分类能力。参见习题7-6。上面的标签平滑方法是给其它K − 1 个标签相同的概率 Kϵ−1，没有考虑标签之间的相关性。一种更好的做法是按照类别相关性来赋予其它标签不同的概率。比如先训练另外一个更复杂（一般为多个网络的集成）的教师网络（TeacherNetwork），并使用大网络的输出作为软目标进行训练学生网络（Student Net-work）。这种方法也称为知识精炼（Knowledge Distillation）[Hinton et al., 2015]。集成学习参见第10.1节。7.8 总结和深入阅读深层神经网络的优化和正则化是即对立又统一的关系。一方面我们希望优化算法能找到一个全局最优解（或较好的局部最优解），另一方面我们又不希望 模型优化到最优解，这可能陷入过拟合。优化和正则化的统一目标是期望风险 最小化。邱锡鹏：《神经网络与深度学习》https://nndl.github.io/
 1942019 年 4 月 6 日第7 章 网络优化与正则化在传统的机器学习中，有一些很好的理论可以帮助我们在模型的表示能力、复杂度和泛化能力之间找到比较好的平衡，比如Vapnik-Chervonenkis（VC）维[Vapnik, 1998] 和 Rademacher 复杂度[Bartlett and Mendelson, 2002]。但是这些理论无法解释深层神经网络在实际应用中的泛化能力表现。目前，深层神经网络的泛化能力还没有很好的理论支持。在传统机器学习模型上比较有效的ℓ1或 ℓ2 正则化在深层神经网络中作用也比较有限，而一些经验的做法，比如使用随机梯度下降和提前停止，会更有效。根据通用近似定理，神经网络的表示能力十分强大。从直觉上，深层神经网络很容易产生过拟合现象，因为增加的抽象层使得模型能够对训练数据中较为罕见的依赖关系进行建模[Bengio et al., 2013]。Zhang et al. [2016] 发现，虽然深层神经网络的容量足够记住所有训练数据，但依然优先记住训练数据中的一般规律，即有泛化能力的规律。近几年来，深度学习的快速发展在一定程度上也归因于一些深层神经网络的优化和正则化方法的出现。虽然这些方法往往是经验性的，但在实践中取得了很好的效果，使得我们可以高效地、端到端地训练神经网络模型，不再依赖早期训练神经网络时的预训练和逐层训练等比较低效的方法。习题α1 − ρ习题7-1 证明在动量法的更新公式(7.18)中，∆θt 实际上是相当于对−gt进行指数衰减的移动平均。习题7-2 在Adam 算法中，说明指数加权平均的偏差修正公式(??)和(??)的合理性。习题 7-3分析为什么批量归一化不能直接应用于循环神经网络。习题7-4 证明在标准的随机梯度下降中，权重衰减正则化和ℓ2 正则化的效果相同。并分析这一结论在动量法和Adam 算法中是否依然成立。习题 7-5弃法？试分析为什么不能在循环神经网络中的循环连接上直接应用丢习题 7-6若使用标签平滑正则化方法，给出其交叉熵损失函数。邱锡鹏：《神经网络与深度学习》https://nndl.github.io/
 参考文献2019 年 4 月 6 日195参考文献Lei Jimmy Ba, Ryan Kiros, and Geof-frey E. Hinton. Layer normalization. CoRR,abs/1607.06450, 2016. URL http://arxiv.org/abs/1607.06450.Yarin Gal and Zoubin Ghahramani.Dropout asabayesian approximation:Representing model uncertainty in deeplearning. In international conference onmachine learning, pages 1050–1059, 2016a.Yarin Gal and Zoubin Ghahramani. A the-oretically grounded application of dropoutin recurrent neural networks. In Advancesin neural information processing systems,pages 1019–1027, 2016b.Peter L Bartlett and Shahar Mendel-son. Rademacher and gaussian complex-ities: Risk bounds and structural results.Journal of Machine Learning Research, 3(Nov):463–482, 2002.Yoshua Bengio, Nicolas Boulanger-Lewandowski, and Razvan Pascanu.Advances in optimizing recurrent networks.In 2013 IEEE International Conference onAcoustics, Speech and Signal Processing,pages 8624–8628. IEEE, 2013.Xavier Glorot and Yoshua Bengio. Un-derstanding the diﬀculty of training deepfeedforward neural networks. In Interna-tional conference on artiﬁcial intelligenceand statistics, pages 249–256, 2010.Stephen José Hanson and Lorien Y Pratt.Comparing biases for minimal network con-struction with back-propagation. In Ad-vances in neural information processingsystems, pages 177–185, 1989.James Bergstra and Yoshua Bengio. Ran-dom search for hyper-parameter optimiza-tion. Journal of Machine Learning Re-search, 13(Feb):281–305, 2012.James S Bergstra, Rémi Bardenet, YoshuaBengio, and Balázs Kégl. Algorithms forhyper-parameter optimization. In Advancesin neural information processing systems,pages 2546–2554, 2011.Geoﬀrey Hinton, Oriol Vinyals, and JeﬀDean. Distilling the knowledge in a neuralnetwork. arXiv preprint arXiv:1503.02531,2015.Anna Choromanska, Mikael Henaﬀ,Michael Mathieu, Gérard Ben Arous, andYann LeCun. The loss surfaces of multi-layer networks. In Artiﬁcial Intelligenceand Statistics, pages 192–204, 2015.Yann N Dauphin, Razvan Pascanu, CaglarGulcehre, Kyunghyun Cho, Surya Ganguli,and Yoshua Bengio. Identifying and at-tacking the saddle point problem in high-dimensional non-convex optimization. InAdvances in neural information processingsystems, pages 2933–2941, 2014.Sepp Hochreiter and Jürgen Schmidhuber.Flat minima. Neural Computation, 9(1):1–42, 1997.Frank Hutter, Holger H Hoos, and KevinLeyton-Brown. Sequential model-based op-timization for general algorithm conﬁgura-tion. In International Conference on Learn-ing and Intelligent Optimization, pages507–523. Springer, 2011.Sergey Ioﬀe and Christian Szegedy. Batchnormalization: Accelerating deep networktraining by reducing internal covariate shift.In Proceedings of the 32nd InternationalConference on Machine Learning, pages448–456, 2015.Timothy Dozat. Incorporating nesterov mo-mentum into adam. In ICLR Workshop,2016.John Duchi, Elad Hazan, and Yoram Singer.Adaptive subgradient methods for onlinelearning and stochastic optimization. TheJournal of Machine Learning Research, 12:2121–2159, 2011.Kevin Jamieson and Ameet Talwalkar.Non-stochastic best arm identiﬁcation andhyperparameter optimization. In ArtiﬁcialIntelligence and Statistics, pages 240–248,2016.邱锡鹏：《神经网络与深度学习》https://nndl.github.io/
 1962019 年 4 月 6 日参考文献Diederik Kingma and Jimmy Ba. Adam:A method for stochastic optimization. InProceedings of International Conference onLearning Representations, 2015.in neural information processing systems,pages 2951–2959, 2012.Jasper Snoek, Oren Rippel, Kevin Swersky,Ryan Kiros, Nadathur Satish, NarayananSundaram, Mostofa Patwary, Mr Prabhat,and Ryan Adams. Scalable bayesian opti-mization using deep neural networks. In In-ternational Conference on Machine Learn-ing, pages 2171–2180, 2015.Alex Krizhevsky, Ilya Sutskever, and Ge-oﬀrey E Hinton. Imagenet classiﬁcationwith deep convolutional neural networks. InAdvances in neural information processingsystems, pages 1097–1105, 2012.Hao Li, Zheng Xu, Gavin Taylor, andTom Goldstein. Visualizing the loss land-scape of neural nets. arXiv preprintarXiv:1712.09913, 2017a.Nitish Srivastava, Geoﬀrey Hinton, AlexKrizhevsky, Ilya Sutskever, and RuslanSalakhutdinov.Dropout: A simple wayto prevent neural networks from overﬁtting.The Journal of Machine Learning Research,15(1):1929–1958, 2014.Lisha Li, Kevin Jamieson, Giulia De-Salvo, Afshin Rostamizadeh, and AmeetTalwalkar. Hyperband: Bandit-based con-ﬁguration evaluation for hyperparameteroptimization. In Proceedings of 5th Inter-national Conference on Learning Represen-tations, 2017b.Ilya Sutskever, James Martens, GeorgeDahl, and Geoﬀrey Hinton. On the im-portance of initialization and momentumin deep learning. In International confer-ence on machine learning, pages 1139–1147,2013.Ilya Loshchilov and Frank Hutter. Fixingweight decay regularization in adam. arXivpreprint arXiv:1711.05101, 2017.Christian Szegedy, Vincent Vanhoucke,Sergey Ioﬀe, Jon Shlens, and ZbigniewYu Nesterov. Gradient methods for mini-mizing composite functions. MathematicalProgramming, 140(1):125–161, 2013.Razvan Pascanu, Tomas Mikolov, andYoshua Bengio. On the diﬀculty of trainingrecurrent neural networks. In Proceedingsof the International Conference on MachineLearning, pages 1310–1318, 2013.Wo- jna. Rethinking theinceptionarchitec- ture for computer vision. InProceedings of the IEEE Conference onComputer Vision and Pattern Recognition,pages 2818–2826, 2016.Tijmen Tieleman and Geoﬀrey Hinton.Lec- ture 6.5-rmsprop: Divide thegradient bya running average of its recentmagnitude. COURSERA: Neural networksfor machinelearning, 2012.Lutz Prechelt. Early stopping-but when? InNeural Networks: Tricks of the trade, pages55–69. Springer, 1998.Vladimir Vapnik. Statistical learning the-ory. Wiley, New York, 1998.David E Rumelhart, Geoﬀrey E Hinton,and RonaldJWilliams.LearningLi Wan, Matthew Zeiler, Sixin Zhang, YannLe Cun, and Rob Fergus. Regularization ofneural networks using dropconnect. In In-ternational Conference on Machine Learn-ing, pages 1058–1066, 2013.representa- tions by back-propagatingerrors. Cognitivemodeling, 5:3, 1988.Tim Salimans and DiederikP Kingma.Weight normalization: A simple reparame-terization to accelerate training of deep neu-ral networks. In Advances in Neural Infor-mation Processing Systems, pages 901–909,2016.Wojciech Zaremba, Ilya Sutskever, andOriol Vinyals.Recurrent neural net-work regularization.arXiv preprintarXiv:1409.2329, 2014.Jasper Snoek, Hugo Larochelle, and Ryan PAdams. Practical bayesian optimization ofmachine learning algorithms. In AdvancesMatthew D Zeiler. Adadelta: An adap-tive learning rate method. arXiv preprintarXiv:1212.5701, 2012.邱锡鹏：《神经网络与深度学习》https://nndl.github.io/
 参考文献2019 年 4 月 6 日197Chiyuan Zhang, Samy Bengio, MoritzHardt, Benjamin Recht, and Oriol Vinyals.Understanding deep learning requires re-thinking generalization. arXiv preprintarXiv:1611.03530, 2016.In Proceedings of 5th International Confer-ence on Learning Representations, 2017.Hui Zou and Trevor Hastie. Regularizationand variable selection via the elastic net.Journal of the Royal Statistical Society: Se-ries B (Statistical Methodology), 67(2):301–320, 2005.Barret Zoph and Quoc V Le. Neural archi-tecture search with reinforcement learning.邱锡鹏：《神经网络与深度学习》https://nndl.github.io/
 

 第8 章 注意力机制与外部记忆智慧的艺术是知道该忽视什么。— 威廉·詹姆斯根据通用近似定理，前馈网络和循环网络都有很强的能力。但由于优化算法和计算能力的限制，在实践中很难达到通用近似的能力。特别是在处理复杂任务时，比如需要处理大量的输入信息或者复杂的计算流程时，目前计算机的计算能力依然是限制神经网络发展的瓶颈。为了减少计算复杂度，通过部分借鉴生物神经网络的一些机制，我们引入了局部连接、权重共享以及汇聚操作来简化神经网络结构。虽然这些机制可以有效缓解模型的复杂度和表达能力之间的矛盾，但是我们依然希望在不“过度”增加模型复杂度（主要是模型参数）的情况下来提高模型的表达能力。以阅读理解任务为例，给定的背景文章（background document）一般比较长，如果用循环神经网络来将其转换为向量表示，那么这个编码向量很难反映出背景文章的所有语义。在比较简单的文本分类任务中，只需要编码一些对分类有用的信息，因此用一个向量来表示文本语义来行得通。但是在阅读理解任务中，编码时还不知道可能会接收到什么样的问句。这些问句可能会涉及到背景文章的所有信息点，因此丢失任何信息都可能导致无法正确回答问题。阅读理解任务是让机器阅读一篇背景文章，然后询问一些相关的问题，来测试机器是否理解了这篇文章。在循环神经网络中，丢失信息的另外一个因素是远距离依赖问题。神经网络中可以存储的信息量称为网络容量（Network Capacity）。一般来讲，利用一组神经元来存储信息的容量和神经元的数量以及网络的复杂度成正比。如果要存储越多的信息，神经元数量就要越多或者网络要越复杂，进而导致神经网络的参数成倍地增加。我们人脑的生物神经网络同样存在网络容量问题，人脑中的工作记忆大概只有几秒钟的时间，类似于循环神经网络中的隐状态。而人脑每个时刻接收的外界输入信息非常多，包括来源于视觉、听觉、触觉的各种各样的信息。但就视觉来说，眼睛每秒钟都会发送千万比特的信息给视觉神经系统。人脑在有限
 2002019 年 4 月 6 日第8 章 注意力机制与外部记忆的资源下，并不能同时处理这些过载的输入信息。大脑神经系统有两个重要机制可以解决信息过载问题：注意力和记忆机制。我们可以借鉴人脑解决信息过载的机制，从两方面来提高神经网络处理信息的能力。一方面是注意力，通过自上而下的信息选择机制来过滤掉大量的无关信息；另一方面是引入额外的外部记忆，优化神经网络的记忆结构来提高神经网络存储信息的容量。8.1 注意力在计算能力有限情况下，注意力机制（Attention Mechanism）是解决信息超载问题的主要手段的一种资源分配方案，将计算资源分配给更重要的任务。8.1.1 认知神经学中的注意力注意力是一种人类不可或缺的复杂认知功能，指人可以在关注一些信息的同时忽略另一些信息的选择能力。在日常生活中，我们通过视觉、听觉、触觉等方式接收大量的感觉输入。但是人脑可以在这些外界的信息轰炸中还能有条不紊地工作，是因为人脑可以有意或无意地从这些大量输入信息中选择小部分的有用信息来重点处理，并忽略其他信息。这种能力就叫做注意力。注意力可以体现在外部的刺激（听觉、视觉、味觉等），也可以体现在内部的意识（思考、回忆等）。注意力一般分为两种：一种是自上而下的有意识的注意力，称为聚焦式（focus）注意力。聚焦式注意力是指有预定目的、依赖任务的、主动有意识地聚焦于某一对象的注意力；另一种是自下而上的无意识的注意力，称为基于显著性（saliency-based）的注意力。基于显著性的注意力是由外界刺激驱动的注意，不需要主动干预，也和任务无关。如果一个对象的刺激信息不同于其周围信息， 一种无意识的“赢者通吃”（winner-take-all）或者门控（gating）机制就可以把注意力转向这个对象。不管这些注意力是有意还是无意，大部分的人脑活动都需要依赖注意力，比如记忆信息，阅读或思考等。一个和注意力有关的例子是鸡尾酒会效应。当一个人在吵闹的鸡尾酒会上和朋友聊天时，尽管周围噪音干扰很多，他还是可以听到朋友的谈话内容，而忽略其他人的声音（聚焦式注意力）。同时，如果未注意到的背景声中有重要的词（比如他的名字），他会马上注意到（显著性注意力）。除非特别声明，本节及以后章节中注意力机制是通常指自上而下的聚焦式注意力。聚焦式注意力一般会随着环境、情景或任务的不同而选择不同的信息。比如当要从人群中寻找某个人时，我们会将专注于每个人的脸部；而当要统计人群的人数时，我们只需要专注于每个人的轮廓。邱锡鹏：《神经网络与深度学习》https://nndl.github.io/
 8.1 注意力2019 年 4 月 6 日2018.1.2 人工神经网络中的注意力机制当用神经网络来处理大量的输入信息时，也可以借鉴人脑的注意力机制，只选择一些关键的信息输入进行处理，来提高神经网络的效率。在目前的神经网络模型中，我们可以将最大汇聚（max pooling）、门控（gating）机制来近似地看作是自下而上的基于显著性的注意力机制。除此之外，自上而下的会聚式注意力也是一种有效的信息选择方式。以阅读理解任务为例，给定一篇很长的文章，然后就此文章的内容进行提问。提出的问题只和段落中的一两个句子相关， 其余部分都是无关的。为了减小神经网络的计算负担，只需要把相关的片段挑选出来让后续的神经网络来处理，而不需要把所有文章内容都输入给神经网络。注意力机制也可称为注意力模型。用 X = [x , · · · , x ] 表示N 个输入信息，为了节省计算资源，不需要将所1N有的N 个输入信息都输入到神经网络进行计算，只需要从X 中选择一些和任务相关的信息输入给神经网络。注意力机制的计算可以分为两步：一是在所有输入信息上计算注意力分布，二是根据注意力分布来计算输入信息的加权平均。注意力分布 给定一个和任务相关的查询向量 q，我们用注意力变量 ꢀ ∈ [1, N ]来表示被选择信息的索引位置，即ꢀ = i 表示选择了第i 个输入信息。为了方便计算，我们采用一种“软性”的信息选择机制，首先计算在给定q 和X 下，选择第i 个输入信息的概率αi，查询向量 q 可以是动态生成的，也可以是可学习的参数。αi = p(ꢀ = i|X, q)= softmax s(xi, q)exp s(xi, q)(8.1)=ΣN,exp (x q),jsj=1其中α 称为注意力分布（Attention Distribution），s(x, q)为注意力打分函数，ii可以使用以下几种方式来计算：加性模型点积模型s(xi, q) = vTtanh(W xi + U q),(8.2)(8.3)s(xi, q) = xTq,ixTiq缩放点积模型双线性模型s(x , q) = √,(8.4)ids(xi, q) = xTiW q,(8.5)其中W, U, v为可学习的网络参数，d为输入信息的维度。理论上，加性模型和点积模型的复杂度差不多，但是点积模型在实现上可以更好地利用矩阵乘积，从而计算效率更高。但当输入信息的维度d比较高，点积模型的值通常有比较大方差，从而导致softmax 函数的梯度会比较小。因此，缩放点积模型可以较好地参见习题8.4。邱锡鹏：《神经网络与深度学习》https://nndl.github.io/
 2022019 年 4 月 6 日第8 章 注意力机制与外部记忆解决这个问题。双线性模型可以看做是一种泛化的点积模型。假设公式(8.5)中W = U V ，双线性模型可以写为s(x , q) = x U V q = (U x) (V q)，即分别TTiTTi对 x 和 q 进行线性变换后计算点积。相比点积模型，双线性模型在计算相似度时引入了非对称性。加权平均 注意力分布αi 可以解释为在给定任务相关的查询q 时，第i 个信息受关注的程度。我们采用一种“软性”的信息选择机制对输入信息进行汇总，ΣNatt(X, q) =α x ,(8.6)(8.7)iii= 1= Eꢀ∼p(ꢀ|X ,q)[x].公式(8.7) 称为软性注意力机制（Soft Attention Mechanism）。图8.1a给出软性注意力机制的示例。aa邱锡鹏：《神经网络与深度学习》https://nndl.github.io/
 8.1 注意力2019 年 4 月 6 日203+××···×邱锡鹏：《神经网络与深度学习》https://nndl.github.io/
 ××···×2042019 年 4 月 6 日第8 章 注意力机制与外部记忆α1 v1α2 v2softmaxsαNα1α2··· αN···softmaxsssss······qq···x1x2··· xNk1k2kN(a) 普通模式(b) 键值对模式图 8.1 注意力机制8.1.3 注意力机制的变体除了上面介绍的基本模式外，注意力机制还存在一些变化的模型。8.1.3.1 硬性注意力公式(8.7)提到的注意力是软性注意力，其选择的信息是所有输入信息在注 意力分布下的期望。此次，还有一种注意力是只关注到某一个位置上的信息，叫 做硬性注意力（Hard Attention）。硬性注意力有两种实现方式：邱锡鹏：《神经网络与深度学习》https://nndl.github.io/
 8.1 注意力2019 年 4 月 6 日205（1） 一种是选取最高概率的输入信息，即att(X, q) = xj ,(8.8)其中j 为概率最大的输入信息的下标，即j = arg maxα。Nii= 1（2） 另一种硬性注意力可以通过在注意力分布式上随机采样的方式实现。硬性注意力的一个缺点是基于最大采样或随机采样的方式来选择信息。因此最终的损失函数与注意力分布之间的函数关系不可导，因此无法使用在反向传播算法进行训练。为了使用反向传播算法，一般使用软性注意力来代替硬性注意力。硬性注意力需要通过强化学习来进行训练。8.1.3.2 键值对注意力更一般地，我们可以用键值对（key-value pair）格式来表示输入信息，其中“键”用来计算注意力分布αi，“值”用来计算聚合信息。用 (K, V ) = [(k , v ), · · · , (k , v )] 表示N 个输入信息，给定任务相关的11NN查询向量q 时，注意力函数为Natt (K, V , ) q= α v ,(8.9)iii=1ΣNexp s(ki, q)vi,Σ(8.10)=exp (k q)s,ji=1j其中s(ki, q) 为打分函数。图8.1b给出键值对注意力机制的示例。当K = V 时，键值对模式就等价于普通的注意力机制。8.1.3.3 多头注意力多头注意力（Multi-Head Attention）是利用多个查询Q = [q1, · · · , qM ]，来平行地计算从输入信息中选取多个信息。每个注意力关注输入信息的不同部分。att (K, V ), Q = att (K, V ), q1 ⊕ · · · ⊕ att (K, V ), qM其中⊕ 表示向量拼接。8.1.3.4 结构化注意力,(8.11)要从输入信息中选取出和任务相关的信息，主动注意力是在所有输入信息上的多项分布，是一种扁平（ﬂat）结构。如果输入信息本身具有层次（hierarchical）结构，比如文本可以分为词、句子、段落、篇章等不同粒度的层次，我们可以邱锡鹏：《神经网络与深度学习》https://nndl.github.io/
 2062019 年 4 月 6 日第8 章 注意力机制与外部记忆使用层次化的注意力来进行更好的信息选择[Yang et al., 2016]。此外，还可以假设注意力上下文相关的二项分布，用一种图模型来构建更复杂的结构化注意力分布[Kim et al., 2017]。8.2 注意力机制的应用注意力机制一般可以用作一个神经网络中的组件。8.2.1 指针网络注意力机制主要是用来做信息筛选，从输入信息中选取相关的信息。注意力机制可以分为两步：一是计算注意力分布α，二是根据α 来计算输入信息的加权平均。我们可以只利用注意力机制中的第一步，将注意力分布作为一个软性的指针（pointer）来指出相关信息的位置。指针网络（Pointer Network）[Vinyals et al., 2015] 是一种序列到序列模型，输入是长度为n的向量序列X = x , · · · , x ，输出是下标序列c= c , c , · · · , c ，1 m21n1:mci ∈ [1, n], ∀i。和一般的序列到序列任务不同，这里的输出序列是输入序列的下标（索引）。 比如输入一组乱序的数字，输出为按大小排序的输入数字序列的下标。比如输入为20, 5, 10，输出为1, 3, 2。条件概率p(c1:m|x1:n) 可以写为Ymp(c1:m x| 1:n) =p(ci |c1:i−1, x1:n)(8.12)(8.13)i=1Ym≈p(c x , · · · , xci−1i= 1|, x ),1:nic1其中条件概率p(ci|x , · · · , x, x1:n ) 可以通过注意力分布来计算。假设用一c1ci− 1个循环神经网络对x , · · · , xci− 1 , x1:n 进行编码得到向量hi，则c1p(ci|c1:i−1, x1:n ) = softmax(si,j ),其中si,j 为在解码过程的第i 步时，每个输入向量的未归一化的注意力分布，si,j = vT tanh(W x + Uh ), ∀j ∈ [1, n],(8.15)(8.14)ji其中v, W, U 为可学习的参数。图8.2给出了指针网络的示例。邱锡鹏：《神经网络与深度学习》https://nndl.github.io/
 8.2 注意力机制的应用2019 年 4 月 6 日205邱锡鹏：《神经网络与深度学习》https://nndl.github.io/
 22082019 年 4 月 6 日第8 章 注意力机制与外部记忆31h0h1h2h3h4h5h6h7邱锡鹏：《神经网络与深度学习》https://nndl.github.io/
 <20510>20105编码器解码器图 8.2 指针网络8.2.2 自注意力模型当使用神经网络来处理一个变长的向量序列时，我们通常可以使用卷积网络或循环网络进行编码来得到一个相同长度的输出向量序列，如图8.3所示。邱锡鹏：《神经网络与深度学习》https://nndl.github.io/
 h1x1h2x2h3210h4x4h5x52019 年 4 月 6 日第8 章 注意力机制与外部记忆x3邱锡鹏：《神经网络与深度学习》https://nndl.github.io/
 (a) 卷积网络(b) 双向循环网络图 8.3 基于卷积网络和循环网络的变长序列编码基于卷积或循环网络的序列编码都是可以看做是一种局部的编码方式，只建模了输入信息的局部依赖关系。虽然循环网络理论上可以建立长距离依赖关系，但是由于信息传递的容量以及梯度消失问题，实际上也只能建立短距离依赖关系。如果要建立输入序列之间的长距离依赖关系，可以使用以下两种方法：一种方法是增加网络的层数，通过一个深层网络来获取远距离的信息交互另一种方法是使用全连接网络。全连接网络是一种非常直接的建模远距离依赖的模型，但是无法处理变长的输入序列。不同的输入长度，其连接权重的大小也是不同的。这时我们就可以利用注意力机制来“动态”地生成不同连接的权重，这就是自注意力模型（Self-Attention Model）。自注意力也称为内部注意力假设输入序列为X = [x , · · · , x ] ∈ Rd ×N，输出序列为H = [h , · · · , h ] ∈（Intra-Attention）。11N1N邱锡鹏：《神经网络与深度学习》https://nndl.github.io/

 2062019 年 4 月 6 日第8 章 注意力机制与外部记忆Rd2×N ，首先我们可以通过线性变换得到三组向量序列：Q = W X ∈ Rd ×N ,(8.16)(8.17)(8.18)3QK = W X ∈ Rd ×N ,3KV = W X ∈ Rd ×N ,2V其中Q, K, V 分别为查询向量序列，键向量序列和值向量序列，W , W , W 分QKV别为可学习的参数矩阵。利用公式(8.9)，可以得到输出向量hi，hi = att (K , V ), qi(8.19)ΣN==αijvj(8.20)j=1ΣNsoftmax s(k , q ) vj(8.21)jij=1其中i, j ∈ [1, N ] 为输出和输入向量序列的位置，连接权重αij 由注意力机制动态生成。如果使用缩放点积来作为注意力打分函数，输出向量序列可以写为K Qd3TH = V softmax( √ ),(8.22)其中softmax 为按列进行归一化的函数。图8.4给出全连接模型和自注意力模型的对比，其中实线表示为可学习的权重，虚线表示动态生成的权重。由于自注意力模型的权重是动态生成的，因此可以处理变长的信息序列。邱锡鹏：《神经网络与深度学习》https://nndl.github.io/
 h1x1h2x2h3x3h4h58.3 外部记忆2019 年 4 月 6 日207x4x5邱锡鹏：《神经网络与深度学习》https://nndl.github.io/
 2082019 年 4 月 6 日第8 章 注意力机制与外部记忆(b) 自注意力模型(a) 全连接模型图 8.4 全连接模型和自注意力模型自注意力模型可以作为神经网络中的一层来使用，既可以用来替换卷积层和循环层[Vaswani et al., 2017]，也可以和它们一起交替使用[Shen et al., 2018]（比如X 可以是卷积层或循环层的输出）。自注意力模型计算的权重αij 只依赖参见习题8-3。邱锡鹏：《神经网络与深度学习》https://nndl.github.io/
 8.3 外部记忆2019 年 4 月 6 日209qi 和kj 的相关性，而忽略了输入信息的位置信息。因此在单独使用时，自注意力模型一般需要加入位置编码信息来进行修正[Vaswani et al., 2017]。8.3 外部记忆为了增强网络容量，我们可以引入辅助记忆单元，将一些信息保存辅助记忆中，在需要时再进行读取，这样可以有效地增加网络容量。这个引入辅助记忆单元一般称为外部记忆（External Memory），以区别与循环神经网络的内部记忆（即隐状态）。以循环神经网络为例，其内部记忆可以类比于计算机的寄存器，外部记忆可以类比于计算机的内存。8.3.1 人脑中的记忆在生物神经网络中，记忆是外界信息在人脑中存储机制。大脑记忆毫无疑问是通过生物神经网络实现的。虽然其机理目前还无法解释，但直观上记忆机制和神经网络的连接形态以及神经元的活动相关。生理学家发现信息是作为一种整体效应（collective eﬀect）存储在大脑组织中。当大脑皮层的不同部位损伤时，其导致的不同行为表现似乎取决于损伤的程度而不是损伤的确切位置[Kohonen, 2012]。大脑组织的每个部分似乎都携带一些导致相似行为的信息。也就是说，记忆在大脑皮层是分布式存储的，而不是存储于某个局部区域[Thompson, 1975]。人脑中的记忆具有周期性和联想性。记忆周期不同脑区参与了记忆形成的几个阶段。人脑记忆的一个特点记忆一般分为长期记忆和短期记忆。长期记忆（Long-Term Memory），也称为结构记忆或知识虽然人脑记忆的存储机制还不清楚，但是在我们已经大概可以确定（Knowledge），体现为神经元之间的连接形态，其更新速度比较慢。短期记忆（Short-Term Memory）体现为神经元的活动，更新较快，维持时间为几秒至几分钟。短期记忆是神经连接的暂时性强化，通过不断巩固、强化可形成长期记忆。短期记忆、长期记忆的动态更新过程称为演化（Evolution）过程。因此，长期记忆可以类比于人工神经网络中的权重参数，而短期记忆可以类比于人工神经网络中的隐状态。事实上，人脑记忆周期的划分并没有清晰的界限，也存在其它的划分方法。除了长期记忆和短期记忆，人脑中还会存在一个“缓存”，称为工作记忆（Working Memory）。在执行某个认知行为（比如记下电话号码，算术运算）时，工作记忆是一个记忆的临时存储和处理系统，维持时间通常为几秒钟。从时间上看，工作记忆也是一种短期记忆，但和短期记忆的内涵不同。短期记忆一般指外界的输入信息在人脑中的表示和短期存储，不关心这些记忆如何被使用；而工作记忆是一个和任务相关的“容器”，可以临时存放和某项任务相关的短期记忆和其它相关的内在记忆。工作记忆的容量一般都比较小，一般可以容纳4组项目。邱锡鹏：《神经网络与深度学习》https://nndl.github.io/
 2102019 年 4 月 6 日第8 章 注意力机制与外部记忆作为不严格的类比，现代计算机的存储也可以按照不同的周期分为不同的存储单元，比如寄存器、内存、外存（比如硬盘等）。联想记忆 大脑记忆的一个主要特点是通过联想来进行检索的。联想记忆（AssociativeMemory）是指一种学习和记住不同对象之间关系的能力，比如看见一个人然后想起他的名字，或记住某种食物的味道等。联想记忆是指一种可以通过内容匹配的方法进行寻址的信息存储方式，也称为基于内容寻址的存储（Content-Addressable Memory，CAM）。作为对比，现代计算机的存储方式根据地址来进行存储的，称为随机访问存储（Random Access Memory，RAM）。联想记忆是一个人工智能、计算机科学和认知科学等多个交叉领域的热点研究问题，不同学科中的内涵也不太相同。和之前介绍的LSTM并且不直接参与计算，通过读写接口来进行操作。而LSTM包含了信息存储和计算两种功能，不能存储太多的信息。因此，LSTM中的记忆单元相比，外部记忆可以存储更多的信息，模型中的记忆单元中的记忆单元可以类比于计算机中寄存器，而外部记忆可以类比于计算机中的存储器： 内存、磁带或硬盘等。借鉴人脑中工作记忆，可以在神经网络中引入一个外部记忆单元来提高网络容量。外部记忆的实现途径有两种：一种是结构化的记忆，这种记忆和计算机中的信息存储方法比较类似，可以分为多个记忆片段，并按照一定的结构来存储；另一种是基于神经动力学的联想记忆，这种记忆方式具有更好的生物学解释性。图8.1给出了不同领域中记忆模型的不严格类比。记忆周期计算机人脑神经网络短期中期长期寄存器内存短期记忆工作记忆长期记忆状态（神经元活性）外部记忆外存可学习参数存储方式随机寻址内容寻址内容寻址为主表 8.1 不同领域中记忆模型的不严格类比8.3.2 结构化的外部记忆为了增强网络容量，一种比较简单的方式是引入结构化的记忆模块，将和任 务相关的短期记忆保存在记忆中，需要时再进行读取。这种装备外部记忆的神经 网络也称 为 记 忆 网 络 （ Memory Network， MN） 或 记 忆 增 强 神 经 网 络 （ MemoryAugmented Neural Network，MANN）。邱锡鹏：《神经网络与深度学习》https://nndl.github.io/
 8.3 外部记忆2019 年 4 月 6 日211记忆网络结构如图8.5所示，一般有以下几个模块构成：外部记忆 M读操作 R写操作 Wxy主网络（控制器）C图 8.5 记忆网络结构1. 主网络C：也称为控制器（Controller），负责信息处理，并与外界的交互（接受外界的输入信息并产生输出到外界）。主网络还同时通过读写模块和外部记忆进行交互。2. 外部记忆单元M：外部记忆单元用来存储信息，一般可以分为很多记忆片段（Memory Segment），这些记忆片段按照一定的结构来进行组织。记忆片段 一般用向量来表示，外部记忆单元可以用一组向量m1:N = [m , · · · , m ]来表1N示。这些向量的组织方式可以是集合、树、栈或队列等。大部分信息存储于外部记忆中，不需要全时参与主网络的运算。3. 读取模块R：根据主网络生成的查询向量qr，从外部记忆单元中读取相应的信息r = R(m1:N ,qr)。4. 写入模块W ：根据主网络生成的查询向量qw 和要写入的信息a 来更新外部记忆m1:N = W (m1:N ,qw, a)。这种结构化的外部记忆是带有地址的，即每个记忆片段都可以按地址读取和写入。要实现类似于人脑神经网络的联想记忆能力，就需要按内容寻址的方式进行定位，然后进行读取或写入操作。按内容寻址通常使用注意力机制来进行。通过注意力机制可以实现一种“软性”的寻址方式，即计算一个在所有记忆片段上的分布，而不是一个单一的绝对地址。比如读取模型R 的实现方式可以为：ΣNr =αimi(8.23)(8.24)i= 1α = softmax s(m , q ) ,iir其中qr 是主网络生成的查询向量，s(·, ·) 为打分函数。类比于计算机的存储器读取，计算注意力分布的过程相当于是计算机的“寻址”过程，信息加权平均邱锡鹏：《神经网络与深度学习》https://nndl.github.io/
 2122019 年 4 月 6 日第8 章 注意力机制与外部记忆的过程相当于计算机的“内容读取”过程。因此，结构化的外部记忆也是一种联想记忆，只是其结构以及读写的操作方式更像是受计算机架构的启发。通过引入外部记忆，可以将神经网络的参数和记忆容量的“分离”，即在少 量增加网络参数的条件下可以大幅增加网络容量。注意力机制可以看做是一个 接口，将信息的存储与计算分离。8.3.3 典型的记忆网络外部记忆从记忆结构、读写方式等方面可以演变出很多模型。比较典型的结构化外部记忆模型包括端到端记忆网络、神经图灵机等。8.3.3.1 端到端记忆网络端到端记忆网络（End-To-End Memory Network，MemN2N）[Sukhbaataret al., 2015] 采用一种可微的网络结构，可以多次从外部记忆中读取信息。在端到端记忆网络中，外部记忆单元是只读的。给定一组需要存储的信息m1:N = {m , · · · , m }，首先将转换成两组记忆片1N段 A = [a , · · · , a ] 和 C = [c , · · · , c ]，分别存放在两个外部记忆单元中， 其1N1N中 A 用来进行寻址，C 用来进行输出。简单起见，这两组记忆单元可以合并，即 A = C。主网络根据输入 x 生成 q，并使用注意力机制来从外部记忆中读取相关信息r，Nr =Tsoftmax(aii= 1qc, (8.25)i并产生输出y = f (q + r),(8.26)其中f(·) 为预测函数。当应用到分类任务时，f(·) 可以设为softmax 函数。多跳操作 为了实现更新复杂的计算，我们可以让主网络和外部记忆进行多轮交互。在第k 轮交互中，主网络根据上次从外部记忆中读取的信息r(k−1)，产生新的查询向量q(k) = r(k−1) + q(k−1),其中q(0) 为初始的查询向量，r(0) = 0。(8.27)假设第k 轮交互的外部记忆为A(k) 和 C(k)，主网络从外部记忆读取信息为ΣNr(k) = softmax((ai(k))q(k))c(k).i(8.28)Ti=1邱锡鹏：《神经网络与深度学习》https://nndl.github.io/
 8.3 外部记忆2019 年 4 月 6 日213在K 轮交互后，用y = f (q(K ) + (K ))r进行预测。这种多轮的交互方式也称为多跳（Multi-Hop）操作。多跳操作中的参数一般是共享的。为了简化起见，每轮交 互 的外部记忆也可以共享使用，比如A(1) = · · · = A(K) 和 C(1) = · · · = C(K)。端到端记忆网络结构如图8.6所示。m1:N邱锡鹏：《神经网络与深度学习》https://nndl.github.io/
 2142019 年 4 月 6 日A(2) C(2)第8 章 注意力机制与外部记忆A(1) C(1)A(3) C(3)r(1)Σr(2)Σr(3)Σq(1)q(2)q(3)ffyx图 8.6 端到端记忆网络8.3.3.2 神经图灵机图灵机 图灵机（Turing Machine）是图灵在1936 年提出的一种抽象数学模型，可以用来模拟任何可计算问题[Turing, 1937]。图灵机有以下几个组件构成：1. 一条无限长的纸带：纸带上有一个个方格组成，每个方格可以存储一个符号；2. 一个符号表：纸带上可能出现的所有符号的集合，包含一个特殊的空白符。3. 一个读写头：指向纸带上某个方格的指针，每次可以向左或右移动一个位置，并可以读取、擦除、写入当前方格中的内容；4. 一个状态寄存器：用来保存图灵机当前所处的状态，其中包含两个特殊的状态：起始状态和终止状态；5. 一套控制规则：根据当前机器所处的状态以及当前读写头所指的方格上的 符号来确定读写头下一步的动作，令机器进入一个新的状态。图灵机的结构如图8.7所示，其中控制器包括状态寄存器、控制规则。邱锡鹏：《神经网络与深度学习》https://nndl.github.io/
 8.3 外部记忆2019 年 4 月 6 日215纸带……读写头控制器图 8.7 图灵机结构示例神经图灵机 神经图灵机（Neural Turing machine，NTM）[Graves et al., 2014]主要由两个部件构成：控制器和外部记忆。外部记忆定义为矩阵M ∈ Rd×N ，这里 N 是记忆片段的数量，d 是每个记忆片段的大小。控制器为一个前馈或循环神经网络。神经图灵机中的外部记忆是可以可读写的，其结构如图8.8所示。邱锡鹏：《神经网络与深度学习》https://nndl.github.io/
 M t+1rtM t2019 年 4 月 6 日第8 章 注意力机制与外部记忆写读α t寻址qtetatht控制器xtrt−1ht−1邱锡鹏：《神经网络与深度学习》https://nndl.github.io/
 8.3 外部记忆2019 年 4 月 6 日217图 8.8 神经图灵机示例在每个时刻t，控制器接受当前时刻的输入xt，上一时刻的输出ht−1 和上一时刻从外部记忆中读取的信息r ，并产生输出h ，同时生成和读写外部记t−1t忆相关的三个向量：查询向量q ，删除向量e 和增加向量a 。然后对外部记忆tttM 进行读写操作，生成读向量r ，和新的外部记忆Mt+1。tt邱锡鹏：《神经网络与深度学习》https://nndl.github.io/
 2182019 年 4 月 6 日第8 章 注意力机制与外部记忆读操作 在时刻t, 外部记忆的内容记为M = [m , · · · , m ]，读操作为从外部tt,1t,n记 忆 M 中读取信息r ∈ Rd。tt神经图灵机中还实现了比较复杂的基于位置的寻址方式。这里我们只介绍比较简单的基于内容寻址方式，整个框架不变。首先通过注意力机制来进行基于内容的寻找，即αt,i = softmax(s(m , q ))(8.29)t,it其中q 为控制器产生的查询向量，用来进行基于内容的寻址。s(·, ·)为加性或乘tΣni=1αt,i =性的打分函数。注意力分布αt,i 是记忆片段mt,i 对应的权重，并满足1。根据注意力分布α ，可以计算读向量（read vector）r 作为下一个时刻控tt制器的输入。Σnrt =αimt,i.(8.30)i= 1写操作外部记忆的写操作可以分解为两个子操作：删除和增加。首先，控制器产生删除向量（erase vector）e 和增加向量（add vector）a ，tt分别为要从外部记忆中删除的信息和要增加的信息。删除操作是根据注意力分布来按比例地在每个记忆片段中删除et，增加操作根据注意力分布来进行按比例地给每个记忆片段加入at。mt+1,i = m (1 − α e ) + α a , ∀i ∈ [1, n].(8.31)t,it,itt,it通过写操作得到下一时刻的外部记忆Mt+18.3.4 基于神经动力学的联想记忆。结构化的外部记忆更多是受现代计算机架构的启发，将计算和存储功能进行分离，这些外部记忆的结构也缺乏生物学的解释性。为了具有更好的生物学解释性，还可以将基于神经动力学（Neurodynamics）的联想记忆模型引入到神 经网络以增加网络容量。神经动力学是将神经网络作为非线性动力系统，研究其随时间变化的规律以及稳定性等问题。联想记忆模型（Associative Memory Model）主要是通过神经网络的动态演化来进行联想，有两种应用场景：1）输入的模式和输出的模式在同一空间，这种模型叫做自联想记忆模型（Auto-Associative Model）。自联想模型可以通过前馈神经网络或者循环神经网络来实现，也经常称为自编码器（Auto-Encoder）；2）输入的模式和输出的模式不在同一空间，这种模型叫做异联想记忆模型（Hetero-Associative Model）。从广义上讲，大部分模式识别问题都可以看作是异联想，因此异联想记忆模型可以作为分类器使用。联想记忆模型可以看做是一种循环神经网络，基于神经动力学来实现按内容寻址的信息存储和检索。一个经典的联想记忆模型为Hopﬁeld 网络。邱锡鹏：《神经网络与深度学习》https://nndl.github.io/
 8.3 外部记忆2019 年 4 月 6 日2198.3.4.1 Hopﬁeld 网络本书中之前介绍的神经网络都是作为一种机器学习模型的输入-输出映射函数，其参数学习方法是通过梯度下降方法来最小化损失函数。除了作为机器学习模型外，神经网络还可以作为一种记忆的存储和检索模型。Hopﬁeld 网络（Hopﬁeld Network）是一种循环神经网络模型，由一组相互连接的神经元组成。Hopﬁeld 网络也可以认为是所有神经元都相互连接的不分层的神经网络。每个神经元既是输入单元，又是输出单元，没有隐藏神经元。一个神经元和自身没有反馈相连，不同神经元之间连接权重是对称的。图8.9给出了Hopﬁeld 网络的结构示例。图 8.9 四个节点的Hopﬁeld 网络这里我们只介绍离散 Hop-ﬁeld 网络， 神经元状态为假设一个Hopﬁeld 网络有m 个神经元，第i 个神经元的更新规则为+1, −1 两种。除此之外，还Σm有连续Hopﬁeld 网络，即神 +1ifwij sj + bi ≥ 0,si =(8.32)(8.33)j=1经元状态为连续值。 −1 otherwise,其中wij 为神经元i 和j 之间的连接权重，bi 为偏置。连接权重wij 有以下性质w ii = 0wij = wji ∀i, j ∈ [1, m].∀i ∈ [1, m]Hopﬁeld 网络的更新可以分为异步和同步两种方式。异步更新是每次更新一个神经元。神经元的更新顺序可以是随机或事先固定的。同步更新是指一次邱锡鹏：《神经网络与深度学习》https://nndl.github.io/
 2202019 年 4 月 6 日第8 章 注意力机制与外部记忆更新所有的神经元，需要有一个时钟来进行同步。第t时刻的神经元状态为st =[st,1, st,2, · · · , st,m ]T ，其更新规则为st = f (W st−1 + b),(8.34)其中s0 = x，W = [wij ]m ×m 为连接权重，b = [bi]m ×1 为偏置向量，f (·) 为非线性阶跃函数。能量函数 在 Hopﬁeld 网络中，我们给每个不同的网络状态定义一个标量属性，称为“能量”。ΣΣ1E = − 2 w s s − b s(8.35)(8.36)ij ii ii,ji12= − sTW s − bTs.Hopﬁeld 网络是稳定的，即能量函数经过多次迭代后会达到收敛状态。权重对称是一个重要特征，因为它保证了能量函数在神经元激活时单调递减，而不对称的权重可能导致周期性震荡或者混乱。能量函数 E 是 Hopﬁeld 网络的 Lyapunov 函数。Lya-punov 定理是非线性动力系统中保证系统稳定性的充分条件。给定一个外部输入，网络经过演化，会达到某个稳定状态。这些稳定状态称为吸引点（Attractor）。一个Hopﬁeld 网络中，通常有多个吸引点，每个吸引点为一个能量的局部最优点。图8.10给出了Hopﬁeld 网络的能量函数。红线为网络能量的演化方向，蓝点为吸引点。E••••••••••••••••••吸引点••••吸引点•吸引点s图 8.10 Hopﬁeld 网络的能量函数联想记忆 Hopﬁeld 网络存在有限的吸引点（Attractor），即能量函数的局部最小点。每个吸引点u都对应一个“管辖”区域ꢀu，如果输入向量x落入这个区域，网络最终会收敛到u。因此，吸引点可以看作是网络中存储的信息。将网络输入x 作为起始状态，随时间收敛到吸引点u 上的过程作为检索过程。即使输入向量x 是有部分信息或有噪声，只用其位于对应存储模式的“吸引”区域邱锡鹏：《神经网络与深度学习》https://nndl.github.io/
 8.3 外部记忆2019 年 4 月 6 日221内，那么随着时间演化，网络最终会收敛到其对应的存储模式。因此，Hopﬁeld的检索是基于内容寻址的检索，具有联想记忆能力。信息存储 信息存储是指将一组向量 x , · · · , x 存储在网络中的过程。存储过1N程主要是调整神经元之间的连接权重，因此可以看做是一种学习过程。Hopﬁeld 网络的学习规则有很多种。一种最简单的学习方式为：神经元 i 和 j 之间的连接权重ΣN1(n) (n)(8.37)w =Nx x ,ijji邱锡鹏：《神经网络与深度学习》https://nndl.github.io/
 2222019 年 4 月 6 日第8 章 注意力机制与外部记忆n=1其中x(n) 是第n 个输入向量的第i 维特征。如果x和xw在输入向量中相同的概率越多，则 ijjii越大。这种学习规则和人脑神经网络的学习方式十分类似。在人脑神经网络中，如果两个神经元经常同时激活，则它们之间的连接加强；如果 经常不同时激活，则连接消失。这种学习方式称为Hebbian 法则。存储容量 对于联想记忆模型来说，存储容量为其能够可靠地存储和检索模式的最大数量。对于数量为m 的相互连接的二值神经元网络，其总状态数2m，其中可以作为有效稳定点的状态数量就是其存储容量。模型容量一般与网络结构和学习方式有关。Hopﬁeld 最大的网络容量为0.14m，玻尔兹曼机的容量为0.6m， 但是其学习效率比较低，需要非常长时间的演化才能达到均衡状态。通过改进学习算法，Hopﬁeld网络的最大容量可以达到O(m)。如果允许高阶（阶数为K）连接，比如三个神经元连接关系，其稳定存储的最大容量为 O(mK−1)。Plate[1995] 引入复数运算，有效地提高了网络容量。总体上讲，通过改进网络结构、学习方式以及引入更复杂的运算（比如复数、量子操作），联想记忆网络的容量可以有效改善。8.3.4.2 使用联想记忆增加网络容量既然联想记忆具有存储和检索功能，我们可以利用联想记忆来增加网络容量。和结构化的外部记忆相比，联想记忆具有更好的生物学解释性。Danihelkaet al. [2016] 将一个联想记忆模型作为部件引入LSTM 网络中，而从在不引入额外参数的情况下增加网络容量。Ba et al. [2016] 将循环神经网络中的部分连接权重作为短期记忆，并通过一个联想记忆模型进行更新，而从提高网络性能。在 上述的网络中，联想记忆都是作为一个更大网络的组件，用来增加短期记忆的 容量。联想记忆组件的参数可以使用Hebbian 方式来学习，也可以作为整个网络参数的一部分来进行学习。邱锡鹏：《神经网络与深度学习》https://nndl.github.io/
 8.4 总结和深入阅读2019 年 4 月 6 日2178.4 总结和深入阅读注意力机制是一种（不严格的）受人类神经系统启发的信息处理机制。比如人视觉神经系统并不会一次性地处理所有接受到的视觉信息。注意力机制最早在计算机视觉中提出。在神经网络中，Mnih et al. [2014] 在循环神经网络模型上使用了注意力机制来进行图像分类。Bahdanau et al. [2014]使用注意力机制在机器翻译任务上将翻译和对齐同时进行。Xu et al. [2015] 利用注意力机制来进行图片的内容描述。目前，注意力机制已经在语音识别、图像标题生成、阅读理解、文本分类、机器翻译等多个任务上取得了很好的效果，也变得越来越流行。注意力机制的一个重要应用是自注意力。自注意力可以作为神经网络中的一层来使用，有效地建模长距离依赖问题[Vaswani et al., 2017]。通过引入外部记忆，神经网络在一定程度上可以解决模型容量问题。外部记忆的代表性模型有神经图灵机[Graves et al., 2014]、端到端记忆网络[Sukhbaatar et al.,2015]、动态记忆网络[Kumar et al., 2016] 等。这类引入外部记忆的模型也称为记忆增强网络（Memory-Enhanced Networks）。此外，基于神经动力学的联想记忆也可以作为一种外部记忆，并具有更好的生物学解释性。Hopﬁeld [1984] 将能量函数的概念引入到神经网络模型中，提出了Hopﬁeld 网络。Hopﬁeld 网络在旅行商问题上获得当时最好结果，引起轰动。Danihelka et al. [2016] 将一个联想记忆模型作为部件引入LSTM网络中，而从在不引入额外参数的情况下增加网络容量。Ba et al. [2016] 将循环神经网络中的部分连接权重作为短期记忆， 并通过一个联想记忆模型进行更新，而从提高网络性能。目前人工神经网络中的外部记忆模型结构还比较简单，需要借鉴神经科学的研究成果，提出更有效的记忆模型，增加网络容量。习题习题 8-1分析LSTM 模型中，隐藏层神经元数量与参数数量之间的关系。习题 8-2 分析缩放点积模型可以缓解softmax 函数梯度消失的原因。参见公式(8.4)。参见第8.2.2节。习题8-3 当用自注意力模型作为一个神经层使用时，分析它和卷积层以及循环层在建模长距离依赖关系的效率和计算复杂度方面的差异。习题 8-4 证明Hopﬁeld 网络的能量函数随时间单调递减。邱锡鹏：《神经网络与深度学习》https://nndl.github.io/
 2182019 年 4 月 6 日参考文献参考文献Jimmy Ba, Geoﬀrey E Hinton, VolodymyrMnih, Joel Z Leibo, and Catalin Ionescu.Using fast weights to attend to the recentpast. In Advances In Neural InformationProcessing Systems, pages 4331–4339, 2016.Tony A Plate. Holographic reduced repre-sentations. IEEE Transactions on Neuralnetworks, 6(3):623–641, 1995.Tao Shen, Tianyi Zhou, Guodong Long,Jing Jiang, Shirui Pan, and Chengqi Zhang.DiSAN: Directional self-attention networkfor RNN/CNN-free language understand-ing. In Proceedings of the Thirty-SecondAAAI Conference on Artiﬁcial Intelligence,pages 5446–5455, 2018.Dzmitry Bahdanau, Kyunghyun Cho, andYoshua Bengio. Neural machine translationby jointly learning to align and translate.ArXiv e-prints, September 2014.Ivo Danihelka, Greg Wayne, Benigno Uria,Nal Kalchbrenner, and Alex Graves. As-sociative long short-term memory. In Pro-ceedings of the 33nd International Confer-ence on Machine Learning, pages 1986–1994, 2016.Sainbayar Sukhbaatar, Jason Weston, RobFergus, et al. End-to-end memory networks.In Advances in Neural Information Process-ing Systems, pages 2431–2439, 2015.Richard F Thompson. Introduction to phys-iological psychology. HarperCollins Publish-ers, 1975.Alex Graves, Greg Wayne, and Ivo Dani-helka. Neural turing machines. arXivpreprint arXiv:1410.5401, 2014.AlanMTuring.On computable num-bers, with an application to the entschei-dungsproblem. Proceedings of the Londonmathematical society, 2(1):230–265, 1937.Ashish Vaswani, Noam Shazeer, NikiParmar, Jakob Uszkoreit, Llion Jones,Aidan N. Gomez, Lukasz Kaiser, and IlliaPolosukhin. Attention is all you need. InAdvances in Neural Information ProcessingSystems, pages 6000–6010, 2017.John J Hopﬁeld. Neurons with graded re-sponse have collective computational prop-erties like those of two-state neurons. Pro-ceedings of the national academy of sci-ences, 81(10):3088–3092, 1984.Yoon Kim, Carl Denton, Luong Hoang,and AlexanderMRush. Structuredattention networks.arXiv preprintarXiv:1702.00887, 2017.Oriol Vinyals, Meire Fortunato, andNavdeep Jaitly. Pointer networks. In Ad-vances in Neural Information ProcessingSystems, pages 2692–2700, 2015.Teuvo Kohonen. Self-organization and as-sociative memory, volume 8. Springer Sci-ence & Business Media, 2012.Ankit Kumar, Ozan Irsoy, Peter Ondruska,Mohit Iyyer, James Bradbury, Ishaan Gul-rajani, Victor Zhong, Romain Paulus, andRichard Socher. Ask me anything: Dynamicmemory networks for natural language pro-cessing. In Proceedings of the 33nd Inter-national Conference on Machine Learning,pages 1378–1387, 2016.Kelvin Xu, Jimmy Ba, Ryan Kiros,Kyunghyun Cho, Aaron Courville, Rus-lan Salakhudinov, Rich Zemel, and YoshuaBengio. Show, attend and tell: Neural im-age caption generation with visual atten-tion. In Proceedings of the InternationalConference on Machine Learning, pages2048–2057, 2015.Volodymyr Mnih, Nicolas Heess, AlexGraves, et al. Recurrent models of visualattention. In Advances in Neural Informa-tion Processing Systems, pages 2204–2212,2014.Zichao Yang, Diyi Yang, Chris Dyer, Xi-aodong He, Alexander J Smola, and Ed-uard H Hovy. Hierarchical attention net-works for document classiﬁcation. In HLT-NAACL, pages 1480–1489, 2016.邱锡鹏：《神经网络与深度学习》https://nndl.github.io/
 第9 章 无监督学习大脑有大约1014 个突触，我们只能活大约109 秒。所以我们有比数据更多的参数。这启发了我们必须进行大量无监督学习的想法，因为感知输入（包括本体感受）是我们可以获得每秒105 维约束的唯一途径。— Geoﬀrey Hinton, 2014 AMA on Reddit更早的正式描述见[Hintonet al., 1999]无监督学习（Unsupervised Learning）是指从无标签的数据中学习出一些有用的模式。无监督学习算法一般直接从原始数据中学习，不借助于任何人工给出标签或者反馈等指导信息。如果监督学习是建立输入-输出之间的映射关 系，无监督学习就是发现隐藏的数据中的有价值信息，包括有效的特征、类别、 结构以及概率分布等。典型的无监督学习问题可以分为以下几类：无监督特征学习 无监督特征学习（Unsupervised Feature Learning）是从无标签的训练数据中挖掘有效的特征或表示。无监督特征学习一般用来进行降维、数据可视化或监督学习前期的数据预处理。特征学习也包含很多的监督学习算法，比如线性判别分析等。密度估计 密度估计（Density Estimation）是根据一组训练样本来估计样本空间的概率密度。密度估计可以分为参数密度估计和非参数密度估计。参数密度估计是假设数据服从某个已知概率密度函数形式的分布（比如高斯分布），然后根据训练样本去估计概率密度函数的参数。非参数密度估计是不假设数据服从某个已知分布，只利用训练样本对密度进行估计，可 以进行任意形状密度的估计。非参数密度估计的方法有直方图、核密度估 计等。聚类 聚类（Clustering）是将一组样本根据一定的准则划分到不同的组（也称为集群（Cluster））。一个比较通用的准则是组内的样本的相似性要高于组间样本的相似性。常见的聚类算法包括K-Means 算法、谱聚类等。
 2202019 年 4 月 6 日第9 章 无监督学习和监督学习一样，无监督学习方法也包含三个基本要素：模型、学习准则和优化算法。无监督学习的准则非常多，比如最大似然估计、最小重构错误等。在无监督特征学习中，经常使用的准则为最小化重构错误，同时也经常对特征进行一些约束，比如独立性、非负性或稀释性等。而在密度估计中，经常采用最大似然估计来进行学习。本章介绍两种无监督学习问题：无监督特征学习和密度估计。9.1 无监督特征学习无监督特征学习是指从无标注的数据中自动学习有效的数据表示，从而能够帮助后续的机器学习模型更快速地达到更好的性能。无监督特征学习主要方法有主成分分析、稀疏编码、自编码器等。9.1.1 主成分分析主成份分析（Principal Component Analysis，PCA）一种最常用的数据降维方法，使得在转换后的空间中数据的方差最大。如图9.1所示的两维数据，如果将这些数据投影到一维空间中，选择数据方差最大的方向进行投影，才能最大化数据的差异性，保留更多的原始数据信息。邱锡鹏：《神经网络与深度学习》https://nndl.github.io/
 2019 年 4 月 6 日221邱锡鹏：《神经网络与深度学习》https://nndl.github.io/
 2222019 年 4 月 6 日图 9.1 主成分分析第9 章 无监督学习假设有一组d 维的样本x(n) ∈ Rd, 1 ≤ n ≤ N ，我们希望将其投影到一维空间中，投影向量为 w ∈ Rd。不失一般性，我们限制w 的模为1，即wTw = 1。邱锡鹏：《神经网络与深度学习》https://nndl.github.io/
 9.1 无监督特征学习2019 年 4 月 6 日223每个样本点 x(n) 投影之后的表示为(n) = wTx(n).(9.1)Σ N我们用矩阵X = [x(1), x(2), · · · , x(N )]表示输入样本，¯x = 1x(n)n=1为原始N样本的中心点，所有样本投影后的方差为ΣN1N(wT x(n)− wT x¯)2σ(X; w) =(9.2)n=11N=(wT X − wT X¯)(wT X − wT X¯)T(9.3)= wTSw,(9.4)其中X¯ = x1T¯为 列 ¯组成的矩阵，dxS = 1 (X − X )(X − X ) 是原始样本的协¯¯ TdN方差矩阵。最大化投影方差σ(X; w) 并满足w束优化问题，Tw = 1，利用拉格朗日方法转换为无约max wTSw + λ(1 − wTw),(9.5)(9.6)(9.7)w其中λ 为拉格朗日乘子。对上式求导并令导数等于0，可得Sw = λw.从上式可知，w 是协方差矩阵S 的特征向量，λ 为特征值。同时σ(X; w) = wTSw = w λw = λ.Tλ也是投影后样本的方差。因此，主成分分析可以转换成一个矩阵特征值分解问题，投影向量w为矩阵S 的最大特征对应的特征向量。如果要通过投影矩阵W ∈ Rd×d′ 将样本投到d′维空间，投影矩阵满足WW =I，只需要将S 的特T征值从大到小排列，保留前d′ 个特征向量，其对应的特征向量即使最优的投影矩阵。SW = W diag(Λ),(9.8)其中Λ = [λ , · · · , λ ] 为S 的前d′ 个最大的特征值。1d′主成分分析是一种无监督学习方法，可以作为监督学习的数据预处理方法，用来去除噪声并减少特征之间的相关性，但是它并不能保证投影后数据的类别可分性更好。提高两类可分性的方法一般为监督学习方法，比如线性判别分析（Linear Discriminant Analysis，LDA）。参见习题9-3。邱锡鹏：《神经网络与深度学习》https://nndl.github.io/
 2242019 年 4 月 6 日第9 章 无监督学习9.1.2 稀疏编码稀疏编码（Sparse Coding）也是一种受哺乳动物视觉系统中简单细胞感受野而启发的模型。在哺乳动物的初级视觉皮层（primary visual cortex）中，每个神经元仅对处于其感受野中特定的刺激信号做出响应，比如特定方向的边缘、条纹等特征。局部感受野可以被描述为具有空间局部性、方向性和带通性（即不同尺度下空间结构的敏感性）[Olshausen et al., 1996]。也就是说，外界信息经过编码后仅有一小部分神经元激活，即外界刺激在视觉神经系统的表示具有很高的稀疏性。编码的稀疏性在一定程度上符合生物学的低功耗特性。带通滤波（bandpass ﬁlter）是指容许某个频率范围的信号通过，同时屏蔽其他频段的设备。在数学上，（线性）编码是指给定一组基向量A = [a , · · · , a ]，将输入样1p本x ∈ Rd 表示为这些基向量的线性组合Σpx =i iꢀ a(9.9)i= 1= Az,(9.10)其中基向量的系数z = [ꢀ , · · · , ꢀ ] 称为输入样本x 的编码（encoding），基向1p量A 也称为字典（dictionary）。编码是对d 维空间中的样本x 找到其在p 维空间中的表示（或投影），其目标通常是编码的各个维度都是统计独立的，并且可以重构出输入样本。编码的关键是找到一组“完备”的基向量A，比如主成分分析等。但是主成分分析得到编码通常是稠密向量，没有稀疏性。数学小知识 | 完备性如果p 个基向量刚好可以支撑p 维的欧氏空间，则这p 个基向量是完备的。如果p 个基向量可以支撑d 维的欧氏空间，并且p > d，则这p♣个基向量是过完备的，冗余的。“过完备”基向量一般是指的是基向量个数远远大于其支撑空间维度。因此这些基向量一般是不具备独立、正交等性质。为了得到稀疏的编码，我们需要找到一组“超完备”的基向量（即 p > d）来进行编码。在超完备基向量之间往往会存在一些冗余性，因此对于一个输入样本，会存在很多有效的编码。如果加上稀疏性限制，就可以减少解空间的大小，得到“唯一”的稀疏编码。邱锡鹏：《神经网络与深度学习》https://nndl.github.io/
 9.1 无监督特征学习2019 年 4 月 6 日225给定一组N 个输入向量x(1), · · · , x(N )，其稀疏编码的目标函数定义为：ΣN¨¨x(n) − A z(n )¨¨2 + ηρ(z(n))L (A, Z ) =,(9.11)n=1其中ρ(·) 是一个稀疏性衡量函数，η 是一个超参数，用来控制稀疏性的强度。对于一个向量z ∈ Rp，其稀疏性定义为非零元素的比例。如果一个向量只有很少的几个非零元素，就说这个向量是稀疏的。稀疏性衡量函数ρ(z) 是给向量z一个标量分数。z越稀疏，ρ(z)越小。严格的稀疏向量有时比较难以得到，因此如果一个向量只有少数几个远大于零的元素，其它元素都接近于0，我们也称这个向量为稀疏向量。稀疏性衡量函数有多种选择，最直接的衡量向量z 稀疏性的函数是ℓ0 范式Σpρ(z) =I(|ꢀi| > 0))(9.12)i= 1但 ℓ0 范数不满足连续可导，因此很难进行优化。在实际中，稀疏性衡量函数通常使用ℓ1 范数Σpρ(z)=|ꢀi|i= 1(9.13)或对数函数或指数函数pρ(z) =2log(1 +ii= 1ꢀ ) (9.14)pρ(z) =2−ii= 1exp(−ꢀ ).(9.15)9.1.2.1 训练方法给定一组N 个输入向量x(1), · · · , x(N )，需要同时学习基向量 以及每个输A入样本对应的稀疏编码z(1), · · · , z(N )。稀疏编码的训练过程一般用交替优化的方法进行。1) 固定基向量A，对每个输入x(n)，计算其对应的最优编码¨2min ¨x(n) − Az(n) ¨ − ηρ(z(n)), ∀n ∈ [1, N ].(9.16)(9.17)x(n )2) 固定上一步得到的编码z(1), · · · , z(N )，计算其最优的基向量Σ¨−¨2¨z(n)¨1minNAx(n)2+n= 1Aλ ∥A∥ ,2其中第二项为正则化项，λ 为正则化项系数。邱锡鹏：《神经网络与深度学习》https://nndl.github.io/
 2262019 年 4 月 6 日第9 章 无监督学习9.1.2.2 稀疏编码的优点稀疏编码的每一维都可以看作是一种特征。和基于稠密向量的分布式表示相比，稀疏编码具有更小的计算量和更好的可解释性等优点。计算量稀疏性带来的最大好处就是可以极大地降低计算量。可解释性 因为稀疏编码只有少数的非零元素，相当于将一个输入样本表示为少数几个相关的特征。这样我们可以更好地描述其特征，并易于理解。特征选择稀疏性带来的另外一个好处是可以实现特征的自动选择，只选择和输入样本相关的最少特征，从而可以更好地表示输入样本，降低噪声并减轻过拟合。9.1.3 自编码器自编码器（Auto-Encoder，AE）是通过无监督的方式来学习一组数据的有效编码（或表示）。假设有一组d 维的样本x(n) ∈ Rd, 1 ≤ n ≤ N ，自编码器将这组数据映射到特征空间得到每个样本的编码z(n) ∈ Rp, 1 ≤ n ≤ N ，并且希望这组编码可以重构出原来的样本。自编码器的结构可分为两部分：编码器（encoder）f : R → R ,(9.18)(9.19)dp和解码器（decoder）g : Rp → Rd.自编码器的学习目标是最小化重构错误（reconstruction errors）NL∥− ∥g(f(x(n))) 2==x(n)(9.20)(9.21)n=1ΣN∥x(n) − f ◦)(n) ∥2g(x.n=1如果特征空间的维度p 小于原始空间的维度d，自编码器相当于是一种降维或特征抽取方法。如果p ≥ d，一定可以找到一组或多组解使得f ◦ g 为单位函数（Identity Function），并使得重构错误为0。但是，这样的解并没有太多的意义。但是如果再加上一些附加的约束，就可以得到一些有意义的解，比如编单位函数I(x) = x。邱锡鹏：《神经网络与深度学习》https://nndl.github.io/
 9.1 无监督特征学习2019 年 4 月 6 日227码的稀疏性、取值范围，f 和g 的具体形式等。如果我们让编码只能取k 个不同的值(k < N)，那么自编码器就可以转换为一个k 类的聚类（Clustering）问题。最简单的自编码器是如图9.2所示的两层神经网络。输入层到隐藏层用来编码，隐藏层到输出层用来解码，层与层之间互相全连接。编码器解码器x1x2x3x4x′1x′2x′3x′4z1z2图 9.2 两层网络结构的自编码器对于样本x，中间隐藏层为编码z = s(W (1)x + b(1)),(9.22)(9.23)输出为重构的数据x′ = s(W (2)z + b(2)),其中W, b为网络参数，s(·)为激活函数。如果令W (2) 等于W (1) 的转置，即W (2) =W (1)T，称为捆绑权重（tied weights）。给定一组样本x(n) ∈ [0, 1]d, 1 ≤ n ≤ N ，其重构错误为ΣN(n)′L = (n)22∥xFn=1− x)∥ + λ∥W ∥ .(9.24)其中λ为正则化项系数。通过最小化重构错误，可以有效地学习网络的参数。我们使用自编码器是为了得到有效的数据表示，因此在训练结束后，我们一般去掉解码器，只保留编码器。编码器的输出可以直接作为后续机器学习模型的输入。9.1.4 稀疏自编码器自编码器除了可以学习低维编码之外，也学习高维的稀疏编码。假设中间隐藏层z 的维度为p 大于输入样本x 的维度d，并让z 尽量稀疏，这就是稀疏自邱锡鹏：《神经网络与深度学习》https://nndl.github.io/
 2282019 年 4 月 6 日第9 章 无监督学习编码器（Sparse Auto-Encoder）。和稀疏编码一样，稀疏自编码器的优点是有很高的可解释性，并同时进行了隐式的特征选择。通过给自编码器中隐藏层单元z 加上稀疏性限制，自编码器可以学习到数据中一些有用的结构。NL∥x(n)x′(n)) 2 + ηρ(z(n))) + λ∥ W∥ 2,−∥=(9.25)n=1其中ρ(·)为稀疏性度量函数，W 表示自编码器中的参数。稀疏性度量函数ρ(·) 除了可以选择公式(9.13)∼(9.15) 的定义外，还可以定义为一组训练样本中每一个神经元激活的频率。给定N 个训练样本，隐藏层第j 个神经元平均活性值为ΣN1N(n=ρˆj(9.26)),n=1ρˆj 可以近似地看作是第j 个神经元激活的概率。我们希望ρˆj 接近于一个事先给定的值ρ ，比如0 05，可以通过∗.KLρˆ距离来衡量 j 和 的差异，即ρ∗∗1 − ρ∗ρKL(ρ∗||ρˆ ) = ρ∗ log+ (1 − ρ∗) log.(9.27)(9.28)jρˆj1 − ρˆj如果ρˆj = ρ∗，则KL(ρ∗||ρˆ ) =j 0。稀疏性度量函数定义为Σpρ(z(n)) =KL(ρ∗ ||ρˆj ).j=19.1.5 堆叠自编码器对于很多数据来说，仅使用两层神经网络的自编码器还不足以获取一种好的数据表示。为了获取更好的数据表示，我们可以使用更深层的神经网络。深层神经网络作为自编码器提取的数据表示一般会更加抽象，能够更好地捕捉到数据的语义信息。在实践中经常使用逐层堆叠的方式来训练一个深层的自编码器，称为堆叠自编码器（Stacked Auto-Encoder，SAE）。堆叠自编码一般可以采用逐层训练（layer-wise training）来学习网络参数[Bengio et al., 2007]。9.1.6 降噪自编码器我们使用自编码器是为了得到有效的数据表示，而有效的数据表示除了具有最小重构错误或稀疏性等性质之外，我们还可以要求其具备其它性质，比如对数据部分损坏（partial destruction）的鲁棒性。高维数据（比如图像）一般邱锡鹏：《神经网络与深度学习》https://nndl.github.io/
 9.2 概率密度估计2019 年 4 月 6 日227都具有一定的信息冗余，比如我们可以根据一张部分破损的图像联想出其完整内容。因此，我们希望自编码器也能够从部分损坏的数据中得到有效的数据表示，并能够恢复出完整的原始信息。降噪自编码器（Denoising Autoencoder）就是一种通过引入噪声来增加编码鲁棒性的自编码器[Vincent et al., 2008]。对于一个向量x，我们首先根据一个比例µ 随机将x 的一些维度的值设置为0，得到一个被损坏的向量x˜。然后将被损坏的向量x˜ 输入给自编码器得到编码z，并重构出原始的无损输入x。损坏比例 µ 一般不超过 0.5。也可以使用其它的方法来损坏数据，比如引入高斯噪声。图9.3给出了自编码器和降噪自编码器的对比，其中f 为编码器，g 为解θθ′码器，L(x, x′) 为重构错误。zfθzgθ′x˜gθ′fθxx′xx′L(x, x′)L(x, x′)(a) 自编码器(b) 降噪自编码器图 9.3 自编码器和降噪自编码器降噪自编码器的思想十分简单，通过引入噪声来学习更鲁棒性的数据编码，并提高模型的泛化能力。9.2 概率密度估计概率密度估计（Probabilistic Density Estimation），简称密度估计（DensityEstimation），是基于一些观测样本来估计一个随机变量的概率密度函数。密度估计在数据建模、机器学习中使用广泛。密度估计方法可以分为两类：参数密度估计和非参数密度估计。9.2.1 参数密度估计参数密度估计（Parametric Density Estimation）是根据先验知识假设随机变量服从某种分布，然后通过训练样本来估计分布的参数。令 D = {x(n)}iN=1 为从某个未知分布中独立抽取的N 个训练样本，假设这邱锡鹏：《神经网络与深度学习》https://nndl.github.io/
 2282019 年 4 月 6 日第9 章 无监督学习些样本服从一个概率分布函数p(x|θ)，其对数似然函数为Nlog p(D|θ) =log p(|x( ) θ).n(9.29)n=1我们要估计一个参数θM L 来使得ΣNθM L = arg maxlog p(x(n)|θ).(9.30)θn=1这样参数估计问题就转化为最优化问题。9.2.1.1 正态分布假设样本x ∈ Rd 服从正态分布11N(x|µ, Σ) =exp−2(x − µ)TΣ−1(x − µ) ,(9.31)(9.32)(2π)d/2|Σ|1/2其中µ 和Σ 分别为正态分布的均值和方差。其对数似然函数为ΣNN212(x − µ)T Σ−1(x− µ ).logp(D|µ, Σ) = − log (2π)2|Σ| −n=1分别上式关于µ, Σ 的偏导数，并令其等于0。可得，ΣN1NM Lx(n),µ=(9.33)(9.34)n=1ΣN1NΣM L =− µ)(x − µ)T .(xn=19.2.1.2 多项分布多项分布参见第D.2.2.1节。假设样本服从K 个状态的多项分布，令onehot 向量x ∈ [0, 1]K 来表示第k个状态，即xk = 1，其余xi,i≠ k = 0。样本x 的概率密度函数为Kp(x|µ) =xµ,(9.35)kkk=1其中µk 为第k 个状态的概率，并满足ΣKµk = 1。k=1数据集 D = {x(n)}Nn=1 的对数似然函数为这里没有多项式系数。ΣNK(n)xklog p( µD) |=log(µk).(9.36)n=1 k=1邱锡鹏：《神经网络与深度学习》https://nndl.github.io/
 9.2 概率密度估计2019 年 4 月 6 日229多项分布的参数估计为约束优化问题。引入拉格朗日乘子λ，将原问题转换为无约束优化问题。拉格朗日乘子参考??。Σ ΣΣKKNmaxx(n) log(µ ) + λµk − 1 .(9.37)µ,λkkn=1 k=1k=1分别上式关于µk, λ 的偏导数，并令其等于0。可得，mNµkM L =  k ,1 ≤ k ≤ K(9.38)ΣN(n)xk其中 mk =为数据集中取值为第k 个状态的样本数量。n=1在实际应用中，参数密度估计一般存在以下问题：（1） 模型选择问题：即如何选择数据分布的密度函数。实际数据的分布往往是非常复杂的，而不是简单的正态分布或多项分布。（2） 不可观测变量问题：即我们用来训练的样本只包含部分的可观测变量，还有一些非常关键的变量是无法观测的，这导致我们很难准确估计数据的真实分布。包含不可观测变量的密度估计问题一般需要使用EM 算法，参见第11.4.2.1节。（3） 维度灾难问题：即高维数据的参数估计十分困难。随着维度的增加，估计参数所需要的样本数量指数增加。在样本不足时会出现过拟合。9.2.2 非参数密度估计非参数密度估计（Nonparametric Density Estimation）是不假设数据服从某种分布，通过将样本空间划分为不同的区域并估计每个区域的概率来近似数据的概率密度函数。对于高维空间中的一个随机向量x，假设其服从一个未知分布p(x)，则x 落入空间中的小区域ꢀ 的概率为∫P =p(x)dx.ꢀ(9.39)给定N 个训练样本D = {x(n)}Nn=1，落入区域ꢀ 的样本数量K 服从二项分布NKP=PK(1 − P )1−K,(9.40)K其中K /N 的期望为E[K /N ] = P ，方差为var(K /N ) = P (1 − P )/N 。当N 非常大时，我们可以近似认为KNP ≈.(9.41)邱锡鹏：《神经网络与深度学习》https://nndl.github.io/
 2302019 年 4 月 6 日第9 章 无监督学习假设区域ꢀ 足够小，其内部的概率密度是相同的，则有P ≈ p(x)V,(9.42)(9.43)其中V 为区域ꢀ 的体积。结合上述两个公式，得到KNVp(x) ≈.根据公式(9.43)，要准确地估计p(x) 需要尽量使得样本数量N 足够大，区域体积V 尽可能地小。但在具体应用中，样本数量一般是有限的，过小的区域会导致落入该区域的样本比较少，这样估计的概率密度就不太准确。因此，实 践中非参数密度估计通常使用两种方式：（1）固定区域大小V ，统计落入不同区域的数量，这种方式包括直方图方法和核方法两种。（2）改变区域大小以使 得落入每个区域的样本数量为K，这种方式称为K 近邻方法。9.2.2.1 直方图方法直方图方法（Histogram Method）是一种非常直观的估计连续变量密度函数的方法，可以表示为一种柱状图。Histogram 源自希腊语his-tos（竖立）和 gramma（描以一维随机变量为例，首先将其取值范围分成M 个连续的、不重叠的区间绘），由英国统计学家卡尔· （bin），每个区间的宽度为∆m 。给定N个训练样本D = {x(n)}Nn=1，我们统计皮尔逊于1895 年提出。这些样本落入每个区间的数量Km，然后将它们归一化为密度函数。KmN ∆mpm=,1 ≤ m ≤ M(9.44)其中区间宽度∆m 通常设为相同的值∆。直方图方法的关键问题是如何选取一个合适的区间宽度∆。如果∆ 太小，那么落入每个区间的样本数量会比较少，其估计的区间密度也具有很大的随机性。如果∆ 太大，其估计的密度函数变得十分平滑，很难反映出真实的数据分布。图9.4给出了直方图密度估计的例子，其中蓝线表示真实的密度函数，红色的柱状图为直方图方法估计的密度。(a) 10 个区间（bin）(b) 30 个区间（bin）图 9.4 直方图密度估计邱锡鹏：《神经网络与深度学习》https://nndl.github.io/
 9.2 概率密度估计2019 年 4 月 6 日231直方图通常用来处理低维变量，可以非常快速地对数据的分布进行可视化， 但其缺点是很难扩展到高维变量。假设一个d 维的随机向量，如果每一维都划分为 M个区间，那么整个空间的区间数量为Md 个。直方图方法需要的样本数量会随着维度d 的增加而指数增长，从而导致维度灾难（Curse of Dimensionality）问题。9.2.2.2 核方法核密度估计（Kernel Density Estimation），也叫Parzen 窗方法，是一种直方图方法的改进。假设ꢀ 为d 维空间中的一个以点x 为中心的“超立方体”，并定义核函数| 1 d− x < h , ≤ i ≤iz − x1if |ꢀi=(9.45)2ϕh0else来表示一个样本z 是否落入该超立方体中，其中h 为超立方体的边长，也称为核函数的宽度。给定N 个训练样本D = {x(n)}nN=1 ，落入区域ꢀ 的样本数量K 为ΣNx(n)x−K =ϕ,(9.46)(9.47)hn=1则点x 的密度估计为ΣKNhd1Nh dNx−x(n)p(x) ==ϕ,hn=1其中hd 表示区域ꢀ 的体积。除了超立方体的核函数之外，我们还可以选择更加平滑的核函数，比如高斯核函数，z − xh1∥z − x∥22h2ϕ=exp −,(9.48)(2π)1/2h其中h2 可以看做是高斯核函数的方差。这样点x 的密度估计为ΣN1N1∥z − x∥2p(x) =−exp.(9.49)(2π)1/2h2n=19.2.2.3 K 近邻方法核密度估计方法中的核宽度是固定的，因此同一个宽度可能对高密度的区域过大，而对低密度区域过小。一种更灵活的方式是设置一种可变宽度的区域，邱锡鹏：《神经网络与深度学习》https://nndl.github.io/
 2322019 年 4 月 6 日第9 章 无监督学习并使得落入每个区域中样本数量为固定的K 。要估计点x 的密度，首先找到一个以x为中心的球体，使得落入球体的样本数量为K，然后根据公式(9.43)，就可以计算出点x 的密度。因为落入球体的样本也是离x 最近的K 个样本，所以这种方法称为K 近邻（K-Nearest Neighbor）方法。K 近邻方法并不是一个严格的密度函数估计方法，参见习题9-5。在K 近邻方法中，K 的选择也十分关键。如果K太小，无法有效地估计密度函数，而K 太大也会使得局部的密度不准确，并且增加计算开销。K 近邻方法也经常用于分类问题，称为K 近邻分类器。当K = 1 也称为最近邻分类器。最近邻分类器的一个性质是，当N → ∞ 时，其分类错误率不超过最优分类器错误率的两倍[Cover and Hart, 1967]。参见习题9-6。9.3 总结和深入阅读无监督学习是一种十分重要的机器学习方法。广义上讲，监督学习也可以看作是一个类特殊的无监督学习，即估计条件概率p(y|x)。条件概率p(y|x)通过贝叶斯公式转为估计概率p(y) 和p(x|y)，并通过无监督密度估计来求解。可以无监督学习问题主要可以分为聚类、特征学习、密度估计等几种类型。关于聚类方面的内容，可以参考《机器学习》[周志华, 2016] 中的第9 章。无监督特征学习是一种十分重要的表示学习方法。当一个监督学习任务的数据比较少时，可以通过大规模的无标注数据，学习到一种有效的数据表示，并有效提高监督学习的性能。关于无监督特征学习的内容，可以参考《机器学习》[周志华,2016] 中的第10 章和《Pattern Classiﬁcation》[Duda et al., 2001] 的第10 章。本章简单介绍了两种概率密度估计方法：参数方法和非参数方法。参数方法是假设数据分布服从某种参数化的模型。我们在本书的后面章节会陆续介绍更多的参数密度估计模型。在第11章中，我们通过概率图模型介绍更一般的参数密度估计方法，包括含隐变量的参数估计方法。当估计出一个数据分布的参数化模型后，我们可以根据这个模型来生成数据，因此这些模型也称为生成模型。第12章介绍两种比较复杂的生成模型：玻尔兹曼机和深度信念网络。第13章 介绍了两种深度生成模型：变分自编码器和对抗生成网络。第15章介绍了几种序列数据的生成模型。关于非参数密度估计的方法一般性介绍可以参考[Duda et al., 2001] 和[Bishop,2007]，理论性介绍可以参考[Devroye and Gyorﬁ, 1985]。但目前无监督学习并没有像监督学习那样取得广泛的成功，主要原因在于无监督学习缺少有效的客观评价方法，导致很难衡量一个无监督学习方法的好坏。邱锡鹏：《神经网络与深度学习》https://nndl.github.io/
 参考文献2019 年 4 月 6 日233习题习题 9-1分析主成分分析为什么具有数据降噪能力？习题9-2 证明对于N 个样本（样本维数d > N）组成的数据集，主成分分析的有效投影子空间不超过N − 1 维。习题9-3 对于一个两类分类问题，试举例分析什么样的数据分布会使得主成分分析得到的特征反而会使得分类性能下降。习题9-4 若数据矩阵X ′ =X − X ，则对X 奇异值分解X = UΣV ，则U¯′′为主成分分析的投影矩阵。习题9-5 举例说明，K 近邻方法估计的密度函数不是严格的概率密度函数，其在整个空间上的积分不等于1。习题 9-6 对于一个C 类的分类问题，使用K 近邻方法估计每个类 c (1 ≤c ≤ C) 的密度函数p(x|c)，并使用贝叶斯公式计算每个类的后验概率p(c|x)。参考文献周志华. 机器学习. 清华大学出版社, 北京,Richard O. Duda, Peter E. Hart, andDavid G. Stork. Pattern classiﬁcation, 2ndEdition. Wiley, 2001. ISBN 9780471056690.2016. ISBN 978-7-302-206853-6.Yoshua Bengio, Pascal Lamblin, DanPopovici, and Hugo Larochelle. Greedylayer-wise training of deep networks. InAdvances in neural information processingGeoﬀrey E Hinton, Terrence Joseph Se-jnowski, and Tomaso A Poggio. Unsuper-vised learning: foundations of neural com-putation. MIT press, 1999.systems, pages 153–160, 2007.Christopher M. Bishop. Pattern recogni-tion and machine learning, 5th Edition. In-BrunoAOlshausen et al.Emergenceformation science and statistics. Springer,of simple-cell receptive ﬁeld properties bylearning a sparse code for natural images.Nature, 381(6583):607–609, 1996.2007. ISBN 9780387310732.Thomas Cover and Peter Hart. Nearestneighbor pattern classiﬁcation. IEEE trans-actions on information theory, 13(1):21–27,Pascal Vincent, Hugo Larochelle, YoshuaBengio, and Pierre-Antoine Manzagol. Ex-tracting and composing robust featureswith denoising autoencoders. In Proceedingsof the International Conference on MachineLearning, pages 1096–1103. ACM, 2008.1967.Luc Devroye and Laszlo Gyorﬁ. Nonpara-metric Density Estimation: The L1 View.Wiley Series in Probability and Statistics.Wiley，New York, 1985.邱锡鹏：《神经网络与深度学习》https://nndl.github.io/
 

 第 10 章 模型独立的学习方式在前面的章节中，介绍了机器学习的几种学习方式，包括监督学习、无监督 学习等。这些学习方式分别可以由不同的模型和算法实现，比如神经网络、线 性分类器等。针对一个给定的任务，首先要准备一定规模的训练数据，这些训练 数据需要和真实数据的分布一致，然后设定一个目标函数和优化方法，在训练 数据上学习一个模型。此外，不同任务的模型往往都是从零开始来训练的，一 切知识都需要从训练数据中得到。这也导致了每个任务都需要准备大量的训练 数据。在实际应用中，我们面对的任务往往难以满足上述要求，比如训练任务 和目标任务的数据分布不一致，训练数据过少等。这时机器学习的应用会受到 很大的局限。因此，人们开始关注一些新的学习方式的任务，现在的深度学习 因为无法快速适应新的任务，就没办法来替代人类的工作。本章介绍一些“模型独立的学习方式”，比如集成学习、协同学习、自学习、 多任务学习、迁移学习、终身学习、小样本学习、元学习等。这里“模型独立”是指这些学习方式不限于具体的模型，不管是前馈神经网络、循环神经网络还是其他模型。然而一种学习方式往往会对符合某种特性的模型更加青睐，比如集成学习往往和方差大的模型组合时效果显著。10.1 集成学习给定一个学习任务，假设输入x 和输出y 的真实关系为y = h(x)。对于M个不同的模型f (x), · · · , f (x)，每个模型的期望错误为1Mh2ifmꢀ (fm ) = Ex(x) − h(x)(10.1)(10.2)hi= Ex ϵ (x)2 ,m其中ϵ (x) = f (x) − h(x) 为模型m 在样本x 上的错误。mm那么所有的模型的平均错误为Σ1¯M2xꢀ(f) =E [ϵ (x) ].(10.3)Mmm=1
 2362019 年 4 月 6 日第10 章 模型独立的学习方式集成学习（Ensemble Learning）就是通过某种策略将多个模型集成起来，通过群体决策来提高决策准确率。集成学习首要的问题是如何集成多个模型。比较常用的集成策略有直接平均、加权平均等。最直接的集成学习策略就是直接平均，即“投票”。基于投票的集成模型f (c)(x)为ΣM1MF (x) =f (x).(10.4)mm=1定理 10.1： 对于M 个不同的模型f (x), · · · , f (x)，其平均期望1MΣM1M错误为 ¯(f )。基于简单投票机制的集成模型F (x) =fm(x)，m=11 ¯ f )F (x) 的期望错误在M¯和f) 之间。证明. 根据定义，集成模型的期望错误为Σh2iM1Mꢀ(F ) =fm(x) − h(x)(10.5)(10.6)(10.7)(10.8)Em=1ΣhM2i1=Exϵ (x)mM 2m=1Σ Σ= M12 ExhMMiϵ (x)ϵ (x)mnm=1 n=1ΣMMhi1=Ex ϵ (x)ϵ (x)m nM 2,m=1 n=1其中E [ϵ (x)ϵ (x)] 为两个不同模型错误的相关性。如果每个模型的错误不相xmn关，即∀m = n, E [ϵ (x)ϵ (x)] = 0。如果每个模型的错误都是相同的，则xmn∀m = n, ϵ (x) = ϵ (x)。并且由于ϵ (x) ≥ 0, ∀m，可以得到mnm1M¯(f ) ≥ ꢀ(F ) ≥ꢀ¯(f ),(10.9)即集成模型的期望错误是大于等于所有模型的平均期望错误的1/M，小于等于所有模型的平均期望错误。从定理10.1可知，为了得到更好的集成效果，要求每个模型之间具备一定的差异性。并且随着模型数量的增多，其错误率也会下降，并趋近于0。集成学习的思想可以用一句古老的谚语来描述：“三个臭皮匠赛过诸葛亮”。但是一个有效的集成需要各个基模型的差异尽可能大。为了增加模型之间的差异性，可以采取Bagging 类和Boosting 类两类方法。邱锡鹏：《神经网络与深度学习》https://nndl.github.io/
 10.1 集成学习2019 年 4 月 6 日237Bagging 类方法 Bagging 类方法是通过随机构造训练样本、随机选择特征等方法来提高每个基模型的独立性，代表性方法有Bagging 和随机森林等。Bagging（Bootstrap Aggregating）是一个通过不同模型的训练数据集的独立性来提高不同模型之间的独立性。我们在原始训练集上进行有放回的随机采样，得到M 比较小的训练集并训练M 个模型，然后通过投票的方法进行模型集成。随机森林（Random Forest）[Breiman, 2001] 是在Bagging 的基础上再引入了随机特征，进一步提高每个基模型之间的独立性。在随机森林中，每个基模型都是一棵决策树。Boosting 类方法Boosting 类方法是按照一定的顺序来先后训练不同的基模型，每个模型都针对前序模型的错误进行专门训练。根据前序模型的结果，来调整训练训练样本的权重，从而增加不同基模型之间的差异性。Boosting 类方法是一种非常强大的集成方法，只要基模型的准确率比随机猜测好，就可以通过集成方法来显著地提高集成模型的准确率。Boosting 类方法的代表性方法有AdaBoost[Freund et al., 1996]等。10.1.1 AdaBoost 算法Boosting 类集成模型的目标是学习一个加性模型（additive model）ΣMF (x) =α f (x),m m(10.10)m=1其中fm(x)为弱分类器（Weak Classiﬁer），或基分类器（Base Classiﬁer），αm为弱分类器的集成权重，F (x) 称为强分类器（Strong Classiﬁer）。Boosting类方法的关键是如何训练每个弱分类器f (x) 以及对应的权重α 。mm为了提高集成的效果，应当尽量使得每个弱分类器的差异尽可能大。一种有效的 算法是迭代的方法来学习每个弱分类器，即按照一定的顺序依次训练每个弱分 类器。在学习了第m 个弱分类器后，增加其分错样本的权重，使得第m + 1 个弱分类器“更关注”于前面弱分类器分错的样本。这样增加每个弱分类器的差异， 最终提升的集成分类器的准确率。这种方法称为AdaBoost（Adaptive Boosting）算法。AdaBoost 算法是一种迭代式的训练算法，通过改变数据分布来提高弱分类器的差异。在每一轮训练中，增加分错样本的权重，减少分对样本的权重，从 而得到一个新的数据分布。以两类分类为例，弱分类器fm(x) ∈ {+1, −1}，AdaBoost 算法的训练过程如算法10.1所示。最初赋予每个样本同样的权重。在每一轮迭代中，根据当前邱锡鹏：《神经网络与深度学习》https://nndl.github.io/
 2382019 年 4 月 6 日第10 章 模型独立的学习方式的样本权重训练一个新的弱分类器。然后根据这个弱分类器的错误率来计算其集成权重，并调整样本权重。算法 10.1: 两类分类的AdaBoost 算法输入: 训练集{(x(n), y(n))}N ，迭代次数Mn=11 初始样本权重：w(n) ← 1 ,∀n ∈ [1,N];1N2 for m = 1 · · · M do(1), · · · , wm(N)，学习弱分类器f ;m345按照样本权重wm计算弱分类器fm 在数据集上的加权错误为ϵm;计算分类器的集成权重：11 − ϵmα←log;m2ϵm6调整样本权重：(n)m+1← wm(n) exp − α y(n)f (x(n)) , ∀n ∈ [1, N ];wmm7 endΣm=1M输出: F (x) = sgnα f (x)m mAdaBoost 算法的统计学解释 AdaBoost 算法可以看做是一种分步（stage-wise）优化的加性模型[Friedman et al., 2000]，其损失函数定义为L(F ) = exp − yF (x)(10.11)(10.12)ΣM= exp − yα f (x) ,m mm=1其中y, fm(x) ∈ {+1, −1}。假设经过m − 1 次迭代，得到Σm−1Fm−1(x) =α f (x),t t(10.13)(10.14)t=1则第m 次迭代的目标是找一个αm 和fm(x) 使得下面的损失函数最小。ΣNL(α , f (x)) =exp − y(n) Fm−1(x(n)) + αmfm(x (n)).mmn=1令 w(n) = exp − y(n)Fm−1(x(n)) ，则损失函数可以写为mNΣL(α , f (x)) =w(n) exp − α y(n)f (x(n)) .(10.15)mmmmmn=1邱锡鹏：《神经网络与深度学习》https://nndl.github.io/
 10.2 自训练和协同训练2019 年 4 月 6 日239因为y, fm(x) ∈ {+1, −1}，有yfm(x) = 1 − 2I(y fm(x)),(10.16)(10.17)其中I(x) 为指示函数。将损失函数在fm(x) = 0 处进行二阶泰勒展开，有指数函数exp(x) 在 x = 0 处ΣN的二阶泰勒展开公式为1 +w(n) 1− α(x(n)) + α2x2L(α , f (x)) =y(n)fx+。12mmmmmm2!邱锡鹏：《神经网络与深度学习》https://nndl.github.io/
 2402019 年 4 月 6 日第10 章 模型独立的学习方式n=1NΣfm(x(n)) .(10.18)ꢀ αm w(mn)I y(n)n=1从上式可以看出，当αm > 0 时，最优的分类器fm(x) 为使得在样本权重为wm(n), 1 ≤ n ≤ N 时的加权错误率最小的分类器。在求解出fm(x) 之后，公式(10.15)可以写为ΣΣL(α , f (x)) =w(n) exp(−α ) +w(n) exp(α )mmmmmmy(n)=fm (x(n))y(n) fm(x(n))(10.19)ꢀ (1 − ϵ ) exp(−α ) + ϵ exp(α ),(10.20)mmmm其中ϵm 为分类器fm(x) 的加权错误率，Σyw(n)m=fm (x(n))(n)=Σ.(10.21)ϵwm(n)邱锡鹏：《神经网络与深度学习》https://nndl.github.io/
 10.2 自训练和协同训练2019 年 4 月 6 日241nm求上式关于αm 的导数并令其为0，得到11 − ϵmα=log.(10.22)m2ϵm10.2 自训练和协同训练监督学习往往需要大量的标注数据，而标注数据的成本比较高，因此如何利 用大量的无标注数据来提高监督学习的效果，有十分重要的意义。这种利用少量 标注数据和大量无标注数据进行学习的方式称为半监督学习（Semi-SupervisedLearning，SSL）。本节介绍两种半监督学习算法：自训练和协同训练。邱锡鹏：《神经网络与深度学习》https://nndl.github.io/
 2422019 年 4 月 6 日第10 章 模型独立的学习方式10.2.1 自训练自训练（Self-Training），也叫自训练（Self-Teaching）或自举法（Bootstrapping），是一种非常简单的半监督学习算法[Scudder, 1965, Yarowsky, 1995]。这 里 的 bootstrapping 和统计中的概念不同。自训练是首先使用标注数据来训练一个模型，并使用这个模型来预测无标注样本的标签，把预测置信度比较高的样本及其预测的伪标签加入训练集，然后重新训练新的模型，并不断重复这个过程。算法10.2给出了自训练的训练过程。算法 10.2: 自训练的训练过程输入: 标注数据集L = {(x(n), y(n))}N;n=1无标注数据集 ꢀ = {x(m)}M;m=1迭代次数T ; 每次迭代增加样本数量P ;1 for t = 1 · · · T do23根据训练集L，训练模型f ;使用模型f 对未标记数据集ꢀ 的样本进行预测，选出预测置信度高的P 个样本P = {(x(p), f(x(p)))}P;p=14更新训练集：L ← L ∪ P,ꢀ ← ꢀ − P.5 end输出: 模型f自训练和密度估计中EM 算法有一定的相似之处，通过不断地迭代来提高模型能力。但自训练的缺点是无法保证每次加入训练集的样本的伪标签是正确的。如果选择样本的伪标签是错误的，反而会损害模型的预测能力。因此，自训练最关键的步骤是如何设置挑选样本的标准。参见习题10-2。10.2.2 协同训练协同训练（Co-Training）是自训练的一种改进方法，通过两个基于不同视角（view）的分类器来相互促进。很多数据都有相对独立的不同视角。比如互联网上的每个网页都由两种视角组成：文字内容（text）和指向其它网页的链接（hyperlink）。如果要确定一个网页的类别，可以根据文字内容来判断，也可根据网页之间的链接关系来判断。假设一个样本x = [x , x ]，其中x 和x 分别表示两种不同视角V 和V 的121212特征，并满足下面两个假设：（1）条件独立性：给定样本标签y 时，两种特征条件独立p(x , x |y) = p(x |y)p(x |y)；（2）充足和冗余性：当数据充分时，每种1212视角的特征都可以足以单独训练出一个正确的分类器。令y = g(x) 为需要学习邱锡鹏：《神经网络与深度学习》https://nndl.github.io/
 10.2 自训练和协同训练2019 年 4 月 6 日243的真实映射函数，f 和f 分别为两个视角的分类器，有12∃f , f , ∀x ∈ X ,f (x ) = f (x ) = g(x),(10.23)121122其中X 为样本x 的取值空间。由于不同视角的条件独立性，在不同视角上训练出来的模型就相当于从不同视角来理解问题，具有一定的互补性。协同训练就是利用这种互补性来来进行自训练的一种方法。首先在训练集上根据不同视角分别训练两个模型f 和f ，然12后用f 和f 在无标记数据集上进行预测，各选取预测置信度比较高的样本加入12训练集，重新训练两个不同视角的模型，并不断重复这个过程。算法10.3给出了协同训练的训练过程。算法 10.3: 协同训练的训练过程输入: 标注数据集L = {(x(n), y(n))}N;n=1无标注数据集 ꢀ = {x(m)}M;m=1迭代次数T ; 候选池大小K; 每次迭代增加样本数量2P ;1 for t = 1 · · · T do234根据训练集L 的视角V1 训练训练模型f1;根据训练集L 的视角V2 训练训练模型f2;从无标记数据集 ꢀ 上随机选取一些样本放入候选池 ꢀ′，使得|ꢀ′| = K;56for f ∈ f , f do12使用模型f 预测候选池ꢀ′ 中的样本的伪标签;for p = 1 · · · P do78根据标签分布，随机选取一个标签y;从ꢀ 中选出伪标签为 ，并且预测置信度最高的样本′yx;910更新训练集：L ← L ∪ {(x, y)},ꢀ′ ← ꢀ′ − {(x, y)}.1112endend13 end输出: 模型 f1,f2协同算法要求两种视图是条件独立的。如果两种视图完全一样，则协同训练退化成自训练算法。邱锡鹏：《神经网络与深度学习》https://nndl.github.io/
 2442019 年 4 月 6 日第10 章 模型独立的学习方式10.3 多任务学习一般的机器学习模型都是针对单一的特定任务，比如手写体数字识别、物体检测等。不同任务的模型都是在各自的训练集上单独学习得到的。如果有两个任务比较相关，它们之间会存在一定的共享知识，这些知识对两个任务都会有所帮助。这些共享的知识可以是表示（特征）、模型参数或学习算法等。目前，主流的多任务学习方法主要关注于表示层面的共享。多任务学习（Multi-task Learning）是指同时学习多个相关任务，让这些任务在学习过程中共享知识，利用多个任务之间的相关性来改进模型在每个任务的性能和泛化能力。多任务学习可以看作是一种归纳迁移学习（InductiveTransfer Learning），即通过利用包含在相关任务中的信息作为归纳偏置（InductiveBias）来提高泛化能力[Caruana, 1997]。共享机制 多任务学习的主要挑战在于如何设计多任务之间的共享机制。在传统的机器学习算法中，引入共享的信息是比较困难的，通常会导致模型变得复杂。 但是在神经网络模型中，模型共享变得相对比较容易。深层神经网络模型提供了一种很方便的信息共享方式，可以很容易地进行多任务学习。多任务学习的共享机制比较灵活，有非常多种的共享模型。图10.1给出了多任务学习中四种常见的共享模式。• 硬共享模式：让不同任务的神经网络模型共同使用一些共享模块（一般是低层）来提取一些通用特征，然后再针对每个不同的任务设置一些私有模块（一般是高层）来提取一些任务特定的特征。•软共享模式：不显式地设置共享模块，但每个任务都可以从其它任务中 “窃取”一些信息来提高自己的能力。窃取的方式包括直接复制使用其它 任务的隐状态，或使用注意力机制来主动选取有用的信息。• 层次共享模式：一般神经网络中不同层抽取的特征类型不同。底层一般抽取一些低级的局部特征，高层抽取一些高级的抽象语义特征。因此如果多任务学习中不同任务也有级别高低之分，那么一个合理的共享模式是让低 级任务在底层输出，高级任务在高层输出。• 共享-私有模式：一个更加分工明确的方式是将共享模块和任务特定（私有）模块的责任分开。共享模块捕捉一些跨任务的共享特征，而私有模块只捕捉和特定任务相关的特征。最终的表示由共享特征和私有特征共同构成。学习步骤 在多任务学习中，每个任务都可以有自己单独的训练集。为了让所有任务同时学习，我们通常会使用交替训练的方式来“近似”地实现同时学习。邱锡鹏：《神经网络与深度学习》https://nndl.github.io/
 10.3 多任务学习2019 年 4 月 6 日243ABCABC邱锡鹏：《神经网络与深度学习》https://nndl.github.io/
 2462019 年 4 月 6 日第10 章 模型独立的学习方式邱锡鹏：《神经网络与深度学习》https://nndl.github.io/
 邱锡鹏：《神经网络与深度学习》https://nndl.github.io/

 2482019 年 4 月 6 日第10 章 模型独立的学习方式邱锡鹏：《神经网络与深度学习》https://nndl.github.io/
 (a) 硬共享模式(b) 软共享模式BACA邱锡鹏：《神经网络与深度学习》https://nndl.github.io/
 2502019 年 4 月 6 日第10 章 模型独立的学习方式邱锡鹏：《神经网络与深度学习》https://nndl.github.io/
 C邱锡鹏：《神经网络与深度学习》https://nndl.github.io/
 2522019 年 4 月 6 日第10 章 模型独立的学习方式邱锡鹏：《神经网络与深度学习》https://nndl.github.io/
 (c) 层次共享模式(d) 共享-私有模式图 10.1 多任务学习中四种常见的共享模式假设有M 个相关任务，第m 个任务的训练集为Dm，包含Nm 个样本。Dm = {(x(m,n) , y(m,n) )}Nm(10.24),n=1其中x(m,n)和y(m,n)表示第m 个任务中的第n 个样本以及它的标签。假设这M 任务对应的模型分别为fm(x, θ), 1 ≤ m ≤ M ，多任务学习的联合目标函数为所有任务损失函数的线性加权。Σ ΣMNmL(θ) =η L f (x( m,n), θ), y(m,n),(10.25)mmmm=1 n=1其中L (·) 为第m 个任务的损失函数，η 是第m 个任务的权重，θ 表示包含了mm共享模块和私有模块在内的所有参数。权重可以根据不同任务的重要程度来赋邱锡鹏：《神经网络与深度学习》https://nndl.github.io/

 2442019 年 4 月 6 日第10 章 模型独立的学习方式值，也可以根据任务的难易程度来赋值。通常情况下，所有任务设置相同的权重，即ηm = 1, 1 ≤ m ≤ M 。多任务学习的流程可以分为两个阶段：（1）联合训练阶段：每次迭代时，随机挑选一个任务，然后从这个任务中随机选择一些训练样本，计算梯度并更新参数；（2）单任务精调阶段：基于多任务的学习到的参数，分别在每个单独任务进行精调。其中单任务精调阶段为可选阶段。当多个任务的差异性比较大时， 在每个单任务上继续优化参数可以进一步提升模型能力。多任务学习中联合训练阶段的具体过程如算法10.4所示。算法 10.4: 多任务学习中联合训练过程输入: M 个任务的数据集Dm, 1 ≤ m ≤ M ;每个任务的批量大小Km, 1 ≤ m ≤ M ;最大迭代次数T ，学习率α;1 随机初始化参数θ0;2 for t = 1 · · · T do// 准备M 个任务的数据3for m = 1 · · · M do将任务m 的训练集Dm 中随机划分为c =Bm = {Im,1, · · · , Im,c};endNmm个小批量集合：4K5合并所有小批量样本B随机排序B¯;¯ = B ∪ B ∪ · · · ∪ BM ;67128foreach I ∈ B¯ do9计算小批量样本I 上的损失L(θ) ; // 只计算I 在对应任务上的损失1011更新参数：θt ← θt−1 − α · ꢀθL(θ);end12 end输出: 模型 fm, 1 ≤ m ≤ M多任务学习通常可以获得比单任务学习更好的泛化能力，主要由于以下几个原因：1. 多任务学习在多个任务的数据集上进行训练，比单任务学习的训练集更大。由于多个任务之间有一定的相关性，因此多任务学习相当于是一种隐式的数据增强，可以提高模型的泛化能力。2. 多任务学习中的共享模块需要兼顾所有任务，这在一定程度上避免了模型 过拟合到单个任务的训练集，可以看作是一种正则化。邱锡鹏：《神经网络与深度学习》https://nndl.github.io/
 10.4 迁移学习2019 年 4 月 6 日2453. 既然一个好的表示通常需要适用于多个不同任务，多任务学习的机制使得 它参见第1.4节。会比单任务学习可以获得一个更好的表示。4. 在多任务学习中，每个任务都可以“选择性”利用其他任务中学习到的隐藏特征，从而提高自身的能力。10.4 迁移学习标准机器学习的前提假设是训练数据和测试数据的分布是相同的。如果不满足这个假设，在训练集上学习到的模型在测试集上的表现会比较差。而在很多实际场景中，经常碰到的问题是由标注数据的成本十分高，无法为一个目标任务准备足够多相同分布的训练数据。因此，如果有一个相关任务已经有了大量的训练数据，虽然这些训练数据的分布和目标任务不同，但是由于训练数据的规模比较大，我们假设可以从中学习某些可以泛化的知识，那么这些知识对目标任务会有一定的帮助。如何将相关任务的训练数据中的可泛化知识迁移到目标任务上，就是迁移学习（Transfer Learning）要解决的问题。具体而言，假设一个机器学习任务ꢀ 的样本空间为X × Y，其中X 为输入空间和 Y 为输出空间，其概率密度函数为 p(x, y)。简单起见，这里设 X 为 d 维实数空间的一个子集，Y 为一个离散的集合。p(x, y) = P (X = x, Yy).=一个样本空间及其分布可以称为一个领域（Domain）：D = (X , Y, p(x, y))。给定两个领域，如果它们的输入空间、输出空间或概率分布中至少一个不同，那么这两个领域就被认为是不同的。从统计学习的观点来看，一个机器学习任务ꢀ 定义为在一个领域D 上的条件概率p(y|x) 的建模问题。迁移学习是指两个不同领域的知识迁移过程，利用源领域（SourceDomain））D 中学到的知识用来帮助目标领域（Target Domain）D 上的学习任务。源ST领域的训练样本数量一般远大于目标领域。表10.1给出了迁移学习和标准机器学习的比较。学习类型样本空间概率分布标准机器学习迁移学习X = X , Y = Yp (x, y) = p (x, y)STSTSTXS X 或 Y = Y 或 p (x, y) = p (x, y)TSTST表 10.1 迁移学习类型迁移学习根据不同的迁移方式又分为两个类型：归纳迁移学习（InductiveTransfer Learning）和推导迁移学习（Transductive Transfer Learning）。这两邱锡鹏：《神经网络与深度学习》https://nndl.github.io/
 2462019 年 4 月 6 日第10 章 模型独立的学习方式个类型分别对应两个机器学习的范式：归纳学习（Inductive Learning）和转导学习（Transductive Learning）[Vapnik, 1998]。一般的机器学习都是指归纳学习，即希望在训练数据集上学习到使得期望风险（即真实数据分布上的错误率）最小的模型。而转导学习的目标是学习一种在给定测试集上错误率最小的模型，在训练阶段可以利用测试集的信息。期望风险参见第2.2.2节。归纳迁移学习是指在源领域和任务上学习出一般的规律，然后将这个规律迁移到目标领域和任务上；而转导迁移学习是一种从样本到样本的迁移，直接利用源领域和目标领域的样本进行迁移学习。10.4.0.1 归纳迁移学习在归纳迁移学习中，源领域和目标领域有相同的输入空间XS = XT ，输出空间可以相同也可以不同，源任务和目标任务一般都不相同ꢀ = ꢀ ，即STp (y|x) = p (y|x)。一般而言，归纳迁移学习要求源领域和目标领域是相关的，ST并且源领 域DS 有大量的训练样本，这些样本可以是有标注的样本也可以是无标注样本。1） 当源领域只有大量无标注数据时，源任务可以转换为无监督学习任务，比如自编码和密度估计任务。通过这些无监督任务学习一种可迁移的表示，然后在将这种表示迁移到目标任务上。这种学习方式和自学习（Self-Taught Learning）[Raina et al., 2007] 以及半监督学习比较类似。比如在自然语言处理领域，由于语言相关任务的标注成本比较高，很多自然语言处理任务的标注数据都比较少，这导致了在这些自然语言处理任务上经常会受限于训练样本数量而无法充分发挥深度学习模型的能力。同时，由于我们可以低成本地获取大规模的无标注自然语言文本，因此一种自然的迁移学习方式是将大规模文本上的无监督学习（比如语言模型）中学到的知识迁移到一个新的目标任务上。从早期的预训练词向量（比如word2vec [Mikolov et al., 2013] 和GloVe [Pennington et al., 2014] 等）到句子级表示（比如ELMO [Peters et al., 2018]、OpenAI GPT [Radford et al.,2018] 以及BERT[Devlin et al., 2018] 等）都对自然语言处理任务有很大的促进作用。自编码器参见第9.1.3节。概率密度估计参见第9.2节。2）当源领域有大量的标注数据时，可以直接将源领域上训练的模型迁移到目标领域上。比如在计算机视觉领域有大规模的图像分类数据集ImageNet[Deng et al., 2009]。由于在ImageNet 数据集上有很多预训练的图像分类模型，比如AlexNet[Krizhevsky et al., 2012]、VGG [Simonyan and Zisserman, 2014]和 ResNet[He et al., 2016] 等，我们可以将这些预训练模型迁移到目标任务上。在归纳迁移学习中，由于源领域的训练数据规模非常大，这些预训练模型通常有比较好的泛化性，其学习到的表示通常也适用于目标任务。归纳迁移学习一般有下面两种迁移方式：邱锡鹏：《神经网络与深度学习》https://nndl.github.io/
 10.4 迁移学习2019 年 4 月 6 日2471. 基于特征的方式：将预训练模型的输出或者是中间隐藏层的输出作为特征直接加入到目标任务的学习模型中。目标任务的学习模型可以是一般的浅层分类器（比如支持向量机等）或一个新的神经网络模型。2. 精调的方式：在目标任务上复用预训练模型的部分组件，并对其参数进行精调（ﬁne-tuning）。假设预训练的模型是一个深层神经网络，不同层的可迁移性也不尽相同[Yosinski et al., 2014]。通常来说，网络的低层学习一些通用的低层特征，中层或高层学习抽象的高级语义特征，而最后几层一般学习和特定任务相关的特征。因此，根据目标任务的自身特点以及和源任务的相关性，可以针对性地选择预训练模型的不同层来迁移到目标任务中。将预训练模型迁移目标任务上通常会比从零开始学习的方式更好，主要体现在以下三点[Torrey and Shavlik, 2010]：（1）初始模型的性能一般比随机初始化的模型要好；（2）训练时模型的学习速度比从零开始学习要快，收敛性更好；（3）模型的最终性能更好，具有更好的泛化性。归纳迁移学习和多任务学习也比较类似，但有下面两点区别：（1）多任务学习是同时学习多个不同任务，而归纳迁移学习是通常分为两个阶段，即源任 务上的学习阶段，和目标任务上的迁移学习阶段；（2）归纳迁移学习是单向的知识迁移，希望提高模型在目标任务上的性能，而多任务学习是希望提高所有 任务的性能。10.4.0.2 转导迁移学习转导迁移学习是一种从样本到样本的迁移，直接利用源领域和目标领域的样本进行迁移学习[Arnold et al., 2007]。转导迁移学习可以看作一个种特殊的转导学习（Transductive Learning）[Joachims, 1999]。转导迁移学习通常假设源领域有大量的标注数据，而目标领域没有（或有少量）标注数据，但是有大量的无标注数据。目标领域的数据在训练阶段是可见的。转导迁移学习的一个常见子问题是领域适应（Domain Adaptation）。在领域适应问题中，一般假设源领域和目标领域有相同的样本空间，但是数据分布不同 pS(x, y) pT (x, y)。根据贝叶斯公式，p(x, y) = p(x|y)p(y) = p(y|x)p(x)，因此数据分布的不一致通常由三种情况造成：1. 协变量偏移（Covariate Shift）：源领域和目标领域的输入边际分布不同p (x) = p (x)，但后验分布相同 p (y|x) = p (y|x)，即学习任务相同STSTꢀ = ꢀ 。ST邱锡鹏：《神经网络与深度学习》https://nndl.github.io/
 2482019 年 4 月 6 日第10 章 模型独立的学习方式2. 概念偏移（Concept Shift）：输入边际分布相同p (x) = p (x)，但后验ST分布不同p (y|x) = p (y|x)，即学习任务不同ꢀSꢀT 。ST3. 先验偏移（Prior Shift）：源领域和目标领域中的输出 y 先验分布不同p (y) = p (y)，条件分布相同 p (x|y) = pT (x|y)。在这样情况下，目STS标领域必须提供一定数量的标注样本。广义的领域适应问题可能包含上述一种或多种偏移情况。目前，大多数的领域适应问题主要关注于协变量偏移，这样领域适应问题在关键就在于如何学习领域无关（Domain-Invariant）的表示。假设p (y|x) = p (y|x)，领域适应的ST目标是学习一个模型f : X → Y 使得ꢀ (θ ) = E(x,y)[L(f (x, θf ), y)]p  (x, y)(10.26)Tf(x,y)∼pT= E[L(f (x,T), y)]f(10.27),y ∼p (x,y )(x)p (x, y)SSpT (x)= E(x,y)∼pS (x,y ) pS(x) [L( (x, θ ), y)],f(10.28)f其中L(·) 为损失函数，θf 为模型参数。如果我们可以学习一个映射函数 g : X → Rd，将 x 映射到一个特征空间中，并在这个特征空间中使得源领域和目标领域的边际分布相同p g(x, θ ) = pSgTg(x, θ ) , ∀x ∈ X，其中θ 为映射函数的参数，那么目标函数可以近似为gg"#ꢀ (θ , θ ) = EL f g(x, θg ), θf , y + γdg (S, T )(10.29)(10.30)其中ꢀ (θf , θ )为源领域上的期望风险函数，d (S, T )是一个分布差异的度量函Tfg(x,y)∼pS (x,y)= ꢀ (θ , θ ) + γd (S, T ),SfggSgg数，用来计算在映射特征空间中源领域和目标领域的样本分布的距离，γ 为一个超参数用来平衡两个子目标的重要性比例。这样，学习的目标是优化参数θf , θg使得提取的特征是领域无关的，并且在源领域上损失最小。令(n) (n)NDS = {(xS , y )} ∼ pS(x, y),(10.31)(10.32)Sn=1(m)MDT = {xT}∼ pT (x, y),m=1分别为源领域和目标领域的训练数据，我们首先用映射函数 g(x, θg) 将两个领域中训练样本的输入x 映射到特征空间，并优化参数θg 使得映射后两个领域的输入分布差异最小。分布差异一般可以通过一些度量函数来计算，比如MMD（Maximum Mean Discrepancy）[Gretton et al., 2007]、CMD（Central Moment邱锡鹏：《神经网络与深度学习》https://nndl.github.io/
 10.5 终生学习2019 年 4 月 6 日249Discrepancy）[Zellinger et al., 2017] 等，也可以通过领域对抗学习来得到领域无关的表示 [Bousmalis et al., 2016, Ganin et al., 2016]。以对抗学习为例，我们可以引入一个领域判别器c 来判断一个样本是来自于哪个领域。如果领域判别器c 无法判断一个映射特征的领域信息，就可以认为这个特征是一种领域无关的表示。对于训练集中的每一个样本x，我们都赋予ꢀ ∈ {1, 0} 表示它是来自于源领域还是目标领域，领域判别器c h, θc 根据其映射特征h = g(x, θg) 来预测它自于源领域的概率p(ꢀ = 1|x)。由于领域判别是一个两分类问题，h来自于目标领域的概率为1 − c h, θc 。因此，领域判别器的损失函数为：ΣΣNM1N1ML (θ , θ ) =log c(h(Sn), θc) +log 1 − c(x(m), θ ) ,(10.33)cgcDcn=1m=1其中h(n) = (x(n), θg )，h(m ) = (x(m ), x(n)θg ) 分别为样本gg和x(m )的特征向量。SSDDSD这样，领域迁移的目标函数可以分解为两个对抗的目标。一方面，要学习参数θ 使得领域判别器c(h, θ ) 尽可能区分出一个表示h = g(x, θ ) 是来自于哪ccg个领域；另一方面，要学习参数θ 使得提取的表示h 无法被领域判别器c(h, θ )预gc测出来，并同时学习参数θg 使得模型f (h, θf ) 在源领域的损失最小。minL (θ , θ ),(10.34)(10.35)cΣfcθ!(n)cminN(n)S()L f g(x , θg , θf , yS)− γL θ , θ .c cfθ ,θfgn=110.5 终生学习虽然深度学习在很多任务上取得了成功，前提是训练数据和测试数据的分布要相同，一但训练结束模型就保持固定，不再进行迭代更新。并且，要想一个模型同时在很多不同任务上都取得成功依然是一件十分困难的事情。比如在围棋任务上训练的AlphaGo 只会下围棋，对象棋一窍不通。如果将让AlphaGo去学习象棋，可能会损害其下围棋的能力，这显然不符合人类的学习过程。我们在学会了围棋之后，再去学象棋，不会忘记围棋的下法。人类的学习是一直持续的，人脑可以通过记忆不断地累积学习到的知识，这些知识累积可以在不同的任务中持续进行。在大脑的海马系统上，新的知识在以往知识的基础上被快速建立起来；之后经过长时间的处理，在大脑皮质区形成较难遗忘的长时记忆。由于不断的知识累积，人脑在学习新的任务时一般不需要太多的标注数据。终生学习（Lifelong Learning），也叫持续学习（Continuous Learning），是指像人类一样具有持续不断的学习能力，根据历史任务中学到的经验和知识邱锡鹏：《神经网络与深度学习》https://nndl.github.io/
 2502019 年 4 月 6 日第10 章 模型独立的学习方式来帮助学习不断出现的新任务，并且这些经验和知识是持续累积的，不会因为新的任务而忘记旧的知识[Chen and Liu, 2016, Thrun, 1998]。在终生学习中，假设一个终生学习算法已经在历史任务ꢀ , ꢀ , · · · , ꢀ 上学12m习到一个模型，当出现一个新任务ꢀm+1 时，这个算法可以根据过去在m 个任务上学习的知识来帮助第m + 1 个任务，同时累积所有的m + 1 个任务上的知识。这个设定和归纳迁移学习十分类似，但归纳迁移学习的目标是优化目标任务的性能，而不关心知识的累积。而终生学习的目标是持续的学习和知识累积。另外， 也和多任务学习的不同之处在于终生学习并不在所有任务上同时学习。多任务学习是在使用所有任务的数据进行联合学习，并不是持续的一个一个的学习。在终生学习中，一个关键的问题是如何避免灾难性遗忘（Catastrophic For-getting），即按照一定顺序学习多个任务时，在学习新任务的同时不忘记先前学会的历史任务[French, 1999, Kirkpatrick et al., 2017]。比如在神经网络模型中，一些参数对任务ꢀ 非常重要，如果在学任务ꢀ 时被改变了，就可能AB给任务ꢀA 造成不好的影响。在网络容量有限时，学习一个新的任务一般需要遗忘一些历史任务的知识。而目前的神经网络往往都是过参数化的，对于任务ꢀA 而言有很多参数组合都可以达到最好的性能。这样在学习任务ꢀ 时，可以找到一组不影响任务ꢀ 而BA又能使得任务ꢀB 最优的参数。解决灾难性遗忘的方法有很多。我们这里介绍一种 弹性权重巩固（ElasticWeight Consolidation）方法[Kirkpatrick et al., 2017]。不失一般性，以两个任务的持续学习为例，假设任务ꢀ 和任务ꢀ 的AB数据集分别为D 和D 。从贝叶斯的角度来看，我们希望计算给定两个任务时AB参数的后验分布：log p(θ|D) = log p(D|θ) + log p(θ) − log p(D),(10.36)其中D = D ∪ D ，θ 为模型参数。根据独立同分布假设，上式可以写为ABlog p(θ|D) = log p(D |θ) + log p(D |θ) + log p(θ) − log p(D ) − log p(D ),ABAB(10.37)= log p(D |θ) + log p(θ|D ) − log p(D ),(10.38)BAB其中p(θ|D ) 包含了所有从任务ꢀ 的学习的信息。当顺序地学习任务ꢀ 时，AAB参数在两个任务上的后验分布和其在任务ꢀA 的后验分布有关。由于后验分布比较难以建模，我们可以通过一个近似的方法来估计。假设参考[Bishop, 2007]中第4章p(θ|D ) 为高斯分布，期望为在任务ꢀ 上学习到的参数θ∗ ，精度矩阵（即协方AAA中的拉普拉斯近似。差矩阵的逆）是用参数 θ 的 Fisher 信息矩阵来衡量。邱锡鹏：《神经网络与深度学习》https://nndl.github.io/
 10.5 终生学习2019 年 4 月 6 日251p(θ|DA ) = N (θA∗ , F −1 ,)(10.39)其中F 为Fisher信息矩阵。为了提高计算效率，F 可以简化为对角阵，由Fisher信息矩阵对角线构成。Fisher 信息矩阵 Fisher 信息矩阵（Fisher Information Matrix）是一种测量可观察一个似然函数p(x|θ) 携带的关于参数θ 的信息量的方法。通常一个参数对分布的影响可以通过对数似然函数的梯度来衡量。我们定义打分函数s(θ) 为s(θ) = ꢀθ log p(x|θ),(10.40)则 s(θ) 的期望为0。证明.∫E[s(θ)] = ꢀθ log p(x|θ)p(x|θ)dx(10.41)∫ꢀθp(x|θ)p(x|θ)==p(x|θ)dx(10.42)(10.43)∫ꢀ p(x|θ)dxθ∫= ꢀθ p(x|θ)dx(10.44)(10.45)= ꢀθ1 = 0.s(θ) 的协方差矩阵称为Fisher 信息矩阵，可以衡量参数θ 的估计的不确定性。F (θ) = E[s(θ)s(θ)T ]= E[ꢀ log p(x|θ)(ꢀ log p(x|θ))T ].(10.46)(10.47)θθ通常我们不知道似然函数p(x|θ)的具体形式，Fisher信息矩阵可以用经验的分布来进度估计。给定一个数据集{x(1), · · · , x(N )}，Fisher信息矩阵可以近似为ΣN1NF (θ) =ꢀ log p(x(n)|θ)(ꢀθ log p(x(n)|θ))θT.(10.48)n=1Fisher 信息矩阵的对角线的值反映了对应参数在通过最大似然进行估计时的不确定性，其值越大表示该参数估计值的方差越小，估计更可靠性，其携带的关于数据分布的信息越多。邱锡鹏：《神经网络与深度学习》https://nndl.github.io/
 2522019 年 4 月 6 日第10 章 模型独立的学习方式因此，对于任务ꢀ 的数据集D ，我们可以用Fisher 信息矩阵来衡量一AA个参数携带的关于D 的信息量。AΣ1NFA(θ) =ꢀ log p(y|x, θ)(ꢀ log p(y|x, θ)) .(10.49)Tθθ(x, )∈DA通过上面的近似，在训练任务ꢀB 时的损失函数为NΣλL(θ) = LB (θ) +FA · (θ − θ∗) ,2(10.50)iiA ,i2i=1其中L (θ) 为任务p(θ|D ) 的损失函数，F 为Fisher信息矩阵的第 个对角线AiBBi参见习题10-3。元素，λ为平衡两个任务重要性的超参数，N 为参数的总数量。10.6 元学习根据没有免费午餐定理，没有一种通用的学习算法在所有任务上都有效。因此，当使用机器学习算法实现某个任务时，我们通常需要“就事论事”，根据任务的特定来选择合适的模型、损失函数、优化算法以及超参数。那么，我们是否可以有一套自动方法，根据不同任务来动态地选择合适的模型或动态地调整超参数呢？事实上，人脑中的学习机制就具备这种能力。在面对不同的任务时， 人脑的学习机制并不相同。即使面对一个新的任务，人们往往也可以很快找到其学习方式。这种可以动态调整学习方式的能力，称为元学习（Meta-Learning），也称为学习的学习（Learning to Learn）[Thrun and Pratt, 2012]。元学习的目的是从已有任务中学习一种学习方法或元知识，可以加速新任务的学习。从这个角度来说，元学习十分类似于归纳迁移学习，但元学习更侧重从多种不同（甚至是不相关）的任务中归纳出一种学习方法。和元学习比较相关的另一个机器学习问题是小样本学习（Few-shot Learn-ing），即在小样本上的快速学习能力。每个类只有K 个标注样本，K 非常小。如果K = 1，称为单样本学习（One-shot Learning），如果K = 0，称为零样本学习（One-shot Learning）。这里我们主要介绍两种典型的元学习方法：基于优化器的元学习和模型无关的元学习。10.6.1 基于优化器的元学习目前神经网络的学习方法主要是定义一个目标损失函数L(θ)，并通过梯度下降算法来最小化L(θ)，θt ← θt−1 − αꢀL(θt−1)(10.51)邱锡鹏：《神经网络与深度学习》https://nndl.github.io/
 10.6 元学习2019 年 4 月 6 日253其中θt 为第t 步时的模型参数，ꢀL(θt−1) 为梯度，α 为学习率。根据没有免费午餐定理，没有一种通用的优化算法在所有任务上都有效。因此在不同的任务上，我们需要选择不同的学习率以及不同的优化方法，比如动量法，Adam 等。这些选择对具体一个学习的影响非常大。对于一个新的任务，我们往往通过经验或超参搜索来选择一个合适的设置。参见第7.2节。不同的优化算法的区别在于更新参数的规则不同，因此一种很自然的元学习就是自动学习一种更新参数的规则，即通过另一个神经网络（比如循环神经网络）来建模梯度下降的过程[Andrychowicz et al., 2016, Schmidhuber, 1992,Younger et al., 2001]。图10.2给出了基于优化器的元学习的示例。T : {x(n), y(n)}NAϕ∗f (x, θ∗)n=1新任务模型学习算法T , T , · · · , TAM12M任务集合元学习算法图 10.2 基于优化器的元学习我们用函数g (·)来预测第t步时参数更新的差值∆θ = θ − θt−1。函数gt(·)ttt称为优化器，输入是当前时刻的梯度值，输出是参数的更新差值∆θt。这样第t步的更新规则可以写为θt+1 = θ + g ꢀL(θ ), ϕ(10.52)ttt其中ϕ 为优化器gt(·) 的参数。学习优化器gt(·) 的过程可以看做是一种元学习过程，其目标是找到一个适用于多个不同任务的优化器。在标准梯度下降中，每步迭代的目标是使得L(θ)下降。而在优化器的元学习中，我们希望在每步迭代的目标是L(θ) 最小，具体的目标函数为ΣTL(ϕ) = Efw L(θ ) ,(10.53)ttt=1θt = θt−1 + gt,(10.54)(10.55)[g ; h ] = LSTM ꢀL(θ − ), h − , ϕ ,ttt1t 1其中T 为最大迭代次数，w > 0 为每一步的权重，一般可以设置w = 1, ∀t。由tt于 LSTM 网络可以记忆梯度的历史信息，学习到的优化器可以看做是一个高阶的优化方法。邱锡鹏：《神经网络与深度学习》https://nndl.github.io/
 2542019 年 4 月 6 日第10 章 模型独立的学习方式在每步训练时，随机初始化模型参数，计算每一步的L(θt)，以及元学习的损失函数L(ϕ)，并使用梯度下降更新参数。由于神经网络的参数非常多，导致LSTM 网络的输入和输出都是非常高维的，训练这样一个巨大的网络是不可行的。因此，一种简化的方法是为每个参数都使用一个共享的LSTM 网络来进行更新，这样可以使用一个非常小的共享LSTM 网络来更新参数。10.6.2 模型无关的元学习既然元学习的目标之一是快速学习的能力，即在多个不同的任务上学习学习一个模型，让其在新任务上经过少量的迭代，甚至是单步迭代，就可以达到一个非常好的性能，并且避免在新任务上的过拟合。模型无关的元学习（Model-Agnostic Meta-Learning，MAML）是一个简单的模型无关、任务无关的元学习算法[Finn et al., 2017]。假设所有的任务都来自于一个任务空间，其分布为p(ꢀ )，我们可以在这个任务空间的所有任务上学习一种通用的表示，这种表示可以经过梯度下降方法在一个特定的单任务上进行精调。假设一个模型为f (θ)，如果我们让这个模型适应到一个新任务ꢀm 上，通过一步或多步的梯度下降更新，学习到的任务适配参数为′( )θ − αꢀθL f ,θ=(10.56)mꢀmθ其中α 为学习率。这里θ′ 可以理解为关于θ 的函数，而不是真正的参数更新。MAML 的目标是学习一个参数θ 使得其经过一个梯度迭代就可以在新任务上达到最好的性能。ΣΣf (θm′ ) =Lꢀm f θ − αꢀθLꢀm (fθ)(10.57)minθLꢀmꢀm ∼p(ꢀꢀ)m ∼p(ꢀ)在所有任务上的元优化（Meta-Optimization）也采用梯度下降来进行优化，即M← − ꢀf),′θmθθβꢀm ((10.58)θm=1L其中β 为元学习率，这里为一个真正的参数更新步骤。这里需要计算关于θ的二阶梯度，但用一级近似通常也可以达到比较好的性能。邱锡鹏：《神经网络与深度学习》https://nndl.github.io/
 10.7 总结和深入阅读2019 年 4 月 6 日255MAML 的具体过程如算法10.5所示。算法 10.5: 模型无关的元学习输入: 任务分布p(ꢀ );最大迭代次数T ，学习率α, β;1 随机初始化参数θ;2 for t = 1 · · · T do3根据p(ꢀ ) 采样一个任务集合 m=1 for m = 1 · · · M do{ꢀm}M45计算ꢀθLꢀm (fθ);计算任务适配的参数：θ′← θ − αꢀθLꢀ(f );θm67end更新参数：θ ← θ − βꢀθΣMm=1L(fθ′ );ꢀmm8 end输出: 模型 fθ10.7 总结和深入阅读目前，神经网络的学习机制主要是以监督学习为主，这种学习方式得到的模型往往是任务定向的，也是孤立的。每个任务的模型都是从零开始来训练的，一切知识都需要从训练数据中得到，导致每个任务都大量的训练数据。这些学习过程和人脑的学习方式是不同，人脑的学习过程一般不太需要太多的标注数据，并且是持续的学习，可以通过记忆不断地累积学习到的知识。本章主要介绍了一些和模型无关的学习方式。关于集成学习可以参考《Pattern Recognition and Machine Learning》[Bishop,2007] 和综述文献[Zhou, 2012]。在训练神经网络时采用的Dropout 方法在一定程度上也是一个模型集成。集成学习通过汇总多个模型来提高预测准确率的有 效方法，代表性模型有随机森林[Breiman, 2001] 和 AdaBoost[Freund et al.,1996]。半监督学习研究的主要内容就是如何高效的利用少量标记数据和大量的未标记数据来训练分类器。相比于监督学习，半监督学习一般需要更少的标注数据，因此在理论和实际在运用中均受到了广泛关注。半监督学习可以参考综述 [Zhu, 2006]。最早在训练中运用未标记数据的方法是自训练（Self-Training）[Scudder, 1965]：在自训练的基础上，Blum and Mitchell [1998]提出了由两个分类器协同训练的算法 Co-Training。该工作获得了国际机器学习会议ICML 2008 的10年最佳论文。关于多任务学习是一种利用多个相关任务来提高模型泛化性的方法，可以邱锡鹏：《神经网络与深度学习》https://nndl.github.io/
 2562019 年 4 月 6 日第10 章 模型独立的学习方式参考文献[Caruana, 1997, Zhang and Yang, 2017]。邱锡鹏：《神经网络与深度学习》https://nndl.github.io/
 

 2562019 年 4 月 6 日参考文献关于迁移学习是研究如何将在一个领域上训练的模型，迁移到新的领域，使 得新模型不用从零开始学习。但在迁移学习中需要避免将领域相关的特征迁移 到新的领域[Ganin et al., 2016, Pan and Yang, 2010]。迁移学习的一个主要研究问题是领域适应[Ben-David et al., 2010, Zhang et al., 2013]。终生学习是一种持续地学习方式，学习系统可以不断累积在先前任务中学到的知识，并在未来新的任务中能够利用这些知识[Chen and Liu, 2016, Good-fellow et al., 2013, Kirkpatrick et al., 2017]。元学习是主要关注于如何在多个不同任务上学习一种可泛化的快速学习能力[Thrun and Pratt, 2012]。上述这些方式都是目前深度学习中的前沿研究问题。习题习题 10-1 集成学习是否可以避免过拟合？习题 10-2 分析自训练和EM 算法之间的联系。习题 10-3 根据最大后验估计来推导公式(10.50)。参考文献Marcin Andrychowicz, Misha Denil, SergioGomez, Matthew W Hoﬀman, David Pfau,Tom Schaul, and Nando de Freitas. Learn-ing to learn by gradient descent by gradientdescent. In Advances in Neural InformationProcessing Systems, pages 3981–3989, 2016.formation science and statistics. Springer,2007. ISBN 9780387310732.Avrim Blum and Tom Mitchell. Combininglabeled and unlabeled data with co-training.In Proceedings of the eleventh annual con-ference on Computational learning theory,pages 92–100, 1998.Andrew Arnold, Ramesh Nallapati, andWilliam W Cohen. A comparative study ofmethods for transductive transfer learning.In icdmw, pages 77–82. IEEE, 2007.Konstantinos Bousmalis, George Trigeorgis,Nathan Silberman, Dilip Krishnan, and Du-mitru Erhan. Domain separation networks.In Advances in Neural Information Process-ing Systems, pages 343–351, 2016.Shai Ben-David, John Blitzer, Koby Cram-mer, Alex Kulesza, Fernando Pereira, andJennifer Wortman Vaughan. A theory oflearning from diﬀerent domains. Machinelearning, 79(1-2):151–175, 2010.Leo Breiman. Random forests. Machinelearning, 45(1):5–32, 2001.R. Caruana. Multi-task learning. MachineLearning, 28(1):41–75, 1997.Christopher M. Bishop. Pattern recogni-tion and machine learning, 5th Edition. In-Zhiyuan Chen and Bing Liu. Lifelong ma-chine learning. Synthesis Lectures on Ar-邱锡鹏：《神经网络与深度学习》https://nndl.github.io/
 参考文献2019 年 4 月 6 日257tiﬁcial Intelligence and Machine Learning,10(3):1–145, 2016.information processing systems, pages 513–520, 2007.Jia Deng, Wei Dong, Richard Socher, Li-Jia Li, Kai Li, and Li Fei-Fei. Imagenet:A large-scale hierarchical image database.In Computer Vision and Pattern Recogni-tion, 2009. CVPR 2009. IEEE Conferenceon, pages 248–255. IEEE, 2009.Kaiming He, Xiangyu Zhang, ShaoqingRen, and Jian Sun. Deep residual learningfor image recognition. In Proceedings of theIEEE conference on computer vision andpattern recognition, pages 770–778, 2016.Thorsten Joachims. Transductive inferencefor text classiﬁcation using support vectormachines. In ICML, volume 99, pages 200–209, 1999.Jacob Devlin, Ming-Wei Chang, KentonLee, and Kristina Toutanova. Bert: Pre-training of deep bidirectional transformersfor language understanding. arXiv preprintarXiv:1810.04805, 2018.James Kirkpatrick, Razvan Pascanu, NeilRabinowitz, Joel Veness, Guillaume Des-jardins, Andrei A Rusu, Kieran Milan, JohnQuan, Tiago Ramalho, Agnieszka Grabska-Barwinska, et al. Overcoming catastrophicforgetting in neural networks. Proceedingsof the national academy of sciences, 114(13):3521–3526, 2017.Chelsea Finn, Pieter Abbeel, and SergeyLevine. Model-agnostic meta-learning forfast adaptation of deep networks. In Pro-ceedings of the 34th International Con-ference on Machine Learning-Volume 70,pages 1126–1135. JMLR. org, 2017.Alex Krizhevsky, Ilya Sutskever, and Ge-oﬀrey E Hinton. Imagenet classiﬁcationwith deep convolutional neural networks. InAdvances in neural information processingsystems, pages 1097–1105, 2012.Robert M French. Catastrophic forgettingin connectionist networks. Trends in cogni-tive sciences, 3(4):128–135, 1999.Yoav Freund, Robert E Schapire, et al. Ex-periments with a new boosting algorithm.In Proceedings of the International Con-ference on Machine Learning, volume 96,pages 148–156. Citeseer, 1996.Tomas Mikolov, Ilya Sutskever, Kai Chen,GregSCorrado, and Jeﬀ Dean.Distributed representations of words andphrases and their compositionality. InAdvances in neu- ral informationprocessing systems, pages 3111–3119,2013.Jerome Friedman, Trevor Hastie, RobertTibshirani, et al. Additive logistic regres-sion: a statistical view of boosting. Theannals of statistics, 28(2):337–407, 2000.Yaroslav Ganin, Evgeniya Ustinova, HanaAjakan, Pascal Germain, Hugo Larochelle,François Laviolette, Mario Marchand, andVictor Lempitsky. Domain-adversarialtraining of neural networks. Journal ofMachine Learning Research, 17(59):1–35,2016.Sinno Jialin Pan and Qiang Yang. A sur-vey on transfer learning. IEEE Transac-tions on knowledge and data engineering,22(10):1345–1359, 2010.Jeﬀrey Pennington, Richard Socher, andChristopher Manning. Glove: Global vec-tors for word representation. In Proceed-ings of the 2014 conference on empiri-cal methods in natural language processing(EMNLP), pages 1532–1543, 2014.Ian J Goodfellow, Mehdi Mirza, Da Xiao,Aaron Courville, and Yoshua Bengio. Anempirical investigation of catastrophic for-getting in gradient-based neural networks.arXiv preprint arXiv:1312.6211, 2013.Matthew E Peters, Mark Neumann, Mo-hit Iyyer, Matt Gardner, Christopher Clark,Kenton Lee, and Luke Zettlemoyer. Deepcontextualized word representations. arXivpreprint arXiv:1802.05365, 2018.Arthur Gretton, KarstenMBorgwardt,andMalte Rasch, Bernhard Schölkopf,Alex J Smola. A kernel method for the two-Alec Radford, Karthik Narasimhan, TimSalimans, and Ilya Sutskever. Improvinglanguage understanding by generativesample-problem. In Advances in neural邱锡鹏：《神经网络与深度学习》https://nndl.github.io/
 2582019 年 4 月 6 日参考文献pre-training.URL https://s3-us-west-2.David Yarowsky. Unsupervised word sensedisambiguation rivaling supervised meth-ods. In Proceedings of the 33rd annualmeeting on Association for ComputationalLinguistics, pages 189–196, 1995.amazonaws. com/openai-assets/research-covers/languageunsupervised/languageunderstanding paper. pdf, 2018.Rajat Raina, Alexis Battle, Honglak Lee,Benjamin Packer, and Andrew Y Ng. Self-taught learning: transfer learning from un-labeled data. In Proceedings of the 24thinternational conference on Machine learn-ing, pages 759–766, 2007.Jason Yosinski, Jeﬀ Clune, Yoshua Bengio,and Hod Lipson. How transferable are fea-tures in deep neural networks? In Advancesin neural information processing systems,pages 3320–3328, 2014.Jürgen Schmidhuber. Learning to controlfast-weight memories: An alternative to dy-namic recurrent networks. Neural Compu-tation, 4(1):131–139, 1992.A Steven Younger, Sepp Hochreiter, andPeter R Conwell. Meta-learning with back-propagation. In Proceedings of Interna-tional Joint Conference on Neural Net-works, volume 3. IEEE, 2001.HScudder. Probability oferrorofsome adaptive pattern-recognition ma-chines. IEEE Transactions on InformationTheory, 11(3):363–371, 1965.Werner Zellinger, Thomas Grubinger, Ed-win Lughofer, Thomas Natschläger, andSusanne Saminger-Platz. Central momentdiscrepancy (cmd) for domain-invariantrepresentation learning. arXiv preprintarXiv:1702.08811, 2017.Karen Simonyan and Andrew Zisserman.Very deep convolutional networks for large-scale image recognition. arXiv preprintarXiv:1409.1556, 2014.Kun Zhang, Bernhard Schölkopf, KrikamolMuandet, and Zhikun Wang. Domain adap-tation under target and conditional shift.In International Conference on MachineLearning, pages 819–827, 2013.Sebastian Thrun. Lifelong learning algo-rithms. In Learning to learn, pages 181–209.Springer, 1998.Sebastian Thrun and Lorien Pratt. Learn-ing to learn. Springer Science & BusinessMedia, 2012.Yu Zhang and Qiang Yang.A surveyon multi-task learning. arXiv preprintarXiv:1707.08114, 2017.Lisa Torrey and Jude Shavlik. Trans-fer learning.In Handbook of ResearchZhi-Hua Zhou. Ensemble methods: founda-tions and algorithms. Chapman and Hal-l/CRC, 2012.on Machine Learning Applications andTrends: Algorithms, Methods, and Tech-niques, pages 242–264. IGI Global, 2010.Vladimir Vapnik. Statistical learning the-ory. Wiley, New York, 1998.Xiaojin Zhu. Semi-supervised learning liter-ature survey. Computer Science, Universityof Wisconsin-Madison, 2(3):4, 2006.邱锡鹏：《神经网络与深度学习》https://nndl.github.io/
 第三部分进阶模型

 

 第 11 章 概率图模型概率论只不过是把常识归纳为计算问题。— 皮诶尔·西蒙·拉普拉斯概率图模型（Probabilistic Graphical Model，PGM），简称图模型（GraphicalModel，GM），是指一种用图结构来描述多元随机变量之间条件独立关系的概率模型，从而给研究高维空间中的概率模型带来了很大的便捷性。对于一个K 维随机向量X = [X , X , · · · , XK ]T ，其联合概率为高维空间12中的分布，一般难以直接建模。假设每个变量为离散变量并有m 个取值，在不作任何独立假设条件下，则需要mK − 1 个参数才能表示其概率分布。当m =2, K = 100 时，参数量约为1030，远远超出了目前计算机的存储能力。一种有效减少参数量的方法是独立性假设。K 维随机向量的联合概率分解为 K 个条件概率的乘积，p(x) , P (X = x)= p(x )p(x |x ) · · · p(x |x , · · · , xK −1),(11.1)(11.2)121K1YK=p(x |x , · · ·, xk−1),(11.3)k1k=1其中x 表示变量X 的取值。如果某些变量之间存在条件独立，其参数量就可kk以大幅减少。假设有四个二值变量X , X , X , X ，在不知道这几个变量依赖关系的情况1234下，可以用一个联合概率表来记录每一种取值的概率p(x1:4)，共需要24 − 1 = 15个参数。假设在已知X 时，X 和 X 独立，即有123p(x |x , x ) = p(x |x ),(11.4)(11.5)21321p(x |x , x ) = p(x |x ).31231
 2622019 年 4 月 6 日第 11 章 概率图模型在已知X 和 X 时，X 也和X 独立，即有2341p(x |x , x , x ) = p(x |x , x ),(11.6)4123423那么其联合概率p(x) 可以分解为p(x) = p(x )p(x |x )p(x |x , x )p(x |x , x , x ),(11.7)(11.8)1213124123= p(x )p(x |x )p(x |x )p(x |x , x ),12131423是 4 个局部条件概率的乘积。如果分别用4 个表格来记录这4 个条件概率的话，只需要1 + 2 + 2 + 4 = 9 个独立参数。当概率模型中的变量数量比较多时，其条件依赖关系也比较复杂。我们可以使用图结构的方式将概率模型可视化，以一种直观、简单的方式描述随机变量之间的条件独立性的性质，并可以将一个复杂的联合概率模型分解为一些简 单条件概率模型的组合。图11.1给出了上述例子中4个变量之间的条件独立性的图形化描述。图中每个节点表示一个变量，每条连边变量之间的依赖关系。对于一个非全连接的图，都存在一个或多个条件独立性假设，可以根据条件独立 性将联合概率分布进行分解，表示为一组局部条件概率分布的乘积。邱锡鹏：《神经网络与深度学习》https://nndl.github.io/
 X3X2X111.1 模 X4 示2019 年 4 月 6 日263邱锡鹏：《神经网络与深度学习》https://nndl.github.io/
 2642019 年 4 月 6 日第 11 章 概率图模型图 11.1 变量X , X , X , X 之间条件独立性的图形化表示1234图模型的基本问题 图模型有三个基本问题：1. 表示问题：对于一个概率模型，如何通过图结构来描述变量之间的依赖关系。2. 推断问题：在已知部分变量时，计算其它变量的后验概率分布。3. 学习问题：图模型的学习包括图结构的学习和参数的学习。在本章我们只关注在给定图结构时的参数学习，即参数估计问题。图模型与机器学习 很多机器学习模型都可以归结为概率模型，即建模输入和输出之间的条件概率分布。因此，图模型提供了一种新的角度来解释机器学习模型，并且这种角度有很多优点，比如了解不同机器学习模型之间的联系，方便设计新模型等。在机器学习中，图模型越来越多地用来设计和分析各种学习算法。邱锡鹏：《神经网络与深度学习》https://nndl.github.io/
 11.1 模型表示2019 年 4 月 6 日26511.1 模型表示图由一组节点和节点之间的边组成。在概率图模型中，每个节点都表示一 个随机变量（或一组随机变量），边表示这些随机变量之间的概率依赖关系。常见的概率图模型可以分为两类：有向图模型和无向图模型。有向图模型的图结构为有向非循环图，如果两个节点之间有连边，表示对于的两个变量为因果关系。无向图模型使用无向图来描述变量之间的关系。每条边代表两个变量之间有概率依赖关系，但是并不一定是因果关系。图11.2给出了两个代表性图模型（有向图和无向图）的示例，分别表示了四个变量{X , X , X , X } 之间的依赖关系1234邱锡鹏：《神经网络与深度学习》https://nndl.github.io/
 X3X1X42662019 年 4 月 6 日第 11 章 概率图模型X2邱锡鹏：《神经网络与深度学习》https://nndl.github.io/
 11.1 模型表示2019 年 4 月 6 日267(a) 有向图：贝叶斯网络(b) 无向图：马尔可夫随机场图11.2 有向图和无向图示例。带阴影的节点表示可观测到的变量，不带阴影的节点表示隐变量，连边表示两变量间的条件依赖关系11.1.1 有向图模型有向图模型（Directed Graphical model），也称为贝叶斯网络（BayesianNetwork），或信念网络（Belief Network，BN），是指用有向图来表示概率分布的图模型。假设一个有向图G(V, ꢀ)，节点集合V = {X , X , · · · , X } 表示12KK 个随机变量，节点k 对应随机变量Xk。ꢀ 为边的集合，每条边表示两个变量之间的因果关系。邱锡鹏：《神经网络与深度学习》https://nndl.github.io/
 2682019 年 4 月 6 日第 11 章 概率图模型定义 11.1–贝叶斯网络： 对于一个随机向量X = [X , X , · · · , XK ]T12和一个有K 个节点的有向非循环图G，G 中的每个节点都对应一个随机变量，可以是可观测的变量，隐变量或是未知参数。G 中的每个连接eij 表示两个随机变量X i和X 之间具有非独立的因果关系。Xπk表示变量 Xk 的所有父节点变量集合，每个随机变量的局部条件概率分布（local conditional probability distribution）为P (X |X )。kπk如果X 的联合概率分布可以分解为每个随机变量Xk 的局部条件概率的连乘形式，即YKp(x) =p(xk|xπk ),(11.9)k=1那么(G, X) 构成了一个贝叶斯网络。在本章后文中，“节点” 与“随机变量”、“变量”的概念会经常混用。每个节点对应一个随机变量。条件独立性 在贝叶斯网络中，如果两个节点是直接连接的，它们肯定是非条件独立的，是直接因果关系。父节点是“因”，子节点是“果”。如果两个节点不是直接连接的，但是它们之间有一条经过其它节点的路径来连接，那么这两个节点之间的条件独立性就比较复杂。以三个节点的贝叶斯网络为例，给定三个节点X , X , X ，X 和 X 是不直接连接的，可以通过节12313点X2 连接。这三个节点之间可以有四种连接关系，如图11.3所示。邱锡鹏：《神经网络与深度学习》https://nndl.github.io/
 11.1 模型表示2019 年 4 月 6 日269X1X2X3邱锡鹏：《神经网络与深度学习》https://nndl.github.io/
 2702019 年 4 月 6 日第 11 章 概率图模型X1X2X3邱锡鹏：《神经网络与深度学习》https://nndl.github.io/
 11.1 模型表示2019 年 4 月 6 日271X1X3X2(a)(b)(c) (d)图 11.3 三个变量的依赖关系示例。在(a)(b) 中，X ⊥ X |∅， 但 X ⊥ X |X ；13132在 (c) 中，X ⊥ X |∅，但X ⊥ X |X ；在(d) 中，X ⊥ X |∅，但X ⊥ X |X2131321313间接因果关系（图11.3a） 当X 已知时，X 和X 为条件独立，即X ⊥ X |X ；213132间接果因关系（图11.3b） 当X 已知时，X 和X 为条件独立，即X ⊥ X |X ；213132共因关系（图11.3c） 当X 未知时，X 和 X 是不独立的；当X 已知时，X12132和 X 条件独立，即X ⊥ X |X ；3132邱锡鹏：《神经网络与深度学习》https://nndl.github.io/
 2722019 年 4 月 6 日第 11 章 概率图模型共果关系（图11.3d） 当X 未知时，X 和 X 是独立的；当X 已知时，X 和21321X 不独立，即X ⊥ X |X 。3132局部马尔可夫性质 对一个更一般的贝叶斯网络，其局部马尔可夫性质为：每个随机变量在给定父节点的情况下，条件独立于它的非后代节点。从公式(11.3) 和 (11.9) 可得到。参见习题11-3。Xk ⊥ Z|Xπk,(11.10)其中Z 为 Xk 的非后代变量。11.1.2 常见的有向图模型很多经典的机器学习模型可以使用有向图模型来描述，比如朴素贝叶斯分类器、隐马尔可夫模型、深度信念网络等。深度信念网络参见第??节。11.1.2.1 sigmoid 信念网络为了减少模型参数，可以使用参数化模型来建模有向图模型中的条件概率分布。一种简单的参数化模型为sigmoid 信念网络[Neal, 1992]。sigmoid 信念网络（sigmoid belief network，SBN）中的变量取值为{0, 1}。对于变量Xk 和它的父节点集合πk，其条件概率分布表示为更复杂的深度信念网络，参见第??节。ΣP (X = 1|x , θ) = σ(θ +θ x ),i i(11.11)kπk0xi∈xπk其中σ(·) 是 Logistic sigmoid 函数，θi 是可学习的参数。假设变量Xk 的父节点数量为M ，如果使用表格来记录条件概率需要2M 个参数，如果使用参数化模型只需要M + 1 个参数。如果对不同的变量的条件概率都共享使用一个参数化模型，其参数数量又可以大幅减少。值得一提的是，Sigmoid 信念网络与Logistic 回归模型都采用Logistic 函数来计算条件概率。如果假设Sigmoid 信念网络中只有一个叶子节点，其所有的父节点之间没有连接，且取值为实数，那么sigmoid 信念网络的网络结构和Logistic 回归模型类似，如图11.4所示。但是，这两个模型区别在于Logistic 回归模型中的x 作为一种确定性的参数，而非变量。因此，Logistic 回归模型只建模条件概率p(y|x)，是一种判别模型；而sigmoid 信念网络建模p(x, y)，是一种生成模型。Logistic 回归模型也经常解释一种条件无向图模型。11.1.2.2 朴素贝叶斯分类器朴素贝叶斯分类器（Naive Bayes Classiﬁer，NB）是一类简单的概率分类器，在强（朴素）独立性假设的条件下运用贝叶斯公式来计算每个类别的后验概率。邱锡鹏：《神经网络与深度学习》https://nndl.github.io/
 11.1 模型表示2019 年 4 月 6 日273X1· · ·Xi· · ·XMX1 · · · X i · · · XMYY(a) 只有一层的简单sigmoid 信念(b) Logistic 回归网络图 11.4 sigmoid 信念网络和Logistic 回归模型的比较给定一个有d 维特征的样本x 和类别y，类别的后验概率为p(x , · · · , x |y)p(y)1dp(y|x, θ) =(11.12)(11.13)p(x , · · · , x )1dꢀ p(x , · · · , x |y, θ)p(y|θ),1d其中θ 为概率分布的参数。在朴素贝叶斯分类器中，假设在给定 Y 的情况下，Xi 之间是条件独立的，即Xi ⊥ Xj |Y, ∀i = j。图11.5给出了朴素贝叶斯分类器的图形表示。邱锡鹏：《神经网络与深度学习》https://nndl.github.io/
 x1xixd· · ·· · ·2742019 年 4 月 6 日第 11 章 概率图模型y邱锡鹏：《神经网络与深度学习》https://nndl.github.io/
 11.1 模型表示2019 年 4 月 6 日275图 11.5 朴素贝叶斯模型的图模型表示条件概率分布p(y|x) 可以分解为p(y|x, θ) ꢀ p(y|θc)dYp(xi|y, θi,y ),(11.14)i=1其中θc 是y 的先验概率分布的参数，θi,y 是条件概率分布p(xi|y, θi,y )的参数。如果xi 为连续值，p(xi|y, θi,y )可以用高斯分布建模。如果xi 为离散值，p(xi|y, θi,y可以用多项分布建模。)虽然朴素贝叶斯分类器的条件独立性假设太强，但是在实际应用中，朴素贝叶斯分类器在很多任务上也能得到很好的结果，并且模型简单，可以有效防止过拟合。邱锡鹏：《神经网络与深度学习》https://nndl.github.io/
 2762019 年 4 月 6 日第 11 章 概率图模型11.1.2.3 隐马尔可夫模型隐马尔可夫模型（Hidden Markov Model，HMM）[Baum and Petrie, 1966]是一种含有隐变量的马尔可夫过程。图11.6给出隐马尔可夫模型的图模型表示。Y1Y2· · ·YT −1YTX1X2· · ·XT −1XT图 11.6 隐马尔可夫模型隐马尔可夫模型的联合概率可以分解为YTp(x, y, θ) =p(yt|yt−1, θ )p(x |y , θ ),(11.15)stttt=1其中p(x |y , θ ) 为输出概率，p(y |y , θ ) 为转移概率，θ , θ 分别表示两类条ttttt−1sst件概率的参数。这里 p(y |y ) 一 般 简 化 为10p(y1)。11.1.3 无向图模型无向图模型，也称为马尔可夫随机场（Markov Random Field，MRF）或马尔可夫网络（Markov Network），是一类用无向图来描述一组具有局部马尔可夫性质的随机向量X 的联合概率分布的模型。定义 11.2–马尔可夫随机场： 对于一个随机向量X = [X1, · · · , XK ]T和一个有K 个节点的无向图G(V, ꢀ )（可以存在循环），图G 中的节点k 表示随机变量Xk，1 ≤ k ≤ K。如果(G, X) 满足局部马尔可夫性质，即一个变量Xk 在给定它的邻居的情况下独立于所有其它变量，p(x |x ) = p(x |xN(k)),(11.16)kKkk其中N (k) 为变量X 的邻居集合，Kk 为除X 外其它变量的集合，那kk么(G, X) 就构成了一个马尔可夫随机场。无向图的马尔可夫性无向图中的马尔可夫性可以表示为Xk ⊥ XKN (k),Kk | XN (k)其中XKN(k),Kk 表示除XN(k) 和 Xk 外的其它变量。,邱锡鹏：《神经网络与深度学习》https://nndl.github.io/
 11.1 模型表示2019 年 4 月 6 日277对于图11.2b中的4 个变量，根据马尔可夫性质，可以得到 X ⊥ X |X , X3142和 X ⊥ X |X , X 。231411.1.4 无向图模型的概率分解团 由于无向图模型并不提供一个变量的拓扑顺序，因此无法用链式法则对p(x) 进行逐一分解。无向图模型的联合概率一般以全连通子图为单位进行分解。无向图中的一个全连通子图，称为团（Clique），即团内的所有节点之间都连边。图11.7中共有7 个团，包括{X , X }，{X , X }，{X , X }，{X , X }，{X , X }，1213233424{X , X , X }，{X , X , X }。123234在所有团中，如果一个团不能被其它的团包含，这个团就是一个最大团（Maximal Clique）。邱锡鹏：《神经网络与深度学习》https://nndl.github.io/
 X32782019 年 4 月 6 日第 11 章 概率图模型X1X4X2邱锡鹏：《神经网络与深度学习》https://nndl.github.io/
 11.1 模型表示2019 年 4 月 6 日279图 11.7 无向图模型中的团和最大团因子分解无向图中的的联合概率可以分解为一系列定义在最大团上的非负函数的乘积形式。定理 11.1 –Hammersley-Clifford定理： 如果一个分布p(x) > 0满足无向图G 中的局部马尔可夫性质，当且仅当p(x)可以表示为一系列定义在最大团上的非负函数的乘积形式，即Y1p(x) =ϕ (x ),(11.17)Zccc∈C其中C 为 G 中的最大团集合，ϕ (x ) ≥ 0 是定义在团c 上的势能cc函数（potential function），Z 是配分函数（partition function），用来将乘积归一化为概率形式。Σ YZ =ϕ (x )(11.18),ccx∈X c∈C邱锡鹏：《神经网络与深度学习》https://nndl.github.io/
 2802019 年 4 月 6 日第 11 章 概率图模型其中X 为随机向量X 的取值空间。Hammersley-Cliﬀord 定理的证明可以参考[Koller and Friedman, 2009]。无向图模型与有向图模型的一个重要区别是有配分函数Z。配分函数的计算复杂度是指数级的，因此在推断和参数学习时都需要重点考虑。配 分 函 数 的 计 算 参 见第11.2.2节。吉布斯分布 公式(11.17)中定义的分布形式也称为吉布斯分布（Gibbs distribu-tion）。根据Hammersley-Cliﬀord 定理，无向图模型和吉布斯分布是一致的。吉布斯分布一定满足马尔可夫随机场的条件独立性质，并且马尔可夫随机场的概率分布一定可以表示成吉布斯分布。由于势能函数必须为正的，因此我们一般定义为这里的负号是遵从物理上习惯，即能量越低意味着概率越高。ϕ (x ) = exp(−E (x )),(11.19)cccc其中E(xc) 为能量函数（energy function）。因此，无向图上定义的概率分布可以表示为：Y1ZP (x) =exp(−E (x ))(11.20)(11.21)ccc∈CΣZ1cc=exp(c∈C −E (x ))这种形式的分布又称为玻尔兹曼分布（Boltzmann Distribution）。任何一个无向图模型都可以用公式(11.21)来表示其联合概率。玻尔兹曼分布参见定义??。玻尔兹曼机参见第12.1节。11.1.5 常见的无向图模型很多经典的机器学习模型可以使用无向图模型来描述，比如对数线性模型（也叫最大熵模型）、条件随机场、玻尔兹曼机、受限玻尔兹曼机等。11.1.5.1 对数线性模型受 限 玻 尔 兹 曼 机 参 见第12.2节。势能函数一般定义为ϕ (x |θ ) = exp θTf (x ) ,(11.22)cccccc其中函数f (x ) 为定义在x 上的特征向量，θ 为权重向量。这样联合概率p(x)cccc的对数形式为Σlog p(x|θ) =θTf (x ) − log Z(θ),(11.23)cccc∈C其中θ 代表所有势能函数中的参数θc。这种形式的无向图模型也称为对数线性模型（Log-Linear Model）或最大熵模型（Maximum Entropy Model）[Bergeret al., 1996, Della Pietra et al., 1997]。邱锡鹏：《神经网络与深度学习》https://nndl.github.io/
 11.1 模型表示2019 年 4 月 6 日281邱锡鹏：《神经网络与深度学习》https://nndl.github.io/
 2822019 年 4 月 6 日第 11 章 概率图模型如果用对数线性模型来建模条件概率p(y|x)，1p(y|x, θ) =exp θTf(x, y) ,(11.24)Z(x, θ)Σ其中 Z(x, θ) =exp(θ fy(x, y))。这种对数线性模型也称为条件最大熵模型Ty或 softmax 回归模型。softmax 回 归 模 型 参 见第3.3节。11.1.5.2 条件随机场条件随机场（Conditional Random Field，CRF）[Laﬀerty et al., 2001] 是一种直接建模条件概率的无向图模型。和最大熵模型不同，条件随机场建模的条件概率p(y|x) 中，y 一般为随机向量，因此需要对p(y|x) 进行因子分解。假设条件随机场的最大团集合为C，其条件概率为Σ1p(y|x, θ) =expθTf (x, y ) ,(11.25)cccZ (x, θ )c∈CΣΣ其中 Z(x, θ) =exp(f (x, y ) θc) 为归一化项。cTyc∈Cc一个最常用的条件随机场为图11.8b中所示的链式结构，其条件概率为ΣT1ΣT −1p(y|x, θ) =expθ f (x, yt ) +θ f (x, y , yt+1) ,(11.26)TT12tZ (x, θ)12t=1t=1其中f (x, y ) 为状态特征，一般和位置t 相关，f (x, y , yt+1) 为转移特征，一般1t2t可以简化为f (y , yt+1) 并使用状态转移矩阵来表示。2t邱锡鹏：《神经网络与深度学习》https://nndl.github.io/
 Y11.1 模型表示2019 年 4 月 6 日283XYY2· · ·YT −1YT1X邱锡鹏：《神经网络与深度学习》https://nndl.github.io/
 2842019 年 4 月 6 日第 11 章 概率图模型(a) 最大熵模型(b) 线性链的条件随机场图 11.8 最大熵模型和线性链的条件随机场11.1.6 有向图和无向图之间的转换无向图模型可以表示有向图模型无法表示的一些依赖关系，比如循环依赖；但它不能表示有向图模型能够表示的某些关系，比如因果关系。邱锡鹏：《神经网络与深度学习》https://nndl.github.io/
 11.2 推断2019 年 4 月 6 日271以图11.9a中的有向图为例，其联合概率分布可以分解为p(x) = p(x )p(x )p(x )p(x |x , x , x ),(11.27)1234123其中p(x |x , x , x ) 和四个变量都相关。如果要转换为无向图，需要将这四个变量4123都归属于一个团中。因此需要将x4 的三个父节点之间都加上连边，如图11.9b所示。这个过程称为道德化（Moralization）。转换后的无向图称为道德图（MoralGraph）。在道德化的过程中，原来有向图的一些独立性会丢失，比如上面例子中X ⊥ X ⊥ X |∅ 在道德图中不再成立。道德化的名称来源是：有共同儿子的父节点都必须结婚（即有连边）。122邱锡鹏：《神经网络与深度学习》https://nndl.github.io/
 2722019 年 4 月 6 日第 11 章 概率图模型X1X3X2X4邱锡鹏：《神经网络与深度学习》https://nndl.github.io/
 11.2 推断2019 年 4 月 6 日273X1X3X2X4(a) 有向图(b) 道德图图 11.9 具有共果关系的有向图的道德化示例邱锡鹏：《神经网络与深度学习》https://nndl.github.io/
 2742019 年 4 月 6 日第 11 章 概率图模型11.2 推断在图模型中，推断（inference）是指在观测到部分变量e = {e , e , · · · , e }12m时，计算其它变量的某个子集q = {q , q , · · · , q } 的后验概率p(q|e)。12n假设一个图模型中，除了变量e、q外，其余变量表示为z。根据贝叶斯公式有不失一般性，这里假设所有变量都为离散变量。p(q, e)p(e)p(q|e) =(11.28)(11.29)ΣΣp(q, e, z)p(q, e, z)=z.q,z因此，图模型的推断问题可以转换为求任意一个变量子集的边际概率分布问题。在图模型中，常用的推断方法可以分为精确推断和近似推断两类。本节介绍两种精确推断算法，下一节介绍近似推断算法。11.2.1 变量消除法以图11.2a的有向图为例，假设推断问题为计算后验概率p(x |x )，需要计14算两个边际概率p(x , x ) 和p(x )。144邱锡鹏：《神经网络与深度学习》https://nndl.github.io/
 11.2 推断2019 年 4 月 6 日275根据条件独立性假设，有Σp(x , x ) =p(x )p(x |x )p(x |x )p(x |x , x ),(11.30)1412131423x ,x23假设每个变量取 K 个值，计算上面的边际分布需要 K2 次加法以及 K2 × 3 次乘法。根据乘法的分配律，ab + ac = a(b + c),(11.31)边际概率p(x , x ) 可以写为14ΣΣp(x , x ) = p(x ) p(x |x ) p(x |x )p(x |x , x ).(11.32)1413121423x3x2这样计算量可以减少到K2 + K 次加法和K2 + K + 1 次乘法。这种方法是利用动态规划的思想，每次消除一个变量，来减少计算边际分布的计算复杂度，称为变量消除法（variable elimination algorithm）。随着图模型规模的增长，变量消除法的收益越大。变量消除法可以按照不同的顺序来消除变量。比如上面的推断问题也可以按照x ，x 的消除顺序进行计算。32同理，边际概率p(x4) 可以通过以下方式计算：Σ ΣΣp(x4) =p(x |x , x ) p(x |x )p(x |x )p(x ).(11.33)42331211x3 x2x1变量消除法的一个缺点是在计算多个边际分布时存在很多重复的计算。比如在上面的图模型中，计算边际概率p(x ) 和 p(x ) 时很多局部的求和计算是一43样的。11.2.2 信念传播算法信念传播（Belief Propagation，BP）算法，也称为和积（Sum-Product）算法或消息传递（Message Passing）算法，是将变量消除法中的和积（Sum-Product）操作看作是消息，并保存起来，这样可以节省大量的计算资源。本节以无向图为例来介绍信念传播，但其同样适用于有向图。11.2.2.1 链式结构上的的信念传播算法µ1,2(x2)µ2,1(x1)µ2,3(x3)µ3,2(x2)µT −1,T (xT )µT,T −1(xT −1X1X2· · ·XT)图 11.10 无向马尔科夫链的消息传递过程邱锡鹏：《神经网络与深度学习》https://nndl.github.io/
 2762019 年 4 月 6 日第 11 章 概率图模型以图11.10所示的无向马尔可夫链为例，其联合概率p(x) 为Y1Zp(x) =ϕ (x )(11.34)(11.35)ccc∈CT −1Y1Z=ϕ(xt, xt+1 )t=1其中ϕ(xt, xt+1) 是定义在团(xt, xt+1) 的势能函数。第t 个变量的边际概率p(xt) 为Σ Σ Σ Σp(xt) =· · ·· · ·p(x)(11.36)(11.37)x1xt−1 t+1xxTΣ Σ Σ Σ YT −11Z=· · ·· · ·ϕ(x t, x t+1).t1xt−1 xt+ 1xT t=1假设每个变量取K 个值，不考虑归一化项，通过公式(11.37)计算边际分布需要KT −1 次加法以及KT −1 × (T − 1) 次乘法。根据乘法的分配律，边际概率p(x ) 可以通过下面方式进行计算：tΣ 1Σ YΣΣ YT −1t−1p(xt) =· · ·ϕ(xj , xj+1) · · · ·ϕ(xj , xj+1)Zx1xt−1 j= 1xt+1xT j=tΣΣΣ1=ϕ(xt−1 , xt ) · · ·ϕ(x , x )ϕ(x , x )  ·12ZΣ23xt−1x2x1ΣΣϕ(xt, xt+1) · · ·(x )µϕ(xT −2, xT −1)ϕ(xT −1, xT )xxT −1xTt+11(x ),t(11.38)=µt−1,ttt+1,tZ其中µt−1,t(xt) 定义为变量Xt−1 向变量Xt 传递的消息。µt−1,t(xt) 是关于变量Xt 的函数，可以递归计算：Σµt−1,t(xt) ,ϕ(xt−1, xt)µt−2,t−1(xt−1).(11.39)xt−1µt+1,t(xt) 是变量Xt+1 向变量X 传递的消息，定义为tΣµt+1,t(xt),ϕ(xt, xt+1)µt+2,t+2(xt+1).(11.40)xt+1边际概率p(xt) 的计算复杂度减少为O(TK2)。如果要计算整个序列上所有变量的边际概率，不需要将消息传递的过程重复T 次，因为其中每两个相邻节点上的消息是相同的。链式结构图模型的信念传播过程为邱锡鹏：《神经网络与深度学习》https://nndl.github.io/
 11.2 推断2019 年 4 月 6 日2771. 依次计算前向传递的消息µt−1,t(xt)，t = 1, · · · , T − 1；2. 依次计算反向传递的消息µt+1,t(xt)，t = T − 1, · · · , 1；3. 在任意节点t 上计算配分函数Z，ΣZ =µt−1,t(xt)µt+1,t(xt).(11.41)xt这样就可以通过公式（11.38）计算所有变量的边际概率了。11.2.2.2 树结构上的信念传播算法信念传播算法也可以推广到具有树结构的图模型上。如果一个有向图满足任意两个变量只有一条路径（忽略方向），且只有一个没有父节点的节点，那么 这个有向图为树结构，其中唯一没有父节点的节点称为根节点。如果一个无向图满足任意两个变量只有一条路径，那么这个无向图也为树结构。在树结构的 无向图中，任意一个节点都可以作为根节点。树结构图模型的信念传播过程为：1）从叶子节点到根节点依次计算并传递消息；2）从根节点开始到叶子节点，依次计算并传递消息；3）在每个节点上计算所有接收消息的乘积（如果是无向图还需要归一化），就得到了所有变量的 边际概率。如果图结构中存在环路，可以使用联合树算法（Junction Tree Algorithm）[Lauritzen and Spiegelhalter, 1988] 来将图结构转换为无环图。11.3 近似推断在实际应用中，精确推断一般用于结构比较简单的推断问题。当图模型的结构比较复杂时，精确推断的计算开销会比较大。此外，如果图模型中的变量是连续的，并且其积分函数没有闭型（closed-form）解时，也无法使用精确推断。因此，在很多情况下也常常采用近似的方法来进行推断。近似推断（Approximate Inference）主要有以下三种方法：1. 环路信念传播：当图模型中存在环路时，使用和积算法时，消息会在环路中一直传递，可能收敛或不收敛。环路信念传播（Loopy Belief Propagation，LBP）是在具有环路的图上依然使用和积算法，即使得到不精确解，在某些任务上也可以近似精确解。2. 变分法：图模型中有些变量的局部条件分布可能非常复杂，或其积分无法计算。变分法（Variational Method）是引入一个变分分布（通常是比较简单的分布）来近似这些条件概率，然后通过迭代的方法进行计算。首先是更新变分分布的参数来最小化变分分布和真实分布的差异（比如交叉熵或KL 距离），然后再根据变分分布来进行推断。邱锡鹏：《神经网络与深度学习》https://nndl.github.io/
 

 11.3 近似推断2019 年 4 月 6 日2753. 采样法： 采样法（Sampling Method）是通过模拟的方式来采集符合某个分布p(x) 的一些样本，并通过这些样本来估计和这个分布有关的运算，比如期望等。本节主要介绍基于采样法的近似推断。11.3.1 蒙特卡罗方法采样法（Sampling Method），也叫蒙特卡罗方法（Monte Carlo Method）或统计模拟方法，是20 世纪40 年代中期提出的一种通过随机采样的方法来近似估计一些计算问题的数值解。随机采样指从给定概率密度函数p(x)中抽取出符合其概率分布的样本。由于电子计算机的出现和快速发展，这种方法作为一种独立方法被提出来，使得当时很多难以计算的问题都可以通过随机模拟的方法来进行估计。采样也叫抽样。蒙特卡罗方法诞生于 20 世纪40 年代美国的“曼哈顿计划”，其名字来源于摩纳哥的一个以赌博业闻名的城市蒙特卡罗，象征概率。蒙特卡罗方法的一个最简单的应用例子是计算圆周率π。我们知道半径为r 的圆的面积为πr2，而直径为2r 的正方形的面积为4r2。当我们用正方形去嵌套一个相切的圆时，它们的面积之比是 41 π。当不知道π 时，我们无法计算圆的面积。因此，需要通过模拟的方法来进行近似估计。首先在正方形内部按均值采样的方式随机生成若干点，计算它们与圆心点的距离，从而判断是否落在圆的内部。然后去统计落在圆内部的点占到所有点的比例。当有足够的点时，这 个比例应该接近于 1 π4，而从近似估算出π 的值。蒙特卡罗方法的基本思想可以归结为根据一个已知概率密度函数为p(x) 的分布来计算函数f(x)的期望∫E[f (x)] = f (x)p(x)dx.(11.42)x本节中假设x 为连续变量，如果x 是离散变量，可以将积当p(x)比较复杂时，很难用解析的方法来计算这个期望。为了计算E[f (x)]，我们可以通过数值解法的方法来近似计算。首先从p(x)中独立抽取的N 个样本x(1),x(2), · · · , x(N)，f (x) 的期望可以用这N 个样本的均值fˆN分替换为求和。来近似。fˆ=f (x(1)) + · · · + f (x(N)) .(11.43)N1N根据大数定律，当N 趋向于无穷大时，样本均值收敛于期望值。fˆfp−→ E [ ( )]x当N → ∞.(11.44)N这就是蒙特卡罗方法的理论依据。邱锡鹏：《神经网络与深度学习》https://nndl.github.io/
 2762019 年 4 月 6 日第 11 章 概率图模型随机采样 蒙特卡罗方法的难点是如何进行随机采样，即如何让计算机生成满足概率密度函数p(x) 的样本。我们知道，计算机可以比较容易地随机生成一个在[0, 1] 区间上均布分布的样本ξ，p(ξ)=1。如果要随机生成服从某个非均匀分布的样本，就需要一些间接的采样方法。如果一个分布的概率密度函数为p(x)，其累积分布函数cdf(x) 为连续的严格增函数，且存在逆函数cdf−1(y), y ∈ [0, 1]，那么我们可以利用累积分布函数的逆函数来生成服从该随机分布的样本。假设ξ 是 [0, 1] 区间上均匀分布的随机变量，则cdf−1(ξ) 服从概率密度函数为p(x) 的分布。参见习题11-4。但当p(x) 非常复杂，其累积分布函数的逆函数难以计算，或者不知道p(x)的精确值，只知道未归一化的分布pˆ(x)，那么就难以直接对p(x) 进行采样，往1p(x) = pˆ(x)，其中Z 为配Z分函数。往需要使用一些间接的采样策略，比如拒绝采样、重要性采样、马尔可夫链蒙特卡罗采样等。这些方法一般是先根据一个比较容易采样的分布进行采样，然后通过一些策略来间接得到符合p(x)分布的样本。11.3.2 拒绝采样拒绝采样（Rejection Sampling），也叫接受-拒绝采样（Acceptance-RejectionSampling）。为了简化起见，我们把概率密度函数为p(x) 为分布简称为分布p(x)，下同。假设原始分布p(x)难以直接采样，我们可以引入一个容易采样的分布q(x)，一般称为提议分布（Proposal Distribution），然后以某个标准来拒绝一部分的样本使得最终采集的样本服从分布p(x)。提议分布在很多文献中也翻译为参考分布。在拒绝采样中，已知未归一化的分布q(x) 和一个常数 k，使得 kq(x) 可以覆盖函数 pˆ(x)，即 kq(x) ≥ pˆ(x), ∀x。如图11.11所示。pˆ(x)，我们需要构建一个提议分布0.40.30.2kq(x)kq(xˆ)p(x)0.1p(xˆ)0−6 −4 −2 xˆ0246图 11.11 拒绝采样。邱锡鹏：《神经网络与深度学习》https://nndl.github.io/
 11.3 近似推断2019 年 4 月 6 日277对于每次抽取的样本xˆ，计算接受概率（acceptance probability）：pˆ(xˆ)α(xˆ) =,(11.45)kq(xˆ)并以概率αxˆ 来接受样本xˆ。拒绝采样的采样过程如下算法11.1所示。算法 11.1: 拒绝采样输入: 提议分布q(x);常数k;样本集合V = ∅;1 repeat234567根据q(x) 随机生成一个样本xˆ;计算接受概率α(xˆ);从 (0, 1) 的均匀分布中随机生成一个值ꢀ;if ꢀ ≤ α(xˆ) thenV = V ∪ {xˆ};end/* 以α(xˆ) 的概率接受xˆ */8 until 直到获得 N 个样本(|V| = N);输出: 样本集合V判断一个拒绝采样方法的好坏就是看其采样效率，即总体的接受率。如果 函数 kq(x) 远大于原始分布函数 pˆ(x)，拒绝率会比较高，采样效率会非常不理想。但要找到一个和pˆ(x) 比较接近的提议分布往往比较困难。特别是在高维空间中，其采样率会非常低，导致很难应用到实际问题中。11.3.3 重要性采样如果采样的目的是计算分布p(x) 下函数f (x) 的期望，那么实际上抽取的样本不需要严格服从分布p(x)。也可以通过另一个分布，即提议分布q(x)，直接采样并估计Ep[f (x)]。函数f (x) 在分布p(x) 下的期望可以写为∫Ep[f (x)] = f(x)p(x)dx(11.46)(11.47)∫xf (x) p(x)q(x)dx==∫xq(x)xf (x)w(x)q(x)dx(11.48)(11.49)= Eq[f (x)w(x)].邱锡鹏：《神经网络与深度学习》https://nndl.github.io/
 2782019 年 4 月 6 日第 11 章 概率图模型其中w(x) 称为重要性权重。重要性采样（Importance Sampling）是通过引入重要性权重，将分布p(x)下f (x) 的期望变为在分布q(x) 下f (x)w(x) 的期望，从而可以近似为fˆ=f (x(1))w(x(1)) + · · · + f (x(N))w(x(N)) ,(11.50)N1N其中x(1), · · · , x(N) 为独立从q(x) 中随机抽取的点。重要性采样也可以在只知道未归一化的分布 pˆ(x) 的情况下计算函数 f (x)p(x) = ˆ(x) ，Z 为配分函数。的期望。Z∫pˆ(x)Ep[f (x)] = f(x)dx(11.51)(11.52)Zx∫pˆ(x)f (x)dx∫=pˆ(x)dxxΣN f(x(n))wˆ(x(n))≈n=Σ1,(11.53)Nn=1 wˆ(x(n))其中wˆ(x) = pˆq((xx)) ，x(1), · · ·, x(N )x为独立从q( ) 中随机抽取的点。11.3.4 马尔可夫链蒙特卡罗方法在高维空间中，拒绝采样和重要性采样的效率随空间维数的增加而指数降低。马尔可夫链蒙特卡罗（Markov Chain Monte Carlo，MCMC）方法是一种更好的采样方法，可以很容易地对高维变量进行采样。MCMC方法也有很多不同的具体采样方法，但其核心思想是将采样过程看作是一个马尔可夫链。马尔 可 夫 链 参 见第D.3.1.1节。x , x , · · · , xt−1, xt, , xt+1, · · ·12第 t + 1 次采样依赖于第 t 次抽取的样本 xt 以及状态转移分布（即提议分布）q(x|xt)。如果这个马尔可夫链的平稳分布为p(x)，那么在状态平稳时抽取的样本就服从p(x) 的分布。MCMC 方法的关键是如何构造出平稳分布为 p(x) 的马尔可夫链，并且该马尔可夫链的状态转移分布q(x|x′) 一般为比较容易采样的分布。当x 为离散变量时，q(x|x′) 可以是一个状态转移矩阵；当x 为连续变量时，q(x|x′) 可以是参数密度函数，比如各向同性的高斯分布 q(x|x′) = N(x|x′, σ2I)，其中σ2为超参数。使用 MCMC 方法进行采样时需要注意两点：一是马尔可夫链需要经过一段时间的随机游走才能达到平稳状态，这段时间称为预烧期（Burn-in Period）。预烧期内的采样点并不服从分布p(x)，需要丢弃；二是基于马尔可夫链抽取邱锡鹏：《神经网络与深度学习》https://nndl.github.io/
 11.3 近似推断2019 年 4 月 6 日279的相邻样本是高度相关的。而在机器学习中，我们一般需要抽取的样本是独立同分布的。为了使得抽取的样本之间独立，我们可以每间隔M 次随机游走，抽取一个样本。如果M 足够大，可以认为抽取的样本是独立的。11.3.4.1 Metropolis-Hastings 算法Metropolis-Hastings算法，简称MH算法，是一种应用广泛的MCMC方法。在MH 算法中，马尔可夫链的状态转移分布q(x|x′)，其平稳分布往往不是p(x)。因此，MH 算法引入拒绝采样的思想来修正提议分布，使得最终采样的分布为p(x)。在MH 算法中，假设第t 次采样的样本为x ，首先根据提议分布q(x|x ) 抽tt取一个样本xˆ，并以概率A(xˆ, xt) 来接受xˆ 作为第t + 1 次的采样样本xt+1，p(xˆ)q(xt|xˆ)A(xˆ, xt) = min 1,.(11.54)p(x )q(xˆ|x )tt因为每次q(x|x ) 随机生成一个样本xˆ，并以概率A(xˆ, x ) 的方式接受，因tt此修正马尔可夫链的状态转移概率为q′(xˆ|x ) = q(xˆ|x )A(xˆ, x ),(11.55)ttt该修正马尔可夫链可以达到平稳状态，且平稳分为p(x)。证明. 根据马尔可夫链的细致平稳条件，有p(x )q′(xˆ|x ) = p(x )q(xˆ|x )A(xˆ, x )细致平稳条件参见定理D.1。(11.56)(11.57)tttttp(xˆ)q(xt|xˆ)p(x )q(xˆ|x )= p(x )q(xˆ|x ) min 1,tttt= min p(x )q(xˆ|x ), p(xˆ)q(x |xˆ)(11.58)(11.59)tttp(x )q(xˆ|x )tt= p(xˆ)q(xt|xˆ) min, 1p(xˆ)q(xt|xˆ)= p(xˆ)q(x |xˆ)A(x , xˆ)(11.60)(11.61)tt= p(xˆ)q′(xt|xˆ).因此，p(x) 是状态转移概率为q′(xˆ|x )的马尔可夫链的平稳分布。tMH 算法的采样过程如算法11.2所示。邱锡鹏：《神经网络与深度学习》https://nndl.github.io/
 2802019 年 4 月 6 日第 11 章 概率图模型算法 11.2: Metropolis-Hastings 算法输入: 提议分布q(x|x′);采样间隔M ;样本集合V = ∅;1 随机初始化x0;2 t = 0;3 repeat// 预热过程45根据q(x|xt) 随机生成一个样本xˆ;计算接受概率A(xˆ, xt);6从 (0, 1) 的均匀分布中随机生成一个值ꢀ;7if ꢀ ≤ α thenxt+1 = xˆ;else/* 以A(xˆ, xt) 的概率接受xˆ */89/* 拒绝接受xˆ */101112131415xt+1 = xt;endt++;if 未到平稳状态 thencontinue;end// 采样过程，每隔M 次采一个样本if t mod M = 0 thenV = V ∪ {xt};161718end19 until 直到获得 N 个样本(|V| = N);输出: 样本集合V邱锡鹏：《神经网络与深度学习》https://nndl.github.io/
 11.3 近似推断2019 年 4 月 6 日28111.3.4.2 Metropolis 算法如果MH 算法中的提议分布是对称的，即q(xˆ|x ) = q(x |xˆ)，第t + 1 次采tt样的接受率可以简化为p(xˆ)p(xt)A(xˆ, xt) = min 1,.(11.62)这种MCMC 方法称为Metropolis 算法。11.3.4.3 吉布斯采样吉布斯采样（Gibbs Sampling）是一种有效地对高维空间中的分布进行采样的MCMC 方法，可以看作是Metropolis-Hastings 算法的特例。吉布斯采样使用全条件概率（Full Conditional Probability）作为提议分布来依次对每个维度进行采样，并设置接受率为A = 1。对于一个M 维的随机向量X = [X , X , · · · , X ]T ，其第i 个变量Xi 的全12M条件概率为p(xi|x−i),P (X = x |X = x−i)(11.63)(11.64)ii−i= p(x |x , x , · · · , xi-1, xi+1, · · · , xM ),i12其中x i = [x , x , · · · , xi- , xi+1, · · · , xM ]T 表示除Xi 外其它变量的取值。−121吉布斯采样可以按照任意的顺序根据全条件分布依次对每个变量进行采样。假设从一个随机的初始化状态 x标顺序依次对M 个变量进行采样。[] 开始，按照下(0) = x(0), x(0), · · · , x(0) T12M(1)(0)(0)(0)x1 ∼ p(x1|x2 , x3(0), · · · , xM ),(11.65)(1)(1)(0)x2 ∼ p(x2|x1 , x3 · · · , xM ),(11.66).(1)(1) (1)(1)xM ∼ p(xM |x1 , x2 · · · , xM −1),(11.67).(t)(t−1) (t−1)(t−1)x1(t) ∼ p(x1|x2x2 ∼ p(x2|x1 , x3, x, · · · , x),(11.68)(11.69)3M(t) (t−1)(t−1)· · · , xM ),.(t)(t) (t)(t)xM ∼ p(xM |x1 , x2 · · · , xM −1),(11.70)其中x(t) 是第t 次迭代时变量X 的采样。ii邱锡鹏：《神经网络与深度学习》https://nndl.github.io/
 2822019 年 4 月 6 日第 11 章 概率图模型吉布斯采样的每单步采样也构成一个马尔可夫链。假设每个单步（采样维度为第i 维）的状态转移概率q(x|x′)为p(x)p(x′if x−i = x′−i)q(x|x′) =− i(11.71)(11.72)0otherwise,Σ其中边际分布p(x−i′ ) =′xp(x′)，等式x = x′−i 表示xj = x′ ,∀j = i，因此−ii有 p(x′−i) = p(x−i)，并可以得到p(x)p(x′)p(x′)q(x|x′) = p(x′)= p(x)= p(x) (x′|x).qp(x−′ i)p(x−i)根据细致平稳条件，公式(11.71) 中定义的状态转移概率q(x|x′) 的马尔可夫链的平稳分布为p(x)。随着迭代次数t 的增加，样本x将收敛于概率分布p(x)。(t) = x(t), x(t) · · · , x(t) T[ ]1 2M11.4 学习图模型的学习可以分为两部分：一是网络结构学习，即寻找最优的网络结构；二是网络参数估计，即已知网络结构，估计每个条件概率分布的参数。网络结构学习一般比较困难，一般是由领域专家来构建。本节只讨论在给定网络结构条件下的参数估计问题。图模型的参数估计问题又分为不包含隐变量时的参数估计问题和包含隐变量时的参数估计问题。11.4.1 不含隐变量的参数估计如果图模型中不包含隐变量，即所有变量都是可观测的，那么网络参数一般可以直接通过最大似然来进行估计。有向图模型 在有向图模型中，所有变量x 的联合概率分布可以分解为每个随机变量x 的局部条件概率p(x |x , θ ) 的连乘形式，其中θ 为第k 个变量的局部条kkπkkk件概率的参数。给定N 个训练样本D = {x(i)}, 1 ≤ i ≤ N ，其对数似然函数为N1L D|θ) =(log p(x(i), θ)(11.73)(11.74)N1Σ Σi= 1NK log p((i) (i)=)Ni=1 k=1xk |x , θ ,πkk其中θk 为模型中的所有参数。邱锡鹏：《神经网络与深度学习》https://nndl.github.io/
 11.4 学习2019 年 4 月 6 日283因为所有变量都是可观测的，最大化对数似然L(D|θ))，只需要分别地最大化每个变量的条件似然来估计其参数。ΣN(i) (i)θk = arg max log p(xk |x , θk).(11.75)πki=1如果变量x是离散的，直接简单的方式是在训练集上统计每个变量的条件概率表。但是条件概率表需要的参数比较多。假设条件概率p(x |x ) 的父节点数kπk量为M，所有变量为二值变量，其条件概率表需要2M 个参数。为了减少参数数量，可以使用参数化的模型，比如sigmoid信念网络。如果变量x 是连续的， 可以使用高斯函数来表示条件概率分布，称为高斯信念网络。在此基础上，还可以通过让所有的条件概率分布共享使用同一组参数来进一步减少参数的数量。无向图模型 在无向图模型中，所有变量x 的联合概率分布可以分解为定义在最大团上的势能函数的连乘形式。以对数线性模型为例，Σ1p(x|θ) =expθ f (x ) ,T(11.76)cccZ(θ)c∈CΣxexp(Σ其 中 Z(θ) =θ f (x ))。Tc c cc∈C给定N 个训练样本D = {x(i)}, 1 ≤ i ≤ N，其对数似然函数为Σ1L(D|θ) =Nlog p(x( ), θ)(11.77)(11.78)NiΣi= 1Σc− log Z(θ),θ f (x(i))NT1N=ccc∈Ci=1其中θc 为定义在团c 上的势能函数的参数。如果采用梯度上升方法进行最大似然估计，L(D|θ)关于参数θc 的偏导数为ΣN∂L(D|θ)∂θc1Nlog Z(θ)f (x(i)) −=(11.79)cc∂θci=1其中ΣΣ θlog Z(θ)1Z(θ)==· expTf (x ) · f (x )(11.80)ccccc∂θcxc∈CΣxhip(x|θ)f (x ) , Ef (x ) .(11.81)(11.82)因此，ccx∼p(x|θ)ccΣN∂L(D|θ)∂θc1Nf− Ex∼p(x|θ)f (x(i))=c (xc)cci=1邱锡鹏：《神经网络与深度学习》https://nndl.github.io/
 2842019 年 4 月 6 日第 11 章 概率图模型= Ex∼p˜(x) f (x ) − Ef (x ) ,(11.83)ccx∼p(x|θ)cc其中p˜(x) 定义为经验数据分布。由于在最优点时梯度为0，因此无向图的最大似然估计的优化目标等价于：对于每个团c 上的特征f (x )，其在经验分布p˜(x)cc下的期望等于模型分布p(x|θ)下的期望。对比公式(11.75) 和公式(11.83) 可以看出，无向图模型的参数估计要比有向图更为复杂。在有向图中，每个局部条件概率的参数是独立的；而在无向图中，所有的参数都是相关的，无法分解。对于一般的无向图模型，公式(11.83) 中的Ex∼p(x|θ)[f (x )]往往很难计算，cc因为涉及到在联合概率空间p(x|θ)计算期望。当模型变量比较多时，这个计算往往无法实现。因此，无向图的参数估计通常采用近似的方法。一是利用采样来近似计算这个期望；二是坐标上升法，即固定其它参数，来优化一个势能函数的参数。11.4.2 含隐变量的参数估计如果图模型中包含隐变量，即有部分变量是不可观测的，就需要用EM算法进行参数估计。11.4.2.1 EM 算法在一个包含隐变量的图模型中，令X 定义可观测变量集合，令Z 定义隐变量集合，一个样本x 的边际似然函数（marginal likelihood）为边 际 似 然 也 称 为 证 据Σ（evidence）。p(x|θ) =p(x, z|θ),(11.84)z其中θ 为模型参数。图11.12给出了带隐变量的贝叶斯网络的图模型结构。zθxN图 11.12 带隐变量的贝叶斯网络。图中的矩形表示其中的变量重复N 次。这种表示方法称为盘子表示法（plate notation），是图模型中表示重复变量的方法邱锡鹏：《神经网络与深度学习》https://nndl.github.io/
 11.4 学习2019 年 4 月 6 日285给定N 个训练样本D = {x(i)}, 1 ≤ i ≤ N ，其训练集的对数边际似然为N1L D|θ) =(log p(x(i), θ)(11.85)(11.86)Ni= 1Σ ΣN1N=logp(x(i), z|θ).i=1z通过最大化整个训练集的对数边际似然L(D|θ)，可以估计出最优的参数θ∗。然而计算边际似然函数时涉及p(x)的推断问题，需要在对数函数的内部进行求和（或积分）。这样，当计算参数 θ 的梯度时，这个求和操作依然存在。除非p(x, z|θ) 的形式非常简单，否则这个求和难以直接计算。为了计算log p(x|θ)，我们引入一个额外的变分函数q(z)，q(z) 为定义在隐变量Z 上的分布。样本x 的对数边际似然函数为Σp(x, z|θ)q(z)log p(x|θ) = log q(z)(11.87)zΣp(x, z|θ)q(z)≥q(z) log(11.88)(11.89)利用Jensen不等式。z,ELBO(q, x|θ),其中ELBO(q, x|θ)为对数边际似然函数log p(x|θ) 的下界，称为证据下界（EvidenceLower Bound，ELBO）。公式(11.88) 使用了Jensen 不等式（即对于凸函数g，有g (E[X ]) ≤ E [g(X )]）。由Jensen不等式的性质可知，仅当q(z) = p(z|x, θ)时，对数边际似然函数log p(x|θ) 和其下界ELBO(q, x|θ) 相等，Jensen 不等式参见第D.2.6.1节。参见习题11-5。log p(x|θ) = ELBO(q, x|θ).这样最大化对数边际似然函数log p(x|θ) 的过程可以分解为两个步骤：（1）先找到近似分布q(z) 使得log p(x|θ) = ELBO(q, x|θ)；（2）再寻找参数θ 最大化ELBO(q, x|θ)。这就是期望最大化（Expectation-Maximum，EM）算法。EM 算法是含隐变量图模型的常用参数估计方法，通过迭代的方法来最大化边际似然。EM 算法具体分为两个步骤：E 步和M 步。这两步不断重复，直到收敛到某个局部最优解。在第t 步更新时，E 步和M 步分布为：1.E 步（Expectation step）：固定参数θ ，找到一个分布使得E LB O(q, x|θ )tt最大，即等于log p(x|θt)。qt+1(z) = arg max ELBO(q, x θ ).(11.90)|tq根据Jensen 不等式的性质，q(z) = p(z|x, θ ) 时，ELBO(q, x|θ ) 最大。因tt此，E 步可以看作是一种推断问题，计算后验概率p(z|x, θt)。邱锡鹏：《神经网络与深度学习》https://nndl.github.io/
 2862019 年 4 月 6 日第 11 章 概率图模型2. M步（Maximization step）：固定qt+1(z)，找到一组参数使得证据下界最大，即θt+1 = arg max ELBO(qt+1, x θ| ).(11.91)θ这一步可以看作是全观测变量图模型的参数估计问题，可以使用第11.4.1节中方法进行参数估计。收敛性证明 假设在第t 步时参数为θt，在E 步时找到一个变分分布qt+1(z) 使得log p(x|θ ) = ELBO(q, x|θ )。在M 步时固定qt+1(z) 找到一组参数θt+1，使得ttELBO(qt+1, x|θt+1) ≥ ELBO(qt+1, x|θt)。因此有log p(x|θt+1) ≥ ELBO(qt+1, x|θt+1) ≥ ELBO(qt+1, x|θ ) = log p(x|θ ),(11.92)tt即每经过一次迭代对数边际似然增加，log p(x|θt+1) ≥ log p(x|θt)。在 E 步中，最理想的变分分布q(z) 是等于后验分布p(z|x, θ)。而后验分布p(z|x, θ) 是一个推断问题。如果z是有限的一维离散变量（比如混合高斯模型），计算起来还比较容易。否则，p(z|x, θ) 一般情况下很难计算。因此需要通过近似推断的方法来进行估计，比如变分自编码器。变分自编码器参见第13.2节。信息论的视角对数边际似然可以通过下面方式进行分解：ΣzΣq(z) = 1.log p(x|θ) = q(z) log p(x|θ)(11.93)(11.94)Σzp(x, z|θ) = p(z|x, θ)p(x|θ).==q(z) log p(x, z|θ) − log p(z|x, θ)zΣΣp(x, z|θ)q(z)p(z|x, θ))q(z)q(z) log−q(z) logz(11.95)(11.96)z= ELBO(q, x|θ) + DKL(q(z)∥p(z|x, θ)),其中DKL(q(z)∥p(z|x, θ)) 为分布q(z) 和后验分布p(z|x, θ) 的KL 散度。参见第E.3.2节。由于 DKL(q(z)∥p(z|x, θ)) ≥ 0，并当且仅当 q(z) = p(z|x, θ) 为 0，因此ELBO(q, x|θ) 为log p(x|θ) 的一个下界。11.4.2.2 高斯混合模型本节介绍一个EM 算 法 的 应 用 例 子 ：高斯混合模型。高斯混合模型（GaussianMixture Model，GMM）是由多个高斯分布组成的模型，其密度函数为多个高斯密度函数的加权组合。不失一般性，这里考虑一维的情况。假设样本x 是从K 个高斯分布中生成的。每个高斯分布为1(x − µk)22σk2N( x|µ , σ ) = √exp−,(11.97)kk2πσk邱锡鹏：《神经网络与深度学习》https://nndl.github.io/
 11.4 学习2019 年 4 月 6 日287其中µ 和 σ 分别为第k 个高斯分布的均值和方差。图11.14给出了高斯混合模kk型的图模型表示。πz(n)µkx(n)σkKN图 11.13 高斯混合模型高斯混合模型的概率密度函数为ΣKN|kp(x) =πk (x µ , σ ),(11.98)kk=1ΣKk=1其中π 表示第k 个高斯分布的权重系数并满足π ≥ 0,πk = 1，即样本xkk由第k 个高斯分布产生的先验概率。高斯混合模型的生成过程可以分为两步：1. 首先按π , π , · · · , π 的分布，随机选取一个高斯分布；12K2. 假设选中第k 个高斯分布，再从高斯分布N(x|µ , σ ) 中选取一个样本x。kk参数估计 给定N 个由高斯混合模型生成的训练样本x(1), x(2), · · · , x(N)，希望能学习其中的参数π , µ , σ , 1 ≤ k ≤ K。由于我们无法观测样本x(n) 是从哪个高斯kkk分布生成的，因此无法直接用最大似然来进行参数估计。我们引入一个隐变量ꢀ(n) ∈ [1, K ]来表示其来自于哪个高斯分布，ꢀ(n) 服从多项分布，其多项分布的参数为π , π , · · · , π ，12K即p(ꢀ(n) = k) = πk.(11.99)对每个样本x(n)，其对数边际分布为Σlog p(x(n)) = logp( (n))p(x(n)| (n))(11.100)(11.101)(Σn)KNπk (x(n) µ , σ ).k|= logkk=1根据EM 算法，参数估计可以分为两步进行迭代：邱锡鹏：《神经网络与深度学习》https://nndl.github.io/
 2882019 年 4 月 6 日第 11 章 概率图模型E 步 先固定参数µ, σ，计算后验分布p(ꢀ(n)|x(n))γnk , p(ꢀ(n) = k|x(n))(11.102)(11.103)(11.104)=p((n))p(x(n)| (n))p(x(n))π N(x(n)|µ , σ )= Σ Kkkk,π N(x(n)|µ , σ )k=1kkk其中γnk 定义了样本x(n) 属于第k 个高斯分布的后验概率。M 步 令q(ꢀ = k) = γnk，训练集D 的证据下界为NKΣ Σ(n) (n)p(x , ꢀ = k)ELBO(γ, D|π, µ, σ) =γnklogγnk(11.105)(11.106)(11.107)n=1 k=1Σ ΣNKπk==γnkγnkN ( (x n |µ , σ ) + log)logkkγnkn=1 k=1Σ ΣNK−(x − µ )2k−log σ + log π +C,2σ2kkkn=1 k=1其中C 为和参数无关的常数。将参数估计问题转为优化问题：max ELBO(γ, D|π, µ, σ),π,µ,σΣKs.t.πk = 1.(11.108)k=1利用拉格朗日方法，分别求 ELBO(γ, D|π, µ, σ) + λ(ΣKπk − 1) 关于k=1π , µ , σ 的偏导数，并令其等于0。可得，kkkNkNπk =,(11.109)(11.110)Nµk1γnk x(n),=Nkn=1Nσ1γ(x(n) − µ )2,(11.111)=kNnkkkn=1其中参见习题11-6。ΣNNk =γ .nk(11.112)n=1邱锡鹏：《神经网络与深度学习》https://nndl.github.io/
 11.5 总结和深入阅读2019 年 4 月 6 日289高斯混合模型的参数学习过程如算法11.3所示。算法 11.3: 高斯混合模型的参数学习算法输入: 训练样本：x(1), x(2), · · · , x(N);1 随机初始化参数：π , µ , σ ，1 ≤ k ≤ K;kkk2 repeat// E 步3固定参数，根据公式(11.104) 计算γnk，1 ≤ k ≤ K， 1 ≤ n ≤ N ;// M 步4固定γ ，根据公式(11.109)，(11.110) 和 (11.111)，计算π , µ , σ ，nkkkk1 ≤ k ≤ K;ΣNn=15 until 对数边际分布log p(x(n)) 收敛;输出: π , µ , σ ，1 ≤ k ≤ Kkkk图11.14给出一个高斯混合模型训练过程的简单示例。给定一组数据，我们用两个高斯分布来估计这组数据的分布情况。0 .5 00 .5 0邱锡鹏：《神经网络与深度学习》https://nndl.github.io/
 2902019 年 4 月 6 日第 11 章 概率图模型0 .4 50 .4 00 .3 50 .3 00 .2 50 .2 00 . 241506172839邱锡鹏：《神经网络与深度学习》https://nndl.github.io/
 11.5 总结和深入阅读2019 年 4 月 6 日291邱锡鹏：《神经网络与深度学习》https://nndl.github.io/
 2922019 年 4 月 6 日第 11 章 概率图模型0 .4 50 .4 00 .3 50 .3 00 .2 50 .2 00 . 241506172839邱锡鹏：《神经网络与深度学习》https://nndl.github.io/
 11.5 总结和深入阅读2019 年 4 月 6 日2931 01 11 21 01 11 2(a) 初始化(b) 第1 次迭代0 .5 00 .0 .5 00 .4 54 50 .0 .4 00 .4 00 .3 53 50 .0 .3 00 .3 00 .2 52 50 .0 .2 02 00 . 2415061728390 . 2415061728391 01 11 21 01 11 2(c) 第4 次迭代(d) 第8次迭代0 .5 00 .0 .5 04 50 .4 00 .3 50 .3 00 .2 50 .2 00 . 241506172839邱锡鹏：《神经网络与深度学习》https://nndl.github.io/
 2942019 年 4 月 6 日第 11 章 概率图模型0 .4 50 .4 00 .3 50 .3 00 .2 50 .2 00 . 241506172839邱锡鹏：《神经网络与深度学习》https://nndl.github.io/
 11.5 总结和深入阅读2019 年 4 月 6 日2951 01 11 21 01 11 2(e) 第 12 次迭代(f) 第16 次迭代图 11.14 高斯混合模型示例11.5 总结和深入阅读概率图模型提供了一个用图形来描述概率模型的框架，这种可视化方法使我们可以更加容易地理解复杂模型的内在性质。目前，概率图模型已经是一个邱锡鹏：《神经网络与深度学习》https://nndl.github.io/
 2962019 年 4 月 6 日第 11 章 概率图模型非常庞大的研究领域，涉及众多的模型和算法。很多机器学习模型也都可以用概率图模型来描述。图11.15给出了概率图模型所涵盖的内容。概率图模型模型表示推断学习有向图模型无向图模型精确推断近似推断参数学习结构学习朴素贝叶斯模型隐马尔可夫模型深度信念网络对数线性模型条件随机场玻尔兹曼机变量消除信念传播环路信念传播变分法最大似然估计最大后验结构搜索贝叶斯优化Junction树蒙特卡罗方法EM 算法结构 EM 算法图 11.15 概率图模型所涵盖内容的简单概括在本章中，我们只介绍了部分内容。要更全面深入地了解概率图模型，可以 阅读《Probabilistic Graphical Models: Principles and Techniques》[Koller andFriedman, 2009]，《Probabilistic Reasoning in Intelligent Systems: Networksof Plausible Inference》[Pearl, 2014]，或机器学习书籍中的相关章节[Bishop,2007]。概率图模型中最基本的假设是条件独立性。图形化表示直观地描述了随机变量之间的条件独立性，有利于将复杂的概率模型分解为简单模型的组合，并更好地理解概率模型的表示、推断、学习等方法。20 世纪90 年代末，概率图模型的研究逐步成熟。到21 世纪，图模型在机器学习、计算机视觉、自然语言处理等领域开始不断的发展壮大。其中比较有代表性的模型有：条件随机场[Laﬀerty et al., 2001]、潜在狄利克雷分配（LatentDirichlet Allocation）Blei et al. [2003] 等。此外，图模型的结构学习也一直是非常重要但极具挑战性的研究方向。图模型与神经网络的关系 图模型和神经网络有着类似的网络结构，但两者也有很大的不同。图模型的节点是随机变量，其图结构的主要功能是用来描述变量间的依赖关系，一般是稀疏连接。使用图模型的好处是可以有效进行统计推。而神经网络中的节点是神经元，是一个计算节点。如果将神经网络中每个经元看做是一个二值随机变量，那神经网络就变成一个sigmoid 信念网络。之断神图模型中的每个变量一般有着明确的解释，变量之间依赖关系一般是人工来定义。而神经网络中的单个神经元则没有直观的解释。神经网络是判别模型，直接用来分类。而图模型不但可以是判别模型，也可以是生成模型。生成模型不但可以用来生成样本，也可以通过贝叶斯公式用来做分类。图模型的参数学习的目标函数为似然函数或条件似然函数，若包含邱锡鹏：《神经网络与深度学习》https://nndl.github.io/
 11.5 总结和深入阅读2019 年 4 月 6 日297隐变量则通常通过EM 算法来求解。而神经网络参数学习的目标为交叉熵或平方误差等损失函数。目前，神经网络和概率图模型的结合越来越进行紧密。一方面我们可以利用神经网络强大的表示能力来建模图模型中的推断问题（比如变分自编码器，第13.2节），生成问题（比如生成对抗网络，第13.3节），或势能函数（比如LSTM+CRF模型[Lample et al., 2016, Ma and Hovy, 2016]）；另一方面可以利用图模型的算法来解决复杂结构神经网络中的学习和推断问题，比如图结构神经网络（Graph Neural Network）[Gilmer et al., 2017, Li et al., 2015, Scarselliet al., 2009] 和结构化注意力[Kim et al., 2017]。习题习题 11-1 证明公式(11.10)。参见公式(11.10)。习题11-2 在图11.2a的有向图，分析按不同的消除顺序计算边际概率p(x3)时的计算复杂度。习题 11-3 在树结构的图模型上应用信念传播时，推导其消息计算公式。习题11-4 证明若分布p(x)存在累积分布函数的逆函数cdf−1(y), y ∈ [0, 1]，且随机变量ξ 为[0, 1] 区间上的均匀分布，则cdf−1(ξ) 服从分布p(x)。参见第11.3.1节。习题11-5 证明仅当q(z) = p(z|x, θ) 时，对数边际似然函数log p(x|θ) 和其下界ELBO(q, x|θ) 相等。习题 11-6 在高斯混合分布的参数估计中，证明M 步中的参数更新公式，即公式(11.109)，(11.110)和(11.111)。习题 11-7 考虑一个伯努利混合分布，即Kp(x|µ, π) =π p(x| µ ),(11.113)kkk=1其中p(x|µ ) = µx(1 − µ )(1−x) 为伯努利分布。kkk伯 努 利 混 合 分 布 参 见给定一组训练集合D = {x(1), x(2), · · · , x(N)}，若用EM 算法来进行参数估计时，推导其每步的参数更新公式。第D.2.1.1节。邱锡鹏：《神经网络与深度学习》https://nndl.github.io/
 2922019 年 4 月 6 日参考文献参考文献Leonard E Baum and Ted Petrie. Statisticalinference for probabilistic functions of ﬁnitestate markov chains. The annals of mathe-matical statistics, 37(6):1554–1563, 1966.John D. Laﬀerty, Andrew McCallum, andFernando C. N. Pereira. Conditional ran-dom ﬁelds: Probabilistic models for seg-menting and labeling sequence data. InProceedings of the Eighteenth InternationalConference on Machine Learning, 2001.Guillaume Lample, Miguel Ballesteros,Sandeep Subramanian, Kazuya Kawakami,and Chris Dyer. Neural architectures fornamed entity recognition. arXiv preprintarXiv:1603.01360, 2016.Adam L Berger, Vincent J Della Pietra, andStephen A Della Pietra. A maximum en-tropy approach to natural language process-ing. Computational linguistics, 22(1):39–71,1996.Christopher M. Bishop. Pattern recogni-tion and machine learning, 5th Edition. In-formation science and statistics. Springer,2007. ISBN 9780387310732.SteﬀenLLauritzen and DavidJSpiegelhal- ter. Local computations withprobabilities on graphical structures andtheir applica- tion to expert systems.Journal of the Royal Statistical Society.Series B (Methodologi- cal), pages 157–224, 1988.David M Blei, Andrew Y Ng, and Michael IJordan. Latent dirichlet allocation. Jour-nal of machine Learning research, 3(Jan):993–1022, 2003.YujiaLi,DanielTarlow,MarcStephen Della Pietra, Vincent Della Pietra,and John Laﬀerty. Inducing features of ran-dom ﬁelds. IEEE transactions on patternanalysis and machine intelligence, 19(4):380–393, 1997.Brockschmidt, and Richard Zemel. Gatedgraph sequence neural networks. arXivpreprint arXiv:1511.05493, 2015.Xuezhe Ma and Eduard Hovy. End-to-endsequence labeling via bi-directional lstm-cnns-crf. arXiv preprint arXiv:1603.01354,2016.Justin Gilmer, SamuelS Schoenholz,Patrick F Riley, Oriol Vinyals, andGeorge E Dahl. Neural message passingfor quantum chemistry. arXiv preprintarXiv:1704.01212, 2017.Radford M Neal. Connectionist learning ofbelief networks. Artiﬁcial intelligence, 56(1):71–113, 1992.Yoon Kim, Carl Denton, Luong Hoang,Judea Pearl. Probabilistic reasoning in in-telligent systems: networks of plausible in-ference. Elsevier, 2014.and AlexanderMRush. Structuredattention networks.arXiv preprintarXiv:1702.00887, 2017.Franco Scarselli, Marco Gori, Ah ChungTsoi, Markus Hagenbuchner, and GabrieleMonfardini. The graph neural networkmodel. IEEE Transactions on Neural Net-works, 20(1):61–80, 2009.Daphne Koller and Nir Friedman. Prob-abilistic graphical models: principles andtechniques. MIT press, 2009.邱锡鹏：《神经网络与深度学习》https://nndl.github.io/
 第 12 章 深度信念网络计算的目的不在于数据，而在于洞察事物。— 理查德·卫斯里·汉明对于一个复杂的数据分布，我们往往只能观测到有限的局部特征，并且这些特征通常会包含一定的噪声。如果要对这个数据分布进行建模，就需要挖掘出可观测变量之间复杂的依赖关系，以及可观测变量背后隐藏的内部表示。本章介绍一种可以有效学习变量之间复杂依赖关系的概率图模型（深度信念网络）以及两种相关的基础模型（玻尔兹曼机和受限玻尔兹曼机）。深度信念网络中包含很多层的隐变量，可以有效地学习数据的内部特征表示，也可以作为一种有效的非线性降维方法。这些学习到的内部特征表示包含了数据的更高级的、有价值的信息，因此十分有助于后续的分类和回归等任务。玻尔兹曼机和深度信念网络都是生成模型，借助隐变量来描述复杂的数据分布。作为概率图模型，玻尔兹曼机和深度信念网络的共同问题是推断和学习问题。因为这两种模型都比较复杂，并且都包含隐变量，它们的推断和学习一般通过MCMC 方法来进行近似估计。这两种模型和神经网络有很强的对应关系，在一定程度上也称为随机神经网络（Stochastic Neural Network，SNN）。12.1 玻尔兹曼机动力系统是数学上的一个概念，用一个函数来描述一个空间中所有点随时间的变化情况，比如钟摆晃动、水的流动等。玻尔兹曼机（Boltzmann Machine）可以看做是一个随机动力系统（StochasticDynamical System），每个变量的状态都以一定的概率受到其它变量的影响。玻尔兹曼机可以用概率无向图模型来描述。一个具有K 个节点（变量）的玻尔兹曼机满足以下三个性质：1. 每个随机变量是二值的，所有随机变量可以用一个二值的随机向量 X{0, 1}K 来表示，其中可观测变量表示为V，隐变量表示为H；∈
 2942019 年 4 月 6 日第 12 章 深度信念网络2. 所有节点之间是全连接的。每个变量Xi 的取值依赖于所有其它变量XKi；3. 每两个变量之间的相互影响（X → X 和 X → X ）是对称的。ijji图12.1给出了一个包含3 个可观测变量和3 个隐变量的玻尔兹曼机。邱锡鹏：《神经网络与深度学习》https://nndl.github.io/
 x2x112.1 玻尔兹曼机2019 年 4 月 6 日295x3x6x4x5邱锡鹏：《神经网络与深度学习》https://nndl.github.io/
 2962019 年 4 月 6 日第 12 章 深度信念网络图 12.1 一个有六个变量的玻尔兹曼机变量X 的联合概率由玻尔兹曼分布得到，即这也是玻尔兹曼机名称的由来。为了简单起见，这里我们把玻尔兹曼常数 k 吸收到1−E(x)p(x) = exp,(12.1)(12.2)ZT温度T 中。其中Z 为配分函数，能量函数E(x) 的定义为E(x) , E(X = x)ΣΣ= −w x x +ijbi xi,i ji<ji其中wij 是两个变量xi 和xj 之间的连接权重，xi ∈ {0, 1} 表示状态，bi 是变量xi 的偏置。如果两个变量Xi 和Xj 的取值都为1 时，一个正的权重wij > 0会使得玻尔兹曼机的能量下降，发生的概率变大；相反，一个负的权重会使得能量上升，发生的概率变小。因此，如果令玻尔兹曼机中的每个变量Xi 代表一个基本假设，其取值为1 或 0 分别表示模型接受或拒绝该假设，那么变量之间连接的权重为可正可负的实数，代表了两个假设之间的弱约束关系[Ackley et al., 1985]。一个正的权重表示两个假设可以相互支持。也就是说，如果一个假设被接受，另一个也很可能被接受。相反，一个负的权重表示两个假设不能同时被接受。德维希·玻尔兹曼（LudwigBoltzmann，1844 –1906），奥地利物理学家、哲学家。主要贡献为分子动力学。玻尔兹曼机可以用来解决两类问题。一类是搜索问题。当给定变量之间的连接权重，需要找到一组二值向量，使得整个网络的能量最低。另一类是学习问题。当给一组定部分变量的观测值时，计算一组最优的权重。邱锡鹏：《神经网络与深度学习》https://nndl.github.io/
 12.1 玻尔兹曼机2019 年 4 月 6 日297数学小知识 | 玻尔兹曼分布在统计力学中，玻尔兹曼分布（Boltzmann Distribution）是描述粒子处于特定状态下的概率，是关于状态能量与系统温度的函数。玻尔兹曼分布取自奥地利物理学家路德维希·玻尔兹曼（Ludwig Boltzmann），他在1868 年研究热平衡气体的统计力学时首次提出了这一分布。一个粒子处于为状态α 的概率pα 是关于状态能量与系统温度的函数，−EαkT1Zpα=exp,(12.3)其中Eα 为状态α 的能量，k 为玻尔兹曼常量，T 为系统温度，exp(−E)αkT称为玻尔兹曼因子（Boltzmann Factor），是没有归一化的概率。Z 为归一化因子，通常称为为配分函数（Partition Function），是对系统所有状态进行总和，♣Σ−EαkTZ =exp.(12.4)α玻尔兹曼分布的一个性质是两个状态的概率比仅仅依赖于两个状态能量的差值。pαpβEβ − Eα= exp.(12.5)kT12.1.1 生成模型在玻尔兹曼机中，配分函数Z 通常难以计算，因此，联合概率分布p(x) 一般通过MCMC 方法来近似，生成一组服从p(x) 分布的样本。本节介绍基于吉布斯采样的样本生成方法。吉布斯采样参见第11.3.4.3节。12.1.1.1 全条件概率吉布斯采样需要计算每个变量Xi 的全条件概率p(xi|x i)，其中x i 表示除\\变 量 Xi 外其它变量的取值。定理 12.1 – 玻尔兹曼机中变量的全条件概率： 对于玻尔兹曼机中的一个变量Xi，当给定其它变量x i 时，全条件概率p(xi|x i)\\邱锡鹏：《神经网络与深度学习》https://nndl.github.io/
 2982019 年 4 月 6 日第 12 章 深度信念网络邱锡鹏：《神经网络与深度学习》https://nndl.github.io/
 12.1 玻尔兹曼机2019 年 4 月 6 日299为Σw x + bijjip(x = 1|x ) = σ,(12.6)(12.7)i\iTp(x = 0|x ) = 1 − p(x = 1|x ),i\ii\i其中σ 为 logistic sigmoid 函数。邱锡鹏：《神经网络与深度学习》https://nndl.github.io/
 3002019 年 4 月 6 日第 12 章 深度信念网络证明. 首先，保持其它变量x 不变，改变变量X 的状态，从0（关闭）和1（打\ii开）之间的能量差异（Energy Gap）为∆E (x ) = E(x = 0, x ) − E(x = 1, x )(12.8)(12.9)i\iΣi\ii\i=w x + b ,ijjij其中wii = 0。又根据玻尔兹曼机的定义可得E(x) = −T log p(x) − T log Z,(12.10)因此有∆E (x ) = −T ln p(x = 0, x ) − (−T ln p(x = 1, x ))(12.11)(12.12)i\ii\ii\ip(x  = 1, x )p(x = 0, x )i\i= T lni\ip(x  = 1|x )i\i= T ln= T ln(12.13)(12.14)p(x = 0|x )i\ip(x = 1, |x )ii\,1 − p(x = 1|x )i\i结合公式(12.14) 和(12.14)，得到= 1|x1((12.15)(12.16)) =p xi\i∆E (x )1 + exp −i\iTΣwij xj + bij= σ.T12.1.1.2 吉布斯采样玻尔兹曼机的吉布斯采样过程为：随机选择一个变量Xi，然后根据其全条件概率p(xi|x i) 来设置其状态，即以p(xi = 1|x i) 的概率将变量Xi 设为1，否\\则为0。在固定温度T 的情况下，在运行足够时间之后，玻尔兹曼机会达到热平邱锡鹏：《神经网络与深度学习》https://nndl.github.io/
 12.1 玻尔兹曼机2019 年 4 月 6 日301衡。此时，任何全局状态的概率服从玻尔兹曼分布p(x)，只与系统的能量有关，与初始状态无关。曼机达到热平衡时，味其能量最低。热平是在所有状态上的一要使得玻尔兹曼机达到热平衡，其收敛速度和温度T 相关。当系统温度非常高T → ∞ 时，p(xi = 1|x\i) → 0.5，即每个变量状态的改变十分容易，每一种系统状态都是一样的，而从很快可以达到热平衡。当系统温度非常低T → 0时，如果∆E (x ) > 0则p(x = 1|x ) → 1，如果∆E (x ) < 0则p(x = 1|x ) → 0，即i\ii\ii\ii\iΣ1ifw x + b ≥ 0,ij jjixi =(12.17)0otherwise,因此，当T → 0 时，随机性方法变成了确定性方法。这时，玻尔兹曼机退化为一个 Hopﬁeld 网络。Hopﬁeld 网第8.3.4.1节。络参见Hopﬁeld 网络是一种确定性的动力系统，而玻尔兹曼机是一种随机性的动力系统。Hopﬁeld 网络的每次的状态更新都会使得系统的能量降低，而玻尔兹曼机则以一定的概率使得系统的能量上升。图12.2给出了Hopﬁeld 网络和玻尔兹曼机在运行时系统能量变化的对比。邱锡鹏：《神经网络与深度学习》https://nndl.github.io/
 3022019 年 4 月 6 日第 12 章 深度信念网络E邱锡鹏：《神经网络与深度学习》https://nndl.github.io/
 12.1 玻尔兹曼机2019 年 4 月 6 日303••••••••••••••••••••••••邱锡鹏：《神经网络与深度学习》https://nndl.github.io/
 3042019 年 4 月 6 日第 12 章 深度信念网络(a) Hopﬁeld 网络E邱锡鹏：《神经网络与深度学习》https://nndl.github.io/
 12.1 玻尔兹曼机2019 年 4 月 6 日305•••••••••••••••••••••••邱锡鹏：《神经网络与深度学习》https://nndl.github.io/
 3062019 年 4 月 6 日第 12 章 深度信念网络(b) 玻尔兹曼机图 12.2 Hopﬁeld 网络和玻尔兹曼机运行时，系统能量变化对比12.1.2 能量最小化与模拟退火在一个动力系统中，找到一个状态使得系统能量最小是一个十分重要的优化问题。如果这个动力系统是确定性的，比如Hopﬁeld 网络，一个简单（但是低效）的能量最小化方法是随机选择一个变量，在其它变量保持不变的情况下，将这个变量设为会导致整个网络能量更低的状态。当每个变量Xi 取值为{0, 1}时，如果能量差异∆E (x ) 大于0，就设X = 1，否则就设X = 0。特别地，离散状态的能量最小化是一个组合优化问题。i\iii这种简单、确定性的方法在运行一定时间之后总是可以收敛到一个解。但是这个解是局部最优的，不是全局最优。为了跳出局部最优，就必须允许“偶尔”可以将一个变量设置为使得能量变高的状态。这样，我们就需要引入一定∆E (x )i的随机性，我们以σ\i 的概率将变量X 设i 为1，否则设为0。这个过程T和玻尔兹曼机的吉布斯采样过程十分类似。局部最优在Hopﬁeld 网络中不是一个缺点。相反，Hop-ﬁeld 网络是通过利用局部最优点来存储信息。要使得动力系统达到热平衡，温度T 的选择十分关键。一个比较好的折中方法是让系统刚开始在一个比较高的温度下运行达到热平衡，然后逐渐降低，直到系统在一个比较低的温度下达到热平衡。这样我们就能够得到一个能量全邱锡鹏：《神经网络与深度学习》https://nndl.github.io/
 12.1 玻尔兹曼机2019 年 4 月 6 日307局最小的分布。这个过程被称为模拟退火（Simulated Annealing）[Kirkpatricket al., 1983]。模拟退火是一种寻找全局最优的近似方法，其名字来自冶金学的专有名词“退火”，即将材料加热后再以一定的速度退火冷却，可以减少晶格中的缺陷。固体中的内部粒子会停留在使内能有局部最小值的位置，加热时能量变大，粒子会变得无序并随机移动。退火冷却时速度较慢，使得粒子在每个温度都达到平衡态。最后在常温时，粒子以很大的概率达到内能比原先更低的位置。可以证明，模拟退火算法所得解依概率收敛到全局最优解。12.1.3 参数学习不失一般性，假设玻尔兹曼机中的变量分为可观测变量v ∈ {0, 1}m 和隐变量 h ∈ {0, 1}n。给定一组可观测的向量D = {vˆ(1), v(2), · · · , v(N )}作为训练集，我们要学ˆˆ习玻尔兹曼机的参数W 和 b 使得训练集中所有样本的对数似然函数最大。训练集的对数似然函数定义为ΣN1NL(D|W, b) =log p(vˆ(n)|W, b)(12.18)(12.19)n=1Σ ΣN1Np(vˆ(n), h|W,logb)=n=1hΣΣexp− E (vˆ(n), h)h1Nlog.(12.20)=NΣv,hn=1exp − E(v, h)对数似然函数L(D|W, b) 对参数θ 的偏导数为θ 为 W 或 b。Σ∂ΣL(D|W, b)1Nlog=p(vˆ(n), h|W, b)(12.21)(12.22)N∂θ∂θn=1hΣΣΣN1∂==logexp − E (vˆ(n ), h) − logexp − E(v, h)N∂θn=1hv,hiE (vˆ n , h)−1NNΣ Σ exp()∂E (vˆ n , h)()Σ∂θexp − E (vˆ(n), h)exp − E(v, h)n=1hhΣh∂E(v, h) i−Σ(12.23)exp − E(v, h)∂θv,hΣv,hΣN Σh∂E (vˆ(n), h)i∂E(v, h)hi1N=p(h|vˆ(n)−)p(v, h)(12.24)(12.25)∂θv,h∂θn=1hih ∂E(v, h) ih∂E(v, h),= Epˆ(v)Ep(h|v)− Ep(v,h)∂θ∂θ邱锡鹏：《神经网络与深度学习》https://nndl.github.io/
 3082019 年 4 月 6 日第 12 章 深度信念网络其中pˆ(v)表示可观测向量在训练集是上的实际分布，p(h|v)和p(v, h)为在当前参数W, b 条件下玻尔兹曼机的条件概率和联合概率。因此，整个训练集的对数似然函数L(D|W, b) 对每个权重 wij 和偏置 bi 的偏导数为∂L(D|W, b)∂wij[x x − E[x x ],](12.26)= Epˆ(v)Ep(h|v)i ji jp(v,h)∂L(D|W, b)= Epˆ(v)Ep(h|v)[xi] − Ep(v,h)[xi],(12.27)∂bi其中i, j ∈ [1, K ]。这两个公式涉及到计算配分函数和期望，很难精确计算。对于一个K 维的随机向量X，其取值空间大小为2K 。当K比较大时，配分函数以及期望的计算会十分耗时。因此，玻尔兹曼机一般通过MCMC方法（如吉布斯采样）来进行近似求解。以参数wij 的梯度为例，公式(12.26) 中第一项为在给定可观测变量为训练集中的样本时，xixj 的期望。为了近似近似这个期望，我们可以固定住可观测变量，只对h进行吉布斯采样。当玻尔兹曼机达到热平衡状态时，采样x x 的值。在训ij练集上所有的训练样本上重复此过程，得到x x 的近似期望⟨x x ⟩。公式i j dataij(12.25) 中的第二项为玻尔兹曼机在没有任何限制时，xixj 的期望。我们可以对所有变量进行吉布斯采样。当玻尔兹曼机达到热平衡状态时，采样x x 的值，得到ij近似期望⟨xix ⟩。j model这样当采用梯度上升法时，权重wij 可以用下面公式近似地更新w ← w + α ⟨x xj ⟩− ⟨xixj ⟩modeldata.(12.28)ijiji其中α > 0 为学习率。这个更新方法的一个特点是仅仅使用了局部信息。也就是说，虽然我们优化目标是整个网络的能量最低，但是每个权重的更新只依赖于它连接的相关变量的状态。这种学习方式和人脑神经网络的学习方式，赫布规则（Hebbian Rule），十分类似。玻尔兹曼机可以用在监督学习和无监督学习中。在监督学习中，可观测的变量v 又进一步可以分为输入和输出变量，隐变量则隐式地描述了输入和输出变量之间复杂的约束关系。在无监督学习中，隐变量可以看做是可观测变量的内部特征表示。玻尔兹曼机也可以看做是一种随机型的神经网络，是Hopﬁeld 神经网络的扩展，并且可以生成的相应的Hopﬁeld 神经网络。在没有时间限制时，玻尔兹曼机还可以用来解决复杂的组合优化问题。12.2 受限玻尔兹曼机全连接的玻尔兹曼机在理论上十分有趣，但是由于其复杂性，目前为止并没有被广泛使用。虽然基于采样的方法在很大程度提高了学习效率，但是每更邱锡鹏：《神经网络与深度学习》https://nndl.github.io/
 12.2 受限玻尔兹曼机2019 年 4 月 6 日301新一次权重，就需要网络重新达到热平衡状态，这个过程依然比较低效，需要很长时间。在实际应用中，使用比较广泛的一种带限制的版本，也就是受限玻尔兹曼机。受限玻尔兹曼机因其结构最初称为簧风琴模型，2000 年后受限玻兹曼机的名称才变得流行。受限玻尔兹曼机（Restricted Boltzmann Machine，RBM）是一个二分图结构的无向图模型，如图12.3所示。受限玻尔兹曼机中的变量也分为隐藏变量和可观测变量。我们分别用可观测层和隐藏层来表示这两组变量。同一层中的节点之间没有连接，而不同层一个层中的节点与另一层中的所有节点连接，这和两层的全连接神经网络的结构相同。邱锡鹏：《神经网络与深度学习》https://nndl.github.io/
 3022019 年 4 月 6 日第 12 章 深度信念网络h1h2h3v1v2v3v4邱锡鹏：《神经网络与深度学习》https://nndl.github.io/
 12.2 受限玻尔兹曼机2019 年 4 月 6 日303图 12.3 一个有7 个变量的受限玻尔兹曼机一个受限玻尔兹曼机由 m 个可观测变量和m 个隐变量组成，其定义如下：12• 可观测的随机向量v = [v1, · · · , vm 1 ]T ；• 隐藏的随机向量h = [h1, · · · , hm 2 ]T ；• 权重矩阵W ∈ Rm1 ×m2 ，其中每个元素w 为可观测变量 v 和隐变量hijij之间边的权重；• 偏置a ∈ Rm 和b ∈ Rm ，其中a 为每个可观测的变量 v 的偏置，b 为12iij每个隐变量hj 的偏置。受限玻尔兹曼机的能量函数定义为E (v, h) = − Σa v −i iΣb h −j jΣ Σv w hi ij j(12.29)ii= −aTv − bTh − vTW h,(12.30)受限玻尔兹曼机的联合概率分布p(v, h) 定义为1exp(−E(v, h))p(v, h) =(12.31)(12.32)Z1=exp(aTv) exp(bTh) exp(v W h),TZΣv,h其中Z =exp(−E(v, h)) 为配分函数。邱锡鹏：《神经网络与深度学习》https://nndl.github.io/
 3042019 年 4 月 6 日第 12 章 深度信念网络12.2.1 生成模型受限玻尔兹曼机的联合概率分布 p(h, v) 一般也通过吉布斯采样的方法来近似，生成一组服从p(h, v)分布的样本。吉布 斯 采 样 参 见第11.3.4.3节。12.2.1.1 全条件概率吉布斯采样需要计算每个变量V 和 H 的全条件概率。受限玻尔兹曼机中ij同层的变量之间没有连接。从无向图的性质可知，在给定可观测变量时，隐变量之间相互条件独立。同样在给定隐变量时，可观测变量之间也相互条件独立。即有p(v |v , h) = p(v |h),(12.33)(12.34)i\iip(hj |v, h\j ) = p(hj |v),其中v i 为除变量Vi 外其它可观测变量的取值，h j 为除变量Hj 外其它隐变量\\的取值。因此，Vi 的全条件概率只需要计算p(vi|h)，而Hj 的全条件概率只需要计算p(hj |v)。定理 12.2 – 受限玻尔兹曼机中变量的条件概率： 在受限玻尔兹曼机中，每个可观测变量和隐变量的条件概率为Σp(v = 1|h) = σ a +w hij j,(12.35)(12.36)iiΣp(h = 1|v) = σ b +w v ) ,ij ii其中σ 为 logistic sigmoid 函数。证明.（1）我们先证明p(vi = 1|h)。邱锡鹏：《神经网络与深度学习》https://nndl.github.io/
 12.2 受限玻尔兹曼机2019 年 4 月 6 日305可观测层变量v 的边际概率为ΣΣ1ZP (v) = P (v, h) =exp(−E(v, h))(12.37)hhΣΣΣ Σ1Z==expaT v +b h +v wi ijh(12.38)(12.39)ΣΣiΣhexp(a v)Thj (bj +wijvi)expZjiΣih!Σ Yexp(aT v)==exphj(bj+w v )(12.40)ij iZh!Σ YΣΣ Σexp(aTv)exphj (b+wijvi利用分配律· · ·jZ)(12.41)(12.42)(12.43)h1 h2hni!Y Σexp(aTv)Σ==exp hj (bj +w v )j为0 1或的 取 值 代ij i!Z将 h入计算hjiYΣexp(aT v)1 + exp(bj+)wijvi.Zi固定hj = 1 时，p(hj = 1, v) 的边际概率为Σ1= 1, v) =p(hjexp (−E(v, h))(12.44)Zh,hj =1!ΣΣYexp(aTv)=1 + exp(bk +w v ) exp(bj+wij vi). (12.45)Zik ik,k=jii由公式(12.43)和( 12.45)，可以计算隐藏单元hj 的条件概率为：p(hi  = 1, v)p(hj = 1|v) =(12.46)(12.47)(12.48)p(v)exp(b +w v )jijΣ=Σ1 + exp(b +w v )ji!ij i= σ bj +w vij i.i（2）同理，条件概率p(vi = 1|h) 为Σp(vi = 1|h) = σ ai +w hjij.(12.49)邱锡鹏：《神经网络与深度学习》https://nndl.github.io/
 3062019 年 4 月 6 日第 12 章 深度信念网络公式(12.48) 和 (12.49) 也可以写为向量形式。p(h = 1|v) = σ (WTv + b)(12.50)(12.51)p(v = 1|h) = σ (W h + a) .因此，受限玻尔兹曼机可以并行地对所有的可观测变量（或所有的隐变量）同时进行采样，而从可以更快地达到热平衡状态。12.2.1.2 吉布斯采样受限玻尔兹曼机的采样过程如下：•（给定）或随机初始化一个可观测的向量v0, 计算隐变量的概率，并从中采样一个隐向量h0；• 基于h ，计算可观测变量的概率，并从中采样一个个可观测的向量v ；01• 重复t 次后，获得(v , h )；tt• 当t → ∞ 时, (v , h ) 的采样服从p(v, h) 分布。tt图12.4也给出了上述过程的示例。h(0)h(1)h(t)· · ·v(0)v(1)v(2)v(t+1)图 12.4 受限玻尔兹曼机的采样过程12.2.2 参数学习和玻尔兹曼机一样，受限玻尔兹曼机通过最大化似然函数来找到最优的参 数W, a, b。给定一组训练样本D = {vˆ(1), vˆ(2), · · · , vˆ(N )}，其对数似然函数为Σlog p(vˆ(|a b)) W, ,.(12.52)L(D|W, a, b) =N1Nnn=1和玻尔兹曼机类似，在受限玻尔兹曼机中，对数似然函数L(D|W, b) 对参参见公式(12.25)。数wij , ai, bj 的偏导数为∂L(D|W, a, b)∂wijv h − E[v h ],[](12.53)= Epˆ(v)Ep(h|v)i ji jp(v,h)邱锡鹏：《神经网络与深度学习》https://nndl.github.io/
 12.2 受限玻尔兹曼机2019 年 4 月 6 日307∂L(D|W, a, b)= E pˆ(v)Ep(h|v)[vi] − Ep(v,h)[vi],(12.54)(12.55)∂ai∂L(D|W, a, b)∂bj= E pˆ(v)Ep(h|v)[hj ] − Ep(v,h)[hj ],其中pˆ(v) 为训练数据集上v的实际分布。参见习题12-3。公式(12.53)、(12.54) 和(12.55) 中都需要计算配分函数Z 以及两个期望Ep(h|v)和Ep(h,v)，因此很难计算，一般需要通过MCMC 方法来近似计算。首先，将可观测向量v 设为训练样本中的值并固定，然后根据条件概率对隐向量 h 进行采样，这时受限玻尔兹曼机的值记为⟨·⟩data。然后在不固定可观测向量v，通过吉布斯采样来轮流更新v 和 h。当达到热平衡状态时，采集v 和h的值，记为⟨·⟩model。采用梯度上升法时，参数W, a, b 可以用下面公式近似地更新w ← w + α ⟨v hj ⟩− ⟨vihj ⟩modeldata,(12.56)(12.57)(12.58)ij ijia ← a + α ⟨v ⟩− ⟨v ⟩,iii datai modelbj ← bj + α ⟨hj ⟩data − ⟨hj ⟩model其中α > 0 为学习率。,根据受限玻尔兹曼机的条件独立性，可以对可观测变量和隐变量进行分组轮流采样，如图12.4中所示。这样受限玻尔兹曼机的采样效率会比一般的玻尔兹曼机有很大提高，但一般还是需要通过很多步采样才可以采集到符合真实分布的样本。12.2.2.1 对比散度学习算法由于受限玻尔兹曼机的特殊结构，因此可以使用一种比吉布斯采样更有效 的学习算法，即对比散度 （Contrastive Divergence）[Hinton, 2002]。对比散度算法仅需k 步吉布斯采样。为了提高效率，对比散度算法用一个训练样本作为可观测向量的初始值。然后，交替对可观测向量和隐藏向量进行吉布斯采样，不需要等到收敛，只需要 k 步就足够了。这就是CD-k 算法。通常，k = 1 就可以学得很好。对比散度的流程如算法12.1所示。12.2.3 受限玻尔兹曼机的类型在具体的不同任务中，需要处理的数据类型不一定都是二值的，也可能是连续值。为了能够处理这些数据，就需要根据输入或输出的数据类型来设计新的能量函数。邱锡鹏：《神经网络与深度学习》https://nndl.github.io/
 3082019 年 4 月 6 日第 12 章 深度信念网络算法 12.1: 单步对比散度算法输入: 训练集: vˆ(n), n = 1, · · · , N学习率：α;1 初始化：W ← 0, a ← 0, b ← 0 ;2 for t = 1 · · · T do34for n = 1 · · · N do选取一个样本vˆ(n)，用公式 12.48 计算据这个分布采集一个隐向量h;计算正向梯度vˆ(n)hT ;()p( = 1 vˆ(n))，并根h|56根据h，用公式(12.49)计算p(v = 1|h)，并根据这个分布采集重构的可见变量v′;7根据v′，重新计算p(h = 1|v′) 并采样一个h′;计算反向梯度v′h′T;89更新参数：W ← W + α(vˆ(n)hT v h ) ;−′ ′T101112a ← a + α(vˆ(n) − v′)b ← b + α(h − h′) ;;end13 end输出: W, a, b一般来说，常见的受限玻尔兹曼机有以下三种：“伯努利-伯努利”受限玻尔兹曼机“伯努利-伯努利”受限玻尔兹曼机（Bernoulli-Bernoulli RBM, BB-RBM）就是上面介绍的可观测变量和隐变量都为二值类型的受限玻尔兹曼机。“高斯-伯努利”受限玻尔兹曼机 “高斯-伯努利”受限玻尔兹曼机（Gaussian-Bernoulli RBM, GB-RBM）是假设可观测变量为高斯分布，隐变量为伯努利分布，其能量函数定义为ΣΣΣ Σviσi(v − µ )2ii−h −w ij h ,E(v, h) =b(12.59)2 σi2ii其中每个可观测变量v 服从(µ , σ) 的高斯分布。iii参见习题12-5。“伯努利-高斯”受限玻尔兹曼机 “伯努利-高斯”受限玻尔兹曼机（Bernoulli-Gaussian RBM, BG-RBM）是假设可观测变量为伯努利分布，隐变量为高斯分邱锡鹏：《神经网络与深度学习》https://nndl.github.io/
 12.3 深度信念网络2019 年 4 月 6 日307布，其能量函数定义为ΣΣ ΣΣ(hj − µj )2hjj−−E(v, h) = a vv iw ij σ,(12.60)i i2σ2jii其中每个隐变量hj 服从(µj , σj ) 的高斯分布。12.3 深度信念网络深度信念网络（Deep Belief Network，DBN）是一种深层的概率有向图模型，其图结构由多层的节点构成。每层节点的内部没有连接，相邻两层的节点之间为全连接。网络的最底层为可观测变量，其它层节点都为隐变量。最顶部的两层间的连接是无向的，其他层之间的连接是有向的。图12.5给出了一个深度信念网络的示例。和全连接的前馈神经网络结构相同。h(3)p(h(2), h(3))W (3)W (2)W (1)h(2)q(h(2)|h(1))q(h(1)|v)p(h(1)|h(2))h(1)p(v|h(1))v图 12.5 一个有4 层结构的深度信念网络对一个有L层隐变量的深度信念网络，令v = h(0) 表示最底层（第0层）为可观测变量，h(1), · · · , h(L) 表示其余每层的变量。顶部的两层是一个无向图，可以看做是一个受限玻尔兹曼机，用来产生p(h(L−1)) 的先验分布。除了最顶上两层外，每一层变量h(l) 依赖于其上面一层h(l+1)，即p(h(l)|h(l+1), · · · , h(L)) = p(h(l)|h(l+1)),其中l = {0, · · · , L − 2}。(12.61)深度信念网络中所有变量的联合概率可以分解为!LY−2( ) (l+1)p(v, h (1), · · · , h (L )) = p(v|h(1))p(h |hl) )p(h( L− 1) , h(L)(12.62)l=1邱锡鹏：《神经网络与深度学习》https://nndl.github.io/
 3082019 年 4 月 6 日LY−1第 12 章 深度信念网络!p(h(l) h(l+1)) p(h(L−1) h( )),L=,(12.63)|l=0其中p(h(l)|h(l+1))为Sigmoid型条件概率分布为p(h(l)|h(l+1)) = σ a(l) + W (l+1)h(l+1),(12.64)其中σ(·) 为按位计算的logistic sigmoid 函数，a(l) 为偏置参数，W (l+1) 为权重参数。这样，每一个层都可以看作是一个Sigmoid 信念网络。Sigmoid 信 念 网 络 参 见第11.1.2.1节。12.3.1 生成模型深度信念网络是一个生成模型，可以用来生成符合特定分布的样本。隐变量用来描述在可观测变量之间的高阶相关性。假如训练数据服从分布p(v)，通过训练得到一个深度信念网络。在生成样本时，首先在最顶两层进行足够多次的吉布斯采样，生成h(L−1)，然后依次计算下一层隐变量的分布。因为在给定上一层变量取值时，下一层的变量是条件独立的，因为可以独立采样。这样，我们可以从第L − 1 层开始，自顶向下进行逐层采样，最终得到可观测层的样本。12.3.2 参数学习深度信念网络最直接的训练方式可以通过最大似然方法使得可观测变量的边际分布p(v) 在训练集合上的似然达到最大。但在深度信念网络中，隐变量h之间的关系十分复杂，由于“贡献度分配问题”，很难直接学习。即使对于简单 的单层Sigmoid 信念网络p(v = 1|h) = σ (b + wTh) ,(12.65)在已知可观测变量时，其隐变量的联合后验概率p(h|v) 不再相互独立，因此很难精确估计所有隐变量的后验概率。早期深度信念网络的后验概率一般通过蒙 特卡罗方法或变分方法来近似估计，但是效率比较低，而导致其参数学习比较 困难。为了有效地训练深度信念网络，我们将每一层的Sigmoid 信念网络转换为受限玻尔兹曼机。这样做的好处是隐变量的后验概率是相互独立的，从而可以很容易地进行采样。这样，深度信念网络可以看作是由多个受限玻尔兹曼机从下到上进行堆叠，第l 层受限玻尔兹曼机的隐层作为第l + 1 层受限玻尔兹曼机的可观测层。进一步地，深度信念网络可以采用逐层训练的方式来快速训练，即 从最底层开始，每次只训练一层，直到最后一层[Hinton et al., 2006]。“逐层训练”是能够有效训练深度模型的最早的方法。深度信念网络的训练过程可以分为预训练和精调两个阶段。先通过逐层预训练将模型的参数初始化为较优的值，再通过传统学习方法对参数进行精调。邱锡鹏：《神经网络与深度学习》https://nndl.github.io/
 12.3 深度信念网络2019 年 4 月 6 日30912.3.2.1 逐层预训练在预训练阶段，采用逐层训练的方式，将深度信念网络的训练简化为对多个受限玻尔兹曼机的训练。图12.6给出了深度信念网络的逐层预训练过程。RBMh(3)W (3)RBMh(2)采样ˆh(2)W (2)RBMh(1)采样ˆh(1)W (1)训练样本ˆh(0)图 12.6 深度信念网络的逐层预训练过程具体的逐层训练过程为自下而上依次训练每一层的受限玻尔兹曼机。假设我们已经训练好了前l − 1层的受限玻尔兹曼机，那么可以计算隐变量自下而上的条件概率p(h(i)|h(i−1) = σ)b(i) + W (i)h(i−1),1 ≤ i ≤ (l − 1)(12.66)其中b(i) 为第i 层受限玻尔兹曼机的偏置，W (i)为连接权重。这样，我们可以按照v = h(0)~h(1)~· · · ~ h(l−1) 的顺序生成一组 h(l−1) 的样本，记为ˆ (l−1)={ˆ(l,1) ,··· ,ˆ(l,M )}。然后，将h(l−1) 和 h(l) 组成一个受ˆ (l−1)作为训练集充分训练第 层的受限玻尔兹曼机。l限玻尔兹曼机，用算法12.2给出一种深度信念网络的逐层预训练方法。大量的实践表明，逐层预训练可以产生非常好的参数初始值，从而极大地降低了模型的学习难度。12.3.2.2 精调经过预训练之后，再结合具体的任务（监督学习或无监督学习），通过传 统的全局学习算法对网络进行精调（ﬁne-tuning），使模型收敛到更好的局部最优点。作为生成模型的精调 除了顶层的受限玻尔兹曼机，其它层之间的权重被分成向上的认知权重（recognition weights）W ′ 和向下的生成权重（generative weights）邱锡鹏：《神经网络与深度学习》https://nndl.github.io/
 3102019 年 4 月 6 日第 12 章 深度信念网络算法 12.2: 深度信念网络的逐层训练方法输入: 训练集: vˆ(n), n = 1, · · · , N;学习率：α, 深度信念网络层数:L, 第l 层权重：W (l), 第 l 层偏置a(l), 第l 层偏置b(l);1 for l = 1 · · · L do初始化：W(l) ← 0, a(l) ← 0, b(l) ← 0;23ˆ从训练集中采样h(0);45for i = 1 · · · l − 1 do(i) ˆ(i−1))ˆ(i)采样h ;根据分布p(h |h67endˆ(l−1)l作为训练样本， 充分训练第 层受限玻尔兹曼机将 hW (l), a(l), b(l);8 end输出: {W (l), a(l), b(l)}, 1 ≤ l ≤ LW。认知权重用来进行后验概率计算，而生成权重用来进行定义模型。认知权重的初始值W ′(l) = W(l)T。深度信念网络一般采用contrastive wake-sleep算法进行精调，其算法过程是：• Wake 阶段：认知过程，通过外界输入（可观测变量）和向上认知权重，计算每一层隐变量的后验概率并采样。然后，修改下行的生成权重使得下一层的变量的后验概率最大。也就是“如果现实跟我想象的不一样，改变我的权重使得我想象的东西就是这样的”；• Sleep 阶段：生成过程，通过顶层的采样和向下的生成权重，逐层计算每一层的后验概率并采样。然后，修改向上的认知权重使得上一层变量的后验概率最大。也就是“如果梦中的景象不是我脑中的相应概念，改变我的认知权重使得这种景象在我看来就是这个概念”；• 交替进行Wake 和 Sleep 过程，直到收敛。作为深度神经网络的精调深度信念网络的一个应用是作为深度神经网络的预训练部分，提供神经网络的初始权重。只需要向上的认知权重。在深度信念网络的最顶层再增加一层输出层，然后再使用反向传播算法对这些权重进行调优。特别是在训练数据比较少时，预训练的作用非常大。因为不恰当的初始化权重会显著影响最终模型的性能，而预训练获得的权重在权值空间中比随机权重更接近最优的权重，避免了反向传播算法因随机初始化权值参数而容易陷入局部最优和训练时间长的缺点。这不仅提升了模型的性能，也加快了调优阶段的收敛速度[Larochelle et al., 2007]。邱锡鹏：《神经网络与深度学习》https://nndl.github.io/
 12.4 总结和深入阅读2019 年 4 月 6 日311图12.7给出深度信念网络作为生成模型和判断模型的精调过程。输出层yW (4)h(3)W (3)h(2)W (2)h(1)W (1)h(3)W ′(3)h(2)W ′(2)h(1)W ′(1)vx可观测层输入层深度信念网络深度神经网络图 12.7 深度信念网络的精调过程12.4 总结和深入阅读玻尔兹曼机是Hopﬁeld 网络的随机化版本，最早由 Geoﬀrey Hinton 等人提出[Hinton and Sejnowski, 1986, Hinton et al., 1984]。玻尔兹曼机能够学习数据的内部表示，并且其参数学习的方式和赫布型学习十分类似。没有任何约束的玻尔兹曼机因为过于复杂，难以应用在实际问题上。通过引入一定的约束（即变为二分图），受限玻尔兹曼机在特征抽取、协同过滤、分类等多个任务上得到了广泛的应用。受限玻尔兹曼机最早由Smolensky [1986] 提出，并命名为簧风琴。Carreira-Perpinan and Hinton [2005] 提出了对比散度算法使得受限玻尔兹曼机的训练非常高效。受限玻尔兹曼机一度变得非常流行，因为其作为深度信念网络的一部分，显 著提高了语音识别的精度[Dahl et al., 2012, Hinton et al., 2012]，并开启了深度学习的浪潮。深层神经网络的误差反向传播算法存在梯度消失问题，因此在2006 年以前，我们还无法有效地训练深层神经网络。Hinton et al. [2006] 提出了深度信念网络，并通过逐层训练和精调可以有效地学习。Salakhutdinov [2015] 给出了深度信念网络可以逐层训练的理论依据。深度信念网络的一个重要贡献是可以为一个深层神经网络提供较好的初始参数，从而使得训练深层神经网络变得可行。深度信念网络也成为早期深度学习算法的主要框架之一。邱锡鹏：《神经网络与深度学习》https://nndl.github.io/
 3122019 年 4 月 6 日第 12 章 深度信念网络和深度信念网络十分类似的一种深度概率模型是深度玻尔兹曼机（DeepBoltzmann Machines，DBM）[Salakhutdinov and Larochelle, 2010]。深度玻尔兹曼机是由多层的受限玻尔兹曼机堆叠而成，是真正的无向图模型，其联合概率是通过能量函数来定义。和深度信念网络相比，深度玻尔兹曼机的学习和推断要更加困难。典型的深度信念网络的隐变量是二值的，其后验为伯努利分布，Wellinget al. [2005] 提出一个改进，允许隐变量为其它类型，其后验分布为指数族分布。Lee et al. [2009]提出了卷积深度信念网络（Convolutional Deep Belief Networks，CDBN），采用和卷积神经网络类似的结构，以便处理高维的图像特征。通过基于卷积的受限玻尔兹曼机和概率最大汇聚操作，卷积深度信念网络也能够使用类似深度置信网络的训练方法进行训练。除了深度信念网络之外，自编码器[Bengio et al., 2007] 以及它的变体，比如稀疏自编码器[Ranzato et al., 2006] 和去噪自编码器[Vincent et al., 2008]，也可以用来作为深度神经网络的参数初始化，并可以得到和深度信念网络类似的果。并随着人们对深度学习认识的加深，出现了很多更加便捷的训练深层神效经网络的技术，比如 ReLU 激活函数、权重初始化、逐层归一化、各自优化算法以及快捷连接[He et al., 2016] 等，使得我们可以不用预训练就可以训练一个非常深的神经网络。优化算法参见第7.2节。尽管深度信念网络作为一种深度学习模型已经很少使用，但其在深度学习发展进程中的贡献十分巨大，并且其理论基础为概率图模型，有非常好的解释性，依然是一种值得深入研究的模型。习题习题 12-1 如果使用Metropolis 算法对玻尔兹曼机进行采样，给出其提议分布的具体形式。Metropolis 算第11.3.4.2节。法 参 见习题 12-2 在受限玻尔兹曼机中，证明公式(12.49)。习题12-3 在受限玻尔兹曼机中，证明公式(12.53)、(12.54) 和(12.55) 中参数的梯度。习题12-4 计算“高斯-伯努利”受限玻尔兹曼机和“伯努利-高斯”受限玻尔兹曼机的条件概率p(v = 1|h)和p(h = 1|v)。邱锡鹏：《神经网络与深度学习》https://nndl.github.io/
 参考文献2019 年 4 月 6 日313习题 12-5 在受限玻尔兹曼机中，如果可观测变量服从多项分布，隐变量服务伯努利分布，若可观测变量的条件概率为exp(ak + Σj W k hj )iijp(vki = 1|h) =exp(ak′ + Σ Wk′ h j),(12.67)KΣjiijk′=1其中k ∈ [1, K ]为可观测变量的取值，v0 表示第 个可观测变量的值是k ∈ {1, }ii否为k，请给出满足这个条件分布的能量函数。习题 12-6习题 12-7在深度信念网络中，试分析逐层训练背后的理论依据。分析深度信念网络和深度玻尔兹曼机之间的异同点。参考文献David H Ackley, Geoﬀrey E Hinton, andTerrence J Sejnowski. A learning algorithmfor boltzmann machines. Cognitive science,9(1):147–169, 1985.acoustic modeling in speech recognition:The shared views of four research groups.IEEE Signal Processing Magazine, 29(6):82–97, 2012.Yoshua Bengio, Pascal Lamblin, DanPopovici, and Hugo Larochelle. Greedylayer-wise training of deep networks. InAdvances in neural information processingsystems, pages 153–160, 2007.Geoﬀrey E Hinton. Training products ofexperts by minimizing contrastive diver-gence. Neural computation, 14(8):1771–1800, 2002.GeoﬀreyE Hinton and Terrence J Se-Miguel A Carreira-Perpinan and Geoﬀreyjnowski. Learning and releaming in boltz-mann machines. Parallel Distrilmted Pro-cessing, 1, 1986.EHinton. On contrastive divergencelearning. In Aistats, volume 10, pages 33–40. Cite- seer, 2005.Geoﬀrey E Hinton, Terrence J Sejnowski,and David H Ackley. Boltzmann machines:Constraint satisfaction networks that learn.Carnegie-Mellon University, Department ofComputer Science Pittsburgh, PA, 1984.Geoﬀrey E Hinton, Simon Osindero, andYee-Whye Teh. A fast learning algorithmfor deep belief nets. Neural computation,18(7):1527–1554, 2006.George E Dahl, Dong Yu, Li Deng, and AlexAcero. Context-dependent pre-trained deepneural networks for large-vocabulary speechrecognition. IEEE Transactions on audio,speech, and language processing, 20(1):30–42, 2012.Kaiming He, Xiangyu Zhang, ShaoqingRen, and Jian Sun. Deep residual learningfor image recognition. In Proceedings of theIEEE conference on computer vision andpattern recognition, pages 770–778, 2016.Geoﬀrey Hinton, Li Deng, Dong Yu,George E Dahl, Abdel-rahman Mohamed,Navdeep Jaitly, Andrew Senior, Vin-cent Vanhoucke, Patrick Nguyen, Tara NSainath, et al. Deep neural networks forScott Kirkpatrick,C Daniel Gelatt, andMario P Vecchi. Optimization by simu-lated annealing. science, 220(4598):671–680, 1983.Hugo Larochelle, Dumitru Erhan, AaronCourville, James Bergstra, and Yoshua Ben-gio. An empirical evaluation of deep archi-tectures on problems with many factors of邱锡鹏：《神经网络与深度学习》https://nndl.github.io/
 3142019 年 4 月 6 日参考文献variation. In Proceedings of the 24th inter-national conference on Machine learning,pages 473–480. ACM, 2007.Ruslan Salakhutdinov and Hugo Larochelle.Eﬀcient learning of deep boltzmannma-chines. In Proceedings of thethirteenth in-ternational conference onartiﬁcial intelli-gence and statistics, pages693–700, 2010. Paul Smolensky.Honglak Lee, Roger Grosse, Rajesh Ran-ganath, and Andrew Y Ng. Convolutionaldeep belief networks for scalable unsuper-vised learning of hierarchical representa-tions. In Proceedings of the 26th annualinternational conference on machine learn-ing, pages 609–616. ACM, 2009.Information processingin dynamical systems: Foundations of har-mony theory. Technical report, Dept OfComputer Science, Colorado Univ At Boul-der, 1986.Marc’Aurelio Ranzato, Christopher Poult-ney, Sumit Chopra, and Yann LeCun. Eﬀ-cient learning of sparse representations withan energy-based model. In Proceedings ofthe 19th International Conference on Neu-ral Information Processing Systems, pages1137–1144. MIT Press, 2006.Pascal Vincent, Hugo Larochelle, YoshuaBengio, and Pierre-Antoine Manzagol. Ex-tracting and composing robust featureswith denoising autoencoders. In Proceedingsof the International Conference on MachineLearning, pages 1096–1103. ACM, 2008.Max Welling, Michal Rosen-Zvi, and Geof-frey E Hinton. Exponential family harmoni-ums with an application to information re-trieval. In Advances in neural informationprocessing systems, pages 1481–1488, 2005.Ruslan Salakhutdinov. Learning deep gen-erative models. Annual Review of Statisticsand Its Application, 2:361–385, 2015.邱锡鹏：《神经网络与深度学习》https://nndl.github.io/
 第 13 章 深度生成模型我不能创造的东西，我就不了解。— 理查德·菲利普·费曼概率生成模型，简称生成模型（Generative Model），是概率统计和机器学习中的一类重要模型，指一系列用于随机生成可观测数据的模型。假设在一个连续的或离散的高维空间X 中，存在一个随机向量X服从一个未知的数据分布pr(x), x ∈ X 。生成模型是根据一些可观测的样本x(1), x(2), · · · , x(N ) 来学习一个参数化的模型p (x) 来近似未知分布p (x)，并可以用这个模型来生成一些样θr本，使得“生成”的样本和“真实”的样本尽可能地相似。生成模型的应用十分广泛，可以用来不同的数据进行建模，比如图像、文本、声音等。比如图像生成，我们将图像表示为一个随机向量X，其中每一维都表示一个像素值。假设自然场景的图像都服从一个未知的分布pr(x)，希望通过一些观测样本来估计其分布。高维随机向量一般比较难以直接建模，需要通过一些条件独立性来简化模型。但是，自然图像中不同像素之间的存在复杂的依赖关系（比如相邻像素的颜色一般是相似的），很难用一个明确的图模型来描 述其依赖关系，因此直接建模pr(x)比较困难。深度生成模型就是利用深层神经网络可以近似任意函数的能力来建模一个 复杂的分布 pr(x)。假设一个随机向量 Z 服从一个简单的分布 p(z), z ∈ Z（比如标准正态分布），我们使用一个深层神经网络g : Z → X，并使得g(z) 服从pr(x)。本章介绍两种深度生成模型：变分自动编码器[Kingma and Welling, 2013,Rezende et al., 2014] 和对抗生成式网络[Goodfellow et al., 2014]。13.1 概率生成模型生成模型一般具有两个基本功能：密度估计和生成样本。
 3162019 年 4 月 6 日第 13 章 深度生成模型邱锡鹏：《神经网络与深度学习》https://nndl.github.io/
 13.2 变分自编码器2019 年 4 月 6 日317zx邱锡鹏：《神经网络与深度学习》https://nndl.github.io/
 3182019 年 4 月 6 日第 13 章 深度生成模型yx邱锡鹏：《神经网络与深度学习》https://nndl.github.io/
 13.2 变分自编码器2019 年 4 月 6 日319(a) 带隐变量的生成模型(b) 带类别的生成模型图 13.1 生成模型13.1.1 密度估计给定一组数据D = {x(i)}, 1 ≤ i ≤ N ，假设它们都是从独立地从相同的概率密度函数为pr(x) 的未知分布中产生的。密度估计（Density Estimation）是根据数据集D 来估计其概率密度函数pθ(x)。在机器学习中，密度估计是一种非常典型的无监督学习问题。如果要建模 的分布包含隐变量（如图13.1a），比如高斯混合模型，就需要利用EM 算法来进行密度估计。密度估计参见第9.2节。EM 算法参见第11.4.2.1节。13.1.1.1 应用于监督学习生成模型也可以应用于监督学习。监督学习的目标是建模输出标签的条件概率密度函数p(y|x)。根据贝叶斯公式，p(x, y)( x) =.(13.1)Σp y|p(x, y)y我们可以将监督学习问题转换为联合概率密度函数p(x, y) 的密度估计问题。图13.1a给出了生成模型用于监督学习的图模型表示。在监督学习中，比较典型的生成模型有朴素贝叶斯分类器、隐马尔可夫模型判别模型 和生成模型相对应的另一类监督学习模型是判别模型（DiscriminativeModel）。判别式模型直接建模条件概率密度函数p(y|x)，并不建模其联合概率密度函数 p(x, y)。常见的判别模型有logistic 回归、支持向量机、神经网络等。由生成模型可以得到判别模型，但由判别模型得不到生成模型。13.1.2 生成样本生成样本就是给定一个概率密度函数为 pθ(x) 的分布，生成一些服从这个分布的样本，也称为采样。我们在第11.3节中介绍了一些常用的采样方法。采样方法参见第11.3节。邱锡鹏：《神经网络与深度学习》https://nndl.github.io/
 3202019 年 4 月 6 日第 13 章 深度生成模型ϕzθxN图13.2 变分自编码器。实线表示生成模型，虚线表示变分近似。对于图13.1a中的图模型，在得到p(z, θ) 和 p(x|z, θ) 之后，我们就可以生成数据x，具体过程可以分为两步进行：1. 根据隐变量的先验分布p(z, θ) 进行采样，得到样本z；2. 根据条件分布p(x|z, θ) 进行采样，得到x。因此在生成模型中，重点是估计条件分布p(x|z, θ)。13.2 变分自编码器13.2.1 含隐变量的生成模型假设一个生成模型（如图13.2所示）中包含隐变量，即有部分变量是不可观 测的，其中观测变量X是一个高维空间X 中的随机向量，隐变量Z是一个相对低维的空间Z 中的随机向量。这个生成模型的联合概率密度函数可以分解为本章中，我们假设 X 和 Z 都是连续随机向量。p(x, z|θ) = p(x|z, θ)p(z|θ),(13.2)其中p(z|θ) 为隐变量z 先验分布的概率密度函数，p(x|z, θ) 为已知z 时观测变量x 的条件概率密度函数，θ 表示两个密度函数的参数。一般情况下，我们可以假设 p(z|θ) 和 p(x|z, θ) 为某种参数化的分布族，比如正态分布。这些分布的形式已知，只是参数θ 未知，可以通过最大化似然来进行估计。给定一个样本x，其对数边际似然log p(x|θ) 可以分解为log p(x|θ) = ELBO(q, x|θ, ϕ) + DKL(q(z|ϕ)∥p(z|x, θ)),(13.3)其中q(z|ϕ) 是额外引入的变分密度函数，其参数为ϕ，ELBO(q, x|θ, ϕ) 为证据参见公式 (11.96)。邱锡鹏：《神经网络与深度学习》https://nndl.github.io/
 13.2 变分自编码器2019 年 4 月 6 日321下界，p(x, z|θ)q(z|ϕ)ELBO(q, x|θ, ϕ) = Ezlog).(13.4)(z∼q |ϕ最大化对数边际似然log p(x|θ) 可以用EM 算法来求解，具体可以分为两步：EM 算法参见第11.4.2.1节。• E-step: 寻找一个密度函数q(z|ϕ) 使其等于或接近于后验密度函数p(z|x, θ)；• M-step: 保持q(z|ϕ) 固定，寻找θ 来最大化ELBO(q, x|θ, ϕ)。这样个步骤不断重复，直到收敛。在 EM 算法的每次迭代中，理论上最优的q(z|ϕ) 为隐变量的后验概率密度函数p(z|x, θ)，p(x|z, θ)p(z|θ)p(z|x, θ) =.(13.5)∫p(x|z, θ)p(z|θ)dzꢀ后验密度函数p(z|x, θ) 的计算是一个统计推断问题，涉及到积分计算。当隐变量 z 是有限的一维离散变量，则计算起来比较容易。在一般情况下，这个后验概率密度函数是很难计算的。此外，概率密度函数p(x|z, θ) 一般也比较复杂，很难直接用已知的分布族函数进行建模。变分自编码器（Variational Autoencoder，VAE）是一种深度生成模型，其思想是利用神经网络来分别建模两个复杂的条件概率密度函数。1. 用神经网络来产生变分分布q(z|ϕ)，称为推断网络。理论上q(z|ϕ) 可以不依赖x。但由于q(z|ϕ) 的目标是近似后验分布p(z|x, θ)，其和x 相关，因此变分密度函数一般写为q(z|x, ϕ)。推断网络的输入为x，输出为变分分布q(z|x, ϕ)。2.用神经网络来产生概率分布p(x|z, θ)，称为生成网络。生成网络的输入为z，输出为概率分布p(x|z, θ)。将推断网络和生成网络合并就得到了变分自编码器的整个网络结构，如图13.3所示，其中实线表示网络计算操作，虚线表示采样操作。邱锡鹏：《神经网络与深度学习》https://nndl.github.io/
 3222019 年 4 月 6 日第 13 章 深度生成模型p(x|z, θ)q(z|x, ϕ)x1x2xˆ1xˆ2z网络计算采样推断网络 fI (x, ϕ)生成网络 fG(z, θ)图 13.3 变分自编码器的网络结构变分自编码器的名称来自于其整个网络结构和自编码器比较类似。推断网 络看作是“编码器”，将可观测变量映射为隐变量。生成网络可以看作是“解码 器”，将隐变量映射为可观测变量。但变分自编码器背后的原理和自编码器完全 不同。变分自编码器中的编码器和解码器的输出为分布（或分布的参数），而不 是确定的编码。自编码器参见第9.1.3节。13.2.2 推断网络为了简单起见，假设q(z|x, ϕ) 是服从对角化协方差的高斯分布，q(z|x, ϕ) = N (z|µI , σ2I),(13.6)其中µ 和σ2 是高斯分布的均值和方差，可以通过推断网络f (x, ϕ) 来预测。IIµI =f(x, ϕ),(13.7)σI其中推断网络 fI (x, ϕ) 可以是一般的全连接网络或卷积网络，比如一个两层的神经网络，h = σ(W (1)x + b(1)),µI = W (2)h + b(2),(13.8)(13.9)σI = softplus(W (3)h + b(3)),(13.10)其中ϕ代表所有的网络参数{W (1), W (2), W (3), b(1), b(2),b ， 和softplus为(3)} σsoftplus(x) = log(1 + ex).激活函数。邱锡鹏：《神经网络与深度学习》https://nndl.github.io/
 13.2 变分自编码器2019 年 4 月 6 日32313.2.2.1 推断网络的目标推断网络的目标是使得q(z|x, ϕ) 来尽可能接近真实的后验p(z|x, θ)，需要找到变分参数ϕ∗ 来最小化两个分布的KL散度。ϕ∗ = arg min DKL(q(z|x, ϕ)||p(z|x, θ)).(13.11)ϕ然而直接计算上面的KL 散度是不可能的，因为p(z|x, θ) 一般无法计算。传统方法是利用采样或者变分方法来近似推断。基于采样的方法效率很低且估计也不是很准确，所以一般使用的是变分推断方法，即用简单的分布q 去近似复杂的分布p(z|x, θ)。但是在深度生成模型中，p(z|x, θ) 是非常复杂的分布，很难用简单的分布去近似。因此，我们需要找到一种间接的计算方法。根据公式(13.3) 可知，变分分布q(z|x, ϕ) 与真实后验p(z|x, θ)) 的 KL 散度等于对数边际似然log p(x|θ) 与其下界ELBO(q, x|θ, ϕ) 的差。DKL(q(z|x, ϕ)||p(z|x, θ)) = log p(x|θ) − ELBO(q, x|θ, ϕ),(13.12)因此，推断网络的目标函数为相当于EM 算法中的E 步。第一项与ϕ 无关。ϕ∗ = arg min DKL(q(z|x, ϕ)||p(z|x, θ))(13.13)ϕ= arg min log p(x|θ) − ELBO(q, x|θ, ϕ)(13.14)(13.15)ϕ= arg max ELBO(q, x θ| , ϕ).ϕ13.2.3 生成网络生成模型的联合分布p(x, z|θ) 可以分解为两部分：隐变量z 的先验分布p(z|θ)和条件概率分布p(x|z, θ)。先验分布p(z|θ) 一般假设隐变量z 的先验分布为各向同性的标准高斯分布N(z|0, I)。隐变量z的每一维之间都是独立的。条件概率分布 p(x|z, θ) 建模条件分布p(x|z, θ) 通过生成网络来建模。为了简单起见，我们同样用参数化的分布族来表示条件概率分布p(x|z, θ)，这些分布族的参数可以用生成网络来计算得到。根据变量 x 的类型不同，可以假设 p(x|z, θ) 服从不同的分布族。如果 x∈{0, 1}d 是 d 维的二值的向量，可以假设 log p(x|z, θ) 服从多变量的伯努利分布，即Ydp(x|z, θ) =p(x z, θ)|(13.16)ii= 1邱锡鹏：《神经网络与深度学习》https://nndl.github.io/
 3242019 年 4 月 6 日第 13 章 深度生成模型Ydxi(1 x )=iγ (1 − γ)ii= 1,(13.17其中γi网络来预测。,p(x = 1|z, θ) 为第i 维分布的参数。γ = [γ , · · · i, γ ] 可以通过生成Ti1d如果x ∈ R 是 维的连续向量，可以假设ddp(x|z, θ)服从对角化协方差的高斯分布，即p(x|z, θ) = N(x|µ , σ2 I),(13.18)GG其中µ 和σ 同样可以用生成网络f (z, θ) 来预测。GGG13.2.3.1 生成网络的目标生成网络的目标是找到一组θ∗ 最大化证据下界ELBO(q, x|θ, ϕ)。相当于 EM 算法中的 M 步。θ∗ = arg max ELBO(q, x θ| , ϕ).(13.19)θ13.2.4 模型汇总结合公式（13.15）和（13.19），推断网络和生成网络的目标都为最大化证据下界ELBO(q, x|θ, ϕ)。因此，变分自编码器的总目标函数为max ELBO(q, x|θ, ϕ) = max Ezp(x|z, θ)p(z|θ)q(z|ϕ)log(13.20)(13.21)∼q(z|ϕ)θ,ϕθ,ϕhi= max Elog p(x|z, θ) − Dq(z|x, ϕ)||p(z|θ) ,z∼q(z|x,ϕ)KLθ,ϕ其中先验分布p(z|θ) = N(z|0, I)，θ 和 ϕ 分别表示生成网络和推断网络的参数。公式(13.21) 中的期望Ez∼q(z|x,ϕ)[log p(x|z, θ)] 一般通过采样的方式进行计算。对于每个样本x，根据q(z|x, ϕ) 采集M 个z(m), 1 ≤ m ≤ M，ΣM1)m), θ .Ezp| , θ≈p|(13.22)[log (x z )]∼q(z|x,ϕ)Mm=1log (x z从 EM 算法角度来看，变分自编码器优化推断网络和生成网络的过程，可以分别看作是EM 算法中的E 步和M 步。但在变分自编码器中，这两步的目标合二为一，都是最大化证据下界。此外，变分自编码器可以看作神经网络和贝叶斯网络的混合体。贝叶斯网络中的节点可以看成是一个随机变量。在变分自编码器中，我们仅仅将隐藏编码对应的节点看成是随机变量，其它节点还是作为普通神经元。这样，编码器变成一个变分推断网络，而解码器可以看作是将隐变量映射到观测变量的生成网络。邱锡鹏：《神经网络与深度学习》https://nndl.github.io/
 13.2 变分自编码器2019 年 4 月 6 日32513.2.5 训练给定一个数据集D，包含 N 个从未知数据分布中抽取的独立同分布样本x(1), x(2), · · · , x(N )。变分自编码器的目标函数为!ΣΣN1 MMJ (ϕ, θ|D) =log p(x(n)|z(n,m), θ) − DKL q(z|x(n), ϕ)∥N (z|0, I),n=1m=1(13.23)其中z(n,m) 为第n 个样本的变分分布q(z|x(n), ϕ) 的第m 个采样。如果采用随机梯度方法，每次从数据集中采一个样本x，然后根据q(z|x, ϕ)采一个隐变量z，则目标函数变为J (ϕ, θ|x) = log p(x|z, θ) − DKL q(z|x, ϕ)∥N (z|0, I) .(13.24)假设 q(z|x, ϕ) 是正态分布，公式(13.24) 中的 KL 散度可以直接计算出解析解。对于两个正态分布N(µ , Σ ) 和 N(µ , Σ )，其KL 散度为1122DKL(N(µ , Σ )∥N (µ , Σ ))112212|Σ2||Σ1|ꢀ=tr(Σ−1Σ ) + (µ − µ ) Σ−1(µ − µ ) − k + log,(13.25)12121其中tr(·) 表示矩阵的迹；| · | 表示矩阵的行列式。矩阵的“迹”为主对角线（从左上方至右下方的对角线）上各个元素的总和。这样当q(z|x(n), ϕ) 为 N(µI, σ2I) 时，DKL q(z|x, ϕ)∥p(z, θ)12=tr(σ2I) + µꢀµ − k − log(|σ2I|) ,(13.26)其中µ 和 σ 为推断网络f (x, ϕ) 的输出。III再参数化 在变分自编码器中，一个问题是如何求随机变量z 关于参数ϕ 的导数。因为随机变量z 采样自后验分布q(z|x, ϕ)，和参数ϕ 相关。但由于是采样的方式，无法直接计算函数z关于ϕ的导数。如果q(z|x, ϕ)的随机性独立于参数ϕ，我们可以通过再参数化（Reparameterization）方法来计算导数。再参数化是实现通过随机变量实现反向传播的一种重要手段，并用随机梯度下降训练整个网络，可以提高变分自编码器的训练效率。假设q(z|x, ϕ) 为正态分布N (µI, σ2I)，我们可以通过下面方式来采样z。z = µ + σ ⊙ ϵ,(13.27)II邱锡鹏：《神经网络与深度学习》https://nndl.github.io/
 3262019 年 4 月 6 日第 13 章 深度生成模型其中ϵ ∼ N (0, I)，µI 和σI 是推断网络fI (x, ϕ) 的输出。这样z和µI , σI 的关系从采样关系变为函数关系，就可以求z 关于ϕ 的导数。如果进一步假设p(x|z, θ) 服从高斯分布N(x|µ , I)，其中µ = f (z, θ) 是GGG生成网络的输出，则目标函数可以简化为J (ϕ, θ|x) = −∥x − µ ∥ + DN(µ , σ )∥N (0, I) ,(13.28)2GKLII其中第一项可以近似看作是输入x 的重构正确性，第二项可以看作是正则化项。这和自编码器非常类似。变分自编码器的训练过程如图13.4所示。邱锡鹏：《神经网络与深度学习》https://nndl.github.io/
 −∥x − µG∥213.2 变分自编码器2019 年 4 月 6 日327邱锡鹏：《神经网络与深度学习》https://nndl.github.io/
 3282019 年 4 月 6 日第 13 章 深度生成模型µG生成网络 fG(z, θ)()DKL N(µ , σ )∥N(0, I)II+×µIσI推断网络 fI(x, ϕ)ϵ ∼ N(0, I)x图 13.4 变分自编码器的训练过程，空心矩形表示目标函数图13.5给出了在MNIST 数据集上，变分自编码器学习到的隐变量流形的可视化示例。图13.5a是将训练集上每个样本x 通过推断网络映射到2 维的隐变量空间，图中的每个点表示E[z|x]，不同颜色表示不同的数字。图13.5b是对2的标准高斯分布上进行均匀采样得到不同的隐变量z，然后通过生成网络产生E[x|z]。维的邱锡鹏：《神经网络与深度学习》https://nndl.github.io/
 13.2 变分自编码器2019 年 4 月 6 日329(a) 训练集上所有样本在隐空间上的投影。(b) 隐变量 z 在图像空间的投影。图13.5 在 MNIST 数据集上，变分自编码器学习到的隐变量流形可视化示例13.3 生成对抗网络13.3.1 显式密度模型和隐式密度模型在本书之前介绍的深度生成模型，比如变分自编码器、深度信念网络等，都 是显示地构建出样本的密度函数p(x|θ)，并通过最大似然估计来求解参数，称为显式密度模型（Explicit Density Model）。比如变分自编码器的密度函数为p(x, z|θ) = p(x|z, θ)p(z|θ)。虽然使用了神经网络来估计p(x|z, θ)，但是我们依然假设p(x|z, θ) 为一个参数分布族，而神经网络只是用来预测这个参数分布族的参数。这在某种程度上限制了神经网络的能力。如果只是希望有一个模型能生成符合数据分布 pr(x) 的样本，那么可以不显示地估计出数据分布的密度函数。假设在低维空间Z 中有一个简单容易采样的分布p(z)，p(z) 通常为标准多元正态分布N(0, I)。我们用神经网络构建一个映射函数G : Z → X ，称为生成网络。利用神经网络强大的拟合能力，使得G(z) 服从数据分布pr(x)。这种模型就称为隐式密度模型（Implicit Density Model）。所谓隐式模型就是指并不对显示地建模pr(x)，而是建模生成过程。图13.6给出了隐式模型生成样本的过程。z ∼ N(0, I)生成网络 G(z, θ)= x图 13.6 隐式模型生成样本的过程邱锡鹏：《神经网络与深度学习》https://nndl.github.io/
 

 13.3 生成对抗网络2019 年 4 月 6 日32513.3.2 网络分解13.3.2.1 判别网络隐式密度模型的一个关键是如何确保生成网络产生的样本一定是服从真实的数据分布。既然我们不构建显示密度函数，就无法通过最大似然估计等方法来训练。生成对抗网络（Generative Adversarial Networks，GAN）是通过对抗训练的方式来使得生成网络产生的样本服从真实数据分布。在生成对抗网络中，有两个网络进行对抗训练。一个是判别网络，目标是尽量准确地判断一个样本是来自于真实数据还是生成网络产生的；另一个是生成网络，目标是尽量生成判别网络无法区分来源的样本。这两个目标相反的网络不断地进行交替训练。当最后收敛时，如果判别网络再也无法判断出一个样本的来源，那么也就等价于生成网络可以生成符合真实数据分布的样本。生成对抗网络的流程图如图13.7所示。x ∼ D判别网络 D(x, ϕ)1/0z ∼ N(0, I)生成网络 G(z, θ)图 13.7 生成对抗网络的流程图判别网络（Discriminator Network）D(x, ϕ) 的目标是区分出一个样本x 时来自于真实分布p (x) 还是来自于生成模型p (x)，因此判别网络实际上是一个两类rθ分类器。用标签y = 1来表示样本来自真实分布，y = 0表示样本来自模型， 判别网络D(x, ϕ) 的输出为x 属于真实数据分布的概率，即p(y = 1|x) = D(x, ϕ),(13.29)则样本来自模型生成的概率为p(y = 0|x) = 1 − D(x, ϕ)。给定一个样本(x, y)，y = {1, 0} 表示其自于p (x) 还是p (x)，判别网络的rθ目标函数为最小化交叉熵，即最大化对数似然。交叉熵等于负的对数似然。himin − E y log p(y = 1|x) + (1 − y) log p(y = 0|x)(13.30)xϕhihi= max Ex∼pr (x) log D(x, ϕ) + Elog(1 − D(xꢀ, ϕ))(13.31)x′∼pθ (x′)ϕhihi= max Ex∼pr(x) log D(x, ϕ) + Ez∼p(z) log(1 − D G(z, θ), ϕ),(13.32)ϕ其中θ 和 ϕ 分布时生成网络和判别网络的参数。邱锡鹏：《神经网络与深度学习》https://nndl.github.io/
 3262019 年 4 月 6 日第 13 章 深度生成模型13.3.2.2 生成网络生成网络（Generator Network）的目标刚好和判别网络相反，即让判别网络将自己生成的样本判别为真实样本。himax Ez∼p(z) log D G(z, θ), ϕ)(13.33)(13.34)θhi= min Ez∼p(z) log 1 − D G(z, θ), ϕ).θ上面的这两个目标函数是等价的。但是在实际训练时，一般使用前者，因为其梯度性质更好。我们知道，函数log(x), x ∈ (0, 1) 在 x 接近1 时的梯度要比接近0 时的梯度小很多，接近“饱和”区间。这样，当判别网络D 以很高的概率认为生成网络G 产生的样本是“假”样本，即 1 − D G(z, θ), ϕ → 1。这时目标函数关于θ 的梯度反而很小，从而不利于优化。还有一种改进生成网络的梯度的方法是将真实样本和生成样本的标签互换，即生成样本的标签为1。13.3.3 训练和单目标的优化任务相比，生成对抗网络的两个网络的优化目标刚好想反。因此生成对抗网络的训练比较难，往往不太稳定。一般情况下，需要平衡两个网络的能力。对于判别网络来说，一开始的判别能力不能太强，否则难以提升生成网络的能力。然后也不能太弱，否则针对它训练的生成网络也不会太好。在训练时需要使用一些技巧，使得在每次迭代中，判别网络比生成网络的能力强一些，但又不能强太多。生成对抗网络的训练流程如算法13.1所示。每次迭代时，判别网络更新K次而生成网络更新一次，即首先要保证判别网络足够强才能开始训练生成网络。邱锡鹏：《神经网络与深度学习》https://nndl.github.io/
 13.3 生成对抗网络2019 年 4 月 6 日327在实践中K 是一个超参数，其取值一般取决于具体任务。算法 13.1: 生成对抗网络的训练过程输入: 训练集D，对抗训练迭代次数T ，每次判别网络的训练迭代次数K，小批量样本数量M1 随机初始化θ, ϕ;2 for t ← 1 to T do// 训练判别网络D(x, ϕ)3for k ← 1 to K do// 采集小批量训练样本456从训练集D 中采集M 个样本{x(m)}, 1 ≤ m ≤ M ;从分布N(0, I) 中采集M 个样本{z(m)}, 1 ≤ m ≤ M ;使用随机梯度上升更新ϕ，梯度为ΣhMi∂1log D(x(m), ϕ) + log1 − D G(z(m), θ), ϕ;∂ϕMm=17end// 训练生成网络G(z, θ)89从分布N(0, I) 中采集M 个样本{z(m)}, 1 ≤ m ≤ M ;使用随机梯度上升更新θ，梯度为ΣhMi∂1DG(z(m), θ), ϕ;∂θMm=110 end输出: 生成网络G(z, θ)13.3.4 一个生成对抗网络的具体实现：DCGAN生成对抗网络是指一类采用对抗训练方式来进行学习的深度生成模型，其包含的判别网络和生成网络都可以根据不同的生成任务使用不同的网络结构。本节介绍一个生成对抗网络的具体例子深度卷积生成对抗网络（Deep Con-volutional Generative Adversarial Networks，DCGAN）[Radford et al., 2015]。在 DCGAN 中，判别网络是一个传统的深度卷积网络，但使用了带步长的卷积来实现下采样操作，不用最大汇聚（pooling）操作。生成网络使用一个特殊的深度卷积网络来实现，如图13.8所示，使用微步卷积来生成64 × 63 大小的图像。微步卷积参见第5.5.1节。DCGAN 的主要优点是通过一些经验性的网络结构设计使得对抗训练更加稳定。比如，（1）使用代步长的卷积（在判别网络中）和微步卷积（在生成网邱锡鹏：《神经网络与深度学习》https://nndl.github.io/
 3282019 年 4 月 6 日第 13 章 深度生成模型图 13.8 DCGAN中的生成网络。第一层是全连接层，输入是从均匀分布中随机采样的100 维向量z，输出是4 × 4 × 1024 的向量，重塑为4 × 4 × 1024 的张量；然后是四层的微步卷积，没有汇聚层。图片来源：[Radford et al., 2015]络中）来代替汇聚操作，以免损失信息；（2）使用批量归一化；（3）去除卷积层之后的全连接层；（4）在生成网络中，除了最后一层使用Tanh 激活函数外， 其余层都使用ReLU 函数；（5）在判别网络中，都使用LeakyReLU激活函数。13.3.5 模型分析将判别网络和生成网络合并，整个生成对抗网络的整个目标函数看作最小化最大化游戏（Minimax Game），hihimin max Ex∼pr(x) log D(x, ϕ) + Ex∼pθ (x) log(1 − D x, ϕ)(13.35)θϕhihi= min max Ex∼pr(x) log D(x, ϕ) + Ez∼p(z) log(1 − D G(z, θ), ϕ), (13.36)θϕ因为之前提到的生成网络梯度问题，这个最小化最大化形式的目标函数一般用来进行理论分析，并不是实际训练时的目标函数。假设p (x) 和p (x) 已知，则最优的判别器为rθ参见习题13-1。pr(x)D⋆(x) =.(13.37)p (x) + p (x)rθ将最优的判别器D(x) 代入公式(13.35)，其目标函数变为⋆hihiL(G|D⋆) = Ex∼plog D⋆(x) + Ex∼plog(1 − D⋆(x))(x)(13.38)(x)rθihihpr(x)p (x) + p (x)pθ(x)= Ex∼plog+ Exlog(13.39)(x)∼pθ (x)rpr (x) + pθ (x)rθ= DKL pr∥pa + DKL pθ∥pa − 2 log 2(13.40)(13.41)= 2D (p ∥p ) − 2 log 2,JSrθ邱锡鹏：《神经网络与深度学习》https://nndl.github.io/
 13.3 生成对抗网络2019 年 4 月 6 日329其中DJS 为JS 散度，pa(x) =1p (x) + p (x)r θ2为一个“平均”分布。参见第E.3.3节。在生成对抗网络中，当判断网络为最优时，生成网络的优化目标是最小化真实分布p 和模型分布p 之间的JS 散度。当两个分布相同时，JS 散度为0，最rθ优生成网络G对应的损失为L(G|D ) = −2 log 2。⋆⋆⋆然而，JS 散度的一个问题是：当两个分布没有重叠时，它们之间的JS 散度恒等于常数log 2。对生成网络来说，目标函数关于参数的梯度为0。∂L(G|D)⋆= 0.(13.42)∂θ图13.9给出了生成对抗网络中的梯度消失问题的示例。当真实分布pr 和模型分布pθ 没有重叠，最优的判断网络对所有生成数据的输出都为0，D(G(z, θ)) = 0,⋆∀z。因此，生成网络的梯度消失。1最优判断函数 D⋆生成数据 pθ真实数据 pr0图 13.9 生成对抗网络中的梯度消失问题因此，在实际训练生成对抗网络时，我们一般不会将判别网络训练到最优，只进行一步或多步梯度下降，使得生成网络的梯度依然存在。然而，判别网络也不能太差，否则生成网络的梯度为错误的梯度。如何使得判别网络在梯度消失和梯度错误之间取得平衡并不是一件容易的事。13.3.5.1 模型坍塌如果使用公式（13.33）作为生成网络的目标函数，将最优判断网络D入，得到代⋆hꢀ⋆L (G|D ) = E⋆(13.43)(13.44)θhpr(x)pr(x) + pθ(x) pθ(x)pθ(x)Dlo(x)= Ex∼p·θhih(x)ipθ(x)pθ(x)= −Ex∼plog+Eh(13.45)(13.46)(13.47)(x)x ∼pθlogθpr(x)p (x) + p (x)irθ= −DKL pθ∥pr + Ex∼plog 1 − D⋆(x))(x)θhi= −DKL pθ∥pr + 2D (p ∥p ) − 2 log 2 − Elog D⋆(x) ,根据公式(13.41)JSrθx∼p r(x)邱锡鹏：《神经网络与深度学习》https://nndl.github.io/
 3302019 年 4 月 6 日第 13 章 深度生成模型其中后两项和生成网络无关，因此max L (′ G D =|)minθDKLpθ∥pr− 2D(p ∥p ),rθ(13.48)⋆JSθ其中JS 散度D (p ∥p ) ∈ [0, log 2] 为有界函数，因此生成网络的目标为更多的JSθr是受逆向KL 散度D (p ∥p ) 影响，使得生成网络更倾向于生成一些更“安全”KLθr的样本，从而造成模型坍塌（Model Collapse）问题。前向和逆向KL 散度 因为KL散度是一种非对称的散度，在计算真实分布pr 和模型分布pθ 之间的KL 散度时，按照顺序不同，有两种KL 散度：前向KL 散度（Forward KL divergence）D (p ∥p )和逆向KL散度（Reverse KL divergence）KLrθD (p ∥p )。前向和逆向KL 散度分别定义为KLθr∫pr(x)pθ(x)pθ(x)DKL(p ∥p ) = p r(x) logdx,(13.49)(13.50)rθ∫D (p ∥p ) = p (x) logdx.KLθrθpr(x)在前向KL 散度中，（1） 当 p (x) → 0 而 p (x) > 0 时，p (x) log(x)pθ(x)pr→ 0。不管pθ(x) 如何取rθr值，都对前向KL 散度的计算没有贡献。(x)pθ(x)（2） 当 p (x) > 0 而 p (x) → 0 时，p (x) logpr→ ∞，前向KL 散度会变rθr得非常大。因此，前向KL 散度会鼓励模型分布p (x) 尽可能覆盖所有真实分布p (x) >θr0 的点，而不用回避pr(x) ≈ 0 的点。在逆向KL 散度中，(x)（1） 当p (x) → 0 而p (x) > 0 时，p (x) log → ∞。即当pθ(x) 接近于p (x)rpθrθθ0，而pθ(x) 有一定的密度时，逆向KL 散度会变得非常大。(x)pr(x)（2） 当p (x) → 0 时，不管p (x) 如何取值，p (x) logpθ→ 0。θrθ因此，逆向KL 散度会鼓励模型分布p (x) 尽可能避开所有真实分布p (x) ≈θr0 的点，而不需要考虑是否覆盖所有布pr(x) > 0 的点。图13.10给出数据真实分布为一个高斯混合分布，模型分布为一个单高斯分布时，使用前向和逆向KL 散度来进行模型优化的示例。蓝色曲线为真实分布pr的等高线，红色曲线为模型分布pθ 的等高线。13.3.6 改进模型生成对抗网络的改进主要有以下几个方面：邱锡鹏：《神经网络与深度学习》https://nndl.github.io/
 13.3 生成对抗网络2019 年 4 月 6 日331邱锡鹏：《神经网络与深度学习》https://nndl.github.io/
 3322019 年 4 月 6 日第 13 章 深度生成模型邱锡鹏：《神经网络与深度学习》https://nndl.github.io/
 13.3 生成对抗网络2019 年 4 月 6 日图 13.10 前向和逆向KL 散度333GAN 中交叉熵（JS 散度）不适合衡量生成数据分布和真实数据分布的距离，如果通过优化JS 散度训练GAN 会导致找不到正确的优化目标，所以，13.3.6.1 W-GANW-GAN 是一种通过用Wassertein 距离替代JS 散度来优化训练的生成对抗网络[Arjovsky et al., 2017]。Wassertein 距第E.3.4节。离参见对于真实分布pr 和模型分布p ，它们的1st-Wasserstein 距离为θhiW 1(p , p ) =infE(x,y)∼γ ||x − y|| ,(13.51)rθγ∼Π(P ,P )rg其中Γ(p , p ) 是边际分布为p 和p 的所有可能的联合分布集合。rθrθ当两个分布没有重叠或者重叠非常少时，它们之间的KL 散度为+∞，JS散度为log 2，并不随着两个分布之间的距离而变化。而1st-Wasserstein 距离可以依然衡量两个没有重叠分布之间的距离。根据Kantorovich-Rubinstein 对偶定理，两个分布 p 和p 之间的 1st-Wassersteinrθ距离的对偶形式为：W 1(p , p ) = sup Ex∼pr [f (x)] − Ex∼p θ[f (x)],(13.52)rθ∥f ∥L≤1其中f : Rd → R为1-Lipschitz函数，满足|f(x) − f(y)|∥f ∥ , sup≤ 1.(13.53)L|x − y|xy我们可以将1-Lipschitz连续的约束宽松为K-Lipschitz连续，等于计算pr 和p 之间的K · W 1(p , p )。θrθ参见习题13-2。令f(x, ϕ)为一个神经网络，假设存在参数集合Φ，对于所有的ϕ ∈ Φ，fϕ(x)为 K-Lipschitz 连续函数。那么公式（13.52）中的上界可以转换为max E[f (x, ϕ)] − Ex∼pθ [f(x, ϕ)],(13.55)x∼prϕ∈Φ邱锡鹏：《神经网络与深度学习》https://nndl.github.io/
 3342019 年 4 月 6 日第 13 章 深度生成模型数学小知识 | Lipschitz 连续函数在数学中，对于一个实数函数f : R → R，如果满足函数曲线上任意两点连线的斜率一致有界，即任意两点的斜率都小于常数K > 0，|f (x ) − f (x )| ≤ K|x − x |,(13.54)1212♣则函数f 就称为K-Lipschitz 连续函数，K 称为Lipschitz 常数。Lipschitz 连续要求函数在无限的区间上不能有超过线性的增长。如果一个函数可导，并满足Lipschitz 连续，那么导数有界。如果一个函数可导，并且导数有界，那么函数为Lipschitz 连续。其中f(x, ϕ)称为评价网络（Critic Network）。对于真实样本，f(x, ϕ)的打分要尽可能的高；对于模型生成的样本，f(x, ϕ)的打分要尽可能的低。和标准GAN中的判别网络的值域为[0, 1]l 不同，评价网络f (x, ϕ) 的值域没有限制。因为神经网络为连续可导函数，为了使得f(x, ϕ)满足K-Lipschitz连续，可∂f(x,ϕ)∂x以令导数∥∥有界。一种近似的方法是限制参数ϕ ∈ [−c, c]，c 为一个比较小的正数，比如0.01。l 为参数数量。生成网络的目标是使得生成样本的f(x, ϕ) 得分尽可能高。himax Eθf G(z, θ), ϕ) .(13.56)z∼p(z)因为f (x, ϕ) 为不饱和函数，所以生成网络参数θ 的梯度不会消失，理论上解决了原始 GAN 训练不稳定的问题。并且 W-GAN 中生成网络的目标函数不再是两个分布的比率，在一定程度上缓解了模型坍塌问题，使得生成的样本具有多样性。算法13.2给出W-GAN 的训练过程。和原始GAN 相比，W-GAN 的评价网络最后一层不使用sigmoid 函数，损失函数不取对数。13.4 总结和深入阅读深度生成模型是一种有机地融合神经网络和概率图模型的生成模型，将神经网络作为一个概率分布的逼近器，可以拟合非常复杂的数据分布。变分自编码器[Kingma and Welling, 2013, Rezende et al., 2014] 是一个有意义的深度生成模型，可以有效地解决含隐变量的概率模型中后验分布难以估计的问题。变分自动编码器的一个详尽介绍可以参考文献[Doersch, 2016]。Bowman et al. [2015] 将进一步将变分自编码器应用于序列生成问题。邱锡鹏：《神经网络与深度学习》https://nndl.github.io/
 13.4 总结和深入阅读2019 年 4 月 6 日333算法 13.2: W-GAN 的训练过程输入: 训练集D，对抗训练迭代次数T ，每次评价网络的训练迭代次数K，小批量样本数量M1 随机初始化θ, ϕ;2 for t ← 1 to T do// 训练评价网络f(x, ϕ)3for k ← 1 to K do// 采集小批量训练样本45从训练集D 中采集M 个样本{x(m)}, 1 ≤ m ≤ M ;从分布N(0, I) 中采集M 个样本{z(m)}, 1 ≤ m ≤ M ;// 计算评价网络参数ϕ 的梯度ΣM∂1=f (x(m ), ϕ) − f G(z(m ), θ), ϕgϕ;67∂ϕ Mm=1// 使用RMSProp 算法更新ϕϕ ← ϕ + α · RMSProp(ϕ, gϕ);// 梯度截断89ϕ ← clip(ϕ, −c, c);end// 训练生成网络G(z, θ)1011从分布N(0, I) 中采集M 个样本{z(m)}, 1 ≤ m ≤ M ;// 更新生成网络参数θΣM∂∂θ1MfG(z(m ), θ), ϕgθ =;m=112θ ← θ + α · RMSProp(θ, gθ);13 end输出: 生成网络G(z, θ)邱锡鹏：《神经网络与深度学习》https://nndl.github.io/
 3342019 年 4 月 6 日参考文献生成对抗网络[Goodfellow et al., 2014] 是一个具有开创意义的深度生成模型，突破了以往的概率模型必须通过最大似然估计来学习参数的限制。DC-GAN[Radford et al., 2015] 是一个生成对抗网络的成功实现，可以生成十分逼真的自然图像。Yu et al. [2017] 进一步在文本生成任务上结合对抗生成网络和强化学习来进行文本生成模型。对抗生成网络的训练不稳定问题的一种有效解决方法是W-GAN[Arjovsky et al., 2017]，通过用Wassertein 距离替代JS 散度来进行训练。虽然深度生成模型取得巨大的成功，但是作为一种无监督模型，其主要的缺点是缺乏有效的客观评价，因此不同模型之间的比较很难客观衡量。习题习题 13-1 假设一个两类分类，类别为c 和 c ，样本x 在两个类的条件分12布为p(x|c ) 和p(x|c )，一个分类器f (x) = p(c |x) 用于预测一个样本x 来自类121别c1 的后验概率。证明若采用交叉熵损失，hihiL(f ) = Ex∼p(x|c1) log f (x) + Elog 1 − f (x) ,(13.57)(13.58)x∼p(x|c2)则最优分类器f(x) 为⋆参见公式(13.58)。p(x|c1)f ⋆(x) =.p(x|c ) + p(x|c )12习题 13-2 分析下面函数是否满足Lipschitz 连续条件。（1）f : [−1, 1] → R，f(x) = x2；（2）f : R → R，f(x) = x2；√x2 + 1；（3）f : R → R，f(x) =（4）f : [0, 1] → [0, 1]，f(x) = √x。参考文献Martin Arjovsky, Soumith Chintala, andLéon Bottou. Wasserstein GAN. arXivpreprint arXiv:1701.07875, 2017.fromacontinuous space. arXiv preprintarXiv:1511.06349, 2015.Carl Doersch.Tutorial on varia-arXiv preprintSamuelRBowman, Luke Vilnis, Orioltional autoencoders.arXiv:1606.05908, 2016.Vinyals, Andrew M Dai, Rafal Jozefowicz,and Samy Bengio. Generating sentencesIan Goodfellow, Jean Pouget-Abadie,邱锡鹏：《神经网络与深度学习》https://nndl.github.io/
 参考文献2019 年 4 月 6 日335Mehdi Mirza, Bing Xu, David Warde-Farley, Sherjil Ozair, Aaron Courville, andYoshua Bengio. Generative adversarialnets. In Advances in Neural InformationProcessing Systems, pages 2672–2680, 2014.tive adversarial networks. arXiv preprintarXiv:1511.06434, 2015.Danilo Jimenez Rezende, Shakir Mohamed,and Daan Wierstra. Stochastic back-propagation and approximate inference indeep generative models. arXiv preprintarXiv:1401.4082, 2014.Diederik P Kingma and Max Welling. Auto-encoding variational bayes. arXiv preprintarXiv:1312.6114, 2013.Lantao Yu, Weinan Zhang, Jun Wang, andYong Yu. Seqgan: Sequence generativeadversarial nets with policy gradient. InThirty-First AAAI Conference on ArtiﬁcialIntelligence, 2017.Alec Radford, Luke Metz, and SoumithChintala. Unsupervised representationlearning with deep convolutional genera-邱锡鹏：《神经网络与深度学习》https://nndl.github.io/
 

 第 14 章 深度强化学习除了试图直接去建立一个可以模拟成人大脑的程序之外，为什么不试图建立一个可以模拟小孩大脑的程序呢？如果它接受适当的教育，就会获得成人的大脑。— 阿兰· 图灵在之前的章节中，我们主要关注于监督学习，而监督学习一般需要一定数量的带标签的数据。在很多的应用场景中，通过人工标注的方式来给数据打标签的方式往往行不通。比如我们通过监督学习来训练一个模型可以来自动下围棋，就需要将当前棋盘的状态作为输入数据，其对应的最佳落子位置（动作）作为标签。训练一个好的模型就需要收集大量的不同棋盘状态以及对应动作。这种做法实践起来比较困难，一是对于每一种棋盘状态，即使是专家也很难给出“正确”的动作，二是获取大量数据的成本往往比较高。对于下棋这类任务，虽 然我们很难知道每一步的“正确”动作，但是其最后的结果（即赢输）却很容易判断。因此，如果可以通过大量的模拟数据，通过最后的结果（奖励）来倒推每一步棋的好坏，从而学习出“最佳”的下棋策略，这就是强化学习。强化学习（Reinforcement Learning，RL），也叫增强学习，是指一类从（与环境）交互中不断学习的问题以及解决这类问题的方法。强化学习问题可以描述为一个智能体从与环境的交互中不断学习以完成特定目标（比如取得最大奖励值）。和深度学习类似，强化学习中的关键问题也是贡献度分配问题 [Minsky,1963]，每一个动作并不能直接得到监督信息，需要通过整个模型的最终监督信息（奖励）得到，并且有一定的延时性。贡献度分配问题即一个系统中不同的组件（components）对最终系统输出结果的贡献或影响。强化学习也是机器学习中的一个重要分支。强化学习和监督学习的不同在于，强化学习问题不需要给出“正确”策略作为监督信息，只需要给出策略的（延迟）回报，并通过调整策略来取得最大化的期望回报。
 3382019 年 4 月 6 日第14 章 深度强化学习14.1 强化学习问题强化学习广泛应用在很多领域，比如电子游戏、棋类游戏、迷宫类游戏、控制系统、推荐等。这里我们介绍几个比较典型的强化学习例子。14.1.1 典型例子多臂赌博机问题 给定K 个赌博机，拉动每个赌博机的拉杆（arm），赌博机会按照一个事先设定的概率掉出一块钱或不掉钱。每个赌博机掉钱的概率不一样。 多臂赌博机问题（multi-armed bandit problem）是指，给定有限的机会次数T ，如何玩这些赌博机才能使得期望累积收益最大化。多臂赌博机问题在广告推荐、投资组合等领域有着非常重要的应用。也称为K 臂赌博机问题（K-armed bandit problem）。悬崖行走问题 在一个网格世界（grid world）中，每个格子表示一个状态。如14.1所示的一个网格世界，每个状态为(i, j), 1 ≤ i ≤ 7, 1 ≤ j ≤ 3，其中格子(2, 1) 到(6, 1) 是悬崖（cliff）。有一个醉汉，从左下角的开始位置S，走到右下角的目标位置E。如果走到悬崖，醉汉会跌落悬崖并死去。醉汉可以选择行走的路线，即在每个状态时，选择行走的方向：上下左右。动作空间A = {↑, ↓, ←, →}。但每走一步，都有一定的概率滑落到周围其他的格子。醉汉的目标是如何安全地到达目标位置。321S1E723456图 14.1 醉汉悬崖问题14.1.2 强化学习定义现在我们描述下强化学习的任务定义。在强化学习中，有两个可以进行交互的对象：智能体和环境。• 智能体（agent）可以感知外界环境的状态（state）和反馈的奖励（reward），并进行学习和决策。智能体的决策功能是指根据外界环境的状态来做出不同的动作（action），而学习功能是指根据外界环境的奖励来调整策略。邱锡鹏：《神经网络与深度学习》https://nndl.github.io/
 14.1 强化学习问题2019 年 4 月 6 日339• 环境（environment）是智能体外部的所有事物，并受智能体动作的影响而改变其状态，并反馈给智能体相应的奖励。在强化学习中的基本要素包括：• 状态s 是对环境的描述，可以是离散的或连续的，其状态空间为S；• 动作a是对智能体行为的描述，可以是离散的或连续的，其动作空间为A；• 策略π(a|s) 是智能体根据环境状态s 来决定下一步的动作a 的函数；• 状态转移概率 p(s′|s, a) 是在智能体根据当前状态 s 做出一个动作 a 之后，环境在下一个时刻转变为状态s′ 的概率；• 即时奖励r(s, a, s′) 是一个标量函数，即智能体根据当前状态s 做出动作a之后，环境会反馈给智能体一个奖励，这个奖励也经常和下一个时刻的状态 s′ 有关。策略 智能体的策略（policy）就是智能体如何根据环境状态s 来决定下一步的动作a，通常可以分为确定性策略（Deterministic Policy）和随机性策略（StochasticPolicy）两组。确定性策略是从状态空间到动作空间的映射函数π : S → A。随机性策略表示在给定环境状态时，智能体选择某个动作的概率分布。π(a|s) , p(a|s),π(a|s) = 1.(14.1)(14.2)Σa∈A通常情况下，强化学习一般使用随机性的策略。随机性的策略可以有很多优点。比如在学习时可以通过引入一定随机性更好地探索环境。二是使得策略更加地多样性。比如在围棋中，确定性策略总是会在同一个位置上下棋，会导致你的策略很容易被对手预测。参考利用-探索策略。14.1.3 马尔可夫决策过程为了简单起见，我们将智能体与环境的交互看作是离散的时间序列。图14.2给 出了智能体与环境的交互。邱锡鹏：《神经网络与深度学习》https://nndl.github.io/
 3402019 年 4 月 6 日第14 章 深度强化学习智能体状态 st奖励 rt+1动作 at环境图 14.2 智能体与环境的交互智能体从感知到的初始环境s0 开始，然后决定做一个相应的动作a0，环境相应地发生改变到新的状态s ，并反馈给智能体一个即时奖励r ，然后智能体11又根据状态s 做一个动作a ，环境相应改变为s ，并反馈奖励r 。这样的交互1122可以一直进行下去。s , a , s , r , a , · · · , st−1, rt−1, at−1, s , r , · · · ,(14.3)00111tt其中rt = r(st−1, at−1, st) 是第t 时刻的即时奖励。智能体与环境的交互的过程可以看作是一个马尔可夫决策过程。马尔可夫过程（Markov Process）是具有马尔可夫性的随机变量序列s , s , · · · ，01st ∈ S，其下一个时刻的状态st+1 只取决于当前状态st，p(st+1|s , · · · , s ) = p(st+1|st),(14.4)t0Σ其中p(st+1|st) 称为状态转移概率，p(st+1|st) = 1。马 尔 可 夫 过 程 参 见st+1∈S第D.3.1节。马尔可夫决策过程（Markov Decision Process，MDP）在马尔可夫过程中加入一个额外的变量：动作a，即下一个时刻的状态st+1 和当前时刻的状态st以及动作at 相关，p(st+1|s , a , · · · , s , a ) = p(s |s , a ),(14.5)tt00t+1tt其中p(st+1|s , a ) 为状态转移概率。tt给定策略π(a|s)，马尔可夫决策过程的一个轨迹（trajectory）τ = s , a , s , r , a , · · · , sT −1, aT −1, sT , rT00111的概率为p(τ) = p(s , a , s , a , · · · ),(14.6)(14.7)0011YT −1=p(s0)π(a |s )p(s |s , a ).t t t+1 t tt=0邱锡鹏：《神经网络与深度学习》https://nndl.github.io/
 14.1 强化学习问题2019 年 4 月 6 日341图14.3给出了马尔可夫决策过程的图模型表示。a1a2· · ·aT −1s1s2s3· · ·sT −1sT图 14.3 马尔可夫决策过程的图模型表示14.1.4 强化学习的目标函数14.1.4.1 总回报给定策略 π(a|s)，智能体和环境一次交互过程的轨迹 τ 所收到的累积奖励为总回报（return）。ΣT −1G(τ) =rt+1(14.8)(14.9)t=0ΣT −1=r(s , a , st+1).t tt=0假设环境中有一个或多个特殊的终止状态（terminal state），当到达终止状态时，一个智能体和环境的交互过程就结束了。这一轮交互的过程称为一个回合（episode）或试验（trial）。一般的强化学习任务（比如下棋、游戏）都属于这种回合式的任务。如果环境中没有终止状态（比如终身学习的机器人），即T = ∞，称为持续性强化学习任务，其总回报也可能是无穷大。为了解决这个问题，我们可以引入一个折扣率来降低远期回报的权重。折扣回报（discounted return）定义为ΣT −1G(τ) =γ trt+1,(14.10)t=0其中γ ∈ [0, 1] 是折扣率。当γ 接近于0 时，智能体更在意短期回报；而当γ 接近于1 时，长期回报变得更重要。14.1.4.2 目标函数因为策略和状态转移都有一定的随机性，每次试验得到的轨迹是一个随机序列，其收获的总回报也不一样。强化学习的目标是学习到一个策略πθ(a|s)来邱锡鹏：《神经网络与深度学习》https://nndl.github.io/
 3422019 年 4 月 6 日第14 章 深度强化学习最大化期望回报（expected return），即希望智能体执行一系列的动作来获得尽可能多的平均回报。持续性强化学习的优化目标也可以定义为 MDP 到达平稳分布时“即时奖励”的期ΣT −1J (θ) = Eτ∼p(τ)[G(τ )] = Eτ∼p(τ)[γt rt+1].(14.11)θθt=0望。其中θ 为策略函数的参数。14.1.5 值函数为了评估一个策略π 的期望回报，我们定义两个值函数：状态值函数和状态-动作值函数。14.1.5.1 状态值函数一个策略π 期望回报可以分解为"i#Σh T−1EEτ∼p(τ)γtrt+1|τs0Eτ∼p(τ) G τ= s(14.12)(14.13)[ ( )] = s∼p(s0)t=0= Es∼p(s0 ) [V π(s)] ,其中V π(s)称为状态值函数（state value function），表示从状态s 开始，执行策略π 得到的期望总回报ΣT −1ihV π(s) = Eτ∼p(τ)γtrt+1|τs0 = s ,(14.14)t=0其中τ 表示轨迹τ 的起始状态。s0为了方便起见，我们用τ0:T 来表示从轨迹s , a , s , · · · , s ，用τ 表示轨001T1:T迹 s , a , · · · , s ，因此有τ = s , a , τ。1:T11T0:T00根据马尔可夫性，V π(s) 可展开得到"#ΣT −1r1 + γγt−1rt+1|τs0 = sV π(s) = Eτ0:T(14.15)(14.16)∼p(τ)t=1"#ΣT −1γt−1 rt+1|τs1 = sꢀr(s, a, sꢀ) + γ= Ea∼π(a|s)E′′Eτ"s ∼p(s |s,a)∼p(τ)1:Tt=1ΣhT −1i#贝 尔 曼 方 程 因 提 出 者γt−1 rt+1|τs1 = sꢀr(s, a, sꢀ) + γERichard Bellman而得名，也= Ea∼π(a|s)Es′∼p(s′|s,a)(14.17)(14.18)τ1:T∼p(τ)叫做“动态规划方程”。t=1Richard Bellman（1920 －1984），美国应用数学家，美国国家科学院院士，和动态规划的创始人。r(s, a, s ) + γV π (s ) .= Ea∼π(a|s)Es′∼p(s′|s,a)ꢀꢀ公式(14.18) 也称为贝尔曼方程（Bellman equation），表示当前状态的值函数可以通过下个状态的值函数来计算。邱锡鹏：《神经网络与深度学习》https://nndl.github.io/
 14.1 强化学习问题2019 年 4 月 6 日343如果给定策略π(a|s)，状态转移概率p(s′|s, a) 和奖励r(s, a, s′)，我们就可以通过迭代的方式来计算V π(s)。由于存在折扣率，迭代一定步数后，每个状态的值函数就会固定不变。14.1.5.2 状态-动作值函数公式(14.18) 中的第二个期望是指初始状态为s 并进行动作a，然后执行策略 π 得到的期望总回报，称为状态-动作值函数（state-action value function），Qπ(s, a) = E′′[r(s, a, s′) + γV π(s′)] ,(14.19)s ∼p(s |s,a)状态-动作值函数也经常称为Q 函数（Q-function）。状态值函数V π(s) 是Q 函数Qπ(s, a) 关于动作a 的期望，V π (s) = Ea∼π(a|s)[Qπ (s, a)].(14.20)(14.21)结合公式（14.19）和（14.20），Q 函数可以写为Qπ (s, a) = E ′′a ∼π(a′|s )r(s, a, s′) + γE ′ ′ [Qπ (s′, a′)] ,s ∼p(s |s,a)这是关于Q 函数的贝尔曼方程。14.1.5.3 值函数的作用值函数可以看作是对策略π的评估。如果在状态s，有一个动作a使得Qπ (s, a)V π(s)，说明执行动作a 比当前的策略π(a|s) 要好，我们就可以调整参数使得策略π(a|s)的概率增加。>14.1.6 深度强化学习在强化学习中，一般需要建模策略 π(a|s) 和值函数 V π(s), Qπ(s, a)。早期的强化学习算法主要关注于状态和动作都是离散且有限的问题，可以使用表格来记录这些概率。但在很多实际问题中，有些任务的状态和动作的数量非常多。 比如围棋的棋局有3361 ≈ 10170 种状态，动作（即落子位置）数量为361。还有些任务的状态和动作是连续的。比如在自动驾驶中，智能体感知到的环境状态是各种传统器数据，一般都是连续的。动作是操作方向盘的方向（−90 ∼ 90 度）和速度控制（0 ∼ 300公里/小时），也是连续的。为了有效地解决这些问题，可以一个复杂的函数（比如深度神经网络）来使得智能体可以感知更复杂的环境状态以及建立更复杂的策略，提高强化学习算法的能力，并提高泛化能力。深度强化学习（deep reinforcement learning）是将强化学习和深度学习结合在一起，用强化学习来定义问题和优化目标，用深度学习来解决策略和值函数邱锡鹏：《神经网络与深度学习》https://nndl.github.io/
 3442019 年 4 月 6 日第14 章 深度强化学习的建模问题，然后使用误差反向传播算法来优化目标函数。深度强化学习在一定程度上具备解决复杂问题的通用智能，并在很多任务上都取得了很大的成功。14.2 基于值函数的学习方法值函数是对策略π 的评估，如果策略π 有限（即状态数和动作数都有限）时，可以对所有的策略进行评估并选出最优策略π∗。∀s,π∗ = arg max V π(s).(14.22)π但这种方式在实践中很难实现。假设状态空间S 和动作空间A 都是离散且有限的，策略空间为|A||S|，往往也非常大。一种可行的方式是通过迭代的方法不断优化策略，直到选出最优策略。对于一个策略π(a|s)，其Q 函数为Qπ(s, a)，我们可以设置一个新的策略π′(a|s)，1if a = arg maxaˆ Qπ (s, ˆ)π′(a|s) =,(14.23)0 otherwise即π′(a|s) 为一个确定性的策略，也可以直接写为π′(s) = arg max Qπ(s, a).(14.24)(14.25)a如果执行π′，会有参见习题14-1。∀s,V π′ (s) ≥ V π(s).根据公式(14.25)，我们可以通过下面方式来学习最优策略：先随机初始化一个策略，计算该策略的值函数，并根据值函数来设置新的策略，然后一直反复迭代直到收敛。基于值函数的策略学习方法中最关键的是如何计算策略π 的值函数，一般有动态规划或蒙特卡罗两种计算方式。14.2.1 动态规划算法从贝尔曼方程可知，如果知道马尔可夫决策过程的状态转移概率p(s′|s, a)和奖励r(s, a, s′)，我们直接可以通过贝尔曼方程来迭代计算其值函数。这种模型已知的强化学习算法也称为基于模型的强化学习（Model-Based ReinforcementLearning）算法，这里的模型就是指马尔可夫决策过程。基于模型的强化学习，也叫做模型相关的强化学习，或有模型的强化学习。在已知模型时，可以通过动态规划的方法来计算。常用的方法主要有策略迭代算法和值迭代算法。邱锡鹏：《神经网络与深度学习》https://nndl.github.io/
 14.2 基于值函数的学习方法14.2.1.1 策略迭代2019 年 4 月 6 日345策略迭代（Policy Iteration）算法中，每次迭代可以分为两步：1. 策略评估（policy evaluation）：计算当前策略下，每个状态的值函数，即算法14.1中的3-6 步。策略评估可以通过贝尔曼方程（公式(14.18)）进行迭代计算V π(s)。如果状态数有限时，也可以通过直接求解Bellman 方程来得到得到V π(s)。2. 策略改进（policy improvement）：根据值函数来更新策略，即算法14.1中的7-8步。策略迭代如算法14.1所示。算法 14.1: 策略迭代算法输入: MDP 五元组：S, A, P, r, γ;1 初始化：∀s,∀a, π(a|s) =1 ;|A|2 repeat// 策略评估345repeat根据贝尔曼方程（公式(14.18)），计算Vπ (s), ∀s;until ∀s，V// 策略改进π(s) 收敛;67根据公式(14.19)，计算Q(s, a);∀s, π(s) = arg maxa Q(s, a);8 until ∀s，π(s) 收敛;输出: 策略π14.2.1.2 值迭代策略迭代中的策略评估和策略改进是交替轮流进行，其中策略评估也是通过一个内部迭代来进行计算，其计算量比较大。事实上，我们不需要每次计算出每次策略对应的精确的值函数，也就是说内部迭代不需要执行到完全收敛。值迭代（Value Iteration）方法将策略评估和策略改进两个过程合并，来直接计算出最优策略。假设最优策略π∗ 对应的值函数称为最优值函数，那么最优状态值函数V ∗(s)和最优状态-动作值函数Q∗(s, a) 的关系为V ∗(s) = max Q∗(s, a).(14.26)a邱锡鹏：《神经网络与深度学习》https://nndl.github.io/
 3462019 年 4 月 6 日第14 章 深度强化学习根据贝尔曼方程可知，最优状态值函数V ∗(s) 和最优状态-动作值函数Q∗(s, a)也可以进行迭代计算。V ∗(s) = max E′′r(s, a, s′) + γV ∗(s′) ,(14.27)(14.28)s ∼p(s |s,a)aQ∗(s, a) = E′′r(s, a, s′) + γ maa x Q∗(s′, a′) ,s ∼p(s |s,a)这两个公式称为贝尔曼最优方程（Bellman Optimality Equation）。参见习题14-2。值迭代方法通过直接优化贝尔曼最优方程（公式(14.27)），迭代计算最优值函数。值迭代方法如算法14.2所示。算法 14.2: 值迭代算法输入: MDP 五元组：S, A, P, r, γ;1 初始化：∀s ∈ S, V (s) = 0 ;2 repeat3∀s, V (s) ← ma ax E ′∼p s′|s,a r(s, a, s′) + γV (s′) ;s()4 until ∀s，V (s) 收敛;5 根据公式(14.19) 计算Q(s, a);6 ∀s, π(s) = arg maxa Q(s, a);输出: 策略π策略迭代 VS 值迭代 在策略迭代中，每次迭代的时间复杂度最大为O(|S|3|A|3)，最大迭代次数为|A||S|。而在值迭代中，每次迭代的时间复杂度最大为O(|S|2|A|)，但迭代次数要比策略迭代算法更多。策略迭代是根据贝尔曼方程来更新值函数，并根据当前的值函数来改进策略。而值迭代算法是直接使用贝尔曼最优方程来更新值函数，收敛时的值函数就是最优的值函数，其对应的策略也就是最优的策略。值迭代和策略迭代都需要经过非常多的迭代次数才能完全收敛。在实际应用中，可以不必等到完全收敛。这样，当状态和动作数量有限时，经过有限次迭代就可以能收敛到近似最优策略。基于模型的强化学习算法实际上是一种动态规划方法。在实际应用中有以下两点限制。一是要求模型已知，即要给出马尔可夫决策过程的状态转移概率p(s′|s, a)和奖励函数r(s, a, s′)，这个要求很难满足。如果是事先不知道模型，但仍然希望通过基于模型的学习算法，也可以通过与环境交互来学习出状态转移概率和奖励函数。一个简单的计算模型的方法为R-max [Brafman and Tennenholtz,2002]，通过随机游走的方法来探索环境。每次随机一个策略并执行，然后收集邱锡鹏：《神经网络与深度学习》https://nndl.github.io/
 14.2 基于值函数的学习方法2019 年 4 月 6 日347状态转移和奖励的样本。在收集一定的样本后，就可以通过统计或监督学习来重构出马尔可夫决策过程。但是，这种基于采样的重构过程的复杂度也非常高，只能应用于状态数非常少的场合。二是效率问题，当状态数量较大的时候，算法的效率比较低。但在实际应用中，很多问题的状态数量和动作数量非常多。比如，围棋有19 × 19 = 361 个位置，每个位置有黑子、白子或无子三种状态，整个棋局有3361 ≈ 10170 种状态。动作（即落子位置）数量为361。不管是值迭代还是策略迭代，以当前计算机的计算能力，根本无法计算。一个有效的方法是通过一个函数（比如神经网络）来近似计算值函数，以减少复杂度，并提高泛化能力。参见第14.2.4节。14.2.2 蒙特卡罗方法在很多应用场景中，马尔可夫决策过程的状态转移概率p(s′|s, a) 和奖励函数 r(s, a, s′) 都是未知的。在这种情况下，我们一般需要智能体和环境进行交互，并收集一些样本。然后再根据这些样本来求解马尔可夫决策过程最优策略。 这种模型未知，基于采样的学习算法也称为模型无关的强化学习（Model-FreeReinforcement Learning）算法。模型无关的强化学习，也叫Q 函数Qπ(s, a) 为初始状态为s，并执行动作a 后的所能得到的期望总回报， 做无模型的强化学习。可以写为参见公式(14.19)。Qπ (s, a) = Eτ ∼p(τ )[G(τ)],(14.29)s =s,a =a00其中τ表示轨迹τ 的起始状态和动作为s, a。s =s,a =a00如果模型未知，Q 函数可以通过采样来进行计算，这就是蒙特卡罗方法。对于一个策略 π，智能体从状态 s，执行动作 a 开始，然后通过随机游走的方法来探索环境，并计算其得到的总回报。假设我们进行N 次试验，得到N 个轨迹τ(1), τ (2), · · · , τ (N)，其总回报分别为G(τ (1)), G(τ(2)), · · · , G(τ(N))。Q 函数可以近似为Σ1ˆπ) =()()((14.30)NG τQπ s, a ≈ Q s, aN.s(n=) s,a =an=100当N → ∞ 时，Q ( a)ˆπ s, → Q s,π (a)。在似估计出Q 函数Qˆπ (s, a) 之后，就可以进行策略改进。然后在新的策略下重新通过采样来估计Q 函数，并不断重复，直至收敛。利用和探索 但在蒙特卡罗方法中，如果采用确定性策略π，每次试验得到的轨迹是一样的，只能计算出Qπ(s, π(s))，而无法计算其它动作a′ 的 Q 函数，因此也无法进一步改进策略。这样情况仅仅是对当前策略的利用（exploitation），而邱锡鹏：《神经网络与深度学习》https://nndl.github.io/
 3482019 年 4 月 6 日第14 章 深度强化学习缺失了对环境的探索（exploration），即试验的轨迹尽可能覆盖所有的状态和动作，以找到更好的策略。这也可以看做是一个多臂赌博机问题。为了平衡利用和探索，我们可以采用ϵ-贪心法（ϵ-greedy一个目标策略π，其对应的ϵ-贪心法策略为method）。对于π(s),按概率1 − ϵ,πϵ(s) =(14.31)随机选择A中的动作,按概率ϵ.这样，ϵ-贪心法将一个仅利用的策略转为带探索的策略。每次选择动作π(s) 的概率为1 − ϵ + 1 ，|A其| 它动作的概率为1。|A|同策略 在蒙特卡罗方法中，如果采样策略是πϵ(s)，不断改进策略也是πϵ(s) 而不是目标策略π(s)。这种采样与改进策略相同（即都是πϵ(s)）的强化学习方法叫做同策略（on policy）方法。异策略 如果采样策略是πϵ(s)，而优化目标是策略π，可以通过重要性采样，引入重要性权重来实现对目标策略π 的优化。这种采样与改进分别使用不同策略的强化学习方法叫做异策略（oﬀ policy）方法。重要性采样参见第11.3节。14.2.3 时序差分学习方法蒙特卡罗采样方法一般需要拿到完整的轨迹，才能对策略进行评估并更新模型，因此效率也比较低。时序差分学习（temporal-diﬀerence learning）结合了动态规划和蒙特卡罗方法，比仅仅使用蒙特卡罗采样方法的效率要高很多[Sutton and Barto, 2018]。时序差分学习是模拟一段轨迹，每行动一步(或者几步)，就利用贝尔曼方程来评估行动前状态的价值。当时序差分学习中每次更新的动作数为最大步数时，就等价于蒙特卡罗方法。首先，将蒙特卡罗方法中Q 函数Qˆπ (s, a) 的估计改为增量计算的方式，假设第N 次试验后值函数Qˆπ (s, a) 的平均为NΣ1Qˆπ (s, a) =N G(τ(n))(14.32)NNn=1s =s,a =a0 0邱锡鹏：《神经网络与深度学习》https://nndl.github.io/
 14.2 基于值函数的学习方法2019 年 4 月 6 日349N −1Σ1==(G(τ(N)) +G(τ(n)))(14.33)(14.34)s =s,a =as =s,a =aN00001n=1G(τ(N )) + (N − 1)QˆπN −1(s,a)Ns =s,a =a001N= Qˆπ(s, a) +G(τ(N))− Qˆπ(s, a) ,(14.35)N −1s =s,a =a N −100其中τ表示轨迹τ 的起始状态和动作为s, a。s =s,a =a00邱锡鹏：《神经网络与深度学习》https://nndl.github.io/
 3502019 年 4 月 6 日第14 章 深度强化学习值函数Qˆπ (s, a) 在第N 试验后的平均等于第N −1 试验后的平均加上一个增量。更一般性地，我们将权重系数 1 改为一个比较小的正数 α。这样每次采N用一个新的轨迹τ，就可以更新Qˆπ (s, a)。s =s,a =a00Qˆπ (s, a) ← Qˆπ (s, a) + α G(τ) − Qˆπ (s, a) ,(14.36)s =s,a =a00其中增量δ实回报 G(τ,G(τ) − Qˆπ (s, a) 称为蒙特卡罗误差，表示当前轨迹的真s =s,a =a00) 与期望回报Qˆπ (s, a) 之间的差距。s =s,a =a00在公式（14.36）中，G(τ)为一次试验的完整轨迹所得到的总回报。s =s,a =a00为了提高效率，可以借助动态规划的方法来计算G(τ)，而不需要得到完整s =s,a =a00的轨迹。从s, a 开始，采样下一步的状态和动作(s′, a′)，并得到奖励r(s, a, s′)，然贝 尔 曼 方 程 参 见 公 式后利用贝尔曼方程来近似估计G(τ )，s =s,a =a00(14.21)。G(τ) = r(s, a, s′) + γG(τ)s =s′,a =a′0 0(14.37)(14.38)s =s,a =a,s =s′,a =a′0011÷ r(s, a, s′) + γQˆπ (s′, a′),其中Q ( , a ) 是当前的Q 函数的近似估计。ˆπ s′′参见习题14-3。结合公式(14.36) 和 (14.38)，有Qˆπ (s, a) ← Qˆπ (s, a) + α r(s, a, s′) + γQˆπ (s′, a′) − Qˆπ (s, a) ,(14.39)因此，更新Q ( a) 只需要知道当前状态 和动作a、奖励 ( a, s′)、下一步的状 态 s′ 和 动 作 a′。这种策略学习方法称为SARSA 算法（State Action RewardState Action，SARSA）[Rummery and Niranjan, 1994]。ˆπ s,sr s,SARSA算法14.3所示，其采样和优化的策略都是πϵ，因此是一种同策略算法。为了提高计算效率，我们不需要对环境中所有的s, a 组合进行穷举，并计算值函数。只需要将当前的探索(s, a, r, s′, a′) 中s′, a′ 作为下一次估计的起始状态邱锡鹏：《神经网络与深度学习》https://nndl.github.io/
 14.2 基于值函数的学习方法2019 年 4 月 6 日351和动作。算法 14.3: SARSA：一种同策略的时序差分学习算法输入: 状态空间S，动作空间A，折扣率γ，学习率α1 随机初始化Q(s, a);2 ∀s, ∀a, π(a|s) =1 ;|A|3 repeat4567初始化起始状态s;选择动作a = πϵ(s);repeat执行动作a，得到即时奖励r 和新状态s′;在状态s′，选择动作a′ = πϵ(s′);89Q(s, a) ← Q(s, a) + α r + γQ(sꢀ, a ) − Q(s, a) ;ꢀ101112更新策略：π(s) = arg maxa∈|A| Q(s, a);s ← s′, a ← a′;until s 为终止状态;13 until ∀s, a，Q(s, a) 收敛;输出: 策略π(s)时序差分学习是强化学习的主要学习方法，其关键步骤就是在每次迭代中优化Q 函数来减少现实 r + γQ(s′, a′) 和预期 Q(s, a) 的差距。这和动物学习的机制十分相像。在大脑神经元中，多巴胺的释放机制和时序差分学习十分吻合。Schultz [1998] 的一个实验中，通过监测猴子大脑释放的多巴胺浓度，发现如果猴子获得比预期更多的果汁，或者在没有预想到的时间喝到果汁, 多巴胺释放大增。如果本来预期的果汁没有喝到，多巴胺的释放就会大减。多巴胺的释放, 来自对于实际奖励和预期奖励的差异，而不是奖励本身。多巴胺是一种神经传导物质，传递开心、兴奋有关的信息。时序差分学习和蒙特卡罗方法的主要不同为：蒙特卡罗需要完整一个路径完成才能知道其总回报，也不依赖马尔可夫性质；而时序差分学习只需要一步，其总回报需要依赖马尔可夫性质来进行近似估计。14.2.3.1 Q 学习Q 学习（Q-Learning）算法[Watkins and Dayan, 1992] 是一种异策略的时序差分学习算法。在Q 学习中，Q 函数的估计方法为事实上，Q 学习算法被提出的时间更早，SARSA算法是Q 学习算法的改进。Q(s, a) ← Q(s, a) + α r + γ maax Q(s′, a′) − Q(s, a) ,相当于让Q(s, a) 直接去估计最优状态值函数Q∗(s, a)。(14.40)与 SARSA 算法的不同，Q 学习算法不通过πϵ 来选下一步的动作a′，而是直接选最优的Q函数，因此更新后的Q函数是关于策略π 的，而不是策略πϵ 的。邱锡鹏：《神经网络与深度学习》https://nndl.github.io/
 3522019 年 4 月 6 日第14 章 深度强化学习Q 学习算法14.4所示。算法 14.4: Q 学习：一种异策略的时序差分学习算法输入: 状态空间S，动作空间A，折扣率γ，学习率α1 随机初始化Q(s, a);2 ∀s, ∀a, π(a|s) =1 ;|A|3 repeat4567初始化起始状态s;repeat在状态s，选择动作a = πϵ(s);执行动作a，得到即时奖励r 和新状态s′;8Q(s, a) ← Q(s, a) + α r + γ maxa′ Q(sꢀ, a ) − Q(s, a) ;ꢀ9s ← s′;10until s 为终止状态;11 until ∀s, a，Q(s, a) 收敛;输出: 策略 π(s) = arg maxa∈|A| Q(s, a)14.2.4 深度Q 网络为了在连续的状态和动作空间中计算值函数 Qπ(s, a)，我们可以用一个函数 Qϕ(s, a) 来表示近似计算，称为值函数近似（value function approximation）。Qϕ(s, a) ≈ Qπ(s, a),(14.41)其中s, a 分别是状态s 和动作a 的向量表示；函数Qϕ(s, a) 通常是一个参数为ϕ的函数，比如神经网络，输出为一个实数，称为Q 网络（Q-network）。如果动作为有限离散的m 个动作a , · · · , a ，我们可以让Q 网络输出一个1mm 维向量，其中每一维用Q (s, a ) 来表示，对应值函数Q(s, a ) 的近似值。ϕiiQ (s, a )Qπ (s, a1)ϕ1Qϕ(s) =≈.(14.42)..Q (s, a )Qπ (s, am )ϕm我们需要学习一个参数ϕ 来使得函数Qϕ(s, a) 可以逼近值函数Qπ(s, a)。如果采用蒙特卡罗方法，就直接让Qϕ(s, a) 去逼近平均的总回报Qˆπ (s, a)；如果采样时序差分方法，就让Qϕ(s, a) 去逼近Es′,a′ [r + γQϕ(s′, a′)]。邱锡鹏：《神经网络与深度学习》https://nndl.github.io/
 14.2 基于值函数的学习方法2019 年 4 月 6 日353以 Q 学习为例，采用随机梯度下降，目标函数为2L (s, a, s′|ϕ ) = r + γ max Q (s′, a′) − Q(s, a)(14.43),ϕϕa′其中s′, a′ 是下一时刻的状态s′ 和动作a′ 的向量表示。然而，这个目标函数存在两个问题：一是目标不稳定，参数学习的目标依赖 于参数本身；二是样本之间有很强的相关性。为了解决这两个问题，Mnih et al.[2015] 提出了一种深度Q 网络（deep Q-networks，DQN）。深度Q 网络采取两个措施：一是目标网络冻结（freezing target networks），即在一个时间段内固定目标中的参数，来稳定学习目标；二是经验回放（experience replay），构建一个经验池来去除数据相关性。经验池是由智能体最近的经历组成的数据集。经验回放可以形象地理解为在回忆中学习。训练时，随机从经验池中抽取样本来来代替当前的样本用来进行训练。这样，也可以就打破了和相邻训练样本的相似性，避免模型陷入局部最优。经验回放在一定程度上类似于监督学习。先收集样本，然后在这些样本上进行训练。深度Q网络的学习过程如算法14.5所示。算法 14.5: 带经验回放的深度Q 网络输入: 状态空间S，动作空间A，折扣率γ，学习率α1初始化经验池D，容量为N ;2 随机初始化Q 网络的参数ϕ;3 随机初始化目标Q 网络的参数ϕ = ϕ;ˆ4 repeat5678初始化起始状态s;repeat在状态s，选择动作a = πϵ;执行动作a，观测环境，得到即时奖励r 和新的状态s′;9将 s, a, r, s′ 放 入 D 中;10从 D 中采样ss, aa, rr, ss′;rr,ssꢀ为终止状态, ;否则11y =rr + γ maxa′ Q (ss , a ),ꢀꢀˆϕ2121314以 y − Qϕ (ss, aa)s ← s′;为损失函数来训练Q 网络;ˆ每隔C 步，ϕ ← ϕ;15until s 为终止状态;16 until ∀s, a，Qϕ(s, a) 收敛;输出: Q 网络Qϕ(s, a)整体上，在基于值函数的学习方法中，策略一般为确定性的策略。策略优邱锡鹏：《神经网络与深度学习》 https://nndl.github.io/
 

 14.3 基于策略函数的学习方法2019 年 4 月 6 日353化通常都依赖于值函数，比如贪心策略 π(s) = arg maxa Q(s, a)。最优策略一般需要遍历当前状态s 下的所有动作，并找出最优的Q(s, a)。如果动作空间离散但是很大时，那么遍历求最大需要很高的时间复杂度；如果动作空间是连续的并且Q(s, a)非凸时，也很难求解出最佳的策略。14.3 基于策略函数的学习方法强化学习的目标是学习到一个策略πθ(a|s)来最大化期望回报。一种直接的方法是在策略空间直接搜索来得到最佳策略，称为策略搜索（policy search）。策略搜索本质是一个优化问题，可以分为基于梯度的优化和无梯度优化。策略搜索和基于值函数的方法相比，策略搜索可以不需要值函数，直接优化策略。参数化的策略能够处理连续状态和动作，可以直接学出随机性策略。策略梯度（policy gradient）是一种基于梯度的强化学习方法。假设πθ(a|s)是一个关于 θ 的连续可微函数，我们可以用梯度上升的方法来优化参数 θ 使得目标函数J (θ) 最大。目 标 函 数 J (θ) 参 见 公 式(14.11)。目标函数J (θ) 关于策略参数θ 的导数为∫∂J (θ)∂θ∂===pθ(τ)G(τ)dτ(14.44)(14.45)(14.46)(14.47)(14.48)∂θ∫∂∂θp θ(τ) G(τ)dτ∫1∂p θ(τ)p θ(τ) G(τ)dτpθ(τ ) ∂θ∫=p θ(τ) ∂∂θlog p θ(τ) G(τ)dτ∂= Elog p (τθ)G(τ) ,∂θτ∼pθ(τ)其中 ∂ log p (τ ) 为函数log p (τ ) 关于θ 的偏导数。从公式(14.48) 中可以看出， 参∂θθθ数θ 优化的方向是使得总回报G(τ) 越大的轨迹τ 的概率pθ(τ) 也越大。∂ log pθ(τ)可以进一步分解为∂θ!TY−1∂∂θ∂∂θlog pθ(τ ) =log p(s0 )π ( a |s ) p( s |s , a )(14.49)θttt+1ttt=0!Σ∂T −1=logp(s0 ) +log π (a |s ) + log p(s |s , a ) (14.50)θ t t t+1 t t∂θt=0T −1Σ∂=log π (a |s ).(14.51)θt t∂θt=0可以看出，∂∂θlog pθ(τ) 是和状态转移概率无关，只和策略函数相关。邱锡鹏：《神经网络与深度学习》https://nndl.github.io/
 3542019 年 4 月 6 日因此，策略梯度 ∂J第14 章 深度强化学习(θ) 可写为∂θ"!#ΣT −1 ∂∂θt=0∂J (θ)∂θΣT −1=Eτ ∼pθ(τ )log π (a s ) G(τ )|!(14.52)θttG(τ) =γtrt+1"t=0Σlog π (a |s )#T −1 ∂G(τ) + γtG(τ(14.53)(14.54)E==∂θτ∼pθ(τ )θtt0:t−1t:T )t=0"#ΣT −1∂Elogπθ( a |s γ G τ)t()参见习题14-5。,τ ∼pθ(τ )ttt:T∂θt=0其中G(τt:T ) 为从时刻t 作为起始时刻收到总回报ΣT −1G(τt:T ) =γ t− trt′+1.(14.55)t′=t14.3.1 REINFORCE 算法公式(14.54)中，期望可以通过采样的方法来近似。对当前策略π ，可以随机θ游走采集多个轨迹τ(1), τ(2), · · · , τ( ，每一条轨迹τ(n) =N )(n) (n) (n) (n), a , s , a , · · · ,，s0011其梯度定义为!Σ Σ∂J (θ)∂θT −1N1N∂≈log πθ(at |s )γt Gτ (n)t:T(n) (n).(14.56)t∂θn=1 t=0结合随机梯度上升算法，我们可以每次采集一条轨迹，计算每个时刻的梯度并更新参数，称为REINFORCE算法[Williams, 1992]，如算法14.6所示。算法 14.6: REINFORCE 算法输入: 状态空间S，动作空间A，可微分的策略函数πθ(a|s)，折扣率γ，学习率α;1 随机初始化参数θ;2 repeat3根据策略πθ(a|s) 生成一条轨迹τ = s , a , s , a , · · · , sT −1, aT −1, sT ;001145for t=0 to T do计算G(τt:T );// 更新策略函数参数67θ ← θ + αγtG(τt:Tend) ∂ log π (a |s );θ t t∂θ8 until θ 收敛;输出: 策略πθ邱锡鹏：《神经网络与深度学习》https://nndl.github.io/
 14.3 基于策略函数的学习方法2019 年 4 月 6 日35514.3.2 带基准线的REINFORCE 算法REINFORCE 算法的一个主要缺点是不同路径之间的方差很大，导致训练不稳定，这是在高维空间中使用蒙特卡罗方法的的通病。一种减少方差的通用方法是引入一个控制变量。假设要估计函数f 的期望，为了减少f 的方差，我们引入一个已知期望的函数g，令ˆf =f −−α(g E[g]).(14.57)因为E[f ] = [ ]，我们可以用 的期望来估计函数 的期望，同时利用函数gˆE ffˆfˆ来减小f 的方差。函数fˆ的方差为ˆvar(f ) = var(f) − 2α cov(f, g) + α2 var(g),(14.58)(14.59)其中var(·), cov(·, ·)分别表示方差和协方差。ˆˆ)如果要使得var(f )最小，令 ∂var(f = 0，得到∂αcov(f, g)α =.var(g)因此，cov(f, g)2var(g) var(f)var(fˆ) = 1−var(f )(14.60)(14.61)=1 − corr(f, g)2 var(f),其中corr(f, g) 为函数f 和g 的相关性。如果相关性越高，则fˆ的方差越小。带基准线的 REINFORCE 算法 在每个时刻t，其策略梯度为∂Jt(θ)∂θ∂∂θ=EstEatγtG(τt:Tπθ(a |st)t.)log(14.62)为了减小策略梯度的方差，我们引入一个和a 无关的基准函数b(s )，tt∂J (θ)ˆ∂∂θt= Est Eat γt G(τt:T ) − b s( )πa |s t)t.log(θ(14.63)t∂θ因为b(s ) 和a 无关，有tt∫∂∂∂θEb(st )log π (a |s ) =(14.64)(14.65)(14.66)(14.67)atθttb(st) log π (a |s ) π (a |s )daθttθttt∂θ∫at∂==b(st) π (a |s ))datθtt∫∂θat∂∂θ∂∂θ∫b(st) π (a |s ))daπ (a |s )da = 1θ t t tθtttatat=b(s t) · 1 = 0.邱锡鹏：《神经网络与深度学习》https://nndl.github.io/
 3562019 年 4 月 6 日第14 章 深度强化学习∂J (θ)∂J (θ)∂θˆtt因此，=。∂θ为了可以有效地减小方差，b(st) 和G(τt:T )越相关越好，一个很自然的选择是令b(s ) 为值函数V π (s )。但是由于值函数未知，我们可以用一个可学习的θtt函数V (s ) 来近似值函数，目标函数为ϕtL(ϕ|s , π ) = V πθ (s ) − V (s ),2(14.68)tθtϕt其中V[ 也用蒙特卡罗方法进行估计。采用随机梯度下降法，π (s ) = E G(τ )]t t:Tθ参数ϕ 的梯度为∂L(ϕ|s , π )∂V (s )tθ− G(τ−ϕt=)V (s ).(14.69)(14.70)t:Tϕt∂ϕ∂ϕ策略函数参数θ 的梯度为∂J (θ)ˆ∂t= Est Eat γt G(τt:T ) − V(s )π(a |sθ.logt)ϕtt∂θ∂θ算法14.7给出了带基准线的REINFORCE 算法的训练过程。算法 14.7: 带基准线的REINFORCE 算法输入: 状态空间S，动作空间A，可微分的策略函数πθ(a|s)，可微分的状态值函数Vϕ(s)，折扣率γ，学习率α，β;1 随机初始化参数θ,ϕ;2 repeat3根据策略πθ(a|s) 生成一条轨迹τ = s , a , s , a , · · · , sT −1, aT −1, sT ;0011456for t=0 to T do计算G(τt:T );δ ← G(τt:T ) − V (s );ϕt// 更新值函数参数ϕ ← ϕ + βδ∂ϕ// 更新策略函数参数θ ← θ + αγ∂ V (s );7ϕt89tδ ∂ log π (a |s );endθtt∂θ10 until θ 收敛;输出: 策略πθ14.4 Actor-Critic 算法在REINFORCE算法中，每次需要根据一个策略采集一条完整的轨迹，并计算这条轨迹上的回报。这种采样方式的方差比较大，学习效率也比较低。我邱锡鹏：《神经网络与深度学习》https://nndl.github.io/
 14.4 Actor-Critic 算法2019 年 4 月 6 日357们可以借鉴时序差分学习的思想，使用动态规划方法来提高采样的效率，即从参见第14.2.3节。状态开始s 的总回报可以通过当前动作的即时奖励r(s, a, s′) 和下一个状态s′ 的值函数来近似估计。演员-评论员算法（Actor-Critic Algorithm）是一种结合策略梯度和时序差分学习的强化学习方法。其中演员（actor）是指策略函数πθ(s, a)，即学习一个策略来得到尽量高的回报，评论员（critic）是指值函数Vϕ(s)，对当前策略的值函数进行估计，即评估actor 的好坏。借助于值函数，Actor-Critic 算法可以进行单步更新参数，不需要等到回合结束才进行更新。在 Actor-Critic 算法中的策略函数π (s, a) 和值函数V (s) 都是待学习的函θϕ数，需要在训练过程中同时学习。假设从时刻t 开始的回报G(τt:T )，我们用下面公式近似计算。Gˆ(τt:T ) = rt+1 + γVϕ(st+1),(14.71)其中st+1 是 t + 1 时刻的状态，rt+1 是即时奖励。在每步更新中，分别进行策略函数π (s, a)和值函数V (s)的学习。一方面，θϕ更新参数ϕ使得值函数V (s ) 接近于估计的真实回报G(τ )，ˆϕtt:T2minϕGˆ(τ)− V (s ),(14.72)t:Tϕt另一方面，将值函数V (s ) 作为基函数来更新参数θ，减少策略梯度的方差。ϕt∂∂θθ ← θ + αγt Gˆ(τ) − V (s )log π (a |s ).(14.73)t:Tϕtθt t在每步更新中，演员根据当前的环境状态s和策略πθ(a|s)去执行动作a，环境状态变为s′，并得到即时奖励r。评论员（值函数Vϕ(s)）根据环境给出的真 实奖励和之前标准下的打分(r + γVϕ(s′))，来调整自己的打分标准，使得自己的评分更接近环境的真实回报。演员则跟据评论员的打分，调整自己的策略πθ， 争取下次做得更好。开始训练时，演员随机表演，评论员随机打分。通过不断的学习，评论员的评分越来越准，演员的动作越来越好。邱锡鹏：《神经网络与深度学习》https://nndl.github.io/
 3582019 年 4 月 6 日第14 章 深度强化学习算法14.8给出了actor-critic 算法的训练过程。算法 14.8: actor-critic 算法输入: 状态空间S，动作空间A;可微分的策略函数πθ(a|s);可微分的状态值函数Vϕ(s);折扣率γ，学习率α > 0,β > 0;1 随机初始化参数θ,ϕ;2 repeat345初始化起始状态s;λ = 1;repeat67在状态s，选择动作a = πθ(a|s);执行动作a，得到即时奖励r 和新状态s′;δ ← r + γVϕ(s′) − Vϕ(s);89ϕ ← ϕ + βδθ ← θ + αλδλ ← γλ;∂ Vϕ(s);∂ϕ∂ log πθ(a|s);101112∂θs ← s′;13until s 为终止状态;14 until θ 收敛;输出: 策略πθ虽然在带基准线的REINFORCE 算法也同时学习策略函数和值函数，但是它并不是一种Actor-Critic 算法。因为其中值函数只是用作基线函数以减少方差，并不用来估计回报（即评论员的角色）。14.5 总结和深入阅读强化学习是一种十分吸引人的机器学习方法，通过智能体不断与环境进行交互，并根据经验调整其策略来最大化其长远的所有奖励的累积值。强化学习更接近生物学习的本质，可以应对多种复杂的场景，而从更接近通用人工智能系统的目标。强化学习和监督学习的区别在于：（1）强化学习的样本通过不同与环境进行交互产生，即试错学习，而监督学习的样本由人工收集并标注；（2）强化学习的反馈信息只有奖励，并且是延迟的；而监督学习需要明确的指导信息（每一个状态对应的动作）。现代强化学习可以追溯到两个来源：一个是心理学中的行为主义理论，即邱锡鹏：《神经网络与深度学习》https://nndl.github.io/
 14.5 总结和深入阅读2019 年 4 月 6 日359有机体如何在环境给予的奖励或惩罚的刺激下，逐步形成对刺激的预期，产生能获得最大利益的习惯性行为；另一个是控制论领域的最优控制问题，即在满足一定约束条件下，寻求最优控制策略，使得性能指标取极大值或极小值。强化学习的算法非常多，大体上可以分为基于值函数的方法（包括动态规划、时序差分学习等）、基于策略函数的方法（包括策略梯度等）以及融合两者的方法。不同算法之间的关系如图14.4所示。邱锡鹏：《神经网络与深度学习》https://nndl.github.io/
 强化学习3602019 年 4 月 6 日值函数估计第14 章 深度强化学习策略搜索无梯度方法策略梯度蒙特卡罗动态规划策略迭代值迭代REINFORCE时序差分学习SARSAQ 学习actor-critic 算法邱锡鹏：《神经网络与深度学习》https://nndl.github.io/
 14.5 总结和深入阅读2019 年 4 月 6 日361图 14.4 不同强化学习算法之间的关系一般而言，基于值函数的方法策略更新时可能会导致值函数的改变比较大，对收敛性有一定影响，而基于策略函数的方法在策略更新时更加更平稳些。但后者因为策略函数的解空间比较大，难以进行充分的采样，导致方差较大，并容易收敛到局部最优解。Actor-Critic 算法通过融合两种方法，取长补短，有着更好的收敛性。这些不同的强化学习算法的优化步骤都可以分为三步：（1）执行策略，生成样本；（2）估计回报；（3）更新策略。表14.1给出了四种典型的强化学习算法（SARSA、Q 学习、REINFORCE、Actor-Critic 算法）的比较。强化学习的主要参考文献为Sutton and Barto [2018] 的《ReinforcementLearning: An Antroduction》。和深度强化学习方面，DeepMind 的 [Mnih et al., 2015] 在 2013 年提出了第一个强化学习和深度学习结合的模型，深度 Q 网络（DQN）。虽然DQN 模型相对比较简单，只是面向有限的动作空间，但依然在Atari 游戏上取了很大的成功，取得了超越人类水平的成绩。之后，深度强化学习开始快速发展。一些基于DQN 的改进包括双Q 网络[Van Hasselt et al., 2016]、优先级经验回放[Schaul邱锡鹏：《神经网络与深度学习》https://nndl.github.io/
 3622019 年 4 月 6 日第14 章 深度强化学习算法步骤（1）执行策略，生成样本：s, a, r, s, aQ(s, a) ← Q(s, a) + α r + γQ(s , a ) − Q(s, a)ꢀꢀSARSA（2）估计回报：ꢀꢀ（3）更新策略：π(s) = arg maxa∈|ꢀ| Q(s, a)（1） 执行策略，生成样本：s, a, r, sꢀQ 学习（2） 估计回报：Q(s, a) ← Q(s, a) + α r + γ maxa′ Q(s , a ) − Q(s, a)ꢀꢀ（3）更新策略：π(s) = arg maxa∈|ꢀ| Q(s, a)（1）执行策略，生成样本：τ = s , a , s , a , · · ·0011T −1ΣREINFORCE（2）估计回报：G(τ) = rt+1t=0ΣT −1t=0（3） 更新策略：θ ← θ +∂ log π (a |s )γtG(τ)θttt:T∂θ（1）执行策略，生成样本：s, a, s, rꢀG(s) = r + γV (s )Actor-Critic （2）估计回报：ϕꢀϕ ← ϕ + β G(s) − Vϕ(s) ∂ V (s)ϕ∂ϕ（3）更新策略：λ ← γλθ ← θ + αλ G(s) − Vϕ(s) ∂ log π (a|s)θ∂θ表 14.1 四种强化学习算法的比较et al., 2015]、决斗网络[Wang et al., 2015] 等。目前，深度强化学习更多是同时使用策略网络和值网络来近似策略函数和值函数。在actor-critic 算法的基础上，Silver et al. [2014] 将策略梯度的思想推广到确定性的策略上，提出了确定性策略梯度（Deterministic Policy Gradient，DPG）算法。策略函数为状态到动作的映射 a = πθ(s)。采用确定性策略的一个好处是方差会变得很小，提高收敛性。确定性策略的缺点是对环境的探索不足，可以通过异策略的方法解决。Lillicrap et al. [2015] 进一步在DPG 算法的基础上，利用DQN 来估计值函数，提出深度确定性策略梯度（Deep Determin- isticPolicy Gradient，DDPG）算法。DDPG 算法可以适合连续的状态和动作空间。Mnih et al. [2016] 利用分布式计算的思想提出了异步优势的演员-评论员（Asynchronous Advantage Actor-Critic，A3C）算法。在A3C 算法中，有多个并行的环境，每个环境中都有一个智能体执行各自的动作和并计算累计的参数梯度。在一定步数后进行累计，利用累计的参数梯度去更新所有智能体共享的全局参数。因为不同环境中的智能体可以使用不同的探索策略，会导致经验样邱锡鹏：《神经网络与深度学习》https://nndl.github.io/
 14.5 总结和深入阅读2019 年 4 月 6 日363本之间的相关性较小，可以提高学习效率。除了本章中介绍的标准强化学习之外，还存在一些更加泛化的强化学习问题。部分可观测马尔可夫决策过程 部分可观测马尔可夫决策过程（Partially Ob-servable Markov Decision Processes，POMDP）是一个马尔可夫决策过程的泛化。POMDP依然具有马尔可夫性，但是假设智能体无法感知环境的状态s，只能知道部分观测值o。比如在自动驾驶中，智能体只能感知传感器采集的有限的 环境信息。POMDP 可以用一个7 元组描述：(S, A, T, ꢀ, Ω, O, γ)，其中S 表示状态空间，为隐变量，A 为动作空间，T (s′|s, a)为状态转移概率，ꢀ 为奖励函数，Ω(o|s, a)为观测概率，O 为观测空间，γ 为折扣系数。逆向强化学习 强化学习的基础是智能体可以和环境进行交互，得到奖励。但在某些情况下，智能体无法从环境得到奖励，只有一组轨迹示例（demonstration）。比如在自动驾驶中，我们可以得到司机的一组轨迹数据，但并不知道司机在每个时刻得到的即时奖励。虽然我们可以用监督学习来解决，称为行为克隆。但行为克隆只是学习司机的行为，并没有深究司机行为的动机。逆向强化学习（Inverse Reinforcement Learning，IRL）就是指一个不带奖励的马尔可夫决策过程，通过给定的一组专家（或教师）的行为轨迹示例来逆向估计出奖励函数r(s, a, s′) 来解释专家的行为，然后再进行强化学习。分层强化学习 分层强化学习（Hierarchical Reinforcement Learning，HRL）是指将一个复杂的强化学习问题分解成多个小的、简单的子问题[Barto and Ma-hadevan, 2003]，每个子问题都可以单独用马尔可夫决策过程来建模。这样，我们可以将智能体的策略分为高层次策略和低层次策略，高层次策略根据当前状态决定如何执行低层次策略。这样，智能体就可以解决一些非常复杂的任务。习题习题 14-1 证明公式(14.25)。习题 14-2 证明公式(14.27) 和 (14.28) 会收敛到最优解。习题 14-3 比较证明公式(14.21) 和 (14.38) 的不同之处。邱锡鹏：《神经网络与深度学习》https://nndl.github.io/
 3622019 年 4 月 6 日参考文献习题 14-4 分析SARSA 算法和Q 学习算法的不同。习题 14-5 证明公式(14.54)。参考文献Andrew G Barto and Sridhar Mahadevan.Recent advances in hierarchical reinforce-ment learning. Discrete Event DynamicSystems, 13(4):341–379, 2003.tems, volume 37. University of Cambridge,Department of Engineering, 1994.Tom Schaul, John Quan, IoannisAntonoglou, and David Silver. Priori-tized experience replay. arXiv preprintarXiv:1511.05952, 2015.Ronen I Brafman and Moshe Tennenholtz.R-max – a general polynomial time algo-rithm for near-optimal reinforcement learn-ing. Journal of Machine Learning Research,3(Oct):213–231, 2002.Wolfram Schultz. Predictive reward signalof dopamine neurons. Journal of neurophys-iology, 80(1):1–27, 1998.TimothyPLillicrap, JonathanJHunt,David Silver, Guy Lever, Nicolas Heess,Thomas Degris, Daan Wierstra, and Mar-tin Riedmiller. Deterministic policy gra-dient algorithms. In Proceedings of Inter-national Conference on Machine Learning,pages 387–395, 2014.Alexander Pritzel, Nicolas Heess, TomErez, Yuval Tassa, David Silver, and DaanWierstra. Continuous control with deepreinforcement learning. arXiv preprintarXiv:1509.02971, 2015.Marvin Minsky. Steps toward artiﬁcial in-telligence. Computers and thought, 406:450,1963.Richard S Sutton and Andrew G Barto.Reinforcement learning: An introduction.MIT press, 2018.Volodymyr Mnih, Koray Kavukcuoglu,David Silver, Andrei A Rusu, Joel Veness,Marc G Bellemare, Alex Graves, MartinRiedmiller, Andreas K Fidjeland, Georg Os-trovski, et al. Human-level control throughdeep reinforcement learning. Nature, 518(7540):529–533, 2015.Hado Van Hasselt, Arthur Guez, and DavidSilver. Deep reinforcement learning withdouble q-learning. In AAAI, pages 2094–2100, 2016.Ziyu Wang, Tom Schaul, Matteo Hessel,Hado Van Hasselt, Marc Lanctot, andNando De Freitas. Dueling network ar-chitectures for deep reinforcement learning.arXiv preprint arXiv:1511.06581, 2015.Christopher JCH Watkins and Peter Dayan.Q-learning. Machine learning, 8(3):279–292, 1992.Volodymyr Mnih, Adria Puigdomenech Ba-dia, Mehdi Mirza, Alex Graves, TimothyLillicrap, Tim Harley, David Silver, and Ko-ray Kavukcuoglu. Asynchronous methodsfor deep reinforcement learning. In Proceed-ings of International Conference on Ma-chine Learning, pages 1928–1937, 2016.Gavin A Rummery and Mahesan Niranjan.On-line Q-learning using connectionist sys-RonaldJWilliams. Simple statisticalgradient-following algorithms for connec-tionist reinforcement learning. Machinelearning, 8(3-4):229–256, 1992.邱锡鹏：《神经网络与深度学习》https://nndl.github.io/
 第 15 章 序列生成模型人类语言似乎是一种独特的现象，在动物世界中没有显著类似的存在。— 诺姆·乔姆斯基在深度学习的应用中，有很多数据是以序列的形式存在，比如声音、语言、视频、DNA 序列或者其它的时序数据等。以自然语言为例，一个句子可以看做是符合一定自然语言规则的词（word）的序列。这些语言规则包含非常复杂的语法和语义的组合关系，很难显式地建模这些规则。在认知心理学上有一个经典的实验，当一个人看到下面两个句子：这里假定语言的最基本单位为词（word），当然也可以为字或字母（character）。面包上涂黄油面包上涂袜子后一个句子在人脑的语义整合时需要更多的处理时间，更不符合自然语言规则。从统计的角度来看，这些语言规则可以看成是一种概率分布。一个长度为T 的文本序列看作一个随机事件X1:T = ⟨X , · · · , X ⟩，其中每个位置上的变量X1Tt的样本空间为一个给定的词表（vocabulary）V，整个序列 x1:T 的样本空间为|V|T 。在某种程度上，自然语言也确实有很多随机因素。比如当我们称赞一个人漂亮时，可以说“美丽”，“帅”或者“好看”等。当不指定使用场合时，这几个词可以交替使用，具体使用哪个词可以看作一个随机事件。给定一个序列样本x1:T = x , x , · · · , x ，其概率可以看出是T 个词的联合12T概率。在本章中，我们用Xt 表示位置 t 上的随机变量，x1:T表P (X1:T = x1:T ) = P (X = x , X = x , · · · , X = x )(15.1)1122TT示一个序列样本，xt 来表示= p(x1:T ).(15.2) 一个序列样本在位置 t 上的值。和一般的概率模型类似，序列概率模型有两个基本问题：（1）学习问题：给
 3642019 年 4 月 6 日第 15 章 序列生成模型定一组序列数据，估计这些数据背后的概率分布；（2）生成问题：从已知的序列分布中生成新的序列样本。序列数据一般可以通过概率图模型来建模序列中不同变量之间的依赖关系，本章主要介绍在序列数据上经常使用的一种模型：自回归生成模型（AutoregressiveGenerative Model）。不失一般性，本章以自然语言为例来介绍序列概率模型。15.1 序列概率模型序列数据有两个特点：（1）样本是变长的；（2）样本空间为非常大。对于一个长度为T 的序列，其样本空间为|V|T 。因此，我们很难用已知的概率模型来直接建模整个序列的概率。根据概率的乘法公式，序列x1:T 的概率可以写为p(x1:T ) = p(x )p(x |x )p(x |x ) · · · p(x |x1:(T −1))(15.3)(15.4)12131:2T=YT p(xt x| 1:(t−1)),t=1其中x ∈ V, t ∈ [1, T ] 为词表V 中的一个词，p(x |x ) = p(x )。t101因此，序列数据的概率密度估计问题可以转换为单变量的条件概率估计问题，即给定x1:(t−1) 时 x 的条件概率p(x |x1:(t−1))。tt}N给定N 个序列数据{x(n) n=1，序列概率模型需要学习一个模型pθ(x|x1:(t−1))1:Tn来最大化整个数据集的对数似然函数。NNTnΣΣ Σ(n)|xxt(n).1:(t−1)(15.5)maxθlog p x(n) = maxlogpθθ1:Tnθn=1n=1 t=1在这种序列模型方式中，每一步都需要将前面的输出作为当前步的输入，是 一种自回归（autoregressive）的方式。因此这一类模型也称为自回归生成模型（Autoregressive Generative Model）。自回归模型参见第6.1.2节。多项分布参见第D.2.2.2节。由于X ∈ V 为离散变量，我们可以假设条件概率p (x |x1:(t−1)) 服从多项分布，tθt然后通过不同的模型来估计。本章主要介绍两种比较主流的模型：N 元统计模型和深度序列模型。N 元统计模型参见第15.2节。深度序列模型参见第15.3节。15.1.1 序列生成一旦通过最大似然估计训练了模型pθ(x|x1:(t−1))，就可以通过时间顺序来 生成一个完整的为在第t 时根据分布pθ(x|xˆ1:(t−1)) 生成的词，序列样本。令ˆtxˆ ∼ p (x|xˆ1:(t−1)),(15.6)tθ邱锡鹏：《神经网络与深度学习》https://nndl.github.io/
 15.1 序列概率模型2019 年 4 月 6 日365其中xˆ1:(t−1) = xˆ1, ∙∙∙∙∙, xˆt−1 为前面t − 1 步中生成的前缀序列。自回归的方式可以生成一个无限长度的序列。为了避免这种情况，通常会设置一个特殊的符号“<eos>”来表示序列的结束。在训练时，每个序列样本的结尾都加上符号“<eos>”。在测试时，一旦生成了符号“<eos>”，就中止生成过程。束搜索 当使用自回归模型生成一个最可能的序列时，生成过程是一种从左到右的贪婪式搜索过程。在每一步都生成最可能的词，xˆ = arg max p (x xˆ1:(t−1)),(15.7)|tθx∈V其中xˆ1:(t−1) = xˆ1, ∙∙∙∙∙, xˆt−1 为前面t − 1 步中生成的前缀序列。这种贪婪式的搜索方式是次优的，生成的序列xˆ1:T 并不保证是全局最优的。TTYYmax p (x |xˆ1:(t−1)) ≤ maxpθ(x|x1:(t−1)).(15.8)θtx ∈Vtx∈V T1:Tt=1t=1一种常用的减少搜索错误的启发式方法是束搜索（Beam Search）。在每一步的生成中，生成K 个最可能的前缀序列，其中K 为束的大小（Beam Size），是一个超参数。束搜索的过程如下：在第1步时，生成K 个最可能的词。在后面每一步中，从K|V| 个候选输出中选择K 个最可能的序列。图15.1给出了一个束搜索过程的示例，其中词表 V = {A, B, C}，束大小为 2。参见习题15-5。t=1t=2At=3AABCBBAABCBACCϕAABBCC图 15.1 束搜索过程示例束搜索可以通过调整束大小K 来平衡计算复杂度和搜索质量之间的优先级。邱锡鹏：《神经网络与深度学习》https://nndl.github.io/
 3662019 年 4 月 6 日第 15 章 序列生成模型15.2 N 元统计模型由于数据稀疏问题，当t 比较大时，依然很难估计条件概率p(xt|x1:(t−1))。一个只依赖于其前面的n − 1 个词（n 阶马尔简化的方法是N元模型（N-Gram Model），假设每个词xt可夫性质），即马尔可夫性质参见第D.3节。p(xt|x1:(t−1)) = p(xt|x(t−n+1):(t−1)).(15.9)当n = 1时，称为一元（unigram）模型；当n = 2时，称为二元（bigram）模型，以此类推。一元模型 当n = 1时，序列x1:T 中每个词都和其它词独立，和它的上下文无关。每个位置上的词都是从多项分布独立生成的。在多项分布中，θ = [θ1, · · · , θ|V|]为词表中每个词被抽取的概率。多项分布参见第D.2.2.2节。在一元模型中，序列x1:T 的概率可以写为T|V|YYp(x1:T |θ) =p(xt) =θm ,(15.10)kkt=1k=1其中m 为词表中第k 个词v 在序列中出现的次数。公式(15.10)和标准多项分kk布的区别是没有多项式系数，因为这里词的顺序是给定的。给定一组训练集{x(n)1:Tn }N ，其对数似然函数为：′n=1Y N ′log|V||θ =k=1(n)1:Tmk(15.11)(15.12)knn=1p xogθΣ|V|=m log θ ,k kk=1其中mk 为第k 个词在整个训练集中出现的次数。这样一元模型的最大似然估计可以转化为约束优化问题：Σ|V|maxmk log θkθk = 1.(15.13)(15.14)θk=1Σ|V|subjuct tok=1拉格朗日乘子参见第C.3节。引入拉格朗日乘子λ，定义拉格朗日函数Λ(θ, λ) 为ΣΣ|V||V|θk − 1 .Λ(θ, λ) =m log θ + λ (15.15)kkk=1k=1邱锡鹏：《神经网络与深度学习》https://nndl.github.io/
 15.2 N 元统计模型2019 年 4 月 6 日367令∂Λ(θ, λ)mk==+ λ = 0,(15.16)(15.17)∂θkθkΣ|V|∂Λ(θ, λ)θk − 1 = 0.∂λk=1ΣV求解上述方程得到 λ = −m ，进一步得到v=1vmmkM L =kθ=,(15.18)Σkm¯V|mkk=1ΣV|其中m¯ =mk 为文档集合的长度。由此可见，最大似然估计等价于频率k=1估计。N 元模型 同理，N 元模型中的条件概率p(xt|x(t−n+1):(t−1)) 也可以通过最大似然函数来得到。参见习题15-1。m x(t−n+1):t(x |x,(15.19)) =pt(t−n+1):(t−1)m xt−n+1):(t−1)(其中m(x(t−n+1):t) 为 x(t−n+1):t 在数据集中出现的次数。元模型广泛应用于各种自然语言处理问题，如语音识别、机器翻译、拼N音输入法，字符识别等。通过N 元模型，我们可以计算一个序列的概率，从而判断该序列是否符合自然语言的语法和语义规则。平滑技术 N 元模型的一个主要问题是数据稀疏问题。数据稀疏问题在基于统计的机器学习中是一个常见的问题，主要是由于训练样本不足而导致密度估计不准确。在一元模型中，如果一个词v 在训练数据集里不存在，就会导致任何包含 v 的句子的概率都为0。同样在N 元模型中，当一个N 元组合在训练数据集中不存在时，包含这个组合的句子的概率为0。数据稀疏问题最直接的解决方法就是增加训练数据集的规模，但其边际效益会随着数据集规模的增加而递减。以自然语言为例，由于大多数自然语言都服从 Zipf 定律。在一个给定自然语言数据集里，一个单词出现的频率与它在频率表里的排名成反比。出现频率最高的单词的出现频率大约是出现频率第二位的单词的2 倍，大约是出现频率第三位的单词的3 倍。因此，在自然语言中大部分的词都是低频词，很难通过增加数据集来避免数据稀疏问题。Zipf 定 律 是 美 国 语 言 学 家George K. Zipf 提出的实验定律。数据稀疏问题的一种解决方法是平滑技术（Smoothing），即给一些没有出现的词组合赋予一定先验概率。平滑技术是N 元模型中的一项必不可少的技术，比如加法平滑的计算公式为：m x(t−n+1):t + δm x(t−n+1):(t−1) + δ|V|p xt|x(t−n+1):(t−1)=,(15.20)邱锡鹏：《神经网络与深度学习》https://nndl.github.io/
 3682019 年 4 月 6 日第 15 章 序列生成模型其中δ ∈ (0, 1] 为常数。δ = 1 时，称为加1 平滑。除了加法平滑，还有很多平滑技术，比如Good-Turing 平滑，Kneser-Ney平滑等，其基本思想都是增加低频词的频率，而降低高频词的频率。参见习题15-2。15.3 深度序列模型深度序列模型（Deep Sequence Model）是指利用神经网络模型来估计条件概率p (x |x1:(t−1))，θt假设一个神经网络f (·, θ)，其输入为历史信息ht = x1:(t−1)，输出为词表V中的每个词vk(1 ≤ k ≤ |V| 出现的概率，并满足Σ|V|fk x1:(t−1), θ = 1,(15.21)k=1其中θ 表示网络参数。条件概率p (x |x1:(t−1) ) 可以从神经网络的输出中得到，θtp (x |x1:(t−1)) = fkxt (x1:(t−1); θ),(15.22)θt其中k 为x 在词表V 中索引。xtt深度序列模型一般可以分为三个部分：嵌入层、特征层、输出层。嵌入层 令ht = x1:(t−1) 表示输入的历史信息，一般为符号序列。由于神经网络模型一般要求输入形式为实数向量，因此为了能够使得神经网络模型能处理符号数据，需要将这些符号转换为向量形式。一种简单的转换方法是通过一个嵌入表（Embedding Lookup Table）来将每个符号直接映射成向量表示。嵌入表也称为嵌入矩阵或查询表。令M ∈ Rd1×|V| 为嵌入矩阵，其中第k 列向量mk ∈ Rd示词表中第k 个词对应的向量表示。表1m 1m 2m 3m km|V|−2 m|V|−1 m |V|图 15.2 嵌入矩阵假设词 x 对应词表中的索引为 k，则其one-hot 向量表示为 δ ∈ {0, 1} ，|V|tt即第k 维为1，其余为0 的|V| 维向量。词xt 对应的向量表示为e = Mδ = m .(15.23)ttk邱锡鹏：《神经网络与深度学习》https://nndl.github.io/
 15.3 深度序列模型2019 年 4 月 6 日369通过上面的映射可以得到序列x1:(t−1) 对应的向量序列e1, ∙∙∙∙∙∙∙∙∙, et−1。特征层 特征层用于从输入向量序列 e1, ∙∙∙∙∙, et−1 中提取特征，输出为一个可以表示历史信息的向量ht。特征层可以通过不同类型的神经网络来实现，比如前馈神经网络和循环神经网络。常见的网络类型有以下三种：（1） 简单平均Σt−1ht =αiei,(15.24)i= 1其中αi 为每个词的权重。权重αi 可以和位置i 及其表示ei 相关，也可以无关。简单起见，可以设置αi = t−11。权重αi 也可以通过注意力机制来动态计算。注意力机制参见第8.1.2节。参见习题15-3。（2） 前馈神经网络前馈神经网络要求输入的大小是固定的。因此和N 元模型类似，假设历史信息只包含前面n − 1 个词。首先将这n − 1 个的词向量的et−n+1, · · · , et−1 拼接成一个d1 × (n − 1) 维的向量h′。h′ = et−n+1 ⊕ · · · ⊕ et−1其中⊕ 表示向量拼接操作。然后将h′ 输入到由前馈神经网络构成的隐藏层，最后一层隐藏层的输出ht。h = g(h′, θ ),,(15.25)(15.26)tg其中g(·, θg) 可以为全连接的前馈神经网络或卷积神经网络，θg 为网络参数。为了增加特征的多样性，前馈网络中也可以包含跳层连接（Skip-Layernections）[Bengio et al., 2003]，比如Con-h = e ⊕ g(h′, θ ).(15.27)ttg（3） 循环神经网络和前馈神经网络不同，循环神经网络可以接受变长的输入序列，依次接受输入e , · · · , e ，得到时刻t 的隐藏状态h1t−1tht = g(ht−1, e , θ ),(15.28)tg其中g(·) 为一个非线性函数，θg 为循环网络的参数，h0 = 0。前馈网络模型和循环网络模型的不同之处在于循环神经网络利用隐藏状态来记录以前所有时刻的信息，而前馈神经网络只能接受前n − 1 个时刻的信息。邱锡鹏：《神经网络与深度学习》https://nndl.github.io/
 3702019 年 4 月 6 日第 15 章 序列生成模型yt. . .. . .ht. . .et− n+ 1et− n+2et− 1. . .. . .. . .. . .嵌入矩阵 M共享参数xt−n+1xt−n+2. . .xt−1(a) 前馈神经网络模型yt邱锡鹏：《神经网络与深度学习》https://nndl.github.io/
 15.4 评价方法2019 年 4 月 6 日371. . .. . .ht. . .ht−1et−1. . .. . .邱锡鹏：《神经网络与深度学习》https://nndl.github.io/
 3722019 年 4 月 6 日第 15 章 序列生成模型xt−1(b) 循环神经网络模型图 15.3 深度序列模型邱锡鹏：《神经网络与深度学习》https://nndl.github.io/
 15.4 评价方法2019 年 4 月 6 日373输出层 输出层为一般使用softmax分类器，接受历史信息的向量表示h ∈ R ，d2t输出为词表中每个词的后验概率，输出大小为|V|。o = softmax(oˆ )(15.29)(15.30)tt= softmax(W ht + b),其中输出向量ot ∈ (0, 1)|V| 为预测的概率分布，第 维是词表中第 个词出现的条件概率；oˆt 是为归一化的得分向量；W ∈ R|V|×d2 是最后一层隐藏层到输出层直接的权重矩阵，b ∈ R|V| 为偏置。kk图15.3给出了两种不同的深度序列模型，图15.3a为前馈网络模型（虚线边 为可选的跳层连接），图15.3b为循环神经网络模型。15.3.1 参数学习给定一个训练序列x1:T ，深度序列模型的训练目标为找到一组参数θ，使得对数似然函数最大。简要起见，这里忽略了正则化项。ΣTlog pθ(x1:T ) =log p (x | x1:(t−1)),(15.31)θtt=1其中θ 表示网络中的所有参数，包括嵌入矩阵M 以及神经网络的权重和偏置。网络参数一般通过梯度上升法来学习，∂ log pθ(x1:T),(15.32)θ ← θ + α∂θ其中α 为学习率。15.4 评价方法构造一个序列生成模型后，需要有一个度量来评价其好坏。15.4.1 困惑度给定一个测试文本集合，一个好的序列生成模型应该使得测试集合中的句子的联合概率尽可能高。困惑度（Perplexity）是信息论的一个概念，可以用来衡量一个分布的不确定性。对于离散随机变量X ∈ X，其概率分布为p(x)，困惑度为Σx∈X2H(p) = 2−其中H(p) 为分布p 的熵。p(x) log2p(x),(15.33)邱锡鹏：《神经网络与深度学习》https://nndl.github.io/
 3742019 年 4 月 6 日第 15 章 序列生成模型困惑度也可以用来衡量两个分布之间差异。对于一个未知的数据分布pr(x)和一个模型分布p (x)，我们从p (x) 中采样出一组测试样本x(1), · · · , x(N)，模θr型分布pθ(x) 的困惑度为Σ NH (p˜ ,p )= 2− 1log2 pθ (x(n))n=12rθ,(15.34)N其中H (p˜ , p ) 为样本的经验分布p˜ 与模型分布p 之间的交叉熵，也是所有样rθrθ本上的负对数似然函数。困惑度可以衡量模型分布与样本经验分布之间的契合程度。困惑度越低则两个分布越接近。因此模型分布pθ(x)的好坏可以用困惑度来评价。}N假设测试集合共有独立同分布的 N 个序列{x(n) n=1。我们可以用模型1:Tnp (x) 对每个序列计算其概率p (x(n) )，整个测试集的联合概率为θθ1:TnNNTnYY Y(n)|xxt(n)1:(t−1)p x(n)=.(15.35)pθθ1:Tnn=1 t=1n=1模型pθ(x) 的困惑度定义为PPLθ( ) = 2−ΣN1log p x(n)(15.36)(15.37)Tn=1θ1:TnΣΣTn− 1= 2Np(n)|x(n)logxTn=1t= 1θt1:(t−1)!−1/TYN YTn(n) (n)pθ xt |x1:(t−1)=,(15.38)n=1 t=1ΣNn=1其中 T =Tn 为测试数据集中序列的总长度。可以看出，困惑度为每个p xt(n)|x(1n:)(t−1)的几何平均数的倒数。测试集中所有序列的概率越θ词条件概率大，困惑度越小，模型越好。几何平均数是一种求数值平Q假设一个序列模型赋予每个词出现的概率均等，即pθ x(n)|x(n)1|V|=，均数的x¯ =√方法， 计算公式为：nnx .t1:(t−1)tt=1则该模型的困惑度为|V|。以英语为例，N 元模型的困惑度范围一般为50 ∼ 1000之间。15.4.2 BLEUBLEU（Bilingual Evaluation Understudy）是衡量模型生成序列和参考序列之间的N 元词组（N-Gram）的重合度，最早用来评价机器翻译模型的质量，目前也广泛应用在各种序列生成任务中。假设从模型分布pθ 中生成一个候选（Candidate）序列x，从真实数据分布中采样出的一组参考（Reference）序列s(1), · · · , s(K )，我们首先从生成序列中邱锡鹏：《神经网络与深度学习》https://nndl.github.io/
 15.4 评价方法2019 年 4 月 6 日375提取N元组合的集合ꢀ ，并计算N元组合的精度（Precision），Σmin c, Kck=1w(x) max w (s(k))(x) = w∈ꢀ,(15.39)ΣPncw(x)w∈ꢀ其中c (x) 是N 元组合w 在生成序列x 中出现的次数，c (s( 是N 元组合wk))在元ww参考序列s(k) 中出现的次数。N 元组合的精度P (x)n是计算生成序列中的N组合有多少比例在参考序列中出现。由于精度只衡量生成序列中的N 元组合是否在参考序列中出现，生成序列越短，其精度会越高，因此可以引入长度惩罚因子(Brevity Penalty)。如果生成序列的长度短于参考序列，就对其进行惩罚。1if lx > ls(15.40)b(x) =exp 1 − ls/lx if lx ≤ ls其中l 为生成序列x 的长度，l 为参考序列的最短长度。xsBLEU 是通过计算不同长度的N 元组合的精度，并进行几何加权平均而得到。ΣNBLEU-N(x) = b(x) expwn ×log Pn,(15.41)n=1其中w 为不同N元组合的权重，一般设为 1 。BLEU取值范围是[0, 1]，越大表nN参见习题15-4。明生成的质量越好。但是BLEU 只计算精度，而不关心召回率（即参考序列里的 N 元组合是否在生成序列中出现）。15.4.3 ROUGEROUGE（Recall-Oriented Understudy for Gisting Evaluation）最早应用于文本摘要领域。和 BLEU 类似，但ROUGE 计算的是召回率（Recall）。假设从模型分布pθ 中生成一个候选（Candidate）序列x，从真实数据分布中采样出的一组参考（Reference）序列s(1), · · · , s(K )，令ꢀ 为从参考序列中提取N元组合的集合，ROUGE-N 的定义为ΣK Σmin cw (x), cw s(k)ROUGE-N(x) = k=1 w∈ꢀ ΣK Σ,(15.42)cw s(k)k=1 w∈ꢀ其中c (x) 是N 元组合w 在生成序列x 中出现的次数，c (s( 是N 元组合wk))在ww参考序列s(k) 中出现的次数。邱锡鹏：《神经网络与深度学习》https://nndl.github.io/
 3762019 年 4 月 6 日第 15 章 序列生成模型15.5 序列生成模型中的学习问题使用最大似然估计来学习自回归序列生成模型时，会存在以下三个主要问题：曝光偏差、训练目标不一致和计算效率。下面我们分别介绍这三个问题以及解决方面。15.5.1 曝光偏差问题在自回归生成模型中，第t 步的输入为模型生成的前缀序列xˆ1:(t−1)。而在训练时，我们使用的前缀序列是训练集中的真实数据x1:(t−1))，而不是模型预测 的ˆ1:(t−1))。这种学习方式也称为教师强制（Teacher Forcing）[Williams andZipser, 1989]。模型生成的分布pθ x1:( 1)) 和 真 实 数 据 分 布 prx1:(1)) 并不严格一致，因此条件概率 pθt−t−x|x1:(t−1)) 在训练和测试会存在协变量偏移问题。一旦在预协 变 量 偏 移 问 题 参 见测前缀 xˆ1:(t−1)) 的过程中存在错误，会导致错误传播，使得后续生成的序列也会偏离真实分布。这个问题称为曝光偏差（Exposure Bias）。第10.4.0.2节。计划采样 为了缓解曝光偏差的问题，我们可以在训练时混合使用真实数据和模型生成数据。在第t 步时，模型随机使用真实数据xt−1 或前一步生成的词xˆt−1作为输入。令 ϵ ∈ [0, 1] 为一个控制替换率的超参数，在每一步时，以ϵ 的概率使用真实数据xt−1，以1 − ϵ 的概率来使用生成数据xˆt−1。当令ϵ = 1 时，训练和最大似然估计一样，使用真实数据；当令ϵ = 0 时，训练时全部使用模型生成数据。直觉上，如果一开始训练时的ϵ 过小，模型相当于在噪声很大的数据上训练，会导致模型性能变差，并且难以收敛。因此，一个较好的策略是在训练初 期赋予ϵ 较大的值，随着训练次数的增加逐步减少ϵ 的取值。这种策略称为计划采样（Scheduled Sampling）[Bengio et al., 2015]。令 ϵi 为在第i 次迭代时的替换率，在计划采样中可以通过下面几种方法来逐步降低ϵ的取值。1. 线性衰减：ϵi = max(ϵ, k − ci)，其中ϵ 为最小的替换率，k 和 c 分别为初始值和衰减率。i<2. 指数衰减：ϵ = k ，其中k 1 为初始替换率。i3. 逆Sigmoid 衰减：ϵi = k/(k + exp(i/k))，其中k ≥ 1 来控制衰减速度。计划采样的一个缺点是在每一步中不管输入如何选择，目标输出依然是来自于真实数据。这可能使得模型预测一些不正确的序列。比如一个真实的序列邱锡鹏：《神经网络与深度学习》https://nndl.github.io/
 15.5 序列生成模型中的学习问题2019 年 4 月 6 日375是“吃饭”，如果在第一步生成时使用模型预测的词“喝”，模型就会强制记住 “喝饭”这个不正确的序列。15.5.2 训练目标不一致问题序列生成模型一般是采用和任务相关的指标来进行评价，比如BLEU、ROUGE等，而训练时是使用最大似然估计，这导致训练目标和评价方法不一致。并且这些评价指标一般都是不可微的，无法直接使用基于梯度的方法来进行优化。基于强化学习的序列生成 为了可以直接优化评价目标，我们可以将自回归的序列生成可以看作是一种马尔可夫决策过程，并使用强化学习的方法来进行训练。参见第14.1.3节。在第t 步，动作a 可以看作是从词表中选择一个词，策略为π (a|s )，其中tθt状态 st 为之前步骤中生成的前缀序列 x1:(t−1)。一个序列 x1:T 可以看作是马尔克夫决策过程的一个轨迹（trajectory）τ = {s , a , s , a ..., s , a }.(15.43)1122TT轨迹τ 的概率为YTpθ(τ) =πθ a = x s| = x,(15.44)ttt1:(t−1)t=1其中状态转移概率 p s = x |s = x1:(t−1), at−1 = xt−1 = 1 是确定性的，t1:t t−1可以被忽略。强化学习的目标是学习一个策略π (a|s ) 使得期望回报最大，θtJ (θ) = Eτ∼pθ (τ)[G(τ)]= Ex1:T )[G(x1:T )],(15.45)(15.46)∼pθ (x1:T其中G(x1:T ) 为序列x1:T 的总回报，可以为BLEU、ROUGE 或其它评价指标。这样序列生成问题就转换为强化学习问题，其策略函数π (a|s ) 可以通过θtREINFORCE 算法或Actor-Critic 算法来进行学习。为了改进强化学习的效率，策略函数π (a|s )一般会通过最大似然估计来进行预训练。θt基于强化学习的序列生成模型不但可以解决训练和评价目标不一致问题，也可以有效地解决曝光偏差问题。15.5.3 计算效率问题序列生成模型的输出层为词表中所有词的条件概率，需要softmax 归一化。当词表比较大时，计算效率比较低。邱锡鹏：《神经网络与深度学习》https://nndl.github.io/
 3762019 年 4 月 6 日第 15 章 序列生成模型在第t 步时，前缀序列为ht = x1:(t−1)，词xt 的条件概率为p (x |h ) = softmax s(x , h ; θ)(15.47)(15.48)θttttexp s(x , h ; θ)tΣ=,exp s(v, h ; θ)v∈Vtexp s(x , h ; θ)tt=,(15.49)Z(h ; θ)t其中s(x , h ; θ)为未经过softmax归一化的得分函数，Z (h ; θ)为配分函数（Partitions(x , h ; θ) = [oˆ ]，oˆ 为tttttt kxt未归一化的网络输出参见公tFunction）。Σ式 (15.29)。Z(ht; θ) =exp s(v, ht; θ) .(15.50)参见第11.1.4节。v∈V配分函数的计算需要对词表中所有的词v 计算s(v, ht; θ) 并求和。当词表比较大时，计算开销非常大。比如在自然语言中，词表V 的规模一般在1 万到10万之间。在训练时，每个样本都要计算一次配分函数，这样每一轮迭代需要计 算T 次配分函数（T 为训练文本长度），导致整个训练过程变得十分耗时。因此在实践中，我们通常采用一些近似估计的方法来加快训练速度。常用的方法可 以分为两类：（1）层次化的softmax计算，将标准softmax函数的扁平结构转换为层次化结构；（2）基于采样的方法，通过采样来近似计算更新梯度。本节介绍三种方法加速训练的方法：层次化softmax 方法、重要性采样和噪声对比估计。15.5.3.1 层次化 Softmax我们先来考虑两层的来组织词表，即将词表中词分成k 组，并每一个词只能属于一个分组，每组大小为 |Vk| 。假设词w 所属的组为c(w)，则p(w|h) = p(w, c(w)|h)= p(w|c(w), h)p(c(w)|h),(15.51)(15.52)其中p(c(w)|h) 是给定历史信息h 条件下，类c(w) 的后验概率，p(w|c(w), h) 是给定历史信息h 和类c(w) 条件下，词w 的后验概率。因此，一个词的概率可以分解为两个概率p(w|c(w), h) 和 p(c(w)|h) 的乘积，它们可以分别利用神经网络来估计，这样计算softmax函数时分别只需要做 |kV| 和k 次求和，从而就大大提高了softmax 函数的计算速度。√√一般对于词表大小 |V|，我们将词平均分到|V|个分组中，每组|V|个√词。这样通过一层的分组，我们可以将 softmax计算加速1|V|倍。比如当词2邱锡鹏：《神经网络与深度学习》https://nndl.github.io/
 15.5 序列生成模型中的学习问题2019 年 4 月 6 日377表大小为40, 000 时，将词表中所有词分到200 组，每组200 个词。这样只需要计算两次200 类的softmax，比直接计算40, 000 类的softmax 加快100 倍。为了进一步降低softmax 的计算复杂度，我们可以更深层的树结构来组织词汇表。假设用二叉树来组织词表中的所有词，二叉树的叶子节点代表词表中 的词，非叶子节点表示不同层次上的类别。图15.4给出了平衡二叉树和Huﬀman 二叉树的示例。邱锡鹏：《神经网络与深度学习》https://nndl.github.io/
 01013782019 年 4 月 6 日第 15 章 序列生成模型v1010101v2v1v2 0 v31v4v3v4邱锡鹏：《神经网络与深度学习》https://nndl.github.io/
 15.5 序列生成模型中的学习问题(a) 平衡树2019 年 4 月 6 日379(b) Huﬀman 树图 15.4 层次化树结构如果我们将二叉树上所有左链接标记为0，右链接标记为1。每一个词可以用根节点到它所在的叶子之间路径上的标记来进行编码。图15.4a中所示的四个词的编码分别为：v1 = 00,v2 = 01,v3 = 10,v4 = 10.(15.53)假设词v 在二叉树上从根节点到其所在叶子节点的路径长度为m，其编码可以表示一个位向量（bit vector）：[b1, · · · , bm ]T 。词v 的条件概率为P (v|h) = p b , · · · , b |h(15.54)(15.55)1mYm==p bjb ,, bj−1, h| ,1j=1Ym· · ·p bj bj−1, h|,(15.56)j=1由于bj ∈ {0, 1} 为二值变量，p(bj |bj−1, h) 可以看作是两类分类问题，可以使 用 logistic 回归来进行预测。p(bj = 1|bj−1, h) = σ wT1 h + bn(b j− 1 ),(15.57)n(bj−邱锡鹏：《神经网络与深度学习》https://nndl.github.io/
 3802019 年 4 月 6 日第 15 章 序列生成模型其中n(bj−1) 为词v 在树T 上的路径上的第j − 1 个节点。若使用平衡二叉树来进行分组，则条件概率估计可以转换为log2 |V| 个两类分类问题。这时softmax 函数可以用logistic 函数代替, 计算效率可以加速 |V|log 2 |V|倍。将词表中的词按照树结构进行组织，有以下几种转换方式：•利用人工整理的词汇层次结构，比如利用WordNet[Miller, 1995] 系统中的“IS-A”关系（即上下位关系）。例如，“狗”是“动物”的下位词。因为WordNet 是 按 照 词 义 来 组织的英语词汇知识库，由WordNet的层次化结构不是二叉树，因此需要通过进一步聚类来转换为二Princeton 大学研发。叉树。• 使用Huﬀman 编码。Huﬀman 编码对出现概率高的词使用较短的编码，出现概率低的词则使用较长的编码。因此训练速度会更快。Huﬀman 编码的算法如算法15.1所示。Huﬀman 编 码 是 DavidHuﬀman 于 1952 年 发 明的 一种用于无损数据压缩的熵编码（权编码）算法。算法 15.1: Huﬀman 树构建算法输入: 词表: V1 初始化：为每个词v 建立一个叶子节点，其概率为词的出现频率;2 将所有的叶子节点放入集合S 中;3 while |S| > 1 do4从集合S 选择两棵概率最低的节点n 和n ;1 25构建一个新节点n′，并将n 和n 作为n′ 的左右子节点;1 26新节点n将新二叉树加入集合S 中，并把n 和n 从集合S 中移除;′ 的概率n 和n 的概率之和，;127128 end9 集合S 中最后一个节点为n;输出: 以n 为根节点的二叉树T15.5.3.2 重要性采样另一种加速训练速度的方法是基于采样的方法，即通过采样来近似计算训练时的梯度。参见第11.3节。用随机梯度上升来更新参数 θ 时，第 t 个样本(h , x ) 的目标函数关于 θ 的tt梯度为Σ∂ logexp s(v, ht; θ)∂ log p (x |h ) ∂s(x , h ; θ)(15.58)θtt=ttv邱锡鹏：《神经网络与深度学习》https://nndl.github.io/
 15.5 序列生成模型中的学习问题2019 年 4 月 6 日381−∂θ∂θ∂θ邱锡鹏：《神经网络与深度学习》https://nndl.github.io/
 3822019 年 4 月 6 日第 15 章 序列生成模型Σ∂exp s(v, ht; θ)∂s(x , h ; θ)1(15.59)==ttv− Σ·∂θexp s(v, ht; θ)∂θexp s(v, h ; θ)vΣt(15.60)(15.61)∂s(x , h ; θ)1∂=tt−vΣw·∂θexp s(w, h ; θ)∂θt∂s(x , h ; θ)exp s(v, ht; θ) ∂s(v, ht; θ)tt−Σ∂θΣ∂θexp s(w, ht; θ)∂s(v, ht; θ)wΣ∂s(x , h ; θ)tt−p (v|h )θ t==(15.62)(15.63)∂θ∂θ∂s(v, h ; θ)v−t.∂s(x , h ; θ)ttE∂θp (v|h )∂θθt公式（15.63）中最后一项是计算  ∂ s(v, h ; θ) 在分布p (v|h ) 下的期望。从公tθt∂θ式（15.61）中可以看出，在计算每个样本的梯度时需要在整个词表上计算两次Σ求和。一次是求配分函数 exp s(w, ht; θ) ，另一次是计算所有词的梯度的w。由于自然语言中的词表都比较大，训练速度会非常慢。期望E[∂ s(v, h ; θ)]t∂θ为了提高训练效率，可以用采样方法来进行近似地估计公式(15.63) 中的期望。但是我们不能使用直接根据分布p (v|h ) 进行采样，因为直接采样需要在θt需要先计算分布p (v|h )，而这正是我们希望避免的。θt重要性采样参见第11.3.3节。重要性采样是用一个容易采样的提议分布q，来近似估计分布p。公式(15.63) 中最后一项可以写为：Σ∂s(v, ht; θ)∂s(v, ht; θ)E=p (vθ|h )t(15.64)(15.65)p (v|h )θt∂θ∂θv∈Vv∈Vtq(v|h )∂θΣtp (v|h ) ∂s(v, h ; θ)θt·t=q(v|h )p (v|h ) ∂s(v, h ; θ)θ= Et·t.(15.66)q(v|ht)q(v|ht)∂θ这样原始分布 p (v|h ) 上的期望转换为提议分布 q(v|h ) 上的期望。提议分布 qθtt需要尽可能和p (v|h ) 接近，并且从q(v|h ) 采样的代价要比较小。在实践中，提θtt议分布q(v|ht)可以采用N 元模型的分布函数。根据分布Q(v|h ) 独立采样K 个样本v , · · · , vK 来近似求解公式（15.66）。t1ΣK∂s(v, h t; θ)1Kp (v |h ) ∂s(v , h ; θ)E≈θktkt.(15.67)p (v|h )θt∂θq(v |h )∂θktk=1在公式(15.67) 中，依然需要每一个计算抽取样本的概率p (v |h)。θks(v , h ; θ)kt,(15.68)p (v |h ) =θktZ (h )t邱锡鹏：《神经网络与深度学习》https://nndl.github.io/
 15.5 序列生成模型中的学习问题其中 Z(ht) =2019 年 4 月 6 日383Σwexp s(w, ht; θ) 为配分函数，需要在所有样本上进行计算s(w, h ; θ) 并求和。为了避免这种情况，我们可以进一步把配分函数Z(h ) 的计tt算也使用重要性采样来计算。ΣZ(ht) = exp s(w, h ; θ)(15.69)(15.70)t1Σwexp s(w, ht; θ)q(w|h)t=q(w|ht)w1= Eq(w|ht)exp s(w, ht; θ)(15.71)(15.72)q(w|ht )Σ1KK1≈s v , h θexp通过采样近似估计q(v |h )ktktk=1(; )ΣK1Kexp s(v , h ; θ)k t=(15.73)(15.74)q(v |h )ktk=1ΣK1Kr(v ),=kk=1s(v ,h ;θ)其中r(v k) = expkt，q(v |h ) 为提议分布。为了提高效率，可以和公式k tq(v |h )kt（15.67）中的提议分布设为一致，并复用在上一步中抽取的样本。在近似估计了配分函数以及梯度期望之后，公式（15.67）可写为ΣK∂s(v, ht ; θ)1Kp (v |h ) ∂s(v , h ; θ)θktktE≈(15.75)p (v|h )θt∂θq(v |h )∂θktk=1ΣK1exp s(v , h ; θ)1∂s(v , h ; θ)=ktkt(15.76)(15.77)KZ h( )q(v |h )∂θtktk=1ΣK11∂s(v , h ; θ)k∂θt=KZ(h )r v(kt)k=1K∂s(v , h ; θ)≈Σkkt(15.78)Σr(v )k∂θ1Σ∂s(v , h= Σr(v ); θ()kk=1(15.79)Kk=1邱锡鹏：《神经网络与深度学习》https://nndl.github.io/
 3842019 年 4 月 6 日第 15 章 序列生成模型Kr vkt.∂θk=1r(vk)K∂θk=1邱锡鹏：《神经网络与深度学习》https://nndl.github.io/
 15.5 序列生成模型中的学习问题2019 年 4 月 6 日385Σ∂s(v , h ; θ)k将公式（15.79）代入公式（15.63），得到每个样本目标函数关于θ 的梯度邱锡鹏：《神经网络与深度学习》https://nndl.github.io/
 3862019 年 4 月 6 日第 15 章 序列生成模型可以近似为∂ log p (x |h ) = ∂s(x , h ; θ)1− Σ邱锡鹏：《神经网络与深度学习》https://nndl.github.io/
 15.5 序列生成模型中的学习问题2019 年 4 月 6 日387邱锡鹏：《神经网络与深度学习》https://nndl.github.io/
 3882019 年 4 月 6 日第 15 章 序列生成模型邱锡鹏：《神经网络与深度学习》https://nndl.github.io/
 15.5 序列生成模型中的学习问题2019 年 4 月 6 日389邱锡鹏：《神经网络与深度学习》https://nndl.github.io/
 3902019 年 4 月 6 日第 15 章 序列生成模型邱锡鹏：《神经网络与深度学习》https://nndl.github.io/
 15.5 序列生成模型中的学习问题2019 年 4 月 6 日391邱锡鹏：《神经网络与深度学习》https://nndl.github.io/
 3922019 年 4 月 6 日第 15 章 序列生成模型邱锡鹏：《神经网络与深度学习》https://nndl.github.io/
 15.5 序列生成模型中的学习问题2019 年 4 月 6 日393邱锡鹏：《神经网络与深度学习》https://nndl.github.io/
 3942019 年 4 月 6 日第 15 章 序列生成模型邱锡鹏：《神经网络与深度学习》https://nndl.github.io/
 15.5 序列生成模型中的学习问题2019 年 4 月 6 日395邱锡鹏：《神经网络与深度学习》https://nndl.github.io/
 3962019 年 4 月 6 日第 15 章 序列生成模型邱锡鹏：《神经网络与深度学习》https://nndl.github.io/
 15.5 序列生成模型中的学习问题2019 年 4 月 6 日397邱锡鹏：《神经网络与深度学习》https://nndl.github.io/
 3982019 年 4 月 6 日第 15 章 序列生成模型邱锡鹏：《神经网络与深度学习》https://nndl.github.io/
 15.5 序列生成模型中的学习问题2019 年 4 月 6 日399邱锡鹏：《神经网络与深度学习》https://nndl.github.io/
 4002019 年 4 月 6 日第 15 章 序列生成模型邱锡鹏：《神经网络与深度学习》https://nndl.github.io/
 15.5 序列生成模型中的学习问题2019 年 4 月 6 日401∂θk=1邱锡鹏：《神经网络与深度学习》https://nndl.github.io/
 4022019 年 4 月 6 日第 15 章 序列生成模型其中v , · · · , v 为从提议分布q(v|h )中从词表V 独立抽取的词。和公式（15.63）1kt相比，重要性采样相当于采样了一个词表的子集V′ = {v , · · · , v }，然后在这个1k∂s(vk,h;θ)子集上求梯度的期望；公式（15.63）中分布 p (v|h ) 被 r(v ) 所替代。θ t k∂θ这样目标函数关于θ的梯度就避免了在词表上对所有词进行计算，只需要 计算较少的抽取的样本。采样的样本数量K 越大，近似越接近正确值。在实际应用中，K 取 100 左右就能够以足够高的精度对期望做出估计。通过重要性采样的方法，训练速度可以加速 |V| 倍。K重要性采样的思想和算法都比较简单，但其效果依赖于建议分布q(v|ht)的选取。如果q(v|ht)选取不合适时，会造成梯度估计非常不稳定。在实践中，提议分布 q(v|h ) 经常使用一元模型的分布函数。虽然直观上 q(v|h ) 采用N 元模型更加tt准确，但使用复杂的N 元模型分布并不能改进性能，原因是N 元模型的分布和神经网络模型估计的分布之间有很大的差异[Bengio and Senécal, 2008]。15.5.3.3 噪声对比估计除重要性采样外，噪声对比估计（Noise-Contrastive Estimation，NCE）也是一种常用的近似估计梯度的方法。噪声对比估计是将密度估计问题转换为两类分类问题，从而降低计算复杂度 [Gutmann and Hyvärinen, 2010]。噪声对比估计的思想在我们日常生活中十分常见。比如我们教小孩认识“苹果”，往往会让小孩从一堆各式各样的水果中 找出哪个是“苹果”。通过不断的对比和纠错，最终小孩会知道了解“苹果”的 特征，并很容易识别出“苹果”。噪声对比估计的数学描述如下：假设有三个分布，一个是需要建模真实数据分布p (x)；第二是模型分布p (x)，并期望调整模型参数θ 来使得p (x) 来拟合rθθ真实数据分布pr(x)；第三个是噪声分布q(x)，用来对比学习。给定一个样本x，如果x是从pr(x)中抽取的，称为真实样本，如果x是从q(x)中抽取的，则称为噪声样本。为了判断样本x 是真实样本还是噪声样本，引入一个辨别函数D。噪声对比估计是通过调整模型pθ(x) 使得辨别函数D 很容易能分别出样本x 来自哪个分布。令y ∈ {1, 0} 表示一个样本x 是真实样本或噪声样本，其条件概率为p(x|y = 1) = pθ(x),p(x|y = 0) = q(x).(15.81)(15.82)一般噪声样本的数量要比真实样本大很多。为了提高近似效率，我们近似假设噪声样本的数量是真实样本的K 倍，即y 的先验分布满足P (y = 0) = KP (y = 1).(15.83)邱锡鹏：《神经网络与深度学习》https://nndl.github.io/
 15.5 序列生成模型中的学习问题2019 年 4 月 6 日403根据贝叶斯公式，样本x 来自于真实数据分布的后验概率为p(x|y = 1)p(y = 1)p(y = 1|x) =(15.84)p(x|y = 1)p(y = 1) + p(x|y = 0)p(y = 0)pθ(x)p(y = 1)==(15.85)(15.86)p (x)p(y = 1) + q(x) · kp(y = 1)θp (x)θ.pθ( x) + Kq (x)相反，样本x 来自于噪声分布的后验概率为 p(y = 0|x) = 1 − p(y = 1|x)。从真实分布p (x) 中抽取N 个样本x , · · · , x ，将其类别设为y = 1，然后r1N从噪声分布中抽取K N 个样本x1, · · · , xkn，将其类别设为y = 0。噪声对比估计的目标是将真实样本和噪声样本区别开来，可以看作是一个两类分类问题。噪声对比估计的损失函数为!ΣΣKN1N−L(θ) =log p(y = 1|xn ) +log p(y = 0|x ).(15.87)N (K + 1)n=1n=1通过不断采样真实样本和噪声样本，并用梯度下降法可以学习参数θ逼近于真实分布pr(x)。使得pθ(x)噪声对比估计相当于用判别式的准则L(θ)来训练一个生成式模型pθ(x)，使得判别函数D 很容易能分别出样本x 来自哪个分布，其思想与生成式对抗网络类似。不同之处在于，在噪声对比估计中的判别函数D 是通过贝叶斯公式计算得到，而生成对抗网络的判别函数D 是一个需要学习的神经网络。生成对抗网络参见第13.3节。基于噪声对比估计的序列模型 在计算序列模型的条件概率时，我们也可以利用噪声对比估计的思想来提高计算效率[Mnih and Kavukcuoglu, 2013, Mnih and Teh,2012]。在序列模型中需要建模的分布是pθ(v|h)，原则上噪声分布q(v|h) 应该是依赖于历史信息h 的条件分布，但实践中一般使用和历史信息无关的分布q(v)，比如一元模型的分布。pθ(v|h) 参见公式(15.48)。给定历史信息h，我们需要判断词表中每一个词v 是来自于真实分布还是噪声分布。p (v|h)θP (y = 1|v, h) =.(15.88)p (v|h) + K q(vθ对于一个训练序列 x1:T ，将 {(x , h )}T作为真实样本，从噪声分布中抽取ttt=1K 个样本(xt,1, · · · , xt,k )。噪声对比估计的目标函数是!ΣTΣKL(θ) = −log P (y = 1|x , h ) +log(1 − P (y = 1|xt,k , ht )) . (15.89)ttt=1k=1为了简洁起见，这里省略了1系数。T (K+1)邱锡鹏：《神经网络与深度学习》https://nndl.github.io/
 

 15.6 序列到序列模型2019 年 4 月 6 日383虽然通过噪声对比估计，将一个|V| 类的分类问题转为一个两类分类问题，但是依然需要计算pθ(v|h)，其中仍然涉及到配分函数的计算。为了避免计算配分函数，我们将负对数配分函数− log Z(h, θ) 作为一个可学习的参数ꢀh（即每一个h 对应一个参数），这样条件概率pθ(v|h) 重新定义为p (v|h) = exp s(v, h; θ) exp(ꢀ ).(15.90)θh噪声对比估计方法的一个特点是会促使未归一化分布exp s(v, h; θ) 可以自己学习到一个近似归一化的分布，并接近真实的数据分布pr(v|h) [Gutmannand Hyvärinen, 2010]。也就是说，学习出来的exp(ꢀh) ≈ 1。这样可以直接令exp(ꢀ ) = 1, ∀h，并用未归一化的分布exp s(v, h; θ) 来代替p (v|h)。hθMnih and Teh [2012]也在实验中证实，直接令exp(ꢀh)=1不会影响模型的性能。因为公式（15.88）可以写为(y = 1|v, h) =exps(v, h; θ)(15.91)p神经网络有大量的参数，这些参数足以让模型学习到一个近似归一化的分布。exp s(v, h; θ) ) + Kq(v)1=(15.92)(15.93)Kq(v)1 +exp s(v,h;θ)1==1 + exp − s(v, h; θ) − log Kq(v)11 + exp(−(∆s(v, h; θ)))(15.94)(15.95)= σ(∆s(v, h; θ)),其中σ 为 logistic 函数，∆s(v, h; θ) = s(v, h; θ) − log(Kq(v)) 为模型打分（未归一化分布）与放大的噪声分布之间的差。在噪声对比估计中，噪声分布q(v) 的选取也十分关键。首先是从q(v) 中采样要十分容易。另外q(v)要和真实数据分布pr(v|h)比较接近，否则分类问题就变得十分容易，不需要学习到一个接近真实分布的pθ(v|h) 就可以分出数据来源了。对自然语言的序列模型，q(v) 取一元模型的分布是一个很好的选择。每次迭代噪声样本的个数K 取值在25 ∼ 100 左右。总结 基于采样的方法并不改变模型的结构，只是近似计算参数梯度。在训练时可以显著提高模型的训练速度，但是在测试阶段依然需要计算配分函数。而基于层次化softmax 的方法改变了模型的结构，在训练和测试时都可以加快计算速度。15.6 序列到序列模型在序列生成任务中，有一类任务是输入一个序列，生成另一个序列，比如邱锡鹏：《神经网络与深度学习》https://nndl.github.io/
 3842019 年 4 月 6 日第 15 章 序列生成模型机器翻译、语音识别、文本摘要、对话系统、图像标题生成等。邱锡鹏：《神经网络与深度学习》https://nndl.github.io/
 15.6 序列到序列模型2019 年 4 月 6 日385序列到序列（Sequence-to-Sequence，Seq2Seq）是一种条件的序列生成问题，给定一个序列x1:S，生成另一个序列y1:T 。输入序列的长度S 和输出序列的长度T 可以不同。比如在机器翻译中，输入源语言，输入为目标语言。图15.5给出了基于循环神经网络的序列到序列机器翻译示例。邱锡鹏：《神经网络与深度学习》https://nndl.github.io/
 机器学习3862019 年 4 月 6 日第 15 章 序列生成模型machinelearning$邱锡鹏：《神经网络与深度学习》https://nndl.github.io/
 15.6 序列到序列模型2019 年 4 月 6 日387图 15.5 基于循环神经网络的序列到序列机器翻译序列到序列模型的目标是估计条件概率Tpθ(y1:T |x1:S) =p (y| y, x ),(15.96)θt1:(t−1)1:St=1其中yt ∈ V 为词表V 中的某个词。给定一组训练数据{(xSn , yT n )}nN=1 ，我们可以使用最大似然估计来训练模型参数。ΣNmθaxlog pθ(y1:Tn |x1:Sn ).(15.97)n=1一旦训练完成，模型就可以根据一个输入序列x来生成最可能的目标序列，(15.98)yˆ = arg max p (y|x),θy具体的生成过程可以通过贪婪方法或束搜索来完成。和一般的序列生成模型类似，条件概率 p (y |y1:(t−1), x1:S) 可以使用各种θt不同的神经网络来实现。这里我们介绍三种主要的序列到序列模型。15.6.1 基于循环神经网络的序列到序列模型实现序列到序列的最直接方法是使用两个循环神经网络来分别进行编码和解码，也称为编码器-解码器（Encoder-Decoder）模型。编码器 首先使用一个循环神经网络Renc 来编码输入序列x1:S 得到一个固定维数的向量u，u 一般为编码循环神经网络最后时刻的隐状态。hte = fenc(het−1 , ext− 1 , θenc),∀t ∈ [1 : S],(15.99)邱锡鹏：《神经网络与深度学习》https://nndl.github.io/
 

 15.6 序列到序列模型2019 年 4 月 6 日385u = heS,(15.100)其中fenc(·) 为编码循环神经网络，可以为LSTM 或GRU，其参数为θenc，ex 为词 x 的词向量。解码器 在生成目标序列时，使用另外一个循环神经网络 Rdec 来进行解码。在解码过程的第t 步时，已生成前缀序列为y1:(t−1)。令ht 表示在网络Rdec 的隐状态，ot ∈ (0, 1)|V| 为词表中所有词的后验概率，则hd = u,(15.101)(15.102)0hd = fdec(hd , ey , θdec),tt−1t−1o = g(hd, θ ),(15.103)tto其中fdec(·)为解码循环神经网络，g(·)为最后一层为softmax函数的前馈神经网络，θdec 和θ 为网络参数，e 为y 的词向量，y 为可以为特殊的符号，比如“$”.oy0基于循环神经网络的序列到序列模型的缺点是：（1）向量c的容量问题，输入序列的信息很难全部保存在一个固定维度的向量中；（2）当序列很长时，由于循环神经网络的长期依赖问题，容易丢失输入序列的信息。长期依赖问题参见第6.5节。15.6.2 基于注意力的序列到序列模型基于注意力的序列到序列生 成 过 程 见https://nndl.github.io/v/sgm-seq2seq为了获取更丰富的输入序列信息，我们可以在每一步中通过注意力机制来从输入序列中选取有用的信息。在解码过程的第t 步时，先用上一步的隐状态hd作为查询向量，利用注t−1意力机制从所有输入序列的隐状态H e = [he, · · · , h ]中选择相关信息。eSSct = att(He, htd−1 ) =αe(15.104)(15.105)iii= 1S注意力机制参见第8.1.2节。Σi=softmax s(hei, hde) ht−1i=1其中s(·) 为注意力打分函数。注 意 力 打 分 函 数 参 见解码器第t 步的隐状态为第8.1.2节。hd = fdec(hd , [ey ; ct], θdec),(15.106)tt−1t− 115.6.3 基于自注意力的序列到序列模型除长期依赖问题外，基于循环神经网络的序列到序列模型的另一个不足是无法并行计算。为了提高并行计算效率以及捕捉长距离的依赖关系，我们可以使用自注意模型来建立一个全连接的网络结构。自 注 意 力 模 型 参 见第8.2.2节。https://nndl.github.io/邱锡鹏：《神经网络与深度学习》
 3862019 年 4 月 6 日第 15 章 序列生成模型本节介绍一个典型的基于自注意力的序列到序列模型：Transformer[Vaswaniet al., 2017]。15.6.3.1 自注意力subsection 多头自注意力对于一个向量序列H = [h , · · · , h ] ∈ Rd ×Th，首先用自注意力模型来对1T其进行编码。K QTself-att(Q, K, V ) = softmax√V,(15.107)(15.108)dhQ = W H, K = W X, V = W X,QKV其中d 是输入向量h 的维度，W ∈ Rd ×d , W ∈ Rd ×d , W ∈ Rd ×d 为khkhvhhtQKV三个投影矩阵。15.6.3.2 多头自注意力自注意力模型可以看作是在一个线性投影空间中建立向量 H 之间交互关系。为了提取更多的交互信息，我们可以使用多头注意力，在多个不同的投影空间中捕捉不同的交互信息。MultiHead(H) = W [head ; · · · ; head ],(15.109)(15.110)(15.111)O1Mheadm = self -att(Q , K , V ),mmm∀m ∈ [1 : M ], Qm = WmH, K = WmX, V = WmX,QKV其中WO ∈ Rd ×Md 为输出投影矩阵，Wm ∈ Rd ×d , Wm ∈ Rd ×d , Wm ∈hvkhkhQKVRd ×d 为投影矩阵，m ∈ [1, M ]。vh15.6.3.3 基于自注意力模型的序列编码对于一个序列x1:T ，我们可以构建一个多层的多头自注意力来对其进行编码。由于自注意力模型忽略了输入信息的位置信息，因此初始的输入序列中加入位置编码信息来进行修正。对于一个输入序列x1:T，H (0) = [ex1 ⊕p1, · · · , exT ⊕pT ],(15.112)其中e 为词x 的嵌入向量表示，p 为位置t 的向量表示。xttt第l 层的隐状态H(l) 为Z(l) =norm H(l−1) + MultiHead H(l−1)H(l) =norm Z(l) + FFN(Z(l)) ,,(15.113)(15.114)邱锡鹏：《神经网络与深度学习》https://nndl.github.io/
 15.6 序列到序列模型2019 年 4 月 6 日387其中norm(·) 表示层归一化，FFN(·) 表示逐位置的前馈神经网络（Position-wiseFeed-Forward Network），为一个简单的两层网络。对于输入序列中每个位置上向量z，层归一化参见第7.5.2节。FFN(z) = W ReLu(W z + b ) + b ,(15.115)2112其中W , W , b , b 为网络参数。1212基于自注意力模型的序列编码可以看作是一个全连接的前馈神经网络，第l 层的每个位置都接受第l − 1 层的所有位置的输出。不同的是，其连接权重是通过注意力机制动态计算得到。基于 Transformer 的15.6.3.4 基于自注意力模型的序列到序列模型序 列 到 序 列 生 成 过 程见https://nndl.github.io/v/sgm-seq2seq将自注意力模型应用在序列到序列任务中，其整个网络结构可以分为两部分：编码器 编码器只包含多层的自注意力模块，每一层都接受前一层的输出作为输入。编码器的输入为序列x1:S ，输出为一个向量序列H e = [he, · · · , h ]。eS解码器 解码器依是通过自回归的方式来生成目标序列。和编码器不同，解码器可以由以下三个模块构成：1. 自注意力模块：第t 步时，先使用自注意力模型对已生成的前缀序列y1:(t−1)进行编码得到H d = [hd, · · · ,hd]。在训练时，解码器的输入为整个目(t−1)标序列，这时可以通过一个掩码（mask）来阻止每个位置选择其后面的输入信息。2. 解码器到编码器注意力模块：使用hd作为查询向量，通过注意力机制(t−1)来从输入序列He 中选取有用的信息。3. 逐位置的前馈神经网络：使用一个前馈神经网络来综合得到所有信息。将上述三个步骤重复多次，最后通过一个全连接前馈神经网络来计算输出概率。图15.6给出了Transformer 的网络结构示例。邱锡鹏：《神经网络与深度学习》https://nndl.github.io/
 3882019 年 4 月 6 日第 15 章 序列生成模型图 15.6 Transformer 网络结构15.7 总结和深入阅读序列生成模型主要解决序列数据的密度估计和生成问题，是一种在实际应用中十分重要的一类模型。目前主流的序列生成模型都是通过自回归模型。最早的深度序列模型是神经网络语言模型。Bengio et al. [2003] 最早提出了基于前馈神经网络的语言模型，随后Mikolov et al. [2010] 利用循环神经网络来实现语言模型。Oord et al. [2016] 针对语音合成任务提出了WaveNet，可以生成接近自然人声的语音。为了解决曝光偏差问题，Venkatraman et al. [2014] 提出了DAD（Data asDemonstrator）算法，即在训练时混合使用真实数据和模型生成的数据，Bengio etal. [2015] 进一步使用课程学习（Curriculum Learning）控制使用两种数据的比例。Ranzato et al. [2015] 将序列生成看作是强化学习问题，并使用最大似然估邱锡鹏：《神经网络与深度学习》https://nndl.github.io/
 15.7 总结和深入阅读2019 年 4 月 6 日389计来预训练模型，并逐步将训练目标由最大似然估计切换为最大期望回报。Yuet al. [2017] 进一步利用对抗生成网络的思想来进行文本生成。由于深度序列模型在输出层使用softmax进行归一化，计算代价很高。Ben-gio and Senécal [2008]提出了利用重要性采样来加速softmax的计算，Mnih andKavukcuoglu [2013] 提出了噪声对比估计来计算非归一化的条件概率，Morinand Bengio [2005] 最早使用了层次化softmax 函数来近似扁平的softmax 函数。在序列生成任务，序列到序列生成是一类十分重要的任务类型。Sutskeveret al. [2014] 最早使用循环神经网络来进行机器翻译，Bahdanau et al. [2014] 使用注意力模型来改进循环神经网络的长期依赖问题，Gehring et al. [2017] 提出了基于卷积神经网络的序列到序列模型。目前最成功的序列到序列模型是全连接的自注意力模型，比如Transformer[Vaswani et al., 2017]。Texar1提供了一个非常好的序列生成工具，提供了很多主流的序列生成模型。习题习题 15-1 证明公式(15.19)。习题 15-2 通过文献了解N 元模型中Good-Turing 平滑，Kneser-Ney 平滑的原理。习题 15-3试通过注意力机制来动态计算公式(15.24)中的权重。习题 15-4 给定一个生成序列“The cat sat on the mat”和两个参考序列“The cat is on the mat”、“The bird sat on the bush”，分别计算BLEU-2 和ROUGE-2得分。习题 15-5 描述束搜索的实现算法。习题 15-6 根据公式(15.89)和(15.95)，计算噪声对比估计的参数梯度，并分析其和重要性采样中参数梯度（公式（15.80））的异同点。1 https://github.com/asyml/texar邱锡鹏：《神经网络与深度学习》https://nndl.github.io/
 3902019 年 4 月 6 日参考文献参考文献Dzmitry Bahdanau, Kyunghyun Cho, andYoshua Bengio. Neural machine translationby jointly learning to align and translate.ArXiv e-prints, September 2014.Andriy Mnih and Yee Whye Teh. A fast andsimple algorithm for training neural prob-abilistic language models. arXiv preprintarXiv:1206.6426, 2012.Frederic Morin and Yoshua Bengio. Hierar-chical probabilistic neural network languagemodel. In Aistats, volume 5, pages 246–252,2005.Samy Bengio, Oriol Vinyals, NavdeepJaitly, and Noam Shazeer. Scheduled sam-pling for sequence prediction with recurrentneural networks. In Advances in Neural In-formation Processing Systems, pages 1171–1179, 2015.Aaron van den Oord, Sander Dieleman,Heiga Zen, Karen Simonyan, Oriol Vinyals,Alex Graves, Nal Kalchbrenner, Andrew Se-nior, and Koray Kavukcuoglu. Wavenet:A generative model for raw audio. arXivpreprint arXiv:1609.03499, 2016.Yoshua Bengio and Jean-Sébastien Senécal.Adaptive importance sampling to acceleratetraining of a neural probabilistic languagemodel. IEEE Transactions on Neural Net-works, 19(4):713–722, 2008.Marc’Aurelio Ranzato, Sumit Chopra,Michael Auli, and Wojciech Zaremba.Sequence level training with recur-rent neural networks. arXiv preprintarXiv:1511.06732, 2015.Yoshua Bengio, Rejean Ducharme, and Pas-cal Vincent. A neural probabilistic languagemodel. Journal of Machine Learning Re-search, 3:1137–1155, 2003.Ilya Sutskever, Oriol Vinyals, and Quoc VVLe. Sequence to sequence learning with neu-ral networks. In Advances in Neural In-formation Processing Systems, pages 3104–3112, 2014.Jonas Gehring, Michael Auli, David Grang-ier, Denis Yarats, and Yann N Dauphin.Convolutional sequence to sequence learn-ing. In Proceedings of the 34th Interna-tional Conference on Machine Learning,pages 1243–1252, 2017.Ashish Vaswani, Noam Shazeer, NikiParmar, Jakob Uszkoreit, Llion Jones,Aidan N. Gomez, Lukasz Kaiser, and IlliaPolosukhin. Attention is all you need. InAdvances in Neural Information ProcessingSystems, pages 6000–6010, 2017.Michael Gutmann and Aapo Hyvärinen.Noise-contrastive estimation: A new esti-mation principle for unnormalized statisti-cal models. In AISTATS, 2010.Arun Venkatraman, Byron Boots, MartialHebert, and J Andrew Bagnell. Data asdemonstrator with applications to systemidentiﬁcation. In ALR Workshop, NIPS,2014.Tomas Mikolov, Martin Karaﬁát, LukasBurget, Jan Cernocky`, and Sanjeev Khu-danpur. Recurrent neural network basedlanguage model. In Interspeech, volume 2,page 3, 2010.RonaldJ Williams and David Zipser. AGeorgeA Miller. Wordnet: a lexicallearning algorithm for continually runningfully recurrent neural networks. Neuralcomputation, 1(2):270–280, 1989.database for english. Communications ofthe ACM, 38(11):39–41, 1995.Andriy Mnih and Koray Kavukcuoglu.Learning word embeddings eﬀciently withnoise-contrastive estimation. In Advancesin Neural Information Processing Systems,pages 2265–2273, 2013.Lantao Yu, Weinan Zhang, Jun Wang, andYong Yu. Seqgan: Sequence generativeadversarial nets with policy gradient. InThirty-First AAAI Conference on ArtiﬁcialIntelligence, 2017.邱锡鹏：《神经网络与深度学习》https://nndl.github.io/
 数学基础本附录介绍一些深度学习涉及的数学基础知识，包括线性代数、微积分、数值优化、概率论和信息论等。A 线性代数线性代数主要包含向量、向量空间（或称线性空间）以及向量的线性变换和有限维的线性方程组。A.1 向量和向量空间A.1.1 向量标量（Scalar）是一个实数，只有大小，没有方向。而向量（Vector）是由一组实数组成的有序数组，同时具有大小和方向。一个n维向量a 是由n个有序实数组成，表示为a = [a , a , · · · , a ],(A.1)12n其中ai 称为向量a 的第i个分量，或第i维。向量符号一般用黑体小写字母a, b, c，或小写希腊字母α, β, γ 等来表示。A.1.2 向量空间向量空间（Vector Space），也称线性空间（Linear Space），是指由向量组成的集合，并满足以下两个条件：1. 向量加法+：向量空间V 中的两个向量a 和 b，它们的和a + b 也属于空间V；2. 标量乘法·：向量空间V 中的任一向量a 和任一标量c，它们的乘积c · a 也属于空间V。

 3922019 年 4 月 6 日附录 A 线性代数欧氏空间 一个常用的线性空间是欧氏空间（Euclidean Space）。一个欧氏空间表示通常为Rn，其中n 为空间维度（Dimension）。欧氏空间中向量的加法和标量乘法定义为：[a , a , · · · , a ] + [b , b , · · · , b ] = [a + b , a + b , · · · , a + b ],(A.2)(A.3)12n12n1122nnc[a , a , · · · , a ] = [ca , ca , · · · , ca ],12n12n其中a, b, c ∈ R 为一个标量。线性子空间 向量空间V 的线性子空间ꢀ 是V 的一个子集，并且满足向量空间的条件（向量加法和标量乘法）。线性无关 线性空间V 中的一组向量{v , v , · · · , v }，如果对任意的一组标量12nλ , λ , · · · , λ ，满足λ v + λ v + · · · + λ v = 0，则必然 λ = λ = · · · =12n1122nn12λ = 0，那么{v , v , · · · , v } 是线性无关的，也称为线性独立的。n12n基向量 向量空间V 的基（Base）B = {e , e , · · · , e } 是V 的有限子集，其元素12n之间线性无关。向量空间V 所有的向量都可以按唯一的方式表达为 B 中向量的线性组合。对任意v ∈ V，存在一组标量(λ , λ , · · · , λ ) 使得12nv = λ e + λ e + · · · + λ e ,(A.4)1122n n其中基B 中的向量称为基向量（Base Vector）。如果基向量是有序的，则标量(λ , λ , · · · , λ ) 称为向量v 关于基B 的坐标（Coordinates）。12nn 维空间V 的一组标准基（Standard Basis）为e1 = [1, 0, 0, · · · , 0],e2 = [0, 1, 0, · · · , 0],· · ·(A.5)(A.6)(A.7)(A.8)en = [0, 0, 0, · · · , 1],V 中的任一向量v = [v , v , · · · , v ] 可以唯一的表示为12n[v , v , · · · , v ] = v e + v e + · · · + v e ,(A.9)12n1122n nv , v , · · · , v 也称为向量v 的笛卡尔坐标（Cartesian Coordinate）。向12n量空间中的每个向量可以看作是一个线性空间中的笛卡儿坐标。内积 一个n 维线性空间中的两个向量a 和 b，其内积为Σn⟨⟩a, b =aibi,(A.10)i= 1邱锡鹏：《神经网络与深度学习》https://nndl.github.io/
 A.1 向量和向量空间2019 年 4 月 6 日393邱锡鹏：《神经网络与深度学习》https://nndl.github.io/
 3942019 年 4 月 6 日附录 A 线性代数邱锡鹏：《神经网络与深度学习》https://nndl.github.io/
 p = 1p = 2p= ∞p=12图 A.1 常见的范数。红线表示不同范数的ℓp = 1 的点。正交 如果向量空间中两个向量的内积为0，则它们正交（Orthogonal）。如果向量空间中一个向量v 与子空间ꢀ 中的每个向量都正交，那么向量v 和子空间ꢀ 正交。A.1.3 范数范数（Norm）是一个表示向量“长度”的函数，为向量空间内的所有向量赋予非零的正长度或大小。对于一个n 维向量v，一个常见的范数函数为ℓp 范数，Σn1/pℓ (v) ≡ ∥v∥ =|vi|p,(A.11)ppi=1其中p ≥ 0 为一个标量的参数。常用的p 的取值有1，2，∞ 等。ℓ 范数 ℓ 范数为向量的各个元素的绝对值之和。11n|∥ ∥v| vi .=(A.12)(A.13)1i= 1ℓ 范数 ℓ 范数为向量的各个元素的22.Σn√∥v 2 = ∥v2 = vTv.ii=1ℓ2 范数又称为Euclidean 范数或者Frobenius 范数。从几何角度，向量也可以表示为从原点出发的一个带箭头的有向线段，其ℓ2 范数为线段的长度，也常称为向量的模。ℓ∞ 范数 ℓ∞ 范数为向量的各个元素的最大绝对值，∥v∥∞ = max{v , v , · · · , v }.(A.14)12n图A.1给出了常见范数的示例。邱锡鹏：《神经网络与深度学习》https://nndl.github.io/
 3942019 年 4 月 6 日附录 A 线性代数A.1.4 常见的向量全 0 向量指所有元素都为0 的向量，用0 表示。全0 向量为笛卡尔坐标系中的原点。全 1 向量指所有值为1 的向量，用1 表示。one-hot 向量为有且只有一个元素为1，其余元素都为0 的向量。one-hot 向量是在数字电路中的一种状态编码，指对任意给定的状态，状态寄存器中只有l位为1，其余位都为0。A.2 矩阵A.2.1 线性映射线性映射（Linear Mapping）是指从线性空间V 到线性空间ꢀ 的一个映射函数f : V → ꢀ，并满足：对于V 中任何两个向量u 和v 以及任何标量c，有f(u + v) = f(u) + f(v),f(cv) = cf(v).(A.15)(A.16)两个有限维欧氏空间的映射函数f : Rn → Rm可以表示为a x + a x + · · · + a x1n n111122a x + a x + · · · + a x2n n,211222y = Ax,(A.17)..am1x1 + am2x2 + · · · + amnxn其中A定义为m×n的矩阵（Matrix），是一个由m行n列元素排列成的矩形阵列。一个矩阵A 从左上角数起的第i 行第j 列上的元素称为第i, j 项，通常记为[A]ij 或aij 。矩阵A 定义了一个从Rn 到Rm的线性映射；向量x ∈Rn和y ∈ Rm分别为两个空间中的列向量，即大小为n × 1 的矩阵。x1x2.y1y2  . x =,y =.(A.18).xnym如果没有特别说明，本书默认向量为列向量。为简化书写、方便排版起见，本书约定逗号隔离的向量表示[x , x , · · · , x ]12n为行向量，列向量通常用分号隔开的表示x = [x ; x ; · · · ; x ]，或行向量的转12n置[x , x , · · · , x ]T 。12n邱锡鹏：《神经网络与深度学习》https://nndl.github.io/
 A.2 矩阵2019 年 4 月 6 日395A.2.2 矩阵操作加 如果A 和B 都为m × n 的矩阵，则A 和B 的加也是m × n 的矩阵，其每个元素是A 和 B 相应元素相加。[A + B]ij = aij + bij .(A.19)乘积 假设有两个A 和 B 分别表示两个线性映射g : Rm → Rk和f : Rn → Rm，则其复合线性映射(g ◦ f)(x) = g(f(x)) = g(Bx) = A(Bx) = (AB)x,其中AB 表示矩阵A 和B 的乘积，定义为(A.20)(A.21)Σm[AB]ij =aik bkj .k=1两个矩阵的乘积仅当第一个矩阵的列数和第二个矩阵的行数相等时才能定义。如 A 是 k × m 矩阵和B 是 m × n 矩阵，则乘积AB 是一个k × n 的矩阵。矩阵的乘法满足结合律和分配律：• 结合律：(AB)C = A(BC),• 分配律：(A + B)C = AC + BC，C(A + B) = CA + CB.Hadamard 积 A 和 B 的 Hadamard 积，也称为逐点乘积，为A 和 B 中对应的元素相乘。[A ⊙B]ij = aij bij .(A.22)一个标量c 与矩阵A 乘积为A 的每个元素是A 的相应元素与c 的乘积[cA]ij = caij .(A.23)转置 m × n 矩阵A 的转置（Transposition）是一个n × m 的矩阵，记为AT ，A的第i 行第j 列的元素是原矩阵A 的第j 行第i 列的元素，T[AT ]ij= [A]ji.(A.24)向量化 矩阵的向量化是将矩阵表示为一个列向量。这里，vec 是向量化算子。设A = [aij ]m ×n ，则vec(A) = [a , a , · · · , a , a , a , · · · , am 2, · · · , a1n , a2n , · · · , amn]T .11 21m 1 12 22邱锡鹏：《神经网络与深度学习》https://nndl.github.io/
 3962019 年 4 月 6 日附录 A 线性代数迹 方块矩阵A 的对角线元素之和称为它的迹（Trace），记为tr(A)。尽管矩阵的乘法不满足交换律，但它们的迹相同，即tr(AB) = tr(BA)。行列式 方块矩阵A 的行列式是一个将其映射到标量的函数，记作det(A) 或|A|。行列式可以看做是有向面积或体积的概念在欧氏空间中的推广。在n中，行列式描述的是一个线性变换对“体积”所造成的影响。维欧氏空间一个n × n 的方块矩阵A 的行列式定义为：Σsgn(σ) Yn ai,σ(i)det(A) =(A.25)σ∈Sni=1其中Sn 是 {1, 2, ..., n} 的所有排列的集合，σ 是其中一个排列，σ(i) 是元素i 在排列σ 中的位置，sgn(σ) 表示排列σ 的符号差，定义为1σ中的逆序对有偶数个(σ) =(A.26) −1 σ中的逆序对有奇数个其中逆序对的定义为：在排列σ 中，如果有序数对(i, j) 满足1 ≤ i < j ≤ n 但σ(i) > σ(j)，则其为σ 的一个逆序对。秩 一个矩阵 A 的列秩是 A 的线性无关的列向量数量，行秩是 A 的线性无关的行向量数量。一个矩阵的列秩和行秩总是相等的，简称为秩（Rank）。一个m×n 的矩阵的秩最大为min(m, n)。两个矩阵的乘积AB 的秩rank(AB) ≤min rank(A), rank(B) 。范数 矩阵的范数有很多种形式，其中常用的ℓp 范数定义为Σ Σmn1/p∥A∥p =|a |pij.(A.27)i=1 j=1A.2.3 矩阵类型对称矩阵 对称矩阵（Symmetric Matrix）指其转置等于自己的矩阵，即满足A = AT。对角矩阵 对角矩阵（Diagonal Matrix）是一个主对角线之外的元素皆为0 的矩阵。对角线上的元素可以为0 或其他值。一个n × n 的对角矩阵A 满足：[A]ij = 0 if ij∀i, j ∈ {1, · · · , n}(A.28)对角矩阵A 也可以记为diag(a)，a 为一个n 维向量，并满足[A]ii = ai.(A.29)邱锡鹏：《神经网络与深度学习》https://nndl.github.io/
 A.2 矩阵2019 年 4 月 6 日397n × n 的对角矩阵A = diag(a) 和n 维向量b 的乘积为一个n 维向量Ab = diag(a)b = a ⊙ b,(A.30)其中⊙表示点乘，即(a ⊙b)i = aibi。单位矩阵 单位矩阵（Identity Matrix）是一种特殊的的对角矩阵，其主对角线元素为1，其余元素为0。n 阶单位矩阵In，是一个n × n 的方块矩阵。可以记为 In = diag(1, 1, ..., 1)。一个m × n 的矩阵A 和单位矩阵的乘积等于其本身。AI = I A = A.(A.31)nm逆矩阵 对于一个n × n 的方块矩阵A，如果存在另一个方块矩阵B 使得AB = BA = In(A.32)为单位阵，则称A 是可逆的。矩阵B 称为矩阵A 的逆矩阵（Inverse Matrix），记为A−1。一个方阵的行列式等于0 当且仅当该方阵不可逆。正定矩阵 对于一个 n × n 的对称矩阵 A，如果对于所有的非零向量 x ∈ Rn都满足x Ax > 0,T(A.33)则 A 为正定矩阵（Positive-Deﬁnite Matrix）。如果x Ax ≥ 0，则A 是半正定T矩阵（Positive-Semideﬁnite Matrix）。正交矩阵 正交矩阵（Orthogonal Matrix ）A 为一个方块矩阵，其逆矩阵等于其转置矩阵。AT = A−1,(A.34)等价于AA = AA = In。TTGram 矩阵 向量空间中一组向量 v , v · · · , v 的 Gram 矩阵（Gram Matrix）12nG 是内积的对称矩阵，其元素G 为 v v 。TiijjA.2.4 特征值与特征矢量如果一个标量λ 和一个非零向量v 满足Av = λv,(A.35)则λ和v分别称为矩阵A 的特征值（Eigenvalue）和特征向量（Eigenvector）。邱锡鹏：《神经网络与深度学习》https://nndl.github.io/
 3982019 年 4 月 6 日附录 A 线性代数A.2.5 矩阵分解一个矩阵通常可以用一些比较“简单”的矩阵来表示，称为矩阵分解（MatrixDecomposition, Matrix Factorization）。奇异值分解 一个m×n 的矩阵A的奇异值分解（Singular Value Decomposition，SVD）定义为A = U ΣVT,(A.36)其中U 和 V 分别为m × m 和 n × n 的正交矩阵，Σ 为 m × n 的对角矩阵，其对角线上的元素称为奇异值（Singular Value）。特征分解 一个n × n 的方块矩阵A 的特征分解（Eigendecomposition）定义为A = QΛQ−1,(A.37)其中Q 为n × n 的方块矩阵，其每一列都为A 的特征向量， 为对角阵，其每一个对角元素为A 的特征值。如果A 为对称矩阵，则A 可以被分解为A = QΛQT,(A.38)其中Q 为正交阵。邱锡鹏：《神经网络与深度学习》https://nndl.github.io/
 2019 年 4 月 6 日399B 微积分B.1 导数导数（Derivative）是微积分学中重要的基础概念。对于定义域和值域都是实数域的函数f : R → R，若f (x) 在点x0 的某个邻域 ∆x 内，极限f(x  + ∆x) − f(x )f′(x0) = lim00(B.1)∆x∆x→0存在，则称函数f (x) 在点x 处可导，f ′(x ) 称为其导数，或导函数，也可以记00df (x )为0。dx在几何上，导数可以看做函数曲线上的切线斜率。图B.1给出了一个函数导数的可视化示例，其中函数g(x) 的斜率为函数f (x) 在点x 的导数，∆y = f (x +∆x) − f (x)。y3g(x)2f (x) = log(x) + 1∆y1∆x0x0123图 B.1 函数f(x) = log(x) + 1 的导数给定一个连续函数，计算其导数的过程称为微分（Diﬀerentiation）。微分的逆过程为积分（Integration）。函数f(x)的积分可以写为∫F (x) = f (x)dx,(B.2)邱锡鹏：《神经网络与深度学习》https://nndl.github.io/
 4002019 年 4 月 6 日附录 B 微积分其中F (x) 称为f(x) 的原函数。若函数f(x) 在其定义域包含的某区间内每一个点都可导，那么也可以说函数 f (x) 在这个区间内可导。如果一个函数 f (x) 在定义域中的所有点都存在导数，则f (x) 为可微函数（Diﬀerentiable Function）。可微函数一定连续，但连续函数不一定可微。例如函数|x| 为连续函数，但在点x = 0 处不可导。表B.1给出了几个常见函数的导数。函数函数形式导数常函数f (x) = C，其中C 为常数f (x) = xr，其中r 是非零实数f(x) = exp(x)f′(x) = 0幂函数f′(x) = rxr−1指数函数f ′(x) = exp(x)对数函数 f(x) = log(x)表 B.1 几个常见函数的导数f ′(x) =1x高阶导数 对一个函数的导数继续求导，可以得到高阶导数。函数 f (x) 的导数2f (x)f ′(x) 称为一阶导数，f ′(x) 的导数称为二阶导数，记为f ′′(x) 或 dd。偏导数 对于一个多变量函数f : Rd → R，它的偏导数（Partial Derivative ）是关于其中一个变量xi 的导数，而保持其他变量固定，可以记为f (x)，′ꢀ f(x)，xixi∂f(x)∂或f(x)。∂xi∂xi对于一个d 维向量x ∈ Rd，函数的偏导数为f(x) = f(x , · · · , x ) ∈ R，则f(x) 关于x1d∂f(x)∂x1.∂f(x)∂x ∈ Rd.(B.3)=∂f(x)∂xd若函数f (x) ∈ Rk 的值也为一个向量，则f (x) 关于x 的偏导数为∂f1(x) · · · ∂fk (x)1∂x∂x1∂f(x)∂x=.∈ Rd×k.(B.4)...∂f1(x)∂fk∂xd称为Jacobian 矩阵。邱锡鹏：《神经网络与深度学习》https://nndl.github.io/
 (x)∂xd· · ·邱锡鹏：《神经网络与深度学习》https://nndl.github.io/
 402 B.1 导数2019 年2 041 9月年64日月 6 日附录 B 微积分401B.1.1 导数法则一个复杂函数的导数的计算可以通过以下法则来简化。B.1.1.1 加（减）法则y = f(x),z = g(x) 则∂(y + z)∂x∂y ∂z=+.(B.5)(B.6)∂x∂xB.1.1.2 乘法法则（1） 若 x ∈ Rp，y = f(x) ∈ Rq，z = g(x) ∈ Rq，则∂yTz∂y∂z∂x=z +∂xy.∂x（2）若 x ∈ Rp，y = f (x) ∈ Rs，z = g(x) ∈ Rt，A ∈ Rs×t 和 x 无关，则∂yTAz∂y Az +∂x∂z∂xAT y.(B.7)=∂x（3） 若 x ∈ Rp，y = f(x) ∈ R z = g(x) ∈ Rp，，则∂yz∂z ∂y= y+z .T(B.8)∂x∂x∂xB.1.1.3 链式法则链式法则（Chain Rule），是求复合函数导数的一个法则，是在微积分中计算导数的一种常用方法1。（1） 若 x ∈ Rp，y = g(x) ∈ Rs z = f (y) ∈ Rt，∂z，则∂y ∂z=.(B.9)∂x∂x ∂y（2） 若 X ∈ Rp×q 为矩阵，Y = g(X) ∈ Rs×t，ꢀ = f(Y ) ∈ R，则∂ꢀ∂ꢀ∂YT= tr().(B.10)(B.11)∂Xij∂Y ∂Xij（3） 若 X ∈ Rp×q 为矩阵，y = g(X) ∈ Rs，ꢀ = f (y) ∈ R，则∂ꢀ∂ꢀ∂y .T= ()∂X∂y ∂Xijij（4） 若 x ∈ R，u = u(x) ∈ R ，pgg = g(u) ∈ Rq，则∂g ∂uT∂=.(B.12)∂x∂u ∂x1详细的矩阵偏导数参考https://en.wikipedia.org/wiki/Matrix_calculus。邱锡鹏：《神经网络与深度学习》https://nndl.github.io/
 

 4022019 年 4 月 6 日附录 B 微积分B.2 常见函数的导数这里我们介绍本书中常用的几个函数。B.2.1 向量函数及其导数∂x= I,= A(B.13)(B.14)∂x∂AxT,∂x∂x AT= A(B.15)∂xB.2.2 按位计算的向量函数及其导数假设一个函数f(x) 的输入是标量x。对于一组K 个标量x , · · · , x ，我们1K可以通过f (x) 得到另外一组K 个标量ꢀ1, · · · , ꢀK ，ꢀ = f(x ), ∀k = 1, · · · , K(B.16)(B.17)kk为了简便起见，我们定义x = [x , · · · , xK ]T ，z = [ꢀ , · · · , ꢀK ]T ，11z = f(x),其中，f (x) 是按位运算的，即[f (x)]i = f (xi)。当x 为标量时，f (x)的导数记为f ′(x)。当输入为K 维向量x = [x1, · · · , xK ]T时，其导数为一个对角矩阵。i∂f (x)∂xh  f∂ (xj )=(B.18)∂xi K × Kf (x )0· · ·0′1(B.19)=0.f′(x2) · · ·0...邱锡鹏：《神经网络与深度学习》https://nndl.github.io/
 00· · · f ′(xK)= diag(f ′(x)).(B.20)B.2.3 Logistic 函数Logistic 函数是一种常用的S 形函数，是比利时数学家 Pierre François Ver-hulst 在 1844-1845 年研究种群数量的增长模型时提出命名的，最初作为一种生态学模型。邱锡鹏：《神经网络与深度学习》https://nndl.github.io/

 404 B.2 常见函数的导数2019 年2 041 9月年64日月 6 日附录 B 微积分 403邱锡鹏：《神经网络与深度学习》https://nndl.github.io/
 21.51k = 1 x 0 = 0 L = 1k = 2, x 0 = 0, L = 1k = 2, x 0 = 0, L = 2k = 1, x 0 = 0, L = 20.5邱锡鹏：《神经网络与深度学习》https://nndl.github.io/
 −10−505104062019 年 4 月 6 日附录 B 微积分图 B.2 Logistic 函数Logistic 函数定义为：logistic(x) =L,(B.21)1 + exp(−k(x − x ))0这里exp(·) 函数表示自然对数，x0 是中心点，L 是最大值，k 是曲线的倾斜度。图B.2给出了几种不同参数的logistic 函数曲线。当x 趋向于−∞ 时，logistic(x)接近于0；当x 趋向于+∞ 时，logistic(x) 接近于L.当参数为(k = 1, x0 = 0, L = 1) 时，logistic 函数称为标准logistic 函数，记为 σ(x)。1σ(x) =.(B.22)1 + exp(−x)标准logistic 函数在机器学习中使用得非常广泛，经常用来将一个实数空间的数映射到(0, 1) 区间。标准logistic 函数的导数为σ′(x) = σ(x)(1 − σ(x))(B.23)当输入为K 维向量x = [x1, · · · , xK ]T 时，其导数为σ′(x) = diag σ(x) ⊙ (1 − σ(x)) .(B.24)(B.25)B.2.4 softmax 函数softmax 函数是将多个标量映射为一个概率分布。对于K 个标量x1, · · · , xK ，softmax 函数定义为exp(xk)= softmax(xk) =Σ,kKexp(xi)i=1邱锡鹏：《神经网络与深度学习》https://nndl.github.io/
 

 4042019 年 4 月 6 日附录 B 微积分这样，我们可以将K 个变量x , · · · , xK 转换为一个分布：ꢀ , · · · , ꢀK ，满足11ΣKꢀk ∈ [0, 1], ∀k,= 1.(B.26)ki= 1当softmax 函数的输入为K 维向量x 时，ˆ = softmax(x)(B.27)(B.28)x )1 exp(1= Σ K.exp(x )kk=1exp(xK )exp(x)(B.29)(B.30)= Σ Kexp(xk)k=1exp(x)1 exp(x)=,TK其中，1K = [1, · · · , 1]K ×1 是K 维的全1 向量。其导数为∂exp(x)∂ soft∂mxax(x)1 T exp(x)=K(B.31)∂x∂11∂ exp(x)1Tx)=+K∂x1TKexp(x) ∂xexp((exp(x))Texp(x)(B.32)(B.33)diag (exp(x))1∂ 1T=(exp(x))TKKK−1Texp(x)(1Texp(x))2∂x邱锡鹏：《神经网络与深度学习》https://nndl.github.io/
 diag (exp(x))1diag (exp(x)) 1K = exp(x)==−−diag (exp(x)) 1 (Kexp(x))T(B.34)(B.35)1Texp(x)(1TKexp(x))2Kdiag (exp(x))exp(x)1exp(x) (exp(x))T(exp(x))T1T(1TKexp(x))2Kexp(x)exp(x)exp(x)1 exp(x) 1 exp(x)K K−·T= diag(B.36)(B.37)1TTK= diag (softmax(x)) − softmax(x) softmax(x)T.邱锡鹏：《神经网络与深度学习》https://nndl.github.io/
 4062019 年2 041 9月年64日月 6 日附录 B 微积分 405C 数学优化数学优化（Mathematical Optimization）问题，也叫最优化问题，是指在一定约束条件下，求解一个目标函数的最大值（或最小值）问题。数学优化问题的定义为：给定一个目标函数（也叫代价函数）f : A → R，寻找一个变量（也叫参数）x∗ ∈ D，使得对于所有 D 中的 x，f(x∗) ≤ f(x)（最小化）；或者f (x∗) ≥f (x)（最大化），其中D 为变量x 的约束集，也叫可行域； D中的变量被称为是可行解。C.1 数学优化的类型C.1.1 离散优化和连续优化根据输入变量x 的值域是否为实数域，数学优化问题可以分为离散优化问题和连续优化问题。C.1.1.1 离散优化问题离散优化（Discrete Optimization）问题是目标函数的输入变量为离散变量，比如为整数或有限集合中的元素。离散优化问题主要有两个分支：1. 组合优化（Combinatorial Optimization）：其目标是从一个有限集合中找出使得目标函数最优的元素。在一般的组合优化问题中，集合中的元素之间存在一定的关联，可以表示为图结构。典型的组合优化问题有旅行商问题、最小生成树问题、图着色问题等。很多机器学习问题都是组合优化问题，比如特征选择、聚类问题、超参数优化问题以及结构化学习（Structured Learning）中标签预测问题等。2. 整数规划（Integer Programming）：输入变量x ∈ Zd 为整数。一般常见的整数规划问题为整数线性规划（Integer Linear Programming，ILP）。整数线性规划的一种最直接的求解方法是：（1）去掉输入必须为整数的限制，将原问题转换为一般的线性规划问题，这个线性规划问题为原问题的松弛问题；（2）求得相应松弛问题的解；（3）把松弛问题的解四舍五入到最接近的整数。但是这种方法得到的解一般都不是最优的，因此原问题的最优解不一定在松弛问题最优解的附近。另外，这种方法得到的解也不一定满足约束条件。离散优化问题的求解一般都比较困难，优化算法的复杂度都比较高。邱锡鹏：《神经网络与深度学习》https://nndl.github.io/
 

 4062019 年 4 月 6 日附录 C 数学优化C.1.1.2 连续优化问题连续优化（Continuous Optimization）问题是目标函数的输入变量为连续变量x ∈ Rd，即目标函数为实函数。本节后面的内容主要以连续优化为主。C.1.2 无约束优化和约束优化在连续优化问题中，根据是否有变量的约束条件，可以将优化问题分为无约束优化问题和约束优化问题。无约束优化问题（UnconstrainedD = Rd，可以写为Optimization）的可行域为整个实数域最优化问题一般可以表示为求最小值问题。求f (x) 最大值等价于求−f (x) 的最小值。min f(x)(C.1)x其中x ∈ Rd 为输入变量，f : Rd → R 为目标函数。约束优化问题（Constrained Optimization）中变量x 需要满足一些等式或不等式的约束。约束优化问题通常使用拉格朗日乘数法来进行求解。拉 格 朗 日 乘 数 法 参 见第C.3节。C.1.3 线性优化和非线性优化如果在公式(C.1)中，目标函数和所有的约束函数都为线性函数，则该问题为线性规划问题（Linear Programming）。相反，如果目标函数或任何一个约束函数为非线性函数，则该问题为非线性规划问题（Nonlinear Programming）。在非线性优化问题中，有一类比较特殊的问题是凸优化问题（Convex Pro-gramming）。在凸优化问题中，变量x 的可行域为凸集，即对于集合中任意两点，它们的连线全部位于在集合内部。目标函数f 也必须为凸函数，即满足f(αx + (1 − α)y) ≤ αf(x) + (1 − α)f(y), ∀α ∈ [0, 1].(C.2)凸优化问题是一种特殊的约束优化问题，需满足目标函数为凸函数，并且等式约束函数为线性函数，不等式约束函数为凹函数。C.2 优化算法优化问题一般都是通过迭代的方式来求解：通过猜测一个初始的估计x0，然后不断迭代产生新的估计x , x , · · · x ，希望x 最终收敛到期望的最优解x 。∗12tt一个好的优化算法应该是在一定的时间或空间复杂度下能够快速准确地找到最优解。同时，好的优化算法受初始猜测点的影响较小，通过迭代能稳定地找到最优解x∗ 的邻域，然后迅速收敛于x∗。邱锡鹏：《神经网络与深度学习》https://nndl.github.io/
 C.2 优化算法2019 年 4 月 6 日407优化算法中常用的迭代方法有线性搜索和置信域方法等。线性搜索的策略是寻找方向和步长，具体算法有梯度下降法、牛顿法、共轭梯度法等。本书中只介绍梯度下降法。C.2.0.1 全局最优和局部最优对于很多非线性优化问题，会存在若干个局部的极小值。局部最小值，或局部最优解x∗ 定义为：存在一个 δ > 0，对于所有的满足∥x − x∗∥ ≤ δ 的x，公式f (x∗) ≤ f (x) 成立。也就是说，在x∗ 的附近区域内，所有的函数值都大于或者等于f(x∗)。对于所有的x ∈ A，都有f (x∗) ≤ f (x) 成立，则x∗ 为全局最小值，或全局最优解。一般的，求局部最优解是容易的，但很难保证其为全局最优解。对于线性规划或凸优化问题，局部最优解就是全局最优解。要确认一个点x∗ 是否为局部最优解，通过比较它的邻域内有没有更小的函数值是不现实的。如果函数f(x) 是二次连续可微的，我们可以通过检查目标函数在点x∗ 的梯度ꢀf(x∗)和Hessian矩阵ꢀ2f(x∗) 来判断。定理 C.1 – 局部最小值的一阶必要条件： 如果 x∗ 为局部最优解并且函数f 在x∗ 的邻域内一阶可微，则在ꢀf (x∗) = 0。证明. 如果函数f (x)是连续可微的，根据泰勒展开公式（Taylor’s Formula），函数 f(x) 的一阶展开可以近似为f(x∗ + △x) = f(x∗) + △xꢀf (x∗),(C.3)T假设ꢀf (x∗) = 0，则可以找到一个△x（比如△x = −αꢀf (x∗)，α 为很小的正数），使得f(x∗ + △x) − f (x∗) = △xꢀf (x∗) ≤ 0.(C.4)T这和局部最优的定义矛盾。定理 C.2 – 局部最优解的二阶必要条件： 如果 x∗ 为局部最优解并且函数f 在 x∗ 的邻域内二阶可微，则在ꢀf (x∗) = 0，ꢀ2f (x∗)为半正定矩阵。证明. 如果函数f (x) 是二次连续可微的，函数f (x) 的二阶展开可以近似为1f (x∗ + △x) = f (x∗) + △xꢀf (x∗) + △x(ꢀ2f (x∗))△x.(C.5)TT2邱锡鹏：《神经网络与深度学习》https://nndl.github.io/
 4082019 年 4 月 6 日附录 C 数学优化由一阶必要性定理可知ꢀf (x∗) = 0，则12f(x∗ + △x) − f (x∗) = △x(ꢀ2f (x∗))△x ≥ 0.(C.6)T即ꢀ2f (x∗) 为半正定矩阵。C.2.0.2 梯度下降法梯度下降法（Gradient Descent Method），也叫最速下降法（Steepest De-scend Method），经常用来求解无约束优化的极小值问题。对于函数f (x)，如果f (x) 在点xt 附近是连续可微的，那么f (x) 下降最快的方向是 f(x) 在xt 点的梯度方法的反方向。根据泰勒一阶展开公式，f (xt+1) = f (x + △x) ≈ f (x ) + △xTꢀf (xt).(C.7)tt要使得f (xt+1) < f (xt)，就得使△xT ꢀf (x ) < 0。我们取△x = −αꢀf (x )。tt如果α > 0 为一个够小数值时，那么 f(xt+1) < f(xt) 成立。这样我们就可以从一个初始值x0 出发，通过迭代公式xt+1 = x − α ꢀf (x ), t ≥ 0.(C.8)(C.9)ttt生成序列 x , x , x , . . . 使得012f(x ) ≥ f(x ) ≥ f(x ) ≥ · · ·012如果顺利的话，序列 (x ) 收敛到局部最优解x 。注意每次迭代步长∗α可以n改变，但其取值必须合适，如果过大就不会收敛，如果过小则收敛速度太慢。梯度下降法的过程如图C.1所示。曲线是等高线（水平集），即函数f 为不同常数的集合构成的曲线。红色的箭头指向该点梯度的反方向（梯度方向与通过该点的等高线垂直）。沿着梯度下降方向，将最终到达函数f 值的局部最优解。邱锡鹏：《神经网络与深度学习》https://nndl.github.io/
 C.3 拉格朗日乘数法与KKT 条件2019 年 4 月 6 日409x0x1x2x3x4图 C.1 梯度下降法梯度下降法为一阶收敛算法，当靠近极小值时梯度变小，收敛速度会变慢，并且可能以“之字形”的方式下降。如果目标函数为二阶连续可微，我们可以采用牛顿法。牛顿法为二阶收敛算法，收敛速度更快，但是每次迭代需要计算Hessian矩阵的逆矩阵，复杂较高。相反，如果我们要求解一个最大值问题，就需要向梯度正方向迭代进行搜索，逐渐接近函数的局部极大值点，这个过程则被称为梯度上升法（GradientAscent）。C.3 拉格朗日乘数法与KKT 条件拉格朗日乘数法（Lagrange Multiplier）是约束优化问题的一种有效求解方法。约束优化问题可以表示为以数学家约瑟夫·拉格朗日命名。minxf (x)(C.10)(C.11)hi(x)= 0, i = 1, . . . , msubject togj (x) ≤ 0, j = 1, . . . , n其中hi(x) 为等式约束函数，gj (x) 为不等式约束函数。x 的可行域为\ \mnD = domf ∩domh ∩domg ⊆ Rd ,jii= 1j=1其中domf 是函数f 的定义域。邱锡鹏：《神经网络与深度学习》https://nndl.github.io/
 4102019 年 4 月 6 日附录 C 数学优化C.3.1 等式约束优化问题如果公式(C.10)中只有等式约束，我们可以构造一个拉格朗日函数Λ(x, λ)ΣmΛ(x, λ) = f(x) +λ h (x),(C.12)iii= 1其中 λ 为拉格朗日乘数，可以是正数或负数。如果 f (x∗) 是原始约束优化问题的局部最优值，那么存在一个λ∗ 使得(x∗, λ∗) 为拉格朗日函数Λ(x, λ) 的平稳点（stationary point）。因此，只需要令 ∂Λ(x,λ) =0和∂Λ(x,λ) =0，得到∂x∂λ平稳点是指一阶偏导数为 0的点。平稳点不一定为极值mΣꢀf (x) + λ ꢀh (x) = 0,(C.13)(C.14)点。iii=1hi(x) = 0,i = 0, · · · , m上面方程组的解即为原始问题的可能解。在实际应用中，需根据问题来验证是否为极值点。拉格朗日乘数法是将一个有d 个变量和m 个等式约束条件的最优化问题转换为一个有d + m 个变量的函数求平稳点的问题。拉格朗日乘数法所得的平稳点会包含原问题的所有极值点，但并不保证每个平稳点都是原问题的极值点。C.3.2 不等式约束优化问题对于公式(C.10)中定义的一般约束优化问题，其拉格朗日函数为ΣmΣnΛ(x, a, b) = f (x) +a h (x) +i ibj gj (x),(C.15)i=1j=1不等式约束优化问题中的拉格朗日乘数也称为KKT 乘数。其中a = [a1, · · · , am ]T 为等式约束的拉格朗日乘数，b = [b , · · · , b ]T 为不等式1n约束的拉格朗日乘数。当约束条件不满足时，有maxa,b Λ(x, a, b) = ∞；当约束条件满足时并且b ≥ 0 时，maxa,b Λ(x, a, b) = f (x)。因此原始约束优化问题等价于min maxΛ(x, a, b),b ≥ 0,(C.16)(C.17)xa,bsubject to这个min-max 优化问题称为主问题（Primal Problem）。对偶问题 主问题的优化一般比较困难，我们可以通过交换min-max 的顺序来简化。定义拉格朗日对偶函数为Γ(a, b) = inf Λ(x, a, b).(C.18)x∈D邱锡鹏：《神经网络与深度学习》https://nndl.github.io/
 C.3 拉格朗日乘数法与KKT 条件2019 年 4 月 6 日411Γ(a, b) 是一个凹函数，即使f (x) 是非凸的。当b ≥ 0时，对于任意的x˜ ∈ D，有Γ(a, b) = inf Λ(x, a, b) ≤ Λ(x˜, a, b) ≤ f (x˜),(C.19)x∈D令p∗ 是原问题的最优值，则有Γ(a, b) ≤ p∗,即拉格朗日对偶函数Γ(a, b) 为原问题最优值的下界。(C.20)优化拉格朗日对偶函数Γ(a, b) 并得到原问题的最优下界，称为拉格朗日对偶问题（Lagrange Dual Problem）。maxΓ(a, b),b ≥ 0.(C.21)(C.22)a,bsubject to拉格朗日对偶函数为凹函数，因此拉格朗日对偶问题为凸优化问题。令 d∗ 是拉格朗日对偶问题的最优值，则有d∗ ≤ p∗，这个性质称为弱对偶性（WeakDuality）。如果d∗ = p∗，这个性质称为强对偶性（Strong Duality）。当强对偶性成立时，令x∗ 和a∗, b∗ 分别是原问题问题和对偶问题的最优解，那么它们满足以下条件：mΣnΣꢀf (x∗) +a∗ꢀhi(x∗) +b ꢀg (x∗) = 0,(C.23)jji=1j=1hi(x∗) = 0,i = 0, · · · , mj = 0, · · · , nj = 0, · · · , nj = 0, · · · , n(C.24)(C.25)(C.26)(C.27)∗ ≤ ,gj (x )0∗ = ,bj gj (x )bj ≥ 0,0称为不等式约束优化问题的KKT条件（Karush-Kuhn-Tucker Conditions）。KKT条件是拉格朗日乘数法在不等式约束优化问题上的泛化。当原问题是凸优化问题时，满足KKT 条件的解也是原问题和对偶问题的最优解。KKT条件中需要关注的是公式(C.26)，称为互补松弛条件（ComplementarySlackness）。如果最优解x 出现在不等式约束的边界上gj (x) 0，则bj>0；∗=如果x∗ 出现在不等式约束的内部gj (x) 0，则bj 0。互补松弛条件说明当最优<=解出现在不等式约束的内部，则约束失效。关于数学优化的内容，可以阅读《Numerical Optimization》[Nocedal andWright, 2006] 和《Convex Optimization》[Boyd and Vandenberghe, 2004]。邱锡鹏：《神经网络与深度学习》https://nndl.github.io/
 4122019 年 4 月 6 日附录 D 概率论D 概率论概率论主要研究大量随机现象中的数量规律，其应用十分广泛，几乎遍及各个领域。D.1 样本空间样本空间是一个随机试验所有可能结果的集合。例如，如果抛掷一枚硬币，那么样本空间就是集合{正面，反面}。如果投掷一个骰子，那么样本空间就是{1, 2, 3, 4, 5, 6}。随机试验中的每个可能结果称为样本点。有些试验有两个或多个可能的样本空间。例如，从52 张扑克牌中随机抽出一张，样本空间可以是数字（A 到 K），也可以是花色（黑桃，红桃，梅花，方块）。如果要完整地描述一张牌，就需要同时给出数字和花色，这时样本空间可以通过构建上述两个样本空间的笛卡儿乘积来得到。数学小知识 | 笛卡儿乘积在数学中，两个集合X 和 Y 的笛卡儿乘积（Cartesian product），又称直积，在集合论中表示为X × Y，是所有可能的有序对组成的集合，其中有序对的第一个对象是X 的成员，第二个对象是Y 的成员。X × Y = {⟨x, y⟩ | x ∈ X ∧ y ∈ Y} .♣比如在扑克牌的例子中，如果集合X 是13 个元素的点数集合{A, K, Q,J, 10, 9, 8, 7, 6, 5, 4, 3, 2}，而集合Y 是 4 个元素的花色集合{♠,Y,♦,W}，则这两个集合的笛卡儿积是有 52 个元素的标准扑克牌的集合{(A,♠), (K, ♠), ..., (2, ♠), (A, Y), ..., (3, W), (2, W)}。D.2 事件和概率随机事件（或简称事件）指的是一个被赋予概率的事物集合，也就是样本空间中的一个子集。概率（Probability）表示一个随机事件发生的可能性大小，为0 到1 之间的一个非负实数。比如，一个0.5 的概率表示一个事件有50% 的可能性发生。邱锡鹏：《神经网络与深度学习》https://nndl.github.io/
 D.2 事件和概率2019 年 4 月 6 日413对于一个机会均等的抛硬币动作来说，其样本空间为“正面”或“反面”。 我们可以定义各个随机事件，并计算其概率。比如，• {正面}，其概率为0.5；• {反面}，其概率为0.5；• 空集∅，不是正面也不是反面，其概率为0；• {正面| 反面}，不是正面就是反面，其概率为1。D.2.1 随机变量在随机试验中，试验的结果可以用一个数 X 来表示，这个数 X 是随着试验结果的不同而变化的，是样本点的一个函数。我们把这种数称为随机变量（Random Variable）。例如，随机掷一个骰子，得到的点数就可以看成一个随机变量X，X 的取值为{1, 2, 3, 4, 5, 6}。如果随机掷两个骰子，整个事件空间Ω 可以由36 个元素组成：Ω = {(i, j)|i = 1, . . . , 6; j = 1, . . . , 6}(D.1)一个随机事件也可以定义多个随机变量。比如在掷两个骰子的随机事件中，可以定义随机变量X 为获得的两个骰子的点数和，也可以定义随机变量Y 为获得的两个骰子的点数差。随机变量X 可以有11 个整数值，而随机变量Y 只有6个。X(i, j) := i + j, x = 2, 3, . . . , 12(D.2)(D.3)Y (i, j) := | i − j |, y = 0, 1, 2, 3, 4, 5.其中i, j 分别为两个骰子的点数。D.2.1.1 离散随机变量如果随机变量X 所可能取的值为有限可列举的，有n 个有限取值{x , · · · , x },1n则称X 为离散随机变量。要了解X 的统计规律，就必须知道它取每种可能值xi 的概率，即P (X = x ) = p(x ), ∀i ∈ [1, n].一般用大写的字母表示一个随机变量，用小字字母表示 该变量的某一个具体的取值。(D.4)iip(x ), · · · , p(x ) 称为离散型随机变量X 的概率分布（Probability Distribution）1n或分布，并且满足Σnp(xi) = 1(D.5)i= 1邱锡鹏：《神经网络与深度学习》https://nndl.github.io/
 4142019 年 4 月 6 日附录 D 概率论p(xi)≥0,∀i ∈ [1, n],(D.6)常见的离散随机变量的概率分布有：伯努利分布 在一次试验中，事件A出现的概率为µ，不出现的概率为1 − µ。若用变量X 表示事件A 出现的次数，则X 的取值为0 和1，其相应的分布为p(x) = µx(1 − µ)(1−x),(D.7)这个分布称为伯努利分布（Bernoulli Distribution）, 又名两点分布或者0-1 分布。二项分布 在n 次伯努利分布中，若以变量X 表示事件A 出现的次数，则X 的取值为{0, · · · , n}，其相应的分布为二项分布（Binomial Distribution）。nkP (X = k) =µk(1 − µ)n−k,k = 1 · · · , n(D.8)nk其中为二项式系数（这就是二项分布的名称的由来），表示从 n个元素中取出k 个元素而不考虑其顺序的组合的总数。数学小知识 | 排列组合排列组合是组合学最基本的概念。排列是指从给定个数的元素中取出指定个数的元素进行排序。组合则是指从给定个数的元素中仅仅取出指定个数的元素，不考虑排序。排列组合的中心问题是研究给定要求的排列和组合可能出现的情况总数。排列的任务是确定n 个不同的元素的排序的可能性。n 个不同的元素可以有n!种不同的排列方式，即n 的阶乘。n!,n × (n − 1) × · · · × 3 × 2 × 1.♣如果从n 个元素中取出k 个元素，这k 个元素的排列总数为n!Pnk , n × (n − 1) × · · · × (n − k + 1) =.(n − k)!从n 个元素中取出k 个元素，这k 个元素可能出现的组合数为,= P k =nkn!Ckn.nk!k!(n − k)!区分排列与组合的关键是“有序”与“无序”。邱锡鹏：《神经网络与深度学习》https://nndl.github.io/
 D.2 事件和概率2019 年 4 月 6 日415D.2.1.2 连续随机变量与离散随机变量不同，一些随机变量X 的取值是不可列举的，由全部实数或者由一部分区间组成，比如X = {x|a ≤ x ≤ b}, −∞ < a < b < ∞则称X 为连续随机变量。连续随机变量的值是不可数及无穷尽的。对于连续随机变量X，它取一个具体值xi 的概率为0，这个离散随机变量截然不同。因此用列举连续随机变量取某个值的概率来描述这种随机变量不但做不到，也毫无意义。连续随机变量X 的概率分布一般用概率密度函数（Probability Density Func-tion，PDF）p(x)来描述。p(x) 为可积函数，并满足∫+∞p(x)dxp(x)=1(D.9)−∞≥0.(D.10)给定概率密度函数p(x)，便可以计算出随机变量落入某一个区间的概率，而p(x) 本身反映了随机变量取落入x 的非常小的邻近区间中的概率大小。常见的连续随机变量的概率分布有：均匀分布 若a, b 为有限数，[a, b] 上的均匀分布（Uniform Distribution）的概率密度函数定义为1( ) =p x,a≤ x ≤b(D.11)b−a, x a或x >b<0正态分布 正态分布（Normal Distribution），又名高斯分布（Gaussian Distri-bution），是自然界最常见的一种分布，并且具有很多良好的性质，在很多领域都有非常重要的影响力，其概率密度函数为(x µ)2−12πσp(x) = √exp −,(D.12)2σ2其中，σ > 0，µ 和 σ 均为常数。若随机变量X 服从一个参数为µ 和 σ 的概率分布，简记为X ∼ N(µ, σ2).(D.13)当µ = 0，σ = 1 时，称为标准正态分布（Standard Normal Distribution）。邱锡鹏：《神经网络与深度学习》https://nndl.github.io/
 4162019 年 4 月 6 日附录 D 概率论图D.1a和D.1b分别显示了均匀分布和正态分布的概率密度函数。110.80.80.60.60.40.200.40.20−3 −2 −10123−3−2−10123(a) 均匀分布(b) 正态分布图 D.1 连续随机变量的密度函数D.2.1.3 累积分布函数对于一个随机变量X ，其累积分布函数（Cumulative Distribution Function，CDF）是随机变量X 的取值小于等于x 的概率。cdf(x) = P (X ≤ x).(D.14)以连续随机变量X 为例，累积分布函数定义为∫xcdf( ) =xp(t) dt,(D.15)−∞其中p(x)为概率密度函数。图D.2给出了标准正态分布的累计分布函数。cdfpdf10.80.60.40.20−3−2−10123图 D.2 标准正态分布的概率密度函数和累计概率分布https://nndl.github.io/邱锡鹏：《神经网络与深度学习》
 D.2 事件和概率2019 年 4 月 6 日417D.2.2 随机向量随机向量是指一组随机变量构成的向量。如果X , X , · · · , X 为 n 个随机12n变量, 那么称[X , X , · · · , X ] 为一个 n 维随机向量。一维随机向量称为随机12n变量。随机向量也分为离散随机向量和连续随机向量。D.2.2.1 离散随机向量离散随机向量的联合概率分布（Joint Probability Distribution）为P (X = x , X = x , · · · , X = x ) = p(x , x , · · · , x ),1122nn12n其中xi ∈ ωi 为变量Xi 的取值，ωi 为变量Xi 的样本空间。和离散随机变量类似，离散随机向量的概率分布满足p(x , x , · · · , x ) ≥ 0,∀x ∈ ω , x ∈ ω , · · · , x ∈ ωn(D.16)(D.17)Σ12ΣnΣ1122n· · ·p(x , x , · · · , x ) = 1.1 2 nx ∈ω x ∈ω2xn∈ωn112多项分布 一个常见的离散向量概率分布为多项分布（Multinomial Distribu-tion）。多项分布是二项分布在随机向量的推广。假设一个袋子中装了很多球，总共有K 个不同的颜色。我们从袋子中取出n 个球。每次取出一个球时，就在袋子中放入一个同样颜色的球。这样保证同一颜色的球在不同试验中被取出的概率是相等的。令X为一个K 维随机向量，每个元素Xk(k = 1, · · · , K) 为取出的n 个球中颜色为k 的球的数量，则X 服从多项分布，其概率分布为n!p(x , . . . , x |µ) =µx · · · µx ,11K(D.18)1x1!· · · xK !KK其中µ = [µ , · · · , µK ]T 分别为每次抽取的球的颜色为1, · · · , K 的概率；x , · · · , xK11Σk=1Kxk= n。为非负整数，并且满足多项分布的概率分布也可以用gamma 函数表示：ΣYKΓ( xk + 1)µx ,kk(x , · · · , x |µ ) = Qkp(D.19)1KΓ(x + 1)kkk=1∫∞tꢀ其中 Γ(ꢀ) =dt 为 gamma 函数。这种表示形式和 Dirichlet 分布类似，− 10exp(t)而 Dirichlet 分布可以作为多项分布的共轭先验。邱锡鹏：《神经网络与深度学习》https://nndl.github.io/
 4182019 年 4 月 6 日附录 D 概率论D.2.2.2 连续随机向量连续随机向量的其联合概率密度函数（Joint Probability Density Function）满足p(x) = p(x , · · · , x ) ≥ 0,(D.20)(D.21)1n∫∫+∞+∞· · ·p(x , · · · , x )dx · · · dx = 1.1 n 1 n−∞−∞多元正态分布 一个常见的连续随机向量分布为多元正态分布（Multivariate Nor-mal Distribution），也称为多元高斯分布（Multivariate Gaussian Distribution）。若n 维随机向量X = [X , . . . , X ]T 服从n 元正态分布，其密度函数为1n112p(x) =exp − (x − µ)TΣ−1(x − µ),(D.22)(2π)n/2|Σ|1/2其中µ 为多元正态分布的均值向量，Σ为多元正态分布的协方差矩阵，|Σ| 表示Σ 的行列式。各项同性高斯分布 如果一个多元高斯分布的协方差矩阵简化为Σ = σ2I，即每一个维随机变量都独立并且方差相同，那么这个多元高斯分布称为各项同性高斯分布（Isotropic Gaussian Distribution）。Dirichlet 分布 一个n 维随机向量X 的 Dirichlet 分布为YΓ(α0)p(x|α) =n x −1,αi(D.23)iΓ(α ) · · · Γ(α )1ni=1其中α = [α1, . . . , αK ]T 为Dirichlet分布的参数。D.2.3 边际分布不失一般性，下面以二维随机向量进行讨论，这些结论在多维时依然成立。对于二维离散随机向量(X, Y )，假设X 取值空间为Ω ，Y 取值空间为Ω 。xy其联合概率分布满足Σ Σp(x, y) ≥ 0,p(xi, yj ) = 1.(D.24)x∈Ωx y∈Ωy对于联合概率分布p(x, y)，我们可以分别对x 和y 进行求和。（1）对于固定的x，Σp(x, y) = P (X = x) = p(x).(D.25)y∈Ωy邱锡鹏：《神经网络与深度学习》https://nndl.github.io/
 D.2 事件和概率2019 年 4 月 6 日419（2）对于固定的y，Σp(x, y) = P (Y = y) = p(y).(D.26)x∈Ωx由离散随机向量(X, Y ) 的联合概率分布，对Y 的所有取值进行求和得到X的概率分布；而对X 的所有取值进行求和得到Y 的概率分布。这里p(x) 和 p(y)就称为p(x, y) 的边际分布（Marginal Distribution）。对于二维连续随机向量(X, Y )，其边际分布为：∫+∞p(x) =p(y) =p(x, y)dyp(x, y)dx(D.27)−∞∫+ ∞(D.28)−∞一个二元正态分布的边际分布仍为正态分布。D.2.4 条件概率分布对于离散随机向量(X, Y )，已知X = x 的条件下，随机变量Y = y 的条件概率（Conditional Probability）为：p(x, y)p(x)p(y|x) = P (Y = y|X = x) =.(D.29)这个公式定义了随机变量Y 关于随机变量X 的条件概率分布（Conditional Prob-ability Distribution），简称条件分布。对于二维连续随机向量(X, Y )，已知X = x 的条件下，随机变量Y = y 的条件概率密度函数（Conditional Probability Density Function）为p(x, y).(D.30)(D.31)p(y|x) =p(x)同理，已知Y = y 的条件下，随机变量X = x 的条件概率密度函数为p(x, y).p(x|y) =p(y)通过公式(D.30) 和 (D.31)，我们可以得到两个条件概率p(y|x) 和 p(x|y) 之间的关系。p(x|y)p(y)p(x)p(y|x) =.(D.32)这个公式称为贝叶斯定理（Bayes’ Theorem），或贝叶斯公式。邱锡鹏：《神经网络与深度学习》https://nndl.github.io/
 4202019 年 4 月 6 日附录 D 概率论D.2.5 独立与条件独立对于两个离散（或连续）随机变量X 和Y ，如果其联合概率（或联合概率密度函数）p(x, y)满足p(x, y) = p(x)p(y),(D.33)则称X 和Y 相互独立（independence），记为X ⊥ Y 。对于三个离散（或连续）随机变量X、Y 和 Z，如果条件概率（或联合概率密度函数）p(x, y| ) 满足p(x, y| ) = P (X = x, Y = y|Z = ) = p(x| )p(y| ), (D.34)则称在给定变量Z 时，X 和Y 条件独立（conditional independence），记为X ⊥⊥ Y |Z。D.2.6 期望和方差期望 对于离散变量X ，其概率分布为p(x ), · · · , p(x )，X 的期望（Expectation）1n或均值定义为ΣnE[X ] =x p(x ).(D.35)(D.36)iii= 1对于连续随机变量X，概率密度函数为p(x)，其期望定义为∫E[X ] = xp(x) dx.R方差 随机变量X 的方差（Variance）用来定义它的概率分布的离散程度，定义为2var(X ) = E X − E[X ].(D.37)√随机变量 X 的方差也称为它的二阶矩。 var(X) 则称为 X 的根方差或标准差。协方差 两个连续随机变量X 和Y 的协方差（Covariance）用来衡量两个随机变量的分布之间的总体变化性，定义为cov(X, Y ) = E X − E[X ] Y − E[Y ],(D.38)协方差经常也用来衡量两个随机变量之间的线性相关性。如果两个随机变量的协方差为0，那么称这两个随机变量是线性不相关。两个随机变量之间没有这里的线性相关和线性代数中的线性相关含义不同。线性相关性，并非表示它们之间独立的，可能存在某种非线性的函数关系。反之，如果X 与Y 是统计独立的，那么它们之间的协方差一定为0。邱锡鹏：《神经网络与深度学习》https://nndl.github.io/
 D.3 随机过程2019 年 4 月 6 日421协方差矩阵 两个m和n维的连续随机向量X和Y，它们的协方差（Covariance）为m × n 的矩阵，定义为Tcov(X, Y) = E X − E[X] Y − E[Y].(D.39)协方差矩阵cov(X, Y) 的第(i, j) 个元素等于随机变量X 和Y 的协方差。两ij个向量变量的协方差cov(X, Y) 与cov(Y, X) 互为转置关系。如果两个随机向量的协方差矩阵为对角阵，那么称这两个随机向量是无关的。单个随机向量X的协方差矩阵定义为cov(X) = cov(X, X).(D.40)D.2.6.1 Jensen 不等式如果X 是随机变量，g 是凸函数，则g (E[X ]) ≤ E [g(X )].(D.41)等式当且仅当 X 是一个常数或g 是线性时成立。D.2.6.2 大数定律大数定律（Law Of Large Numbers）是指n个样本X , · · · , X 是独立同分1n布的，即E[X ] = · · · = E[X ] = µ，那么其均值1n1X = (X¯+ · · · + Xn ),(D.42)(D.43)n1n收敛于期望值µ。X → µforn → ∞¯nD.3 随机过程随机过程（Stochastic Process）是一组随机变量Xt 的集合，其中t 属于一个索引（index）集合ꢀ 。索引集合ꢀ 可以定义在时间域或者空间域，但一般为时间域，以实数或正数表示。当t 为实数时，随机过程为连续随机过程；当t 为整数时，为离散随机过程。日常生活中的很多例子包括股票的波动、语音信号、身高的变化等都可以看作是随机过程。常见的和时间相关的随机过程模型包括贝努力过程、随机游走、马尔可夫过程等。和空间相关的随机过程通常称为随机场（Random Field）。比如一张二维的图片，每个像素点（变量）通过空间的位置进行索引，这些像素就组成了一个随机过程。邱锡鹏：《神经网络与深度学习》https://nndl.github.io/
 4222019 年 4 月 6 日附录 D 概率论D.3.1 马尔可夫过程马尔可夫性质 在随机过程中，马尔可夫性质（Markov Property）是指一个随机过程在给定现在状态及所有过去状态情况下，其未来状态的条件概率分布仅依赖于当前状态。以离散随机过程为例，假设随机变量X , X , · · · , X 构成一个随机01T过程。这些随机变量的所有可能取值的集合被称为状态空间（State Space）。如果Xt+1 对于过去状态的条件概率分布仅是Xt 的一个函数，则P (Xt+1 = xt+1|X0:t = x0:t) = P (Xt+1 = xt+1|X = x ),(D.44)tt其中X0:t 表示变量集合X , X , · · · , X ，x 为在状态空间中的状态序列。01t0:t马尔可夫性质也可以描述为给定当前状态时，将来的状态与过去状态是条件独立的。D.3.1.1 马尔可夫链离散时间的马尔可夫过程也称为马尔可夫链（Markov Chain）。如果一个马尔可夫链的条件概率P (Xt+1 = s |X = s ) = T(s , s ),(D.45)itji j在不同时间都是不变的，即和时间t 无关，则称为时间同质的马尔可夫链（Time-Homogeneous Markov Chains）。如果状态空间是有限的，T (si, sj ) 也可以用一个矩阵T 表示，称为状态转移矩阵（Transition Matrix），其中元素tij 表示状态s 转移到状态s 的概率。ij平稳分布 假设状态空间大小为M ，向量π = [π , · · · , π ]T 为状态空间中的一1MΣi=1个分布，满足0 ≤ πi ≤ 1 和M π= 1。i对于状态转移矩阵为T 的时间同质的马尔可夫链，如果存在一个分布π 满足π = Tπ,(D.46)即分布π 就称为该马尔可夫链的平稳分布（Stationary Distribution）。根据特征向量的定义可知，π 为矩阵T 的（归一化）的对应特征值为1 的特征向量。如果一个马尔可夫链的状态转移矩阵T 满足所有状态可遍历性以及非周期性，那么对于任意一个初始状态分布π(0)，将经过一定时间的状态转移之后，都会收敛到平稳分布，即π = lim TN π(0).(D.47)N → ∞邱锡鹏：《神经网络与深度学习》https://nndl.github.io/
 D.3 随机过程2019 年 4 月 6 日423定理 D.1 – 细致平稳条件（Detailed Balance Condition）： 如果一个马尔科夫链满足π t = π t ,(D.48)i ijj ji则一定会收敛到平稳分布π。细致平稳条件保证了从状态i 转移到状态j 的数量和从状态j转移到状态i 的数量相一致，相互抵消，所以数量不发生改变。细致平稳条件只是马尔科夫链收敛的充分条件，不是必要条件。D.3.2 高斯过程高斯过程（Gaussian Process）也是一种应用广泛的随机过程模型。假设有一组连续随机变量X , X , · · · , X ，如果由这组随机变量构成的任一有限集合01TXt1 ,··· ,tk = [X , · · · , Xt n ]Tt1都服从一个多元正态分布，那么这组随机变量为一个随机过程。高斯过程也可以定义为：如果Xt1,··· ,tn 的任一线性组合都服从一元正态分布，那么这组随机变量为一个随机过程。高斯过程回归 高斯过程回归（Gaussian Process Regression）是利用高斯过程来对一个函数分布进行建模。和机器学习中参数化建模（比如贝叶斯线性回归） 相比，高斯过程是一种非参数模型，可以拟合一个黑盒函数，并给出拟合结果的置信度[Rasmussen, 2004]。假设一个未知函数f (x) 服从高斯过程，且为平滑函数。如果两个样本x1, x2比较接近，那么对应的f (x ), f (x ) 也比较接近。假设从函数f (x) 中采样有限12个样本X = [x , x , · · · , x ]，这N 个点服从一个多元正态分布，12N[f (x ), f (x ), · · · , f (x )]T ∼ N µ(X ), K (X, X ) ,(D.49)12N其中µ(X ) = [µ(x ), µ(x ), · · · , µ(x )]T 是均值向量，K (X, X ) = [k(xi, xj )]N ×N12N是协方差矩阵，k(xi, xj ) 为核函数，可以衡量两个样本的相似度。在高斯过程回归，一个常用的核函数是平方指数（Squared Exponential）函在支持向量机中，平方指数核函数也叫高斯核函数或径向基函数。这里为了避免混数−∥x − x ∥2ijk(x , x ) = exp,(D.50)ij淆，我们称为平方指数核函数。2l2其中l 为超参数。当xi 和xj 越接近，其核函数的值越大，表明f (xi) 和f (xj ) 越相关。邱锡鹏：《神经网络与深度学习》https://nndl.github.io/
 4242019 年 4 月 6 日附录 D 概率论假设f (x) 的一组带噪声的观测值为{(x , y )}N，其中y ∼ N(f (x ), σ2)nnn=1nn为正态分布，σ 为噪声方差。对于一个新的样本点x∗，我们希望预测函数y∗ =f (x )。令y = [y , y , · · · , y ]1 n2∗为已有的观测值，根据高斯过程的假设，[y; y∗] 满足µ(X )K (X, X ) + σ2I K (x∗, X )T y,y∗µ(x∗)K(x∗, X)∗∗k(x , x )∼ N  邱锡鹏：《神经网络与深度学习》https://nndl.github.io/
 D.3 随机过程2019 年 4 月 6 日425,(D.51)其中K(x∗, X) = [k(x∗, x ), · · · , k(x∗, x )]。n1根据上面的联合分布，y∗ 的后验分布为p(y∗|X, y) = N (µˆ, σˆ2),(D.52)其中均值µˆ 和方差σˆ 为µˆ = K (x∗, X )(K (X, X ) + σ2I)−1(y µ( )) + µ(x∗),− X(D.53)(D.54)σˆ2 = k(x∗, x )∗ − K ∗, X K X, X +(x)(()−1K (x∗, Xσ2I) )T .从公式(D.53)可以看出，均值函数µ(x)可以近似地互相抵消。在实际应用中，一般假设µ(x) = 0，均值µˆ 可以将简化为µˆ = K (x∗, X )(K (X, X ) + σ2I)−1y.(D.55)高斯过程回归可以认为是一种有效的贝叶斯优化方法，广泛地应用于机器学习中。邱锡鹏：《神经网络与深度学习》https://nndl.github.io/
 4262019 年2 041 9月年64日月 6 日附录 D 概率论 425E 信息论信息论（Information Theory）是数学、物理、统计、计算机科学等多个学科的交叉领域。信息论是由 Claude Shannon 最早提出的，主要研究信息的量化、存储和通信等方法。这里，“信息”是指一组消息的集合。假设在一个噪声通道上发送消息，我们需要考虑如何对每一个信息进行编码、传输以及解码，使得接收者可以尽可能准确地重构出消息。Claude Shannon，1916 年 4月30日－2001年2月26日），美国数学家、电子工程师和密码学家，被誉为信息论的创始人。在机器学习相关领域，信息论也有着大量的应用。比如特征抽取、统计推断、自然语言处理等。E.1 熵E.1.1 自信息和熵熵（Entropy）最早是物理学的概念，用于表示一个热力学系统的无序程度。 在信息论中，熵用来衡量一个随机事件的不确定性。假设对一个随机变量X（取值集合为X，概率分布为p(x), x ∈ X）进行编码，自信息I(x) 是变量X = x 时的信息量或编码长度，定义为I(x) = − log(p(x)),(E.1)那么随机变量X 的平均编码长度，即熵定义为H(X) = EX [I(x)]= E [− log(p(x))](E.2)(E.3)(E.4)XΣ= −p(x) log p(x),x∈X其中当p(xi) = 0时，我们定义0 log 0 = 0，这与极限一致，limp→0+ p log p = 0。在熵的定义中，对数的底可熵是一个随机变量的平均编码长度，即自信息的数学期望。熵越高，则随机变 以使用2、自然常数e，或是10。量的信息越多；熵越低，则信息越少。如果变量X 当且仅当在x 时p(x) = 1，则熵为0。也就是说，对于一个确定的信息，其熵为0，信息量也为0。如果其概率分布为一个均匀分布，则熵最大。假设一个随机变量X 有三种可能值x , x , x ，不123同概率分布对应的熵如下：邱锡鹏：《神经网络与深度学习》https://nndl.github.io/
 

 4262019 年 4 月 6 日附录 E 信息论邱锡鹏：《神经网络与深度学习》https://nndl.github.io/
 p(x1)p(x2)p(x3)熵100012141432131313log(3)邱锡鹏：《神经网络与深度学习》https://nndl.github.io/
 4282019 年 4 月 6 日附录 E 信息论E.1.2 联合熵和条件熵对于两个离散随机变量X 和Y ，假设X 取值集合为X ；Y 取值集合为Y，其联合概率分布满足为p(x, y)，则X 和Y 的联合熵（Joint Entropy）为Σ ΣH(X, Y ) = −p(x, y) log p(x, y).(E.5)x∈X y∈YX 和Y 的条件熵（Conditional Entropy）为Σ ΣH(X|Y ) = −= −p(x, y) log p(x|y)p(x, y)(E.6)(E.7)x∈X y∈YΣ Σp(x, y) log.p(y)x∈X y∈Y根据其定义，条件熵也可以写为H(X|Y ) = H(X, Y ) − H(Y ).(E.8)E.2 互信息互信息（Mutual Information）是衡量已知一个变量时，另一个变量不确定性的减少程度。两个离散随机变量X 和Y 的互信息定义为Σ Σp(x, y)I(X; Y ) =p(x, y) log p(x) p(y).(E.9)x∈X y∈Y互信息的一个性质为I(X; Y ) = H(X) − H(X|Y )= H(Y ) − H(Y |X).(E.10)(E.11)如果X 和Y 相互独立，即X 不对Y 提供任何信息，反之亦然，因此它们的互信息为零。邱锡鹏：《神经网络与深度学习》https://nndl.github.io/
 E.3 交叉熵和散度2019 年 4 月 6 日427E.3 交叉熵和散度E.3.1 交叉熵对应分布为p(x)的随机变量，熵H(p)表示其最优编码长度。交叉熵（CrossEntropy）是按照概率分布q 的最优编码对真实分布为p 的信息进行编码的长度，定义为H(p, q) = E [− log q(x)](E.12)(E.13)pΣ= −p(x) log q(x).x在给定p 的情况下，如果q 和 p 越接近，交叉熵越小；如果q 和 p 越远，交叉熵就越大。E.3.2 KL 散度KL散度（Kullback-Leibler Divergence），也叫KL距离或相对熵(RelativeEntropy)，是用概率分布q 来近似p 时所造成的信息损失量。KL 散度是按照概率分布q 的最优编码对真实分布为p 的信息进行编码，其平均编码长度H(p, q)和 p 的最优平均编码长度H(p) 之间的差异。对于离散概率分布p 和 q，从q 到 p的KL 散度定义为D (p∥q) = H(p, q) − H(p)(E.14)(E.15)KLΣp(x)q(x)=p(x) log,x其中为了保证连续性，定义0 log 0 = 0, 0 log 0 = 0。0qKL散度可以是衡量两个概率分布之间的距离。KL散度总是非负的，DKL(p∥q) ≥0。只有当p = q 时，DKL(p∥q) = 0。如果两个分布越接近，KL 散度越小；如果两个分布越远，KL 散度就越大。但KL 散度并不是一个真正的度量或距离，一是KL 散度不满足距离的对称性，二是KL 散度不满足距离的三角不等式性质。E.3.3 JS 散度JS 散度（Jensen–Shannon Divergence）是一种对称的衡量两个分布相似度的度量方式，定义为11D (p∥q) = D (p∥m) + DK L (q∥m),(E.16)JSKL22其中m =1 (p + q)。2邱锡鹏：《神经网络与深度学习》https://nndl.github.io/
 4282019 年 4 月 6 日附录 E 信息论JS 散度是KL 散度一种改进。但两种散度有存在一个问题，即如果两个分布 p, q 个分布没有重叠或者重叠非常少时，KL 散度和JS 散度都很难衡量两个分布的距离。E.3.4 Wasserstein 距离Wasserstein距离（Wasserstein Distance）也是用于衡量两个分布之间的距离。对于两个分布q , q ，pth-Wasserstein 距离定义为121pW (q , q ) =infE(x,y)∼γ(x,y)[d(x, y)p],(E.17)p12γ(x,y)∈Γ(q ,q )12其中Γ(q , q ) 是边际分布为q 和 q 的所有可能的联合分布集合，d(x, y) 为 x 和1212y 的距离，比如ℓp 距离等。如果将两个分布看作是两个土堆，联合分布γ(x, y) 看作是从土堆q1 的位置x 到土堆q 的位置y 的搬运土的数量，并有2Σγ(x, y) = q2(y),γ(x, y) = q1(x).(E.18)(E.19)Σxyq 和q 为γ(x, y) 的两个边际分布。12E(x,y)∼γ(x,y)[d(x, y)p] 可以理解为在联合分布 γ(x, y) 下把形状为 q1 的土堆搬运到形状为q2 的土堆所需的工作量，ΣE(x,y)∼γ(x,y)[d(x, y)p] =γ(x, y)d(x, y)p,(E.20)(x,y)其中从土堆q 中的点x 到土堆q 中的点y 的移动土的数量和距离分别为γ(x, y)12和d(x, y)p。因此，Wasserstein距离可以理解为搬运土堆的最小工作量，也称为推土机距离（Earth-Mover’s Distance，EMD）。图E.1给出了两个离散变量分布的Wasserstein 距离示例。图E.1c中同颜色方块表示在分布q1 中为相同位置。邱锡鹏：《神经网络与深度学习》https://nndl.github.io/
 邱锡鹏：《神经网络与深度学习》https://nndl.github.io/
 4302019 年 4 月 6 日附录 E 信息论(a) q1(x)(b) q2(x)(c) q 到 q 最优的运输方案12图 E.1 Wasserstein 距离示例邱锡鹏：《神经网络与深度学习》https://nndl.github.io/
 参考文献2019 年 4 月 6 日429Wasserstein 距离相比KL 散度和JS 散度的优势在于：即使两个分布没有重叠或者重叠非常少，Wasserstein 距离仍然能反映两个分布的远近。对于Rn 空间中的两个高斯分布2nd-Wasserstein 距离为p = N(µ , Σ ) q = N(µ , Σ )和，它们的11221/211D (p∥q) = ∥µ − µ ∥2 + tr Σ + Σ − 2 ΣΣ1Σ.(E.21)22W1221222当两个分布的的方差为0 时，2nd-Wasserstein 距离等价与欧氏距离。参考文献Stephen Boyd and Lieven Vandenberghe.Convex optimization. Cambridge universitypress, 2004.ness Media, 2006.Carl Edward Rasmussen. Gaussian pro-cesses in machine learning. In Advancedlectures on machine learning, pages 63–71.Springer, 2004.Jorge Nocedal and Stephen Wright. Numer-ical optimization. Springer Science & Busi-邱锡鹏：《神经网络与深度学习》https://nndl.github.io/
 

